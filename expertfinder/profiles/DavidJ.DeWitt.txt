prof david dewitt home page nbsp nbsp nbsp search nbsp nbsp nbsp nbsp computer science home page dewitt biography contact nbsp information teaching research graduates professional activities miscellaneous dept nbsp home page david dewitt john morgridge professor research interests database system design implementation evaluation biography david dewitt john morgridge professor computer sciences wisconsin madison professor dewitt received degree colgate degree michigan professor dewitt member national academy engineering named fellow acm received acm sigmod innovations award contributions database systems field published technical papers nbsp computer sciences home feedback content questions send dewitt wisc server technical accessibility issues lab wisc copyright copy board regents wisconsin system 
copyright message function copyright notice alert respect copyrights npermission copy fee part material granted nprovided copies made distr ibuted direct ncommercial advantage copy republish quires fee specific permission acm ieee prof david dewitt home page nbsp nbsp nbsp search nbsp nbsp nbsp nbsp computer science home page dewitt biography contact nbsp information teaching research graduates professional activities miscellaneous dept nbsp home page david dewitt john morgridge professor number selected papers organized research area project additional papers found dblp web site wisconsin database group web site parallel database systems past years implemented parallel database systems nbsp direct nbsp nbsp gamma paradise nbsp nbsp nbsp papers links longer original text nbsp paper presents high-level overview mechanisms today commercial parallel database products parallel database systems future database processing passing fad nbsp gray communications acm june direct direct project ran nbsp operational parallel database systems nbsp versions system built starting pdp ending pdp processors connected megabtit token ring passing messages shared-memory constructed ccd chips direct multiprocessor organization supporting relational data base management systems ieee transactions computers nbsp vol june implementation database machine direct boral friedland jarrell wilkinson ieee transactions software engineering seno november gamma gamma project began january ran late point code broken years patching gave nbsp version gamma operational fall collection vax connected mbit token ring contructed proteon nbsp system ported nbsp nbsp processor nbsp intel ipschyerpcube configured disk processor gamma high performance dataflow database machine gerber graefe heytens kumar muralikrishna nbsp nbsp proceedings vldb conference japan august gamma database machine project ghandeharizadeh schneider hsiao bricker rasmussen ieee transactions knowledge data engineering vol march performance analysis gamma database machine ghandeharizadeh schneider proceedings sigmod conference chicago ill june multiprocessor hash-based join algorithms bob gerber nbsp proceedings vldb conference stockholm sweden august performance evaluation parallel join algorithms shared-nothing multiprocessor environment schneider proceedings sigmod conference portland oregon comparison non-equijoin algorithms naughton schneider proceedings international vldb conference barcelona spain august parallel sorting shared-nothing architecture probabilistic splitting nbsp naughton schneider proceedings parallel distributed information systems conference miami beach florida december practical skew handling parallel joins nbsp naughton schneider seshadri proceedings large data base conference nbsp vancouver august nested loops revisited nbsp naughton burger proceedings international conference parallel nbsp distributed information systems san diego nbsp january tradeoffs processing multi-way join queries hashing multiprocessor database machines schneider proceedings vldb conference nbsp brisbane australia august dynamic memory allocation multiple query workloads mehta proceedings large data base conference nbsp dublin ireland august managing intra-operator parallelism parallel database systems mehta proceedings vldb conference zurich september chained declustering nbsp availability strategy multiprocessor database machines nbsp hsiao proceedings international conference data engineering los angeles february performance study high availability data replication strategies hui-i hsiao proceedings parallel distributed information systems conference miami beach florida december paradise client-server paradise nbsp patel luo proceedings vldb conference chile august building scalable geospatial database system technology implementation evaluation nbsp nbsp naughton patel kabra cast dozens proceedings sigmod conference tucson arizona query pre-execution batching paradise nbsp two-pronged approach efficient processing queries tape-resident data sets nbsp jiebing proceedings international conference scientific statistical database management nbsp olympia washington august processing satellite images tertiary storage nbsp study impact tile size performance jiebing proceedings nasa conference mass storage systems nbsp college park sept partition based spatial merge join jignesh patel nbsp proceedings sigmod conference montreal june benchmarking benchmarking database systems systematic approach nbsp bitton turbyfill proceedings large database conference nbsp october link tar file benchmark queries generator methodology database system performance evaluation boral proceedings sigmod conference june benchmark nbsp carey naughton proceedings sigmod conference washington bucky object relational benchmark nbsp carey naughton asgarian gehrke shah proceedings sigmod conference tucson arizona query optimization exodus optimizer generator graefe proceedings sigmod conference san francisco opt object oriented approach query optimization kabra nbsp vldb journal november object-oriented database systems objects relations decade turmoil nbsp carey invited paper proceedings vldb conference bombay india august shoring persistent applications carey naughton solomon proceedings sigmod conference minneapolis minn benchmark carey naughton proceedings sigmod conference washington quickstore nbsp high performance mapped object store white proceedings sigmod conference nbsp minneapolis minn nbsp nbsp vldb journal nbsp quot sigmod issue vldb journal vol october implementing crash recovery quickstore performance study white proceedings sigmod conference san francisco performance study alternative object faulting pointer swizzling nbsp strategies seth white proceedings large data base conference nbsp vancouver august study alternative workstation-server architectures object oriented database systems futtersack maier velez proceedings vldb conference nbsp brisbane australia august architecture exodus extensible dbms nbsp carey frank graefe richardson shekita muralikrishna proceedings international workshop object oriented database systems nbsp asilomar september exodus extensible dbms project overview carey graefe haight richardson schuh shekita vandenberg nbsp readings object-orient database systems zdonik maier eds morgan-kaufman publ object file management exodus extensible database system carey richardson shekita proceedings vldb conference japan august storage management objects exodus carey richardson shekita object-oriented concepts applications databases nbsp kim lochovsky eds addison-wesley publishing crash recovery client-server exodus nbsp franklin zwilling tan carey proceedings sigmod conference san diego june nbsp nbsp computer sciences home feedback content questions send dewitt wisc server technical accessibility issues lab wisc copyright copy board regents wisconsin system 
prof david dewitt home page nbsp nbsp nbsp search nbsp nbsp nbsp nbsp computer science home page dewitt biography contact nbsp information teaching research graduates professional activities miscellaneous dept nbsp home page david dewitt john morgridge professor contact information office computer sciences statistics bldg e-mail dewitt wisc telephone department mailing address department computer sciences wisconsin-madison west dayton street madison usa nbsp computer sciences home feedback content questions send dewitt wisc server technical accessibility issues lab wisc copyright copy board regents wisconsin system 
prof david dewitt home page nbsp nbsp nbsp search nbsp nbsp nbsp nbsp computer science home page dewitt biography contact nbsp information teaching research graduates professional activities miscellaneous dept nbsp home page david dewitt john morgridge professor current graduate students pedro bizarro kristin lefevre srinath shankar graduates jim baroody haran boral dina bitton kevin wilkinson john mcpherson rakesh agrawal setrag koshafian hong tai choi goetz graefe bob gerber muralikrishna donovan schneider hui-i hsiao shahram ghandeharizadeh dan lieuwen scott vandenberg seth white manish mehta craig freedman jignesh patel navin kabra biswadeep nag natassa ailamaki jiebing jianjun chen feng tian leonidas galanis ravi ramamurthy yuan wang kristin tufte pedro bizarro nbsp computer sciences home feedback content questions send dewitt wisc server technical accessibility issues lab wisc copyright copy board regents wisconsin system 
prof david dewitt home page nbsp nbsp nbsp search nbsp nbsp nbsp nbsp computer science home page dewitt biography contact nbsp information teaching research graduates professional activities miscellaneous dept nbsp home page david dewitt john morgridge professor courses teach introduction database systems advanced topics database systems nbsp computer sciences home feedback content questions send dewitt wisc server technical accessibility issues lab wisc copyright copy board regents wisconsin system 
prof david dewitt home page copyright message function copyright notice alert respect copyrights npermission copy fee part material granted nprovided copies made distr ibuted direct ncommercial advantage copy republish quires fee specific permission acm ieee nbsp nbsp nbsp search nbsp nbsp nbsp nbsp computer science home page dewitt biography contact nbsp information teaching research graduates professional activities miscellaneous dept nbsp home page david dewitt john morgridge professor current recent research projects niagara paradise shore nbsp computer sciences home feedback content questions send dewitt wisc server technical accessibility issues lab wisc copyright copy board regents wisconsin system 
prof david dewitt home page nbsp nbsp nbsp search nbsp nbsp nbsp nbsp computer science home page dewitt biography contact nbsp information teaching research graduates professional activities miscellaneous dept nbsp home page david dewitt john morgridge professor miscellaneous link wisconsin database group web site nbsp computer sciences home feedback content questions send dewitt wisc server technical accessibility issues lab wisc copyright copy board regents wisconsin system 
prof david dewitt home page nbsp nbsp nbsp search nbsp nbsp nbsp nbsp computer science home page dewitt biography contact nbsp information teaching research graduates professional activities miscellaneous dept nbsp home page david dewitt john morgridge professor selected professional activities member national academy engineering chair computer sciences department wisconsin national science foundation cise advisor board member member national research council task force availability usefullness nasa space mission data general chair acm sigmod conference member national academy science digital government study panel member national academy science review committee jpl daac member darpa dynamic database study panel member nasa cesdis science council advisor board chairman acm sigmod special interest group parallel processing advisor board member ncr technical advisor board member objectivity program co-chair large data base conference program chair international workshop database machines program chair sigmod conference management data associate editor acm transactions database systems program chair sixth berkeley workshop distributed data management computer networks nbsp computer sciences home feedback content questions send david wisc server technical accessibility issues lab wisc copyright copy board regents wisconsin system 


gamma high performance dataflow database machine david dewitt robert gerber goetz graefe michael heytens krishna kumar muralikrishna computer sciences department wisconsin research partially supported department energy contract de-ac national science foundation grants dcrmcs mcs digital equipment corporation external research grant abstract paper present design implementation techniques initial performance evaluation gamma gamma relational database machine exploits dataflow query processing techniques gamma fully operational prototype consisting vax computers design gamma based learned building earlier multiprocessor database machine prototype direct years subsequent research problems raised direct prototype addition demonstrating parallelism made work database machine context gamma prototype shows parallelism controlled minimal control overhead combination algorithms based hashing pipelining data processes messages initiate operator query tree message operator terminates execution query self-scheduling introduction database machine field active area research years handful research prototypes ozka leil dewi ston hell gard fish kaku demu commercial products tera ubel idm built demonstrated highly parallel relational database machine constructed commercial products successful idm exploit parallelism form easier develop database machine paper turn idea working prototype measured evaluated academic researchers simply sufficient funding develop ideas works ibm endorsed concept database machine limited interest part major computer vendors develop product recent events radically changed commercial outlook database machines research project develop database machine begun ibm almaden research center japanese generation project mura based establishment highly parallel database machine spurred development intelligent database machine project mcc major computer vendors ibm members database program mcc expect number machines emerge years member company begun design highly parallel database machine paper present design gamma relational database machine exploits dataflow query processing techniques gamma fully operational prototype design based learned building earlier multiprocessor database machine prototype direct years subsequent research problems raised direct prototype evaluation direct bitt showed number major flaws design types queries direct performance severely constrained limited bandwidth problem exaggerated fact direct attempted parallelism substitute indexing indices viewpoint bandwidth cpu resources index mechanism avoid searching large piece database answer types queries bandwidth critical resource database machine bora approach direct rumor teradata spent million dollars developing machine conceptually appealing leads disastrous performance bitt major problem direct number control actions messages required control execution parallel algorithms complex relational operations join proportional product sizes input relations message passing implemented shared memory time spent passing handling messages dominated processing time type query felt implementing prototype gamma achieve number important objectives demonstrate parallelism made work database machine context teradata claims accomplished published performance data refused repeated requests benchmark machine numbers published performance delta kaku parallel sort engine kami numbers disappointing sort engine slower commercial sorting package super-minicomputer finally mbds database machine shows promising speedup factors selection operations demu results complex operations objective flexible model prototype provide reliable information performance bottlenecks design finally felt prototype gamma provide powerful research vehicle exploring variety future research directions parallel algorithms processing queries involving recursion remainder paper organized architecture gamma rationale design presented section section describe process structure gamma software discuss processes cooperate execute queries describe mechanism processing complex relational queries dataflow manner mechanism designed implemented requires control messages processor operator query tree initiate operator operator completion controlling scheduler process synchronization messages execution query self-scheduling section describe algorithms techniques implement relational algebra operations section present results preliminary performance evaluation gamma conclusions future research directions section conclusions future research directions paper presented design relational database machine gamma gamma hardware design simple disk drive processor processors interconnected interconnection network initial prototype consists vax processors interconnected megabit token ring processors megabyte disk drive design simple high disk bandwidth requiring unconventional mass storage systems parallel read-out disk drives advantage design permits bandwidth expanded incrementally utilize bandwidth design relations gamma horizontally partitioned disk drives order minimize overhead controlling intraquery parallelism gamma exploits dataflow query processing techniques operator relational query tree executed processes processes scheduler combination processors disk drives control messages beginning operator operator terminates execution data flows processes executing query centralized control preliminary performance evaluation gamma encouraging design linear speedup selection join operations number processors execute operation increased results obtained single processor configuration demonstrated competitive commercially database machine evaluated update operations reason expect similar results completed prototype implemented aggregate operations aggregate functions plan conducting evaluation single multiuser performance system evaluation include complex queries non-uniform distributions attribute values prototype research vehicle intend explore number issues issues include adjustable join parallelism technique load balancing low priority queries effectiveness alternative techniques implementing bit filtering index balancing algorithms effect duplicating root node multiple sites evaluation alternative techniques handling bucket overflows strategies processing complex queries agra agrawal dewitt recovery architectures multiprocessor database machines proceedings sigmod conference austin astr astrahan system relational approach database management acm transactions database systems vol june babb babb implementing relational database means specialized hardware acm transactions database systems vol march baru baru performance evaluation statistical aggregation categorization system proceedings sigmod conference boston june bell bell threaded code communications acm vol june bitt bitton dewitt turbyfill benchmarking database systems systematic approach proceedings large database conference october blas blasgen gray mitoma price convoy phenomenon operating system review vol april bora boral dewitt applying data-flow techniques database machines computer vol august bora boral dewitt database machines idea time passed database machines edited leilich missikoff springer-verlag proceedings international workshop database machines munich brat bratbergsengen kjell hashing methods relational algebra operations proceedings large database conference august brow browne dale leung jenevein parallel multi-stage architecture self-managing disk cache database management applications database machines proceedings international workshop springer verlag edited dewitt boral march chou chou h-t dewitt katz klug design implementation wisconsin storage system wiss software practices experience vol october demu demurjian hsiao menon multi-backend database system performance gains capacity growth hardware upgrade proceedings international conference data engineering feb dewa dewar indirect threaded code communications acm vol june dewi dewitt direct multiprocessor organization supporting relational database management systems ieee transactions computers june dewi dewitt query execution direct proceedings sigmod international conference management data boston mass dewi dewitt katz olken shapiro stonebraker wood implementation techniques main memory database systems proceedings sigmod conference boston june dewi dewitt finkel solomon crystal multicomputer design implementation experience ieee transactions software engineering wisconsin madison computer sciences department technical report september dewi dewitt 
gerber multiprocessor hash-based join algorithms proceedings vldb conference stockholm sweden august ensc enscribe programming manual tandem part tandem computers march fish fishman lai wilkinson overview jasmin database machine proceedings sigmod conference boston june gard gardarin design multiprocessor relational database system proceedings ifip conference paris good goodman investigation multiprocessor structures algorithms database management california berkeley technical report ucb erl hell hell rdbm relational database machine proceedings workshop computer architecture non-numeric processing june heyt heytens gamma query manager gamma internal design documentation december heyt heytens gamma catalog manager gamma internal design documentation december idm idm database server britton-lee jark jarke koch query optimization database system acm computing surveys vol june john johnson thompson database machine architecture performing aggregations tech report ucrl june kaku kakuta miyazaki shibayama yokota murakami design implementation relational database machine delta database machines proceedings international workshop springer verlag edited dewitt boral march kami kamiya hardware pipeline algorithm relational database operations implementation dedicated hardware proceedings sigarch conference boston june kim kim parallel operation magnetic disk storage devices database machines proceedings international workshop springer verlag edited dewitt boral march kits kitsuregawa tanaka moto-oka application hash data base machine architecture generation computing vol kits kitsuregawa tanaka moto-oka architecture performance relational algebra machine grace tokyo technical report leil leilich stiege zeidler search processor database management systems proceedings vldb international conference livn livny khoshafian boral multi-disk management algorithms proceedings international workshop high performance transaction systems pacific grove september mura murakami relational data base machine step knowledge base machine proceedings symposium computer architecture stockholm sweden june ozka ozkarahan schuster smith rap associative processor data base management proc ncc vol afips press montvale prot proteon associates operation maintenance manual pronet model waltham mass ries ries epstein evaluation distribution criteria distributed database systems ucb erl technical report berkeley sale salem garcia-molina disk striping technical report eecs department princeton december seli selinger access path selection relational database management system proceedings sigmod conference boston ston stonebraker michael eugene wong peter kreps design implementation ingres acm transactions database systems vol september ston stonebraker muffin distributed database machine proceedings international conference distributed computing huntsville alabama oct ston stonebraker performance enhancements relational database system acm transactions data systems vol june mikkilineni parallel algorithms implementation micronet proceedings vldb conference mexico city september tand disk storage facility tandem computers tane tanenbaum computer networks prentice-hall tera teradata dbc data base computer concepts facilities teradata corp document ubel ubell intelligent database machine idm query processing database systems edited kim reiner batory springer-verlag vald valduriez gardarin join semi-join algorithms multiprocessor database machine acm transactions database systems vol march wagn wagner indexing design considerations ibm system journal vol dec wats watson timer-based mechanisms reliable transport protocol connection management computer networks 
makefile ustar dewitt dewitt make db-library sample programs makefile change definitions site sybase sybase incdir sybase include libdir sybase lib headers incdir sybfront incdir sybdb dblibs libdir libsybdb include incdir progs wisc dbgen wisc index wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc query wisc util wiscbench progs progs wisc util include wisc util dblibs wisc util wisc util include wisc util wisc dbgen wiscbench wisc index wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc query wiscbench wisc util wiscbench clean progs readme ustar dewitt dewitt directions create database increase size tempdb order avoid filling log checkpointed database set queries closedb wisc util ideally logging turned result tables queries figured edit file wiscbench things edit include verbose flag enables additional debugging output define verbose database created step define database wiscbench names sizes base relations created automatically wisc dbgen define baserelation tenktup define baserelation tenktup define baserelsize names size prime relations size base relations leave names aprime bprime created automatically wisc dbgen define prime aprime define prime bprime define primesize reasonable configuration running tuples base relations minimal small configurations type make wiscbench compile benchmark programs makefile reason remade file changed work stopped reason type wisc run csh run benchmark queries scale automatically size database changed queries indices run indices created indexed queries run output kind messy figured turn garbage sybase likes spit good luck problems sybdbex ustar dewitt dewitt sybdbex header file db-library examples define user user define password server password define language english define sqlbuflen define err stderr define stdout extern void error extern int err handler extern int msg handler wisc dbgen ustar dewitt dewitt include include include include sybdbex include wiscbench wisc dbgen database generator wisconsin benchmark usage wisc dbgen define true define false define buflen program generates standard wisconsin benchmark relations size including million rows relation byte integer attributes byte string attributes integer attributes written binary string attributes written ascii relations created defined file wiscbench baserelation baserelation prime prime sizes baserelation defined constant baserelsize sizes prime defined constant primesize resultant relations loaded sybase database bulk copy utility generator based similiar generator written tal susanne englert tandem computers relations generated program differ slightly early versions specification attribute twenty attribute order facilitate smooth scaling attributes documented relation format ten twenty odd stru stru str attribute descriptions unique unique candidate key values maxtuplesin random order unique unique candidate key values maxtuplesin order correlated twos half tuples half distribution random fours divides relation quarters range distribution random ten tens divides relation tenths range distribution random twenty twenties divides reln twentieths range distribution random values range randomly distributed values range randomly distributed values range randomly distributed values range randomly distributed equal values randomly distributed odd odd values randomly distributed stringu string random candidate key consists significant characters providing unique combinations stringu string candidate key format identical str str varies aaaaaaaxx aaaaaabx aaaaaazx aaaaabax aaaaabzx aaaaacax string string assumes values aaaaxxx hhhhxxx ooooxxx vvvvxxx cyclic manner aaaaxxx hhhhxxx ooooxxx vvvvxxx aaaaxxx hhhhxxx ooooxxx vvvvxxx long prime generator main argc argv int argc char argv char relname char username char passwd char temp char optstring extern char optarg extern int optind opterr int int errflg int tupcount sybase specific variables dbprocess dbproc retcode return code char cmdbuf buflen username passwd null tupcount baserelsize errflg getopt argc argv eof switch case username optarg break case passwd optarg break case errflg errflg fprintf stderr usage relgen username passwd exit fprintf stderr generating wisconsin benchmark table dbname table tuples database relname tupcount fprintf stderr username passwd username passwd step choose prime generator size table values directly tandem benchmark generator dbproc open database username passwd true create load relations create populate baserelation drop table dbproc baserelation delete copy table create table dbproc baserelation tupcount baserelsize initprimegenerator tupcount generate relation dbproc database baserelation tupcount printf number rows inserted row count dbproc create populate baserelation drop table dbproc baserelation delete copy table create table dbproc baserelation tupcount baserelsize initprimegenerator tupcount generate relation dbproc database baserelation tupcount printf number rows inserted row count dbproc create populate prime drop table dbproc prime delete copy table create table dbproc prime tupcount primesize initprimegenerator tupcount generate relation dbproc database prime tupcount printf number rows inserted row count dbproc create populate prime drop table dbproc prime delete copy table create table dbproc prime tupcount primesize initprimegenerator tupcount generate relation dbproc database prime tupcount printf number rows inserted row count dbproc close bulk copy process committed database closedb dbproc exit stdexit generate relation main loop producing data values generate relation dbproc dbname relname tupcount dbprocess dbproc char dbname database char relname relation int tupcount number tuples relation register int register char strptr char uniquechar int outcount int current int long rand long seed generator fields hold tuple attribute values generated dbint unique dbint unique dbint dbint dbint ten dbint twenty dbint onepercent dbint tenpercent dbint twentypercent dbint fiftypercent dbint unique dbint evenonepercent dbint oddonepercent dbchar stringu dbchar stringu dbchar string char temp printf populating relation tuples relname tupcount fill stringu stringu string limit return seed convert convert integer character null termination string convert unique result int unique char result register int char tmp int rem set result string aaaaaaa rem unique result rem unique i-initprimegenerator tupcount int tupcount tupcount include include include sybdbex include wisc index wisconsin benchmark create indexes wisconsin benchmark tables unique clustered unique non-clustered onepercent non-clustered main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr 
int int errflg char query username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case errflg errflg usage exit open database dbproc open database username passwd false create indices printf creating clustered index unique baserelation sprintf query create unique clustered index unique fillfactor baserelation baserelation dbcmd dbproc query form query dbsqlexec dbproc result code dbresults dbproc results continue printf creating clustered index unique baserelation sprintf query create unique clustered index unique fillfactor baserelation baserelation dbcmd dbproc query form query dbsqlexec dbproc result code dbresults dbproc results continue printf creating non-clustered index unique baserelation sprintf query create unique nonclustered index unique fillfactor baserelation baserelation dbcmd dbproc query form query dbsqlexec dbproc result code dbresults dbproc results continue printf creating non-clustered index unique baserelation sprintf query create unique nonclustered index unique fillfactor baserelation baserelation dbcmd dbproc query form query dbsqlexec dbproc result code dbresults dbproc results continue printf creating non-clustered index onepercentd baserelation sprintf query create nonclustered index oneperd onepercentd fillfactor baserelation baserelation dbcmd dbproc query form query dbsqlexec dbproc result code dbresults dbproc results continue printf creating non-cluster index onepercente baserelation sprintf query create nonclustered index onepere onepercente fillfactor baserelation baserelation dbcmd dbproc query form query dbsqlexec dbproc result code dbresults dbproc results continue closedb dbproc exit stdexit usage fprintf stderr nusage wisc index username passwd exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark selection relation query index flag query clustered flag note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int lower upper bounds selection predicate int range range predicate float selfactor selectivity factor int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case indexing index true break case indexing index false break case errflg errflg fprintf stderr specifiy index indexed flag usage exit index fprintf stderr nquery noix select fprintf stderr nquery clusterix select open database dbproc open database username passwd false run query selection set base constants selfactor selectivity factor tupcount baserelsize wiscbench range tupcount selfactor calculate range predicates numtrials totaltime totalrows tupcount sprintf query insert tmp select unique baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime relation create table dbproc tmp create result relation calculate lower upper ranges predicates lower int random tupcount upper lower range upper tupcount sprintf query insert tmp select unique baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime index print result query noix select numtrials totalrows totaltime print result query clusterix select numtrials totalrows totaltime closedb dbproc exit stdexit usage fprintf stderr nusage wisc query username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark selection relation query index flag query clustered flag note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int lower upper bounds selection predicate int range range predicate float selfactor selectivity factor int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case indexing index true break case indexing index false break case errflg errflg fprintf stderr specifiy index indexed flag usage exit index fprintf stderr nquery noix select fprintf stderr nquery clusterix select open database dbproc open database username passwd false run query selection set base constants selfactor selectivity factor tupcount baserelsize wiscbench range tupcount selfactor calculate range predicates numtrials totaltime totalrows tupcount sprintf query insert tmp select unique baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime relation create table dbproc tmp create result relation calculate lower upper ranges predicates lower int random tupcount upper lower range upper tupcount sprintf query insert tmp select unique baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime index print result query noix select numtrials totalrows totaltime print result query clusterix select numtrials totalrows totaltime closedb dbproc exit stdexit usage fprintf stderr nusage wisc query username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc 
query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark selection relation non-clustered index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int lower upper bounds selection predicate int range range predicate float selfactor selectivity factor int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case errflg errflg usage exit fprintf stderr nquery non-clusterix select open database dbproc open database username passwd false run query selection set base constants selfactor selectivity factor tupcount baserelsize wiscbench range tupcount selfactor calculate range predicates numtrials totaltime totalrows tupcount sprintf query insert tmp select unique baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime relation create table dbproc tmp create result relation calculate lower upper ranges predicates lower int random tupcount upper lower range upper tupcount sprintf query insert tmp select unique baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime print result query non-clusterix select numtrials totalrows totaltime closedb dbproc exit stdexit usage fprintf stderr nusage wisc query username passwd fprintf stderr database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark selection relation non-clustered index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int lower upper bounds selection predicate int range range predicate float selfactor selectivity factor int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case errflg errflg usage exit fprintf stderr nquery non-clusterix select open database dbproc open database username passwd false run query selection non-clustered index set base constants selfactor selectivity factor tupcount baserelsize wiscbench range tupcount selfactor calculate range predicates numtrials totaltime totalrows tupcount sprintf query insert tmp select unique baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime relation create table dbproc tmp create result relation calculate lower upper ranges predicates lower int random tupcount upper lower range upper tupcount sprintf query insert tmp select unique baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime print result query non-clusterix select numtrials totalrows totaltime closedb dbproc exit stdexit usage fprintf stderr nusage wisc query username passwd fprintf stderr database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark single tuple selection screen implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int int attrvalue int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case errflg errflg usage exit fprintf stderr nquery tuple select screen open database dbproc open database username passwd false run query tuple selection screen set base constants tupcount baserelsize wiscbench numtrials totaltime totalrows include include include sybdbex include wisc query wisconsin benchmark selection screen implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int int lower upper bounds selection predicate int range range predicate float selfactor selectivity factor int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case errflg errflg usage exit fprintf stderr nquery select screen open database dbproc open database username passwd false run query selection screen set base constants selfactor selectivity factor tupcount baserelsize wiscbench range tupcount selfactor calculate range predicates numtrials totaltime totalrows tupcount sprintf query select unique baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results result code succeed result 
tuples dbproc endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows print trial numtrials trialrows endtime-starttime relation calculate lower upper ranges predicates lower int random tupcount upper lower range upper tupcount sprintf query select unique baserelation lower upper printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results result code succeed result tuples dbproc endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows print trial numtrials trialrows endtime-starttime print result query select screen numtrials totalrows totaltime closedb dbproc exit stdexit usage fprintf stderr nusage wisc query username passwd fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark join selb selection selectivity factor query index flag query clustered flag note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int lower upper bounds selection predicate int range range predicate float selfactor selectivity factor int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case indexing index true break case indexing index false break case errflg errflg fprintf stderr specifiy index indexed flag usage exit index fprintf stderr nquery noix joinaselb fprintf stderr nquery clusterix joinaselb open database dbproc open database username passwd false run query join sel set base constants selfactor selectivity factor tupcount baserelsize wiscbench range tupcount selfactor calculate range predicates numtrials totaltime totalrows tupcount sprintf query insert tmp select unique unique unique baserelation baserelation baserelation baserelation baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime create join temp dbproc tmp calculate lower upper ranges predicates lower int random tupcount upper lower range upper tupcount sprintf query insert tmp select unique unique unique baserelation baserelation baserelation baserelation baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime index print result query noix joinaselb numtrials totalrows totaltime print result query clusterix joinaselb numtrials totalrows totaltime closedb dbproc exit stdexit usage fprintf stderr nusage wisc query username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark join bprime query index flag query clustered flag note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case indexing index true break case indexing index false break case errflg errflg fprintf stderr specifiy index indexed flag usage exit index fprintf stderr nquery noix joinabrime fprintf stderr nquery clusterix joinabrime open database dbproc open database username passwd false run query join bprime set base constants tupcount baserelsize wiscbench numtrials totaltime totalrows username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark join sela selb query index flag query clustered flag note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int range range predicate float selfactor selectivity factor int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case indexing index true break case indexing index false break case errflg errflg fprintf stderr specifiy index indexed flag usage exit index fprintf stderr nquery noix joinaselbselc fprintf stderr nquery clusterix joinaselbselc open database dbproc open database username passwd false run query join sela selb set base constants selfactor selectivity factor tupcount baserelsize wiscbench range tupcount selfactor calculate range predicates numtrials totaltime totalrows username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark join selb clustered index note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int int lower upper bounds 
selection predicate int range range predicate float selfactor selectivity factor int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case errflg errflg usage exit fprintf stderr nquery non-clusterix joinaselb open database dbproc open database username passwd false run query join sel set base constants selfactor selectivity factor tupcount baserelsize wiscbench range tupcount selfactor calculate range predicates numtrials totaltime totalrows tupcount sprintf query insert tmp select unique unique unique baserelation baserelation baserelation baserelation baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime create join temp dbproc tmp calculate lower upper ranges predicates lower int random tupcount upper lower range upper tupcount sprintf query insert tmp select unique unique unique baserelation baserelation baserelation baserelation baserelation lower upper verbose printf query query dbcmd dbproc query form query send command buffer sql server execution starttime time dbsqlexec dbproc result code dbresults dbproc results continue endtime time update running statistics totaltime endtime-starttime trialrows row count dbproc totalrows trialrows drop table dbproc tmp delete result relation print trial numtrials trialrows endtime-starttime print result query non-clusterix joinaselb numtrials totalrows totaltime closedb dbproc exit stdexit usage fprintf stderr nusage wisc query username passwd fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark join bprime non-clustered index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case errflg errflg fprintf stderr specifiy index indexed flag usage exit fprintf stderr nquery clusterix joinabrime open database dbproc open database username passwd false run query join bprime clustered index set base constants tupcount baserelsize wiscbench numtrials totaltime totalrows include include include sybdbex include wisc query wisconsin benchmark join sela selb non-clustered index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int int range range predicate float selfactor selectivity factor int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case errflg errflg fprintf stderr specifiy index indexed flag usage exit fprintf stderr nquery non-clusterix joinaselbselc open database dbproc open database username passwd false run query join sela selb set base constants selfactor selectivity factor tupcount baserelsize wiscbench range tupcount selfactor calculate range predicates numtrials totaltime totalrows include include include sybdbex include wisc query wisconsin benchmark query projection implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case errflg errflg usage exit fprintf stderr query project open database dbproc open database username passwd false run query projection set base constants tupcount baserelsize wiscbench numtrials totaltime totalrows include include include sybdbex include wisc query wisconsin benchmark scalar minimum aggregate query index flag query clustered flag note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case indexing index true break case indexing index false break case errflg errflg fprintf stderr specifiy index indexed flag usage exit index fprintf stderr nquery noix scalar min aggregate fprintf stderr nquery clusterix scalar min aggregate open database dbproc open database username passwd false run query scalar min aggregate set base constants numtrials totaltime totalrows username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark minimum agg partitions query index flag query indexed flag note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user 
passwd passwd optarg break case indexing index true break case indexing index false break case errflg errflg fprintf stderr specifiy index indexed flag usage exit index fprintf stderr nquery noix min agg partitions fprintf stderr nquery clusterix min agg paritions open database dbproc open database username passwd false run query min aggregate partitions set base constants numtrials totaltime totalrows username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark sum agg partitions query index flag query indexed flag note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case indexing index true break case indexing index false break case errflg errflg fprintf stderr specifiy index indexed flag usage exit index fprintf stderr nquery noix sum agg partitions fprintf stderr nquery clusterix sum agg paritions open database dbproc open database username passwd false run query sum aggregate partitions set base constants numtrials totaltime totalrows username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark insert tuple query index flag query indexed flag note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case indexing index true break case indexing index false break case errflg errflg fprintf stderr specifiy index indexed flag usage exit index fprintf stderr nquery noix insert tuple fprintf stderr nquery indexed insert tuple open database dbproc open database username passwd false run query insert tuple set base constants tupcount baserelsize wiscbench numtrials totaltime totalrows username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include wisc query wisconsin benchmark delete tuple query index flag query indexed flag note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case indexing index true break case indexing index false break case errflg errflg fprintf stderr specifiy index indexed flag usage exit index fprintf stderr nquery noix delete tuple fprintf stderr nquery indexed delete tuple open database dbproc open database username passwd false run query delete tuple set base constants tupcount baserelsize wiscbench numtrials totaltime totalrows username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include char malloc wisc query wisconsin benchmark update key attribute query index flag query clustered flag note valid results query run running wisc index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int index int int values int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd passwd optarg break case indexing index true break case indexing index false break case errflg errflg fprintf stderr specifiy index indexed flag usage exit index fprintf stderr nquery noix update key attribute fprintf stderr nquery clusterix update key attribute open database dbproc open database username passwd false run query update key attribute set base constants tupcount baserelsize wiscbench numtrials totaltime totalrows values int malloc selrepeatcnt sizeof int values null printf malloc failed modified tuples selected running timing tests reset attributes original values username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc query ustar dewitt dewitt include include include include sybdbex include char malloc wisc query wisconsin benchmark query update key attribute non-clustered index implemented david dewitt michael franklin copyright david dewitt michael franklin main argc argv char argv sybase specific variables dbprocess dbproc retcode result code hold results dbresults status row code hold results dbnextrow char username char passwd char optstring extern char optarg extern int optind opterr int int errflg int int values int tupcount number tuples relation char query int starttime endtime totaltime int numtrials totalrows trialrows username passwd null errflg process command line arguments getopt argc argv eof switch case user username optarg break case user passwd 
passwd optarg break case errflg errflg fprintf stderr specifiy index indexed flag usage exit fprintf stderr nquery non-clusterix update key attribute open database dbproc open database username passwd false run query update key attribute set base constants tupcount baserelsize wiscbench numtrials totaltime totalrows values int malloc selrepeatcnt sizeof int values null printf malloc failed modified tuples selected running timing tests reset attributes original values username passwd fprintf stderr t-n indices built database fprintf stderr t-i database indexed fprintf stderr t-p show query plan exit wisc run csh ustar dewitt dewitt bin csh set user dewitt note build database complete benchmark index cases run wisc dbgen user run non-indexed cases echo running non-indexed queries wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user run indexed cases echo indexing database date wisc index user echo finished indexing database date date echo running indexed queries wisc query user wisc query user wisc query user wisc query user wisc query user note redirect output query wisc query user query temp wisc query wisc query wisc query wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc query user wisc util ustar dewitt dewitt wisc util utilities wisconsin benchmark implemented david dewitt michael franklin copyright david dewitt michael franklin include include include include sybdbex include include define tmpstrlen include wiscbench loginrec login time time seconds units time struct timeval struct timezone gettimeofday return sec usec setup session initalize locking mode dbms specific things prior running set queries setup session show plan int show plan printf setting granule locks print query plans requested show plan printf show plan implemented printf turning journaling make journaling turned row count return count rows affected query note ingres specific changed based method accessing sqlca dbms int row count dbproc dbprocess dbproc int rowcount rowcount dbcount dbproc return rowcount create table creates standard wiscbench benchmark table create table dbproc tablename tableno dbprocess dbproc char tablename table int tableno type table create char query char type table create table unique int unique int twod int fourd int tend int twentyd int onepercentd int tenpercentd int twentypercentd int fiftypercentd int unique int evenonepercentd int oddonepercentd int stringu char stringu char string char char type table create table unique int unique int twoe int foure int tene int twentye int onepercente int tenpercente int twentypercente int fiftypercente int unique int evenonepercente int oddonepercente int stringu char stringu char string char tableno sprintf query type table tablename dbcmd dbproc query dbsqlexec dbproc dbresults dbproc results continue tableno sprintf query type table tablename dbcmd dbproc query dbsqlexec dbproc dbresults dbproc results continue fprintf stderr error bad table number create sel temp return create join temp create temporary relation join queries create join temp dbproc tablename dbprocess dbproc char tablename char query char jointable create table unique int unique int twod int fourd int tend int twentyd int onepercentd int tenpercentd int twentypercentd int fiftypercentd int unique int evenonepercentd int oddonepercentd int stringu char stringu char string char unique int unique int twoe int foure int tene int twentye int onepercente int tenpercente int twentypercente int fiftypercente int unique int evenonepercente int oddonepercente int stringu char stringu char string char sprintf query jointable tablename dbcmd dbproc query dbsqlexec dbproc dbresults dbproc results continue return create proj temp create temporary relation projection queries create proj temp dbproc table dbprocess dbproc int table table create char type table create table tmp twod int fourd int tend int twentyd int onepercentd int string char char type table create table tmp twoe int foure int tene int twentye int onepercente int string char table dbcmd dbproc type table dbsqlexec dbproc dbresults dbproc results continue table dbcmd dbproc type table dbsqlexec dbproc dbresults dbproc results continue fprintf stderr error bad table number create proj temp return create proj temp create temporary relation projectction queries create proj temp dbproc table dbprocess dbproc int table table create char type table create table tmp twod int fourd int tend int twentyd int onepercentd int tenpercentd int twentypercentd int fiftypercentd int unique int evenonepercentd int oddonepercentd int stringu char stringu char string char char type table create table tmp twoe int foure int tene int twentye int onepercente int tenpercente int twentypercente int fiftypercente int unique int evenonepercente int oddonepercente int stringu char stringu char string char table dbcmd dbproc type table dbsqlexec dbproc dbresults dbproc results continue table dbcmd dbproc type table dbsqlexec dbproc dbresults dbproc results continue fprintf stderr error bad table number create proj temp return create agg temp create temporary relation aggregate queries create agg temp dbproc dbprocess dbproc dbcmd dbproc create table tmp dbcmd dbproc uniqueval int dbsqlexec dbproc dbresults dbproc results continue return drop table drop relation drop table dbproc relname dbprocess dbproc char relname char query sprintf query drop table relname dbcmd dbproc query dbsqlexec dbproc dbresults dbproc results continue return print trial print timing info trial print trial numtrial rowcount totaltime int numtrial rowcount totaltime fprintf stderr ttrial rows elapsed time seconds numtrial rowcount totaltime totaltime return print result print timing info query run print result expname numtrials rowcount totaltime char expname int numtrials rowcount totaltime int avgtime avgtime totaltime numtrials fprintf stderr number trials expname numtrials fprintf stderr ttotal row count avg elapsed time seconds rowcount avgtime avgtime return print tuple print tuple wisconsin benchmark relation print tuple tupptr benchtup tupptr printf tupptrunique tupptrunique tupptrtwo tupptrfour tupptrten tupptrtwenty tupptronepercent tupptrtenpercent tupptrtwentypercent tupptrfiftypercent tupptrunique tupptrevenonepercent tupptroddonepercent tupptrstringu tupptrstringu tupptrstring return result tuple result tuple back database result tuples dbproc dbprocess dbproc benchtup tuple bind program variables table columns dbbind dbproc intbind dbint tuple unique dbbind dbproc intbind dbint tuple unique dbbind dbproc intbind dbint tuple dbbind dbproc intbind dbint tuple dbbind dbproc intbind dbint tuple ten dbbind dbproc intbind dbint 
tuple twenty dbbind dbproc intbind dbint tuple onepercent dbbind dbproc intbind dbint tuple tenpercent dbbind dbproc intbind dbint tuple twentypercent dbbind dbproc intbind dbint tuple fiftypercent dbbind dbproc intbind dbint tuple unique dbbind dbproc intbind dbint tuple evenonepercent dbbind dbproc intbind dbint tuple oddonepercent dbbind dbproc charbind tuple stringu dbbind dbproc charbind tuple stringu dbbind dbproc charbind tuple string dbnextrow dbproc rows print tuple tuple print summary print summary timing info query suite print summary suite total char suite char int total long clock fprintf stderr fprintf stderr wisconsin benchmark suite fprintf stderr total elapsed time queries seconds total total fprintf stderr database print current time date clock time long fprintf stderr benchmark execution completed ctime clock printf open open database dbprocess open dbname username passwd enablebulkcopy char dbname username passwd int enablebulkcopy sybase specific variables dbprocess dbproc retcode return code char temp initialize sybase db-library facility dbinit fail exit errexit install user-supplied error-handling message-handling routines defined bottom source file stolen sybase examples dberrhandle err handler dbmsghandle msg handler login dblogin dbsetluser login username dbsetlpwd login passwd dbsetlapp login dbname enablebulkcopy enable bulk copy connection bcp setl login true connection database dbproc dbopen login null dbprocess null fprintf stderr connect server exit errexit verbose printf connection server successful turn option bulk copy enablebulkcopy dbuse dbproc master sprintf temp execute dboption bulk true dbname dbcmd dbproc temp dbsqlexec dbproc dbresults dbproc results continue dbuse dbproc dbname dbcmd dbproc checkpoint dbsqlexec dbproc dbresults dbproc results continue verbose printf turned bulk copy option dbuse dbproc dbname return dbproc close close database closedb dbproc dbprocess dbproc verbose printf closing database verbose printf checkpoint truncate log dbcmd dbproc checkpoint dbsqlexec dbproc dbresults dbproc results continue dbexit int err handler dbproc severity dberr oserr dberrstr oserrstr dbprocess dbproc int severity int dberr int oserr char dberrstr char oserrstr dbproc null dbdead dbproc return int exit fprintf err db-library error dberrstr oserr dbnoerr fprintf err operating-system error oserrstr return int cancel int msg handler dbproc msgno msgstate severity msgtext srvname procname line dbprocess dbproc dbint msgno int msgstate int severity char msgtext char srvname char procname dbusmallint line fprintf err msg level state msgno severity msgstate strlen srvname fprintf err server srvname strlen procname fprintf err procedure procname line fprintf err line line fprintf err msgtext return wiscbench ustar dewitt dewitt define true define false define verbose database define database wiscbench names sizes base relations define baserelation tenktup define baserelation tenktup define baserelsize names size prime relations size base relations define prime aprime define prime bprime define primesize number times execute type query define selrepeatcnt define projrepeatcnt define aggrepeatcnt define joinrepeatcnt forward declarations sybase error message handlers extern int err handler extern int msg handler extern dbprocess open random number generator long random structure holding result values typedef struct int unique int unique int int int ten int twenty int onepercent int tenpercent int twentypercent int fiftypercent int unique int evenonepercent int oddonepercent char stringu char stringu char string benchtup 
chained declustering availability strategy multiprocssor database machines hui-i hsiao david dewitt computer sciences department wisconsin research partially supported defense advanced research projects agency contract -cby national science foundation grants dcrmcs mcs digital equipment corporation external research grant abstract paper presents strategy increasing availability data multi-processor shared-nothing database machines technique termed chained declustering demonstrated provide superior performance event failures maintaining high degree data availability unlike earlier replication strategies implementation chained declustering requires special hardware minimal modifications existing software introduction number solutions proposed increasing availability reliability computer systems commonly technique involves replication processors mass storage borr jone kast systems step replicating hardware components software modules hardware software module fails redundant software modules continue running application software borr result application programs isolated forms failures database applications availability disk-resident data files major concern approach obtaining high availability replicate data items separate disks attached separate processors borr tera copy fails copy continue copies fail time failure single copy transparent users interruption service occur alternative approach array disks store data redundant error detection correction information parity bytes disk drives kim patt errors discovered redundant information restore data application program continue data minimum interruption advantage approach higher availability performance transactionoriented database applications merit approach disk space redundant information stored potentially higher bandwidth large block transfers identical copy scheme employed tandem teradata systems commercially suitability approach database applications investigation paper focus attention multiprocessor database machines employ sharednothing architecture ston systems processor main memory processors communicate interconnection network disks connected processor traditionally performance computer system measured terms response time throughput multiprocessor system resiliency hardware software failures performance measured operating modes normal mode failed components failure mode processors disks failed normal mode operation application intra inter query parallelism proven successful improving performance database management system software tera dewi livn tand dewi failure occurs balancing workload remaining processors disks difficult nodes processor disk pairs pick workload component failed data placement scheme workload failed node distributed remaining operational nodes system unbalanced response time query degrade significantly thousand nodes failed addition throughput system drastically reduced bottleneck form multiprocessor shared-nothing database machines replicated data application horizontal partitioning declustering techniques ries tera dewi livn facilitates successful application inter intra query parallelism normal mode operation existing availability techniques fully balance workload failures occur paper present declustering technique termed chained declustering managing replicated data technique capable providing high availability addition fully balance workload operational nodes event failure balance workload failure mode static load balancing algorithm designed conjunction chained declustering scheme algorithm predetermines active fragments primary backup copies relation directs data accesses fragments manner fully balance workload modes operation active fragments initially designated time database creation reassigned node failures occur section related research dealing replication presented chained declustering strategy section data placement algorithms operation static load balancing scheme section section comparison availability performance remainder paper focus attention hardware failures ignore software failures assume absence special purpose hardware dual ported disks disk controllers failure processor controlling disks renders data disks unavailable assume relation declustered disks call data replication method fully balanced workload evenly distributed n-i disks disks fail chained declustering strategy existing availability techniques conclusions future research directions contained section related availability strategies section briefly describe existing techniques improving data availability including mirrored disks borr data clustering tera disk arrays redundant check information patt mirrored disk declustering strategies employed tandem teradata maintain identical copies relation bubba cope employs copies relation stores copy combination inverted indices copy remainder file uninverted attributes raid sdi kim employ error correcting techniques rebuild database event disk failure strategies sustain single disk failure resiliency disk failures bubba tandem teradata schemes remaining copy continue primary copy fails raid sdi data remaining disks accessed manipulated satisfy data requests data stored failed drive sections describe tandem mirrored disk scheme teradata data clustering scheme raid data placement scheme additional detail tandem mirrored disks architecture hardware structure tandem system borr consists clusters linked token ring cluster processors multiple disk drives processors cluster interconnected dual high speed mbyte sec bus processor power supply main memory channel disk drive connected controllers controller connected processors providing completely independent paths disk drive disk drive mirrored duplicated insure data availability relations tandem nonstop sql ref system generally declustered multiple disk drives figure shows relation partitioned disks mirrored disk strategy represents i-th horizontal fragment copy stands mirror image shown figure contents disks identical controllercontroller disk disk disk disk figure data placement tandem mirrored disk scheme disks accessed mechanism process-pairs process pair consists cooperating processes execute processors physically connected specific mirror-disk pair processes designated primary process controls disk handles requests process serves backup primary process activated failure occur primary process read operations directed controller drive mirrored-pair write operations directed drives order contents disks identical causing disk arms synchronized ref disk mirrored pair fails remaining disk assume workload failed drive disks mirrored pair fail time data actual impact drive failure performance system depends fraction read write operations ref read operations losing drive result doubling average time disk arm hand write operations impact disk failure minimal impact failure processor significant negative impact performance failure processor figure data disks remain mirrored pair dual ported processor handle accesses disks disks processor repaired fully utilized failure occurs response time queries access data pair drives double system cpu bound teradata data clustering scheme teradata database machine tera processors disk drives attached subdivided clusters cluster processors processor disk drives relations declustered disk drives clusters hashing key attribute tuples relation stored disk termed fragment optionally relation replicated increased availability case copy designated primary copy backup fallback copy fragments primary backup copies termed primary backup fragments primary fragment stored node backup fragments teradata employs special data placement scheme cluster size backup fragment subdivided subfragments subfragments stored disk cluster disk primary fragment processor failure occurs strategy job balancing load mirrored disk scheme workload failed processor distributed processors single processor improvement load balancing cost demonstrate section probability data unavailable increases proportionately size cluster ------- ------- disk disk disk disk cluster disks figure teradata data clustering scheme figure illustrates teradata data replication scheme relation declustered cluster consisting processors disks hashing key attribute produce hash values ranging shown figure tuples 
primary copy hash values disk tuples backup copy hash values stored disks disk drives treated logical drive data unavailable nodes cluster fail stands tuples primary copy partitioning attribute hash backup copy normal mode operation read requests directed fragments primary copy write operations result copies updated event node failure renders fragment primary copy unavailable fragment backup copy promoted primary active fragment data accesses directed raid data storage scheme raid data storage scheme patt gibs array small inexpensive disks single storage unit termed group replicating data drives strategy stores check parity bytes recovering random single byte failures single disk failures scheme interleaves stripes data block units disk sector multiple disk drives sectors single block accessed parallel resulting significant increase data transfer rate figure illustrates data placement raid group disks represents j-th sector i-th data block check byte sector block basically formed computing xor byte wise data sectors block illustrated shaded sectors figure check byte sectors raid group distributed evenly disk drives disks failed reading sector block requires access single disk writing sector hand requires disk accesses read write sector updated read write check sector block disk failure occurs disk raid group accessed time access attempted sector inoperative disk drive recovering byte sector failed drive proceeds bytes sectors block check sector xor resulting byte compared bitwise byte check sector block bits match failed bit patt presents levels raid scheme level raid end-of-fragment parity byte level raid sdi kim data checks disks block block block block block block figure data placement raid rectangle represents physical sector potential concern raid scheme inherent reliability large numbers disks connected form single system increased number disks support hardware cables controllers increase probability component failure turn increases probability unavailable data concern supported results schu -disk raid system probability data unavailable result non-media failure shown factor higher media failures considered chained declustering strategy techniques presented previous section significantly improves probability data remaining event failure significant limitations mirrored disk drives offers highest level availability shown section poor job distributing load failed processor teradata scheme tradeoff availability performance event failure cluster size increased probability failures rendering data unavailable increases imbalance workloads processors event failure decreases raid emphasizes importance disk space performance section describe data replication technique termed chained declustering offers high availability excellent load balancing event failure chained declustering identical copy based scheme require disk space raid strategy discussion assume processor single disk attached term node represent processordisk pair data placement algorithm chained declustering chained declustering strategy nodes divided disjoint groups called relation-clusters tuples relation database declustered disk drives relation cluster chained declustering strategy maintains physical copies relation copy termed primary copy declustered disks relation-cluster gamma partitioning strategies hashed range round-robin dewi copy termed backup copy declustered partitioning strategy fragments copies stored nodes fragments distributed disks algorithm assume total disks numbered relation i-th fragment primary copy stored mod -th disk drive fragment backup copy stored mod -th disk drive insuring primary backup fragments disk drives function devised fragment relation disk relationcluster data replication method chained declustering disks linked fragments relation chain figure illustrates data placement scheme chained declustering size relation-cluster stand i-th fragment primary backup copy figure identical data systems disks reasonable relation-cluster disks system systems large number disks generally practical decluster relation drives overhead initiating committing transactions generally overshadow benefits obtained parallelism smith sigmod ref situation set disks generalized formula mod greatest common divisor gcd equal data placement chained declustering node primary copy backup copy figure replicated data placement chained declustering scheme divided groups group form relation-cluster data placement algorithm previously modified adapt change adding term represent starting disk number relationcluster addition number disks relation-cluster large disks disks relation-cluster divided smaller groups termed chain-clusters unit load balancing event node failure data placement algorithm earlier modified accommodate grouping mechanism summary chained declustering algorithm declusters relation disks total disks chains groups disks special cases chained declustering similar demonstrated higher data availability teradata cluster scheme figure illustrates data placement chained declustering scheme shown figure fragments chained disks fragments chained disks disk disk disk disk disk disk disk disk figure i-th fragments primary backup copy availability load balancing current disk technology time failure disk drive years assume failures independent failure rates exponentially distributed years time repair replace disk restore contents hours pair disks probability disks failing time form probability disks failing time failure disks time data unavailable data unavailable years months days chained declustering relation unavailable logically adjacent disks chain-cluster fail simultaneously disk fails replaced probability data unavailable result relation declustered disks chained declustering strategy data unavailable years days unique capability chained declustering scheme balance workload disk drives normal failure modes operation figure illustrates idea workload balanced event node processor disk failure fragments primary copy initially designated active fragments i-th fragments primary copy backup copy relation part figure node fails workload shifted backup node case active fragments relation dynamically reassigned workload uniformly distributed remaining nodes illustrated part figure workload node increased active fragments rearranged workload node increased shown parts iii figure fraction primary backup fragments node responsible varies depending node failed exponential distribution important property memoryless property considers disk failures failures components unavailability included probability unavailable data higher case node responsible work load increased analysis assumes workload uniformly distributed nodes failure occurred node primary fragments backup fragments relation distributed chained declustering scheme primary fragments active fragments node active ---ruru ruru ruru ruru ruru ruru fragments relation ruru ---r ruru ruru ruru ruru ruru reassignment active fragments node fails node active ruru ruru ruru --ruru ruru ruru fragments relation ruru ruru ruru ruru --r ruru ruru iii reassignment active fragments node fails figure assignment active fragments node failure makes scheme attractive reassignment active fragments incurs disk data movement bound values pointers indices memory resident control table changed process quickly efficiently queries exhibit uniform access pattern chained declustering scheme dynamic load balancing moving physically stored data data fragments chained work node easily reassigned neighbors technique dynamic load balancing investigation discussed paper load balancing algorithms chained declustering shown figure simplified view chained declustering mechanism balances workload event node failure reality queries simply access arbitrary fraction data fragment data 
clustered attribute values indices exist query optimizers generate access plans gamma dewi user declustering alternatives range hash round-robin partitioning partitioning alternatives ruru fragment node fraction responsibility i-th fragment node gamma supports storage organizations relation clustered index partitioning attribute clustered index non-partitioning attribute non-clustered index partitioning attribute non-clustered index non-partitioning attribute heap index addition alternative access plans generated gamma query optimizer processing tuples utilize clustered index utilize non-clustered index sequential file scan problem design load balancing algorithm chained declustering mechanism handles combinations partitioning methods storage organizations access plans keys solution notion responsible range indexed attributes query modification techniques ston availability extent map relations stored heap sections describe techniques detail illustrate responsible range extent map indexed attribute term range values node responsible responsible range attribute responsible range responsible range fragment represented interval attribute values stored table termed active fragment table maintained query scheduler formulas compute responsible range relation indexed attributes node fails node responsible range attribute primary fragment mod responsible range attribute backup fragment mod total number nodes relation-cluster correspond lower upper bound values attribute fragment ruru assuming fragments relation local storage organization node fails responsible range node attribute primary fragment ruru relation stored heap fragment logically divided extents physical disk address page extent stored table termed extent map responsible ranges extents fragments indices marked extent numbers extents responsible range node fragment determined formulas primary fragments extents backup fragments extents i-th extent fragment functions previously defined figure illustrates structure extent map shown figure extent map fragment relation node array records record fields addresses pages extent sectors fragment uniformly distributed extents j-th extent consist sectors rurururururu rurururururu total number sectors occupied fragment node figure illustrates responsible extents node node failure relation stored heap normal mode operation primary fragments designated active fragments responsible ranges set range indexed attribute extents number nodes relation cluster node failure occurs responsible ranges active fragments tailtailtail headheadhead sector extent extent extent sector sector sector sector sector figure extent map active fragment node fragment responsible extents extents extents extents extents failure --- --- --- responsible extents extents extent extent extents extents extents node failed failed --- figure active fragment table relation stored heap reassigned event active fragments consist primary backup fragments operational nodes reassignment responsible ranges event node failure sizes active fragments remaining nodes relation-cluster increased rururururu turn increase workload active nodes relation-cluster rururururu queries exhibit uniform access pattern nodes queries exhibit non-uniform access pattern functions defined easily modified capture skewed data access pattern section illustrated responsible ranges active fragments determined marked section show information query scheduler modify process queries event node failure load balancing algorithm order insure active fragments accessed failure occurs queries modified local nodes processing indexed relations query modification techniques technique modifies range selection predicate reflect responsible range node sending query node technique index retrieve qualifying tuples query modification technique adds selection predicate query based responsible range attribute clustered index exists technique sequential file scan selected query optimizer query modification techniques applied indexed relations relations stored heap technique needed ensure fragments primary backup copies chain-cluster relation cluster divided chain-clusters accessed situation extent map section algorithm changing selection predicate selection queries index qualified attribute retrieve qualifying tuples load balancing algorithm employs query modification techniques query scheduler computes intersection range selection predicate responsible range node intersection ranges non-empty query modified intersection range modified query node exact match selection query treated special case range queries range selection predicate single point algorithm adding selection predicate suitable index query processed sequentially scanning active fragments data moved active fragments reassigned node fails distinguish active passive fragments primary backup copies local node range attribute clustered index assuming clustered index exists attribute load balancing algorithm works active fragment node fetch responsible range attribute selection predicate attribute current responsible range fragment appended original query query node receiving query node retrieves tuples sequentially tuples fragment sorted attribute values algorithm extent map relations stored heap retrieve tuples sequential file scan active fragment table extent map section determining responsible ranges extents active fragments event node failure condition queries processed manner type query addresses pages extent stored extent map node perform sequential scan extent receiving query query scheduler node sequentially retrieve tuples extents normal mode operation node access extents primary fragment case node failure active fragments consist primary backup fragments extents fragments processed retrieval process node completed tuples responsible range accessed examples applications load balancing algorithms illustrate operation load balancing algorithm assume relation attributes horizontally partitioned chained declustering strategy partitioning attribute attributes values ranging assume loss generality nodes system relation-cluster chain-cluster consist nodes node failed examples subscript fragment backup copy relation processed range variable subscript primary fragment relation examples show load balancing algorithms previous section node fails clustered index range partitioning attribute retrieve qualified tuples assume relation range partitioned attribute clustered index constructed primary backup fragments relation local node disjoint sets attribute values figure illustrates assignment responsible ranges active fragments attribute failure node active fragment node fragment responsible ranges ----- ----- backup ranges ----- ----- brbr brbr brbr brbr node failure active fragment node fragment responsible range failed failure node figure active fragment table attribute exact match selection queries attribute constant access plan clustered index access relation run-time query scheduler active fragment table direct query node execution active fragment responsible range assignment figure queries predicates directed nodes normal mode operation directed nodes event node failed case range queries attribute node failed query scheduler modify ranges query sending query nodes active fragments stored algorithm section employed figure illustrates query modified failure node figure range query responsible range nodes figure intersection query range node responsible range original query modified node query modification process node similar fashion node intersection query range responsible range empty query original modified version nodes modified query applied active fragments stored site retrieve retrieve original query iii modified query node retrieve node responsible query modified query node figure query modification non-clustered index non-partitioning attribute retrieve qualified tuples simplify explanation original query actual implementation algorithm modify query execution plan generated query optimizer special case means fragments relation disjoint ordered local node index clustered trees fragments joined form single tree assume 
non-clustered index constructed attribute attribute values ranging figure depicts responsible range remaining nodes node failed fragments range values reassignment responsible range nodes equal full range attribute values query active nodes processing site responsible ranges primary fragment backup fragment vary depending node failed range selection queries attribute access plan non-clustered index query scheduler algorithm section modify query nodes processing figure illustrates range query modified failure node query unmodified node query range subrange node responsible range primary fragment intersection query range node responsible range backup fragment empty node query range subrange responsible range primary fragment intersection query range responsible range backup fragment non-empty result query modified include intersections node query modification node similar fashion shown subscript serves inform node fragment backup copy relation processed active fragment node fragment responsible ranges ----- ----- backup ranges ----- ----- brbr brbr brbr brbr node failure active fragment node fragment responsible ranges failed failure node figure active fragment table indexed attribute relation partitioned retrieve retrieve original query iii modified query node retrieve retrieve original query node modified query node figure query modification range queries non-partitioning attribute clustered index hash partitioning attribute retrieve qualified tuples assume relation hash partitioned attribute clustered index constructed hashed partitioning strategy tuple loaded database hash function applied partitioning attribute resulting select storage unit hash function gamma generates -bit hash values applied partitioning attribute tuple hash divided number storage units remainder select storage unit store tuple quotient values ranging max max rurururururu determine responsible range fragment case responsible range active node consists values hash attribute actual attribute hash attribute query scheduler select responsible node exact match selection queries actual processing range queries file scans normal mode operation primary fragments designated active fragments responsible range set responsible ranges set max primary fragments failure occurs responsible ranges recomputed fragment formulas section recomputing responsible range substituted max substituted figure illustrates assignment responsible ranges node failure assume nodes node failed attribute values ranging purposes assume hash function generates -bit hash max rurururururu simplicity range fragments practice fragments slightly ranges subrange exact match selection queries attribute query directed single node processed clustered index query scheduler applies hash function constant selection predicate outcome divided generate quotient remainder qualified tuple stored select primary backup fragment responsible range equal equal rurururururu equal mod qualified tuple fragment tuples hashed stored -th fragment fragment stored nodes primary copy stored node backup copy stored node select node comparing responsible ranges nodes fragment figure part node responsible range fragment max query node processing receiving query local node clustered index retrieve qualified tuple active fragment node fragment responsible ranges ----- ----- responsible ranges --q --q --q --ululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululbr node failure rurururururu active fragment node fragment responsible ranges failed responsible ranges failed failure node figure assignment responsible ranges hash partitioning attribute fragment stored node backup copy query modified node summary idea algorithm section process queries set active fragments initially designated relation created reassigned node failures occur relation queries active fragments union active fragments process query guaranteed correspond complete copy relation query query scheduler selects responsible node based current assignment active fragments node retrieves tuples responsible range table summarizes operation load balancing algorithm combinations partitioning methods storage organizations access plans range partitioning clustered clustered index clustered index non-clustered index file scan hash partitioning clustered index non-clustered index file scan round robin clustered index non-clustered index file scan table summary load balancing algorithm partitioning attribute modify query range based intersection responsible range original selection predicate query append range selection predicate attribute clustered index extent map send queries active nodes relation-cluster send queries limited nodes select nodes based qualified attribute select node based responsible range exact match queries applicable availability performance availability improved data replication performance improved declustering parallelism straightforward task simultaneously achieve objectives event processor disk failures tension objectives illustrated figures extracted tera figure illustrates system nodes cluster size increased processors time cluster failures mttf decreases dramatically words increase cluster size reduces probability data hand figure demonstrates larger cluster sizes beneficial effect reducing increase workload remaining processors node cluster fails demonstrate chained declustering resolve conficts probability data unavailable result nodes failing chained declustering independent cluster size mttf cluster size number nodes disks years figure time cluster failures failed nodes cluster size cluster size shown mttf defined disks nodes cluster time cluster size number nodes disks load factor figure excess load cluster node fails cluster size availability purpose availability performance comparisons made assumptions relation distributed disks size chain-cluster cluster size teradata scheme group size raid number ways disk disks fail number ways disk failure failure result data unavailable number combinations selecting disks depends data placement scheme teradata clustering scheme failure cluster data unavailable case raid similar failure raid group failed disk data unavailable mirrored disks failure data unavailable mirror image failed disk fails disk mirror image chained declustering data unavailable logically adjacent disks fail disks neighbors number ways happen equal total number events failure disks data unavailable system disks scheme schemes considered paper respective values chained mirrored teradata raid probability data unavailable equal multiplied probability disks failing time scheme scheme analysis mirrored disk scheme highest degree data availability chained declustering technique schemes constant fixed contrast teradata clustering scheme varies significantly depending cluster size teradata scheme probability data unavailable higher chained declustering scheme higher raid availability teradata scheme group size equal cluster size teradata suggests customers select cluster size order achieve reasonable balance performance availability raid assumes design analysis raid times data unavailable mirrored disks times chained declustering load balancing performance mirrored disk scheme highest degree data availability major drawback balance workload node fails assume files stored mirrored disk pairs attached processors processor fails access files directed mirrored pair workload remaining processor double contrast chained declustering scheme evenly distribute workload remaining nodes node fails recall earlier node fails workload backup node increase ruru event node failure teradata clustering scheme limited load balancing depending cluster size order improve load balancing larger cluster size teradata scheme pay price higher probability data unavailable hand order reduce probability unavailable data smaller cluster size load balancing event node failure poorer raid data placement scheme system restricted disk 
recovery group disks access data failed disk repaired replaced true remaining disks group read order regenerate bad sector addition reconstruct failed disk sectors check data sectors disks group read manipulated exclusive-or -ed byte byte reconstructing process compete normal processes cpu bandwidth system performance terms throughput response time degrad significantly reconstruction period disks system disk fail hours disks employed raid system group undergo reconstruction day summary table summarized probability data availabile impact processor failure workload remaining processors schemes chained mirrored raid data teradata declustering disks placement probability data unavailable load increase rururururu rururururu remaining probability data unavailable load increase remaining andn probability data unavailable load increase remaining andn probability data unavailable load increase remaining nodes table summary availability load balancing data placement schemes accesses sectors failed disk slow remaining disks failed group accessed order regenerate requested data conclusions future research directions paper introduced declustering technique termed chained declustering distributing replicated data shared-nothing multiprocessor database machine chained declustering shown provide high degree availability tandem mirrored disk approach current disk technology makes simultaneous failure disks large database machine configurations failures occur occasionally major contribution chained declustering robustness respect simultaneous node processor disk failures ability chained declustering equally balance workload remaining processors failure occurs teradata replication technique uniformly distribute workload event failure nodes teradata cluster fail data cluster chained declustering data unavailable logically adjacent drives fail event teradata load balancing mechanism handle relations hash-partitioned mechanisms developed chain declustering handle combinations partitioning mechanisms access methods provided gamma mirrored disk teradata strategies chained declustering relies identical copies relation techniques raid requires half disk space cost disks accounts small fraction total system expense performance advantage provided chained declustering event failures compensate increased consumption disk space arena highly high performance systems analysis paper assumes processor responsible disk issue addressed results obtained significantly disk connected processor respect availability answer data depends decided data placement scheme disk connected processor original affect availability load balancing hand multiple disks connected processor reduce relative increase workload remaining processors event disk processor failure absolute increase workload remaining processors increased considers workload disk disk queue length result remain future intend conduct detailed performance study chained declustering mechanism issues intend investigate impact single node failure query types overhead query modification maintenance active fragment table extent maps chained declustering impact performance update copies relation anon anon measure transaction processing power tandem computer cupertino raid bitt bitton gray disk shadowing proceedings vldb los angeles august borr borr transaction monitoring encompass reliable distributed transaction processing proceedings vldb care carey livny dynamic task allocation distributed database system proceedings international conference distributed computer systems denver care carey load balancing locally distributed database system proceedings acm-sigmod international conference management data cope copeland alexander boughter keller data placement bubba proceedings acm-sigmod international conference management data chicago dewi dewitt gerber graefe heytens kumar muralikrishna gamma-a high performance dataflow database machine proceedings vldb conference japan august dewit dewitt ghandeharizadeh schneider performance analysis gamma database machine proceedings acm-sigmod international conference management data chicago eage eager lazowska zahorjan adaptive load sharing homogeneous distributed systems ieee transactions software engineering vol seno gibs gibson hellerstein karp katz patterson failure correction techniques large disk arrays proceedings asplos iii boston march gray gray notes database operating systems operating systems advanced vol lecture notes computer science springer-verlag york jone jones synapse approach high system database availability database engineering vol june kast kastner fault-tolerant transaction processing environment database engineering vol june katz katzman fault-tolerant computing system proceedings hawaii conference system sciences january kim kim synchronized disk interleaving ieee transactions computers vol november lind lindsay seilinger galtieri gray lorie price putzulo traiger wade notes distributed databases distributed databases drattan poole eds cambridge press york livn livny melman load balancing homogeneous broadcast distributed systems proceedings acm computer network performance symposium april livn livny khoshafian boral multi-disk management proceedings acm sigmetrics conference alberta canada patt patterson gibson katz case redundant arrays inexpensive disks raid proceedings acm-sigmod international conference management data chicago ries ries epstein evaluation distribution criteria distributed database systems ucb erl technical report berkeley sale salem garcia-molina disk striping eecs princeton princeton december schu schulze gibson katz patterson reliable raid unpublished technical report ston stonebraker implementation integrity constraints views query modification proceedings sigmod workshop management data san jose calif ston stonebraker case shared database engineering vol tand tandem database group nonstop sql distributed high-performance high-reliability implementation sql workshop high performance transaction systems asilomar sep tera teradata dbc database computer system manual release document teradata corp nov 
performance study high availability data replication strategies hui-i hsiao ibm watson research center yorktown heights david dewitt computer sciences department wisconsin madison research partially supported defense advanced research projects agency contract -cby national science foundation grants dcrby digital equipment corporation external research grant research grant tandem computer corporation work author wisconsin abstract data replication strategies proposed provide high data availability database system applications tradeoffs strategies workloads operating modes understood paper study relative performance high availability data replication strategies chained declustering mirrored disks interleaved declustering shared database machine environment issues examined relative performance strategies failures occurred effect single node failure system throughput response time performance impact varying cpu speed disk page size replication strategies tradeoff benefit intra query parallelism overhead activating scheduling extra operator processes experimental results obtained simulation study normal mode operation chained declustering interleaved declustering perform comparably perform mirrored disks application bound due disk scheduling slightly worse mirrored disks application cpu bound event disk failure chained declustering balance workload noticeably performance interleaved declustering performance mirrored disks introduction motivation number solutions proposed increasing availability reliability computer systems commonly technique involves replication processors mass storage borr database applications availability disk-resident data files major concern database management systems employ combination disk-based log periodic checkpointing memoryresident data insure integrity availability database event disk system failures techniques satisfy availability requirements database applications recovery time event media failure intolerably long fact recovery period data unavailable achieve high degree data availability basic techniques multiple copies data item stored disks attached separate processors copy fails copy continue copies fail simultaneously failure transparent users system interruption service occur examples mechanism include mirrored disks katz bitt interleaved declustering tera inverted file strategy cope chained declustering hsia approach data redundant error detection correction information parity bytes spread array disk drives errors discovered redundant information restore data application programs continue data minimal interruption strategies based approach include synchronized disk interleaving kim redundant array inexpensive disks raid patt parity striping disk arrays gray approaches commercial systems tandem nonstop sql database machine teradata dbc database machine employ identical copies ibm system disk array approaches choice database applications tradeoffs approaches captured factors performance availability cost traditionally performance computer system measured terms response time throughput multiprocessor system resiliency hardware software failures performance measured operating modes normal mode failed components failure mode processors disks failed operating failures gray examples applications stock market trading air defense systems air traffic control systems airline reservation-type systems banking oltp demonstrates mirrored disks identical copy based strategy performance raid oltp applications chen demonstrates small requests track data mirrored disk mechanism higher disk throughput mbbyte sec disk raid requests database applications transfer track data results identical copy mechanisms generally provide superior performance database applications failure mode operation conclusion holds remaining copy continue interruption service copy fails service degradation users application programs hand disk array query access data failed disk copy data reconstructed fly process requires accessing remaining disks array order satisfy single disk request cases failed disk array restricted serve request time performance degrade significantly availability system data file greatly influenced data files disks hsia time needed recover restore failed disk node longer recovery time higher probability failure render data unavailable identical copy approach data copied intact disk disk broken disk repaired replaced process easily quickly vulnerable window failure result loss data availability shortened disk array approach hand disk pages failed array read processed order rebuild data originally stored failed drive process longer simply copying disk failures occur systems employing disk array remain failure mode longer possibility failure occurring failure fixed higher result probability data unavailable higher disk array approach hand disk array approach attractive cost disk space major concern paper focus multiprocessor database systems employ shared-nothing architecture ston systems application horizontal partitioning declustering techniques ries tera dewi livn facilitates successful application interand intra-query parallelism normal mode operation tand dewi failure occurs balancing workload remaining processors disks difficult nodes processor disk pairs assume workload component failed data placement scheme workload addition pages read disks xor reconstruct failed data assume absence special purpose hardware dual ported disks disk controllers failure processor controlling disks renders data disks unavailable failed node distributed remaining operational nodes system unbalanced response time query degrade significantly hundred nodes failed addition throughput system drastically reduced bottleneck form paper simulation model study performance identical copy based high availability schemes chained declustering mirrored disks interleaved declustering simulation model based software hardware architectures gamma database machine dewi simulation model performance data replication strategies evaluated number workload assumptions issues examined relative performance mechanisms failures occurred effect single node failure system throughput response time performance impact varying cpu speed disk page size replication strategies tradeoff benefit intra-query parallelism overhead activating scheduling extra operator processes organization rest paper section high availability strategies presented simulation model section results simulation experiments presented analyzed section conclusions future research directions contained section existing high availability strategies section briefly describe data replication schemes studied paper mirrored disks borr bitt interleaved declustering tera cope chained declustering hsia scheme stores identical copies relation disks sustain single node disk processor failure tandem mirrored disks architecture tandem nonstop sql system tand disk drive connected controllers controller connected processors providing completely independent paths disk drive disk drive mirrored duplicated ensure data availability relations generally declustered multiple disk drives figure shows relation partitioned disks represents i-th horizontal fragment copy stands mirror image shown figure contents disks identical read operations directed controller drive write operations directed drives order contents disks identical causing disk arms synchronized writes bitt medium file grn fig tan figure data placement tandem mirrored disk scheme disk mirrored pair fails remaining disk assume workload failed drive disks fail simultaneously data actual impact failure performance system depends fraction read write operations reads losing drive result doubling average time disk arm hand write operations impact failure minimal bitt failure processor significant negative impact performance failure processor figure data disks remain processor handle accesses disks disks repaired fully utilized failure occurs response time queries access data pair drives double system cpu bound teradata interleaved declustering scheme teradata database machine tera processors divided clusters processors disk drives attached processor 
tuples relation declustered drives clusters hashing key attribute tuples relation stored disk termed fragment optionally relation replicated case copy designated primary copy backup copy tuples primary fragment stored node backup fragments teradata employs special data placement scheme termed interleaved declustering tera cope cluster size backup fragment subdivided subfragments stored disk cluster disk primary fragment figure relation declustered disk drives represents i-th primary fragment represents j-th subfragment backup fragment node failure occurs interleaved declustering job balancing load mirrored disk scheme workload failed node distributed nodes improvement load balancing penalty probability data unavailable increases proportionately size cluster hsia normal mode operation read requests directed fragments primary copy write operations update copies event cpu disk failure renders fragment primary copy unavailable fragment backup copy promoted primary active fragment data accesses directed center expand csss csss cccc cccc cluster cluster node primary copy backup copy figure interleaved declustering cluster size chained declustering chained declustering hsia physical copies primary backup relation declustered set disks primary backup copies fragment nodes nodes divided disjoint groups called relation-clusters tuples relation declustered drives form relation-clusters optionally disks relation-cluster sub-divided smaller groups termed chain-clusters small system consist relation-cluster large system purposes simplicity paper assume relation-cluster disks system subdivided multiple chain-clusters data placement algorithm chained declustering operates assume total disks numbered relation i-th primary fragment stored mod -th disk i-th backup fragment stored mod -th disk function fragment relation disk relation-cluster formula ensure primary backup copies fragment disks figure number disks relation-cluster equal tuples primary copy relation declustered gamma horizontal partitioning strategies tuples i-th primary fragment designated stored i-th disk drive backup copy declustered partitioning strategy i-th backup fragment designated stored -th disk stored -th disk figure identical data term technique chained declustering disks linked fragments relation chain data unavailable nodes cluster fail generalized formula mod greatest common divisor gcd equal center expand cccccccc node primary copy backup copy figure chained declustering relation cluster size data placement strategy relation unavailable logically adjacent disks relation-cluster fail simultaneously disk fails repaired suppose node failed node node fails node repaired data unavailable subsequent node failure node node nodes compromise availability data normal operation reads directed fragments primary copy writes update copies case single node processor disk failure chained declustering distribute workload cluster uniformly remaining operational nodes illustrated figure cluster size processor disk fails load read portion workload remaining node increase primary backup fragments read operations node fails primary fragment longer accessed backup fragment node processing queries directed requiring node process accesses chained declustering offloads ths accesses redirecting node turn ths access node dynamic reassignment workload results increase workload remaining node cluster relation-cluster size increased compromising data availability make load increase small desired center expand cccccccc node primary copy --ruru ruru ruru ruru ruru ruru backup copy ruru --r ruru ruru ruru ruru ruru figure fragment utilization chained declustering failure node relation-cluster size attractive feature reassignment active fragments incurs disk data movement bound values pointers indices memory resident control table changed modifications quickly efficiently shown figure simplified view chained declustering mechanism balances workload event node failure actual database applications queries simply access arbitrary fraction data fragment data clustered attribute values indices exist query optimizer generate access plans addition declustering alternatives range hash round-robin gamma clustered non-clustered indices partitioning non-partitioning attributes hsia describe design load balancing algorithm chained declustering mechanism handle combinations partitioning methods storage organizations access plans keys solution notion responsible range indexed attributes query modification techniques ston availability extent map relations stored heap simulation model model overview evaluate availability mechanisms constructed simulation model gamma dewi running node intel ipsc hypercube inte figure depicts structure model component implemented denet livn discrete event module arcs figure discrete event connectors thought combination preconstructed message path set predefined message types role component briefly actual model parameters found table database manager database modeled set relations consisting number data pages clustered nonclustered indices constructed system catalog track relations indices chained declustering interleaved declustering location primary backup fragments relation medium file grn model figure architecture simulation model fragments relation local storage organization terminal module responsible generating queries query select update number tuples executed sequential file scan clustered nonclustered index model simulates closed system outstanding request terminal number active terminals system determines multi-programming level query completed terminal waits thinktime seconds submitting query simulation runs preselected response time confidence interval confidint reached query manager query request module examines schema determine node execute query constructs query plan single node execute query directly node scheduler module scheduler module responsible coordinating execution multiple-node queries query scheduler traverses tree top activating operator process nodes relevant fragments failure occurred vertices query modified initiating query scheduler waits message operator process committing query sending query message requesting terminal network manager network manager encapsulates operation communication network key parameter module packetthreshold determines network packets served simultaneously network packets served first-come first-served fcfs order network manager packet arrives network manager served immediately packetthreshold packets outstanding packet queue packet leaves network module head waiting queue removed service begin served packet delayed time network module delivered destination node proportional number bytes packet includes packet header size network packet ranges hundred bytes control packet thousand bytes data packet network interface module models sending receiving network packets messages operator node amount cpu cycles consumed message received actual number cycles consumed determined message type data control packet size operator manager operator manager simulates gamma operator processes module models types operator processes selection processes store processes depending type incoming query packet operator process begin requesting data pages disk manager select wait data packet arrive processor network module store operator process requests amount cpu time initiates request processes disk network data pages cpu cpu module models sharing cpu resource processes running node process cpu cycles sends request cpu module number cpu instructions needed cpu free request served immediately reply back requester requested cpu time elapsed request put cpu ready queue key parameter actual plan generated differ depending mode operation normal failure module cpu speed mips disk manager disk disk manager responsible handling requests generated operator manager disk request received disk manager maps logical page number generated operator manager physical 
disk address cylinder sector issues disk request waits completion disk request elevator disk scheduling discipline case mirrored disks case fifo shortest seek time scheduling discipline bitt gray total time required complete disk access diskaccesstime seektime rotationallatency settletime transfertime seek time seeking tracks modeled formula bitt seek time seekfactor rnrn rotational latency modeled random function returns uniformly distributed values range minlatency maxlatency settletime models disk head settle time disk arm movement transfer time computed dividing disk page size disk transfer rate failure manager log manager failure manager impact normal mode operation failure mode module randomly select node fail log manager implemented scheme approximately overhead generating storing log records exclusion log manager significantly affect relative performance physical data placement simulation model figure illustrates layout primary backup fragments disks mirrored disks chained declustering interleaved declustering schemes illustrated figure relation partitioned disks mirrored pairs i-th primary fragment relation backup fragment mirrored disk strategy contents disks mirrored pair identical represents union fragments chained declustering primary fragments indices relations outer half cylinders backup fragments stored half interleaved declustering primary fragments indices relations outer half disk drive chained declustering backup subfragments half file grn datapla figure data placement mirrored disk scheme disk read request served disk pair tandem non-stop sql system model architecture disk shortest seek time assigned serve disk read request result expected seek distance random reads one-sixth tracks bitt gray chained interleaved declustering primary fragment access scheme simulation experiments primary fragments outer half disk drive expected seek distance random read requests reduced one-third one-sixth tracks result data replication schemes provide improved performance non-replicated case read queries alternative update mechanisms backup fragments chained interleaved declustering update query processed ways update processed nodes relevant primary backup fragments stored approach send update query node primary fragment processing processing completed node sends redo log records backup node applied variation approach direct update queries nodes primary fragments shipping redo records updated disk pages shipped nodes backup fragments written directly disk method incurs additional communications costs fewer total disk methods network message delay data page measured intel hypercube average disk service time read requests selected method processing update queries chained interleaved declustering experiment results section presents results comparison availability mechanisms variety workloads normal failure modes operation interest load imbalance caused disk processor failure affects system throughput response time types queries comparing performance high availability strategies related issues explored impact updating backup copies tradeoff benefit intra query parallelism overhead activating scheduling extra operator processes model validation order evaluate accuracy results produced simulation model configured model reflect accurately characteristics gamma ran number experiments replication hsia model predicted measured performance gamma margin error experimental design typically system throughput average response time key metrics evaluate system model simulates closed system response time inversely proportional system throughput remainder section throughput main performance metric additional metrics aid analysis results obtained disk service time average time serve disk request including time spent waiting disk queue metric disk utilization computed dividing total disk service time disk experiment time metric cpu utilization measured dividing total cpu busy time experiment time finally average number index data pages accessed query examined experiments table specifies parameter settings experiments mirrored disk scheme requires disks mirrored pair processor processors disks attached database consists relations million tuples relations fully declustered number terminals sources model varied buffer hit ratio disk read requests assumed cluster size number disks interleaved declustering scheme set maximum size recommended teradata customers box center parameter setting number processors disks processor number relations relation size tuples tuple size bytes multi-programming level buffer hit ratio cpu speed mips cluster size seek factor minlatency msec maxlatency msec settle time msec transfer rate bytes sec disk page size bytes pachetthreshold time sec confidint confidence table parameter settings performance experiments experiments relations database declustered disks system hashing attribute selection predicate queries tuples declustered clustered index constructed partitioning attribute motivation physical organization cover broad spectrum performance space queries case experiment single-tuple indexed retrieval partitioning attribute declustering indexing strategy query directed single node processing incurs minimum number true experiment single tuple update hand queries experiment indexed selection partitioning attribute experiment update tuples selected query experiment processors execution involve range selections hash partitioned relation relations range partitioned selection attribute queries directed subset processors reducing response time improving throughput system reason elect alternative wanted bracket performance space queries range declustering required push simulations found experiments higher multiprogramming levels order demonstrate differences strategies observe lower mpls hash partitioning partitioning indexing combination chosen subtle impact performance scheme reader aware system consisting processors disk assume disk page hold tuples assume relation tuples partitioning attribute values hash declustered mod hash function tuples stored key values tuples declustered clustered sorted index created node partitioning attribute step place tuples keys page page page ways making backup copy tuples residing approach teradata apply hash function key attribute tuple mapping tuple processors tuples advantage approach fails single tuple selection query partitioning attribute routed directly backup processor hash function disadvantage updates applied places incurring additional disk processing overhead single update normal failure mode approach constructing backup fragments distribute duplicate copies pages primary copy nodes relation cluster page page page advantage approach updates page reflected simulation model detailed ran forever simply shipping copy page disadvantage fails single tuple selections handled processing database design chosen search index backup fragments locate desired tuple search index find matching tuple alternatives path length updates normal mode operation shorter indexing partitioning combination impacts performance mechanisms executing selection operation experiments failure mode operation relation consists kbyte pages pages disk relation hash partitioned selection attribute disks produce approximately pages result tuples pages overlap occasionally backup subfragments backup subfragment approximately pages disks fails subquery originally served failed primary fragment served backup subfragments processors cluster similar effect occurs division responsibility primary backup copies based attribute ranges performance results selection queries section examines relative performance chained declustering interleaved declustering mirrored disks selection queries experiment single tuple selection partitioning attribute query tested single-tuple exact-match selection partitioning attribute index selection partitioning attribute query directed single node execution figure shows average throughput obtained scheme normal mode operation schemes provide approximately performance multiprogramming level mpl disks 
outstanding disk requests chance request disk queue small order requests serviced schemes disk service times mpl greater probability request waiting disk queue higher turn increasing effectiveness elevator disk scheduling algorithm mechanisms average seek distance smaller mechanism design preclude record-level locking basically updated page backup node buffer pool manager primary site forces updated page disk file grn nclidx sel figure single tuple selection figure single tuple selection normal mode failure mode mpl average disk seek service time result provide level throughput process queries mpl henceforth refer effect referred disk scheduling effect failure mode operation figure schemes suffers performance degradation low multiprogramming levels mpl processors disk utilized mpl increases impact disk failure significant mpl throughput scheme levels remaining disk failed mirrored pair fully utilized bottleneck hand schemes throughput continues increase mechanisms job distributing workload originally served failed disk henceforth referred load balancing effect comparing figures mpl decrease throughput due disk failure contrast decrease throughput mirrored disks higher performance differences mechanisms figure result differences disk utilizations failure occurs scheme mpl average utilization remaining disks cluster suffered disk failure utilization drives clusters hand disk utilization remaining drives mpl respect cpu utilization mechanisms interesting observation cpu utilization processor operational disk attached effect occurs cpu utilization proportional number pages processed node turn proportional number operational disks experiment selection query clustered index experiment considers performance mechanisms executing indexed selection query selectivity factor source relation assumed hash partitioned query active nodes processing schemes node produces result tuples returned submitting terminal process query mechanism normal mode operation processor read index pages data pages case processor read index pages data pages disks read process index pages data page primary backup fragments distributed disk drives addition operator processes activated schemes incur extra disk overhead benefit higher degree intra-query parallelism henceforth referred query parallelism effect cpu bottleneck higher multiprogramming levels results obtained presented figures normal mode operation provide throughput mpl greater point cpu utilized hand scheme cpu bottleneck form throughput level mpl reaches ultimately mpl scheme throughput figure illustrates tradeoff benefit higher intra query parallelism overhead scheduling operator processes processing index pages system consistently operated high cpu utilization applications cpu bound partitioning strategy data placement algorithm modified fragments treating disks attached processor logical unit figure shows throughput mechanisms event disk failure mpl throughput provided drops discussed section principal drop schemes workload failed disk ends handled single disk ends file grn clidx sel figure selection figure selection normal mode failure mode index pages read range selection predicate overlaps range leaf pages index pages read simulation model gamma processor responsible transferring data channel fifo buffer main memory overhead cpu bottleneck form higher mpl servicing requests disks addition operating failure mode average seek distance longer primary backup copies accessed higher mpls multiple outstanding queries generating requests work failed disk evenly distributed remaining disks failed cluster performance degradation drastic demonstrated figure mpl reduction throughput scheme performance degradation mpl disk mirrored pair idle assume workload penalty mpl utilization mirrored pair rises remaining disks remain utilized causing throughput mechanism level mpl remaining disk failed mirrored pair fully utilized bottleneck throughput levels mpl schemes throughput continues increase mpl reached point cpu fully utilized bottleneck figure illustrates higher throughput failure mode operation job load balancing load balancing effect schemes incur level overhead event disk node failure performance results update queries update query time data item updated change reflected primary backup copies data item case page backup copy item disk connected processor update incurs cpu cycles packaging sending receiving page communications network wire delay communication network henceforth referred remote update overhead extra cpu cycles required mechanism write mirrored pair ends synchronizing disk arms average seek distance number cylinders bitt higher average seek distance single disk henceforth refer effect synchronizing write overhead query types studied section single tuple update query clustered index query selects tuples clustered index updates selected tuples relations hash partitioned query single processor processors experiments update transaction committed primary backup copies updated addition assume attribute updated indexed partitioning attribute experiment single tuple update query results experiment contained figures schemes provide comparable performance low multiprogramming levels system resources cpu disk network utilized overhead updating backup copies significant factor mpl pushed higher differences schemes begin emerge overhead synchronizing disk writes starts limit performance system hand overhead remote update function page size significantly affected mpl network network interface bottleneck result schemes provide significantly higher throughput mpl greater normal mode operation figure shows throughput mechanisms event disk failure mpl performance strategies significantly affected cpu disk utilized load increase results failure significant performance affected slightly reads processes index pages failure mode mpl pushed higher significant differences performance begin mpl figures show throughput drops strategy strategy strategy reasons suffers larger drop performance distribute workload failed disk remaining disks cluster failed drive evenly redistribute workload remaining disks query originally served failed disk processors cluster processing increasing number index pages read processed file grn nclidx update figure single tuple update figure single tuple update normal mode failure mode subfragment finds updates matching tuple mechanism remaining operational disk failed mirrored pair assume entire workload pair unlike single tuple selection case decrease throughput major reasons behavior writes disks failed disk assume read requests originally handled failed disk query reads pages updates page queries disk mirrored pair responsible disk reads disk writes assuming workload uniformly distributed disks disk failure occurs remaining disk failed pair responsible disk reads disk writes resulting increase number disk requests buffer hit ratio read requests number experiments increase disk requests decreases roughly failed mirrored pair longer synchronize disk arms remaining disk process write requests efficiently offsetting impact increase number disk requests update query experiment bound update query cpu bound scheme provide performance normal mode operation remote update overhead incurred consumes extra cpu cycles synchronizing write overhead increases disk service time advances cpu technology occurred faster advances disk technology joy fran operations bound future additional cost remote updates significant experiment selection update clustered index experiment assume relation updated hash partitioned query operational nodes processing query experiment clustered index sequentially read tuples randomly updating read figures show throughput consistency mechanisms normal failure modes update frequencies normal mode operation 
slightly higher throughput higher throughput mpl mpl schemes provide higher throughput scheme equal higher throughput equal factors interact switch mpl benefit effect intra-query parallelism experiment update frequency increased disk contention occurs reads writes primary fragments writes backup fragments update frequency query parallelism effect dominates provide results relation range partitioned clustered index constructed nonpartitioning attribute throughput update frequency overhead longer disk service time dominates performance mpl average disk service times disk service times beginning mpl update portion query begins disk contention resulting higher disk service time previous case higher update percentage severe disk contention addition synchronize disk heads performing write increases average service time mpl average disk service time throughput continues increase mpl point disks fully utilized forms bottleneck continued increase disk service times results slight decrease throughput mpls mpl throughput levels throughput decreases slightly mpls levels mpl throughput increases significantly mpl update levels mpl rate increase drops significantly disks utilized small increase throughput due decrease disk service time result elevator scheduling algorithm employed disk controller mpl provide throughput scheme figure shows throughput provided mechanisms event disk failure provide significantly performance update frequencies multiprogramming levels job balancing load event disk failure mpl increased failed mirrored pair bottleneck exhibit fairly significant drop performance mpl compared normal performance mpl drop file grn fig figure selection update figure selection update normal mode failure mode varying cpu speed page size addition experiments presented previous sections studied effect increasing cpu speed mips decreasing page size kbytes kbytes selection clustered index experiment queries remained bound relative performance replication schemes change significantly hand case experiment longer performs high mpls normal mode operation mip cpu throughput higher mpl mpl mip cpu provide throughput conclusions paper studied performance chained declustering interleaved declustering mirrored disk schemes simulation model gamma database machine examined relative performance strategies failures occurred effect single node failure system throughput response time performance impact varying cpu speed disk page size replication strategies tradeoff benefit intra query parallelism overhead activating scheduling extra operator processes experiments conducted read-only selection queries update queries requiring reads writes selection queries chained declustering interleaved declustering shown perform comparably normal mode operation performed mirrored disks application bound due disk scheduling slightly worse mirrored disks application cpu bound event failure chained declustering balance workload remaining disks interleaved declustering redistributed workload failed cluster mirrored disks load redistribution mirror image failed disk process requests originally served failed disk result chained declustering provided slightly performance interleaved declustering performance mirrored disks failure mode operation update backup copy data item chained declustering interleaved declustering incur cpu overhead packaging sending updated data remote node backup copy stored addition remote node consumes extra cpu cycles receive network packet updated page initiate extra disk write operation write updated page disk mirrored disks copies data item stored disks attached processor extra cpu cycles needed updating backup copy mirrored disks write operation ends synchronizing read write heads disks mirrored pair bitt disk service time write maximum service time writes addition disk arms mirrored pair cylinder write operation effectively reducing number disk arms serving read request mirrored disks average disk service time request longer update queries select queries update queries chained declustering interleaved declustering incur cpu overhead mirrored disks incurs overhead disk seek distance relative performance schemes depends relative performance processor disk drive normal mode operation update query bound chained declustering interleaved declustering perform mirrored disks hand update query cpu bound mirrored disk mechanism perform advances cpu technology occur faster disk drive technology future database applications disk bound chained declustering provide performance mirrored disks update intensive applications failures occur mirrored disk scheme bottleneck forms failed mirrored pair throughput limited rate failed pair service requests hand chained declustering workload failed disk evenly redistributed remaining disks chained declustering higher throughput mirrored disks event failure relative performance chained declustering interleaved declustering event disk failure depends query type size cluster cluster size experiments showed chained declustering provide throughput interleaved declustering single tuple update query improvement update query notice cluster size providing lower throughput interleaved declustering scheme times data unavailable chained declustering scheme hsia future work includes studying performance tradeoffs replication schemes skewed data access possibility dynamic load balancing chained declustering scheme data replication data partitioning declustering commonly multiprocessor multi-disk database machines break hot spots achieve load balancing hot spots dynamic nature database reorganized periodically chained declustering query subquery processed node storing primary backup copy matching tuples addition work node shifted neighbor physically moving data nodes chained primary backup copies fragment characteristics chained declustering scheme provide good opportunity dynamic load balancing care hot spot time reorganization database required acknowledgements mike carey invaluable developing simulation model gamma interpreting results obtained anon anon measure transaction processing power tandem computer cupertino bitt bitton gray disk shadowing proceedings international conference large data base los angeles august bitt bitton arm scheduling shadowed disks compcon ieee press march borr borr transaction monitoring encompass reliable distributed transaction processing proceedings international conference large data base care carey load balancing locally distributed database system proceedings acm-sigmod international conference management data care carey livny parallelism concurrency control performance distributed database machines proceedings acm-sigmod international conference management data portland oregon june chen chen gibson katz patterson evaluation redundant arrays disks amdahl proceedings acm sigmetrics conference colorado cope copeland alexander boughter keller data placement bubba proceedings acm-sigmod international conference management data chicago cope copeland keller comparison high-availability media recovery techniques proceedings acm-sigmod international conference management data portland oregon june dewi dewitt gerber graefe heytens kumar muralikrishna gamma high performance dataflow database machine proceedings international conference large data base japan august dewi dewitt ghandeharizadeh schneider performance analysis gamma database machine proceedings acm-sigmod international conference management data chicago dewi dewitt ghandeharizadeh schneider bricker hsiao rasmussen gamma database machine project ieee transactions knowledge data engineering vol march fran frank advances head technology presentation challenges disk technology short institute information storage technology santa clara santa clara december gerb gerber dewitt impact hardware software alternatives performance gamma database machine computer sciences technical report wisconsin-madison july gray gray sammer whitford shortest seek shortest service time scheduling mirrored disc reads tandem computers december gray gray horst walker parity striping disc arrays 
low-cost reliable storage acceptable throughput proceedings onternational conference large data base brisbane australia august hsia hsiao dewitt chained declustering availability strategy multiprocessor database machines proceedings international conference data engineering los angeles february hsia hsiao performance availability database machines replicated data computer sciences technical report wisconsin-madison august inte intel corporation ipsc user guide intel corporation order march joy joy presentation isscc panel session february katz katzman fault-tolerant computing system proceedings hawaii conference system sciences january kim kim synchronized disk interleaving ieee transactions computers vol november livn livny khoshafian boral multi-disk management proceedings acm sigmetrics conference alberta canada livn livny denet user guide version computer sciences department wisconsin-madison patt patterson gibson katz case redundant arrays inexpensive disks raid proceedings acm-sigmod international conference management data chicago ries ries epstein evaluation distribution criteria distributed database systems ucb erl technical report berkeley ston stonebraker implementation integrity constraints views query modification proceedings sigmod workshop management data san jose calif ston stonebraker case shared database engineering vol tand tandem database group nonstop sql distributed high-performance high-reliability implementation sql workshop high performance transaction systems asilomar september tera teradata dbc database computer system manual release document teradata corp nov triv trivedi probability statistics reliability queueing computer science applications prentice-hall jersey 
benchmarking database systems systematic approach dina bitton david dewitt carolyn turbyfill computer sciences department wisconsin madison research partially supported national science foundation grant mcs department energy contract de-ac abstract paper describes customized database comprehensive set queries systematic benchmarking relational database systems designing database set carefully tuned benchmarks represents attempt developing scientific methodology performance evaluation database management systems database perform comparative evaluation database machine direct commercial versions ingres database system relational database system oracle idm database machine present subset measurements single user case constitute preliminary performance evaluation systems note reader important reader recognize results presented paper represent performance database systems point time releases systems undoubtably perform differently objective research make definitive statement relational database system market today goal develop standard set benchmarks database system designers evaluating systems users selecting system suits imperative reader understands results presented measure performance systems multiuser environment developing methodology benchmarking database systems environment david dewitt december introduction past decade large number database machines encompassing wide variety architectures possessing range characteristics proposed enhance performance database management systems today clear specialized architectures offer significant performance advantages general purpose computers paper attempt provide answer question presenting results benchmarks run conventional database management systems database machines specifically measured compared performance database machine direct dewi bora britton-lee idm database machine database accelerator dac idm epst ubel commercial versions ingres database system ston ston oracle database system database machines active field research entire decade machines implemented feel time measuring actual performance enhancement expected special purpose hardware software database management database machines designs cassm rap ozka ozka dbc bane direct dewi proposed future database machines looked bright successful research efforts advances hardware technology lead widespread commercial database machines projects appeared promising initially recently special purpose computers commercially icl cafs machine mcgr babb shipped small quantities britton-lee idm intelligent database machine appears database machine reach market place large volumes exceptions overwhelming evidence majority database machine designs proposed laboratory toys cases leave promising paper status database machines marketed database management systems offered rely special hardware enhancing performance years experience ingres database management system led development commercial version system face limited bandwidth bora discussion impact trends mass storage technology future highly parallel database machines april approximately hundred idm idm database machines shipped general purpose computers development added apparent slowdown research database machines provided strong motivation experiments paper previous performance evaluation studies database machines hawt dewi insight problems database machine architectures face studies based simplified analytical models feel extend empirical measurements measurements addition providing comparison systems provide means evaluating accuracy performance evaluation tools compare alternative database machine architectures dewi hawt results provide insight extent conventional operating system database management system ston idm database accelerator represents performance database management system running conventional processor zilog general purpose operating system addition relative performance database machines conventional database management systems paper describes customized database comprehensive set queries systematic benchmarking relational database systems designing database set carefully tuned benchmarks represents attempt developing scientific methodology performance evaluation database management systems addition providing mechanism comparing performance systems feel benchmark tool database system implementors evaluating algorithms query optimizers paper organized section provide description systems evaluated hardware configuration detail machines basic software structure outlined section explain designed experiments motivate framework benchmarks section present analyze results comparisons finally section summarize conclusions plan extend present study description systems evaluated section describe basic architecture software structure systems compared ingres database management system configurations version vax running berkeley unix commercial version vax running vms operating system oracle database management system vax running berkeley unix idm connected pdp host direct prototype vax host back-endcontroller bora detailed descriptions design implementation stages research projects led current versions ingres direct found published papers referenced section hand written documentation development idm oracle systems recent system start intended commercial product present complete description systems provide reader background comparing systems hardware configurations run benchmarks made fair system evaluated disk drives similar characteristics similar disk controller interfaces equivalent amounts buffer space database system ingres systems ingres project began california berkeley ingres implemented top unix operating system operational multiuser dbms original version system improved enhanced number ways improve usability performance recently commercial version ingres completed reaching market place section shortly summarize main features university-ingres describe system configuration benchmarks run describe enhancements added commercial-ingres university-ingres version university-ingres tested delivered berkeley distribution tape version ingres runs unix processes monitor process interacting user process responsible performing operations database query execution interpretative fashion vax university-ingres tested megabytes memory disk drives connected vax system industries controller cmi interface operating system run berkeley unix utilizes byte data pages database stored fujistu eagle disk drive megabytes immediately database loaded unix file system constructed drive maximizing probability logically adjacent blocks physically adjacent disk atypical situation typically scrambled unix file system ingres buffer management relying unix operating system buffer database pages discussed ston buffer management strategies good managing virtual memory pages frequently poor choosing page eject database environment repeated access relation join lru absolutely worst algorithm selecting pages relation eject algorithm berkeley unix commercial-ingres commercial-ingres relational technology runs processes vms version commercial-ingres evaluated vax megabytes memory attached processor mass-bus interface fujistu eagle drive connected processor cmi bus emulex controller ingres software stored drive test database stored fujistu drive operating system vms release vms extent based file system logically adjacent blocks physically adjacent disk test bytes main memory allocated buffer space bytes allocated sort space buffer management random replacement policy version commercial version ingres vms operating system includes number performance enhancements present version number routines rewritten improved performance major occurred areas query optimizer develops complete query execution plan execution query initiated sort-merge join strategies byte data pages versus byte pages unix caching query trees permits repetitive queries reexecuted re-parsing buffer management control database system permits implementation replacement strategies tuned enhance database operations sharing database pages multiple transactions oracle oracle relational database management system presents sql cham compatible interface user oracle runs processes user background utility processes vax oracle evaluated megabytes memory attached processor mass-bus interface fujistu eagle drive connected processor cmi bus emulex controller database oracle software stored eagle drive operating system berkeley unix vms version unix extent based file 
methodology database system performance evaluation haran boral computer science department technion israel institute technology david dewitt computer sciences department wisconsin madison research partially supported national science foundation grant mcs department energy contract de-ac abstract paper presents methodology evaluating performance database management systems database machines multiuser environment main factors affect transaction throughput multiuser environment identified multiprogramming level degree data sharing simultaneously executing transactions transaction mix demonstrate basic query types needed construct benchmark evaluate performance system wide variety workloads finally present results applying techniques britton-lee idm database machine introduction recent widespread acceptance relational model data model introduction large number relational database systems database machines fact computer system number alternative relational products digital equipment corporation vax product line relational database systems machines vax include idm database machine ingres informex mistress oracle rim unify user faced task selecting system ideally rate systems dbms richter scale assign systems rating quantitatively measuring performance benchmarking benchmarks designed general model systems capabilities results fair metric assign system rating measure systems systems idmfor sophisticated statistics gathering mechanisms make statistics gathered user argue statistics comparing systems uniformity portability problems thrust argument presented paper simple measures elapsed time cpu time amount activity generally commercial systems suffice statistics benchmarking database management systems machines developing fair metric comparing performance systems thrust paper impediments developing metric choice fair metric difficult problem application institution dependent parameters considered factors response time throughput cost effect host computer important parameters parameters formula reduce measurements systems point dbms richter scale highly dependent user expected system comparing performance systems hot potato juggle overview describes approach developed benchmarking database systems machines input data benchmark synthetic database set queries generated user databases easily generated programs examples found bitt bogd controversy generated comparison systems bitt primary advantage synthetic database real database control exercised inputs outputs benchmark runs benchmarking effort proceed phases phase large list queries run single user mode obtain performance measures optimal conditions phase multi-user benchmarks run study system operation realistic loads step crucial success benchmarking effort uncover anomalies give picture resources required queries turn design multi-user benchmark run reasonable amount time remainder paper illustration importance single-user benchmarks join benchmark reported bitt version ingres relational technology sort-merge join algorithm oracle nested loops algorithm index joining attribute oracle release vax require hours join tuple relation tuple relation relations byte tuples ingres release vax execute query minutes bitt application characterized large percentage ad-hoc joins large relations point performing multi-user benchmarks system provide adequate performance single user case paper extend research single user benchmark techniques present methodology evaluating multi-user performance relational database management systems relational database machines proposed methodology section sections present design results experiment based methodology conclusions suggestions future research directions summarized section evaluation techniques strategies introduction principal factors affect database system performance multiuser environment multiprogramming level query mix degree data sharing factor defines axis performance space varied independently holding level multiprogramming degree data sharing constant varying mix transactions observe effect transaction mix system performance section elaborate factors present methodology developed multiuser benchmarks multiprogramming level multiprogramming level factor explanation experiments number queries executed concurrently measure multiprogramming level relied broad interpretation word executed submission query passes number stages parsing access planning execution finally transmission results user application program strict definition multiprogramming level include queries execution phase controlling system constant number queries phase difficult impossible choose define multiprogramming level number queries phase execution attempt minimize times phases time parsing access planning minimized precompiled queries time transmit results back user reduced selecting queries produced tuples reducing number attributes returned result tuple degree data sharing notion data sharing based observation database applications multiple queries accessing relations concurrently accesses data pages rare high probability index pages repeatedly accessed applications case design buffer management system significant effect multiuser performance buffer management system makes intelligent replacement decisions increase frequency requested page found buffer pool interesting note lru replacement strategy poor performance relational operators ston sacc appears lru policy managing replacement shared data pages achieve optimal performance database system algorithms depending data page shared investigating issue explore effects data sharing system performance scale measure degree data sharing degree data sharing data sharing concurrently executing queries query partition database separate database queries application relations partition partition complete set relations number partitions equal maximum multiprogramming level degree data sharing set concurrently executing queries partition database values defined number active partitions function multiprogramming level multiprogramming level degree data sharing active part database consist partitions ways distributing queries partitions degree datasharing approach queries randomly distributed active partitions successive queries application distinct partitions approach application programs uniformly distributed partitions multiprogramming level degree data sharing queries application programs partition queries application programs partition approach reflects reality accurately appears problems arise multiprogramming level multiple number partitions multiprogramming level partitions felt lead anomalous results query running partition run slower queries sharing partition elected approach experiments interesting extension research explore fact differences approaches query mix selection hardest part developing methodology multiuser benchmarks devising small set representative queries developing single user benchmark bitt began queries hot-set executing query buffer pool sacc analyzed results realize needed queries characterize performance system found relative performance systems searches integer string attributes test selection operations selectivity factors found adequate began development multiuser benchmark strategy paring list queries thought time minimal list queries paring more-or-less seat pants manner assurances list representative types queries expanding set back queries guarantee problem resolved makes running benchmark prohibitively time consuming interpreting results difficult resource utilization approach query mix selection database queries consume main system resources cpu cycles disk bandwidth cpu cycles consumed software executes query overhead functions performed database access path selection buffer pool management additional cpu cycles consumed operating system behalf database system initiating disk operations disk operations performed order data required answer query buffer pool store results query disk result swapping activity generated page replacement algorithm buffer manager partitioned consumption resources classifications low high query types needed basis multiuser benchmark type low cpu utilization low disk utilization type low cpu utilization high disk utilization type iii high cpu utilization low disk utilization type high cpu utilization high disk utilization divided utilization resource finer subdivisions low medium high feel values needed 
bracket database system performance multiuser queries bitton martinez turbyfill wiley multiuser benchmark experiment los alamos laboratory august stra viewpoint design multiuser benchmarks environment query types basis single user benchmark system exhibit anomalous behavior query section application resource utilization approach application resource utilization approach requires selecting query exhibits behavior query type hypothesized selecting tuple clustered index hashing type query selecting small number tuples non-clustered index type query solid leads queries correspond query types iii verify hypotheses choose candidates query types iii queries single user benchmarks ran britton-lee idm query-level performance monitoring tools found release software measured cpu disk utilization query summary results presented table expected query number found type query query number type query type iii query selected query number query number type iii query afraid extremely long running time make experiments unacceptably lengthy query obvious choice type query queries selected reasonable choices perfect ideally level resource utilization low high consume amount resource nice type type queries utilize amount cpu time type queries perform number disk operations general difficult achieve initiating disk operation requires additional cpu time portability issues selection type iii queries independent database system hypothesize queries type queries relational database systems selection type iii type queries appears dependent algorithms database system aggregate function query type query idm b-tree group members partition type query system implemented aggregate queries run ad-hoc query interface idl table resource utilization figures idm database machine database accelerator query query cpu usage disk seconds operations select tuple clustered index select tuples clustered index select tuples non-clustered index select tuples clustered index select tuples non-clustered index scalar aggregate operation tuple relation aggregate function tuple relation partitions join tuples tuples clustered index join attribute tuple relation select tuples clustered index join tuple relation clustered index select tuples select tuples join tuple relations form tuple relation joined tuple relation functions hashing similarly query type query system executes joins exclusively sorting performance metric system throughput measured queries-per-second principal performance metric illustrative response time performance indicator system throughput response time measured section experiment design description test database database experiments based synthetic database bitt basic relations generate database multiuser benchmarking experiments refer names onektup tenktup ten thousand tuples tuple bytes long consists number integer string attributes attribute unique assumes unique values relation constitutes key thoustup relation unique assumes values tenthoustup relation values unique attribute unique range values unique random number generator scramble values unique unique relations generated remaining integer attributes named range values attribute assumes ten twenty hundred tenthous attributes assume values uniformly distributed ranges finally tuple byte string attributes structure relations facilitate formulation wide variety queries ingres queries retrieve tuples tenktup relation range tenktup retrieve unique retrieve hundred similarly query computes aggregate function query partitions tuples range onektup retrieve minvalue min tenthous hundred permit benchmark runs multiprogramming level data sharing simultaneously executing queries database populated copies onektup tenktup relations copy basic relations unique relation sorted unique attribute leaving relation unsorted unique attribute tenktup relations clustered index constructed unique attribute non-clustered index constructed unique attribute indices constructed onektup relations hardware configuration evaluate benchmarking techniques section idm database machine test vehicle idm hardware consists high-speed bus board types ubel database processor responsible controlling boards implements system functionality database processor implemented zilog microprocessor chip processor runs special-purpose operating system tunes process management special database software database accelerator dac specially designed ecl processor achieves high speed defined tasks microcoded channel consisting microprocessor memory hardware implement serial parallel ieeeinterface channel implements communication protocol host memory timing control board memory accessed modes byte-mode database processor faster word-mode accelerator disk controller memory board megabytes disk buffers additional space user processes consequence bit address space limitation maximum megabytes buffer space disk controller expanded interface gigabytes disk storage idm utilized benchmarks megabytes memory disk controller mbyte cdc drive tracks cylinder parallel channel interface host processor pdp running variant unix dac switched remotely release idm software benchmarks megabyte memory allocated buffer space exact kbyte buffers query specifications section basic query types form basis multiuser benchmark section present specific queries experiments idm ad-hoc query interface idl embedded query facility query encapsulated program runs host computer noted stored query facility provided idm facility mechanism query precompiled stored database idm queries query types shown figures important points observe queries query types selection criterion randomly generated query executed insures access data index pages pages randomly distributed data index pages approach critical multiuser benchmark step query types iii case query type time query executed entire tenktup relation large buffer pool accessed situation query type iii slightly complicated time query type iii executed entire onektup relation accessed approximately index data pages tenktup relation tenktup relation accessed multiple instances query type iii executed concurrently high degree data sharing resident main memory occupies approximately bytes buffer pool approximately megabyte size interpret potential problem remember objective type iii query high cpu activity low activity part database resident buffer pool helps achieve objective point set queries query returns attributes qualifying tuple host finally note order maximize performance system operations performed data returned host tuples tenktup unique attribute falls range apply argument query type decided result artificially high transaction rates qryi select tuple clustered index int long randomnumber randomnumber random seed select random key randomnumber range tenktup retrieve unique unique unique figure query type qryii select tuples non-clustered index int lowervalue uppervalue randomnumber random seed select lower range lowervalue randomnumber uppervalue lowervalue range tenktup retrieve unique unique unique lowervalue unique uppervalue figure query type qryiii join clustered index join attribute unique query produces tuples int range tenktup range onektup retrieve unique unique unique unique unique unique figure query type iii qryiv aggregate function min partitions int xmin range tenktup retrieve min min twothousd hundredd figure query type multiuser benchmark program design simplify task performing wide variety experiments program purpose designed implemented structure program shown figure iteration select query type select partition database execute query structure benchmark program figure number copies program executed concurrently corresponds multiprogramming level experiment parameters program instance include multiprogramming level number iterations executed percentage query type executed degree data sharing general instances executed concurrently receive parameter values iteration query 
executed step iteration query type randomly selected distribution query types input parameters query type selected partition database chosen experiment data sharing instance program separate partition database experiment data sharing programs select partition levels data sharing partition randomly selected generating random number mpl mpl current multiprogramming level finally instance chosen query type executed selected database partition gather timing information analysis time-of-day clock read recorded immediately query executed initially hoped program instance terminate execution reaching steady state approach proved difficult implement concurrent program run fixed number iterations number iterations performed varied query type type queries iterations performed ten iterations type queries general goal run program long enable system reach steady state instances subsequent analysis output data revealed system reached steady state forcing rerun experiment insure randomness repeatability experiments program instance provided random number seed experimental results analysis introduction section describe experiments conducted multiprogramming benchmark analyze results obtained wide variety interesting experiments benchmark present results found interesting experiments explore system performance function multiprogramming level degree data sharing query types results demonstrate query types sufficient evaluating multiuser performance system set experiments conducted designed determine effect system performance number factors began mixes concurrently executing queries mix consisted query types mix consisted type queries queries update single tuples experiment explored effect precompiled stored queries system throughput examined performance idm database accelerator finally looked system performance varying size buffer pool measurement system throughput response time discussed section time-of-day clock read recorded immediately query executed concurrently executing program iterations experiment concluded program dumps measurements output file multiprogramming level output files produced determine transaction throughput response time experiment output files analyzed manner mpl donate multiprogramming level experiment number iterations concurrent program executes represent starting ending times jth query ith concurrent program mpl output data analyzed find start max mpl start time multiprogramming level reaches level experiment step find finish min mpl point multiprogramming level desired level start finish determined number queries completely executed last-to-start first-to-finish interval calculated jth query ith program included total start finish transaction throughput defined number queries divided length interval seconds average response time calculated dividing sum execution times set queries completely executed last-to-start first-to-finish interval number queries approach eliminates termination effects system reached steady state start determining database system reaches steady state appears interesting area future research system performance query types iii tests conducted measure system throughput function multiprogramming level degree data sharing multiprogramming level varied increments levels data sharing tested results experiments shown figures query types iii make number general comments results claim query types sufficient evaluating multiuser performance database system ignoring moment transactions update database number queries executed ranged maximum query type minimum query type range orders magnitude extent concurrently executing queries portion database effect performance query type factor difference throughput data sharing data sharing important note data sharing relation accessed size buffer pool increase performance due exclusively data sharing concurrently executing queries query type iii difference factor degree data sharing effect query types reasonable query type single records retrieved explain query type exhibits lower throughput rate data sharing data sharing degree data sharing minimal effect performance query type query makes sequential scan million byte relation buffer pool million bytes data sharing concurrently executing queries simultaneously load portions relation fact performance idm degrades marginally query type multiprogramming level increased replacement strategy buffer pool works properly degradation performance query type iii interesting illustration effect data sharing discussed section time type iii query executed entire outer relation pages accessed pages pages relation data sharing sets pages remain memory resident page buffer pool data sharing pages relations memory multiprogramming level reaches data sharing drop performance occurs multiprogramming level interesting differences throughput occur fifo random buffer pool replacement policy lru figures plotted average response time function multiprogramming level query types iii figures provide interesting view performance idm figure response time remains constant multiprogramming level response time multiprogramming level impressive figures provide verification effects data sharing figure transitions found figure observed finally clear figure instance query type sufficient saturate system experiments involving mix query types addition type query evaluated performance system mixes concurrently executing queries mix figure consisted type queries type queries type iii queries type queries query mix intended reflect mix query types find real environment performance system constant data sharing shows moderate decline increases multiprogramming level data sharing levels isolate degradation performance mix consisted type queries queries update single tuples tuples updated randomly selected ten thousand tuple relation accessed key attribute updating tuple involved replacing key attribute idm check update trick allowed execute update operations database changing replacing key attribute idm delete tuple clustered index reinsert modified tuple experiment fixed multiprogramming level varied query mix update queries type queries update queries type queries results shown figure make number interesting observations results fact system throughput data sharing conflicts occur insignificant effect performance expected updates expensive retrievals due cost maintaining primary index writing recovery information log impact query precompilation experiment conducted examine effect precompiled queries stored commands system throughput impact feature minimal long queries evaluated feature type queries rerunning experiments query type stored command facility data sharing level minimize number disk operations performed figure results experiment factor improvement performance obtained precompiled queries enhancing system performance performance enhancement provided database accelerator database accelerator dac customized ecl processor microcoded provided enhanced cpu performance frequently executed database operations single-user static benchmarks bitt dac provided speedup query type query type iii interested dac provide higher level enhancement multiuser environment figures present results tests query types iii query types selected perform minimum number disk operations emphasizing cpu utilization disk traffic minimized data sharing tests results dac additional enhancement multiuser environment query type maximum speedup multiprogramming level query type iii dynamic speedup achieved conflicts observed examining statistics relation maintained idm effect buffer size final tests designed explore effects buffer size system performance query type selection non-clustered index selected test exhibits high disk cpu utilization ratio multiprogramming level fixed results displayed figure surprising results data sharing easily explained pages buffer space index pages relations fit memory iteration concurrently executing queries randomly selects tuples retrieve retrieval non-clustered index tuple stored data page iteration set pages referenced 
expect curve remain flat buffer pool large hold significant fraction relations accessed pages test data sharing illustrates interaction size buffer pool effect data sharing detailed analysis relationship appears warrant investigation conclusions future research paper presented methodology evaluating performance database management systems database machines multiuser environment identified main factors affect transaction throughput multiuser environment multiprogramming level degree data sharing simultaneously executing transactions transaction mix resource utilization main criteria choosing representative transaction mix construct benchmark evaluate performance system wide variety workloads basic query types applied methodology britton-lee idm database machine multiuser benchmarks critical evaluating performance database system feel single user benchmarks presented bitt bodg stra essential uncovering anomalies system performance number interesting areas warrant investigation careful exploration relationship data sharing buffer management yield improved buffer management algorithms multiuser environment additional work warranted updating transactions paper explored effect single tuple updates clustered index examined updates non-indexed attributes attributes secondary indices effects throughput addition considered bulk update operations interesting attempt verify analytically derived locking granularity results ries stonebraker ries ries area worthy investigation effect back-end communications bandwidth system performance experiment fix multiprogramming level degree data sharing query mix vary number bytes returned query finally techniques developed benchmarking distributed database systems distributed database environment query consumes communication resources addition cpu disk resources query consume local remote cpu disk resources bogd bogdanowicz crocker hsiao ryder stone strawser experiments benchmarking relational database machines database machines springer-verlag bitt bitton dewitt turbyfil benchmarking database systems systematic approach computer sciences department technical report computer sciences department wisconsin december revised expanded version paper appeared title proceedings large database conference october epst epstein hawthorn design decisions intelligent database machine proceedings national computer conference idm idm manual britton-lee los gatos california ries ries stonebraker effects locking granularity database management system performance acm transactions database systems vol september ries ries stonebraker locking granularity revisited acm transactions database systems vol june sacc sacco schkolnick mechanism managing buffer pool relational database system hot set model proceedings large database conference september stra strawser paula methodology benchmarking relational database machines dissertation ohio state december ston stonebraker operating system support database management communications acm july ubel ubell intelligent database machine database engineering vol dec suggested paula strawser 
system logically adjacent blocks physically adjacent disk version oracle tests attempted allocate megabyte main memory buffer space system run reliably buffer space fact make system work forced limit buffer space hundred byte buffers impossible accurately predict oracle performance megabyte buffer space evaluate commercial-ingres twenty byte buffers byte buffers found virtually difference attribute surprising result design benchmark section idm database machine intelligent database machine appears widely commercial database machine developed britton-lee machines marketed idm hardware consists high-speed bus board types ubel database processor responsible controlling boards implements system functionality standard -bit microprocessor chip zilog processor runs special-purpose operating system schedules disk accesses intelligently unlike operating systems idm operating system tunes process management special database software database accelerator dac specially designed ecl processor achieves high speed defined tasks microcoded idm configured accelerator depending cost performance desired accelerator physically emulated database processor channel consisting microprocessor memory hardware implement serial parallel ieeeinterface channel implements communication protocol host buffers commands coming host idm result data returning idm host memory timing control board memory accessed modes byte-mode database processor faster word-mode accelerator disk controller beta-test release berkeley unix significant differences versions memory board megabytes disk buffers additional space user processes consequence bit address space limitation maximum megabytes buffer space disk controller expanded interface gigabytes disk storage idm utilized benchmarks megabytes memory disk controller mbyte cdc drive parallel channel interface host processor pdp running variant unix dac switched remotely release idm software benchmarks megabyte memory allocated buffer space cdc disk drive tracks cylinder fujistu eagle track-to-track seek time transfer rate slower eagle calculated time read tuple relation bytes tuple seconds cdc drive seconds fujistu drive results presented section slightly biased idm important realize degree bias highly dependent query type availability suitable indices performance idm cpu limited limited database machine direct direct dewi multiprocessor database machine designed implemented wisconsin madison initial design proposed complete description architecture software structure current implementation direct found bora basic idea motivated direct project multiprocessor back-end machine ingres relational database system dramatically enhance performance queries entered host machine vax current prototype compiled machine language query processors pdp packets relational operators back-end back-end responsible executing query returning result tuples host back-end includes processors query processors controlled synchronized back-end controller processors share access megabyte disk cache virtual memory manager back-end monitors transfer data three-level memory hierarchy query processors memory disk cache disk initializing execution instruction back-end controller estimates optimal number query processors primarily function operand relations sizes assigns processors instruction configuration benchmarks run consists vax running berkeley unix doubles host processor back-end controller lsi computers kbytes main memory processors run reliably multiport mbyte memory addressable byte boundaries disk cache unit transfer byte page memory transmission control information query processors back-end controller fujitsu eagle disk database resides benchmark description starting point experiments design database database customized extensive benchmarking previous efforts area generally unscientific benchmarks aware involve existing database system run restricted set queries cases database supplier-parts database ingres users familiar small results benchmarks provide insight real world database management systems cases size database large data values provide flexibility required systematic benchmarking specific generate wide range retrieval update queries control result queries existing data selection query selects source relation tuples query retrieves precisely tuples queries involving joins harder model selectivity factors build queries produce result relation size additional shortcoming empirical data versus synthetic data deal large amounts data safely assumed data values randomly distributed building database random number generators obtain uniformly distributed attribute values relation sizes tractable section describe guidelines designed benchmark design effort resulted simple carefully tuned database comprehensive set queries section describe structure relations database section description queries run benchmarks sections made descriptions explicit explaining design principles motivated choice attribute specific query section describe experiment environment queries run performance parameters measured wisconsin database database designed naive user quickly understand structure relations distribution attribute consequence results queries run benchmark easy understand additional queries simple design attributes relation distributions values partitioning aggregates controlling selectivity factors selections joins varying number duplicate tuples created projection straightforward build index primary secondary attributes reorganize relation clustered respect index basic relations database refer names thoustup twothoustup fivethoustup tenthoustup tuples appendix schema benchmark fragment thoustup relation shown figure tuples bytes long relations occupy approximately megabytes disk storage order build queries operate operand relation generate relations size join queries section operate tuple relations tenthoustupa tenthoustupb attributes integer numbers character strings length characters attribute unique integer number assumes unique values relation made simplest choice values unique fragment thoustup relation attributes omitted unique unique ten hundred thousand figure tuples relation thoustup unique assumes values relations tuples values unique attribute unique range values unique unique unique key attributes random number generator scramble values unique unique attribute unique sort key relations sorted sorted respect attribute build clustered index index unique instance execute ingres query observe effect primary index selection retrieves twothoustup relation range twothoustup retrieve unique unique unique attributes set integer-valued attributes assume non-unique values main purpose attributes provide systematic modeling wide range selectivity factors attribute named range values attribute assumes ten twenty hundred tenthous attributes assume values ranges instance relation hundred attribute uniform distribution values depending number tuples relation attribute control percentage tuples duplicates projection percentage tuples selected selection join query twothoustup relation hundred attribute projecting single attribute relation tuples duplicates values distinct attribute values ingres statement query range twothoustup retrieve hundred hundred attribute creating partitions aggregate function queries query minimum attribute assumes values randomly distributed fivethous relation partitioned partitions range twothoustup retrieve minvalue min fivethous hundred finally relations string attributes string letters long letters middle varied separating substrings letter significant letters chosen range unique string values string attributes follow pattern xxxx xxx xxx xxx stands letters basic pattern modified provide wider range string values replacing significant letters hand varying position significant letters database designer control cpu time required string comparisons attributes category string versions unique unique integer valued attributes stringu stringu key attributes primary index built stringu thousand tuple relation thoustup stringu attribute values axxxx xxxaxxx xxxa bxxxx xxxaxxx xxxa cxxxx xxxaxxx xxxa vxxxx xxxaxxx xxxa axxxx xxxbxxx xxxa vxxxx xxxbxxx xxxa axxxx xxxcxxx xxxa vxxxx xxxvxxx 
gamma database machine project david dewitt shahram ghandeharizadeh donovan schneider allan bricker hui-i hsiao rick rasmussen computer sciences department wisconsin research partially supported defense advanced research projects agency contract -cby national science foundation grant dcrby darpa nasa sponsored graduate research assistantship parallel processing research grants intel scientific computers tandem computers digital equipment corporation abstract paper describes design gamma database machine techniques employed implementation gamma relational database machine operating intel ipsc hypercube processors disk drives gamma employs key technical ideas enable architecture scaled processors relations horizontally partitioned multiple disk drives enabling relations scanned parallel parallel algorithms based hashing implement complex relational operators join aggregate functions dataflow scheduling techniques coordinate multioperator queries techniques control execution complex queries minimal coordination necessity configurations involving large number processors addition describing design gamma software performance evaluation ipsc hypercube version gamma presented addition measuring effect relation size indices response time selection join aggregation update queries analyze performance gamma relative number processors employed sizes input relations constant speedup sizes input relations increased proportionally number processors scaleup speedup results obtained selection join queries linear doubling number processors halves response time query scaleup results obtained encouraging reveal constant response time maintained selection join queries workload increased adding proportional number processors disks introduction years gamma database machine project focused issues design implementation highly parallel database machines number ways design gamma based learned earlier database machine direct dewi direct demonstrated parallelism successfully applied processing database operations number design deficiencies made scaling architecture processors impossible primarily shared memory centralized control execution parallel algorithms bitt solution problems encountered direct gamma employs today straightforward solutions architecturally gamma based shared-nothing ston architecture consisting number processors interconnected communications network hypercube ring disks directly connected individual processors generally accepted architectures scaled incorporate processors fact teradata database machines tera incorporating shared-nothing architecture processors key idea employed gamma hash-based parallel algorithms unlike algorithms employed direct algorithms require centralized control hardware architecture scaled indefinitely finally make limited bandwidth provided current generation disk drives gamma employs concept horizontal partitioning ries termed declustering livn distribute tuples relation multiple disk drives design enables large relations processed multiple processors concurrently incurring communications overhead design gamma software completed fall work began prototype operational fall version gamma implemented top existing multicomputer consisting vax processors dewi period prototype enhanced addition number operators aggregate update operators parallel join methods hybrid grace sort-merge schn complete concurrency control mechanism addition conducted number performance studies system period dewi dewi ghan ghan spring gamma ported processor intel ipsc hypercube vax-based prototype retired gamma similar number active parallel database machine efforts addition teradata tera bubba cope tandem tand utilize shared-nothing architecture employ concept horizontal partitioning teradata tandem rely hashing decentralize execution parallel algorithms systems tend rely conventional join algorithms sort-merge processing fragments relation site gamma xprs ston volcano grae utilize parallel versions hybrid join algorithm dewi remainder paper organized section describe hardware gamma prototypes experiences section discusses organization gamma software describes multioperator queries controlled parallel algorithms employed gamma section techniques employ transaction failure management contained section section performance study processor intel hypercube prototype conclusions future research directions section hardware architecture gamma overview gamma based concept shared-nothing architecture ston processors share disk drives random access memory communicate sending messages interconnection network mass storage architecture generally distributed processors connecting disk drives processor shown figure number reasons shared-nothing approach architecture choice prevent architecture scaling processors unlike shared-memory machines scaling processors impossible demonstrated dewi cope tand associating small number ppp interconnection network figure disks processor distributing tuples relation disk drives achieve high aggregate bandwidths custom disk controllers kim patt employing off-the-shelf mass storage technology employ latest technology small disk drives embedded disk controllers advantage shared approach longer roll hardware recently intel ncube added mass storage hypercubebased multiprocessor products gamma version initial version gamma consisted vax processors megabytes memory megabit token ring prot connect processors vax running unix processor acted host machine gamma attached processors megabyte fujitsu disk drives storing database diskless processors processors disks execute join aggregate function operators order explore diskless processors exploited effectively encountered number problems prototype token ring maximum network packet size bytes version prototype size disk page set bytes order transfer intact disk page processor copy required disk page space protocol header interprocessor communication software initially appeared good idea quickly realized benefits larger disk page size offset cost copy tuples disk page network packet problem encountered network interface unibus bottlenecks gerb dewi bandwidth token ring megabits unibus network interface attached bandwidth megabits processing join query selection predicate input relations unibus bottleneck transfer rate pages disk higher speed unibus dewi network interface bottleneck buffer incoming packets time packet transferred vax memory incoming packets rejected retransmitted communications protocol eventually constructed interface token ring plugged directly backplane vax time board operational vax obsolete elected spend additional funds upgrade entire system problem encountered prototype megabytes memory processor problem operating system gamma provide virtual memory problem exacerbated fact space join hash tables stack space processes buffer pool managed separately order avoid flushing hot pages buffer pool advantages spaces managed separately software configuration memory tight balancing sizes pools memory proved difficult gamma version fall replaced vax-based prototype processor ipsc hypercube intel processor configured cpu megabytes memory -megabyte maxtor disk drive disk drive embedded scsi controller kbyte ram buffer acts disk cache read operations nodes hypercube interconnected form hypercube custom vlsi routing modules module supports full-duplex serial reliable communication channels operating megabytes small messages bytes datagrams large messages hardware builds communications circuit nodes entire message transmitted software overhead copying message completely transmitted circuit released length message limited size physical memory processor table summarizes transmission times gamma process hypercube nodes variety message sizes packet size bytes transmission time table conversion gamma software hypercube began early december users intel hypercube tend run single process time crunching numerical data operating system provided intel supports limited number heavy weight processes began conversion process porting gamma operating system nose section order simplify conversion elected run nose thread package inside single process order avoid port nose run bare hardware directly configurations mix compute nodes channels dedicated communication subsystem nose running began converting gamma software process man months 
lasted months process conversion discovered interface scsi disk controller memory transfer disk blocks larger bytes pitfall beta test site part conversion gamma software trivial porting nose differences systems initiating disk message transfers completely hidden gamma software porting code discover number hidden bugs vax version code vax trap null pointer dereferenced biggest problem encountered nodes vax multicomputer numbered beginning hypercube logical address node thought making tedious straightforward half port realized find change loop system loop index address machine message set sounds silly weeks find places changed retrospect made nose mask differences addressing schemes database system perspective number areas intel improve design ipsc light-weight process mechanism provided alternative increased time required port long run avoided maintaining nose problem current version system disk controller perform dma transfers directly memory block read disk disk controller dma transfer byte fifo fifo half full cpu interrupted contents fifo copied location memory block instruction copy operation measured cpu cycles wasted copy operation addition cpu interrupted times transfer kbyte block partially scsi disk controller partially fifo disk controller memory software architecture gamma section present overview gamma software architecture describe techniques gamma employs executing queries dataflow fashion begin describing alternative storage structures provided gamma software system architecture top describing process structure illustrate operation system describing interaction intel forced design system added system completed empty socket board dma access memory processes execution queries detailed presentation techniques control execution complex queries presented section illustrates execution multioperator query finally briefly describe wiss storage system provide low level database services nose underlying operating system gamma storage organizations relations gamma horizontally partitioned ries disk drives system key idea horizontally partitioning relation enable database software exploit bandwidth provided hardware declustering tuples relation task parallelizing selection scan operator trivial required start copy operator processor query language gamma user alternative declustering strategies round robin hashed range partitioned strategy tuples distributed round-robin fashion disk drives default strategy relations created result query hashed partitioning strategy selected randomizing function applied key attribute tuple partition command relation select storage unit strategy user specifies range key values site disk system command partition employee emp result distribution tuples shown table partitioning information relation stored database catalog range hash-partitioned relations partitioning attribute case range-partitioned relations range values partitioning attribute site termed range table distribution condition processor emp emp emp emp range table table relation partitioned gamma normal collection relational database system access methods including clustered non-clustered indices user requests index created relation system automatically creates index fragment relation unlike vsam wagn tandem file system ensc gamma require clustered index relation constructed declustering term horizontal partitioning coined bubba project livn partitioning attribute query optimized partitioning information source relation query incorporated query plan produced query optimizer case hash range-partitioned relations partitioning information query scheduler discussed restrict number processors involved execution selection queries partitioning attribute relation hash partitioned attribute direct selection operations predicates form constant single site avoiding participation sites execution query case rangepartitioned relations query scheduler restrict execution query processors ranges overlap range selection predicate equality range predicate retrospect made mistake choosing decluster relations nodes disks approach proposed cope heat relation determine degree relation declustered add capability gamma software point time require fairly major effort undertake gamma process structure structure processes form gamma software shown figure role process briefly operation distributed deadlock detection recovery mechanism presented sections system initialization time unix daemon process catalog manager initiated set scheduler processes set operator processes deadlock detection process recovery process catalog manager function catalog manager act central repository conceptual internal schema information database schema information loaded memory database opened multiple users database open user reside machine catalog manager executing catalog manager responsible insuring consistency copies cached user query manager query manager process active gamma user query manager responsible caching schema information locally providing interface ad-hoc queries gdl variant quel ston query parsing optimization compilation scheduler processes executing multisite query controlled scheduler process process responsible activating operator processes execute nodes compiled query tree scheduler processes run processor insuring processor bottleneck practice scheduler processes consume resources run large number single processor centralized dispatching process assign scheduler processes queries queries optimizer detect single-site queries directly node execution by-passing scheduling process recovery process process detection deadlock processes scheduler manager catalog manager query manager query processors gamma host operator processes operator processes processes operator operator processes database database database database schema gamma process structure figure operator process operator query tree operator process employed processor participating execution operator operators primed system initialization time order avoid overhead starting processes query execution time additional processes forked needed structure operator process mapping relational operators operator processes discussed detail scheduler wishes start operator node sends request special communications port task port request received port idle operator process assigned request communications port operator process returned requesting scheduler process overview query execution ad-hoc embedded query interfaces interfaces gamma ad-hoc query language embedded query language interface queries embedded program user invokes ad-hoc query interface query manager process started immediately connects process unix internet socket mechanism compiled query interface preprocessor translates embedded query compiled query plan invoked run-time program mechanism passing parameters program compiled query plans run time provided query execution gamma traditional relational techniques query parsing optimization seli jark code generation optimization process simplified gamma employs hash-based algorithms joins complex operations queries compiled left-deep tree operators execution time operator executed operator processes participating site designing optimizer vax version gamma set query plans considered optimizer restricted left-deep trees felt memory support rightdeep bushy plans combination left-deep query trees hash-based join algorithms insure join operations active simultaneously maximize amount physical memory allocated join operator memory limitation artifact vax prototype recently begun examine performance implications deep bushy query plans schn discussed section process optimizing query query optimizer recognizes queries directed subset nodes system case single site query query directly processor execution case multiple site query optimizer establishes connection idle scheduler process centralized dispatcher process dispatcher process controlling number active schedulers implements simple load control mechanism established connection scheduler process sends compiled query scheduler process waits query complete execution scheduler process turn activates operator processes query processor selected execute operator finally reads results query returns ad-hoc 
query interface user embedded query interface program query initiated operator process structure algorithms relational operators written run single processor shown figure input operator process stream tuples output stream tuples demultiplexed structure term split table process begins execution continuously reads tuples input stream operates tuple split table route resulting tuple process split table process detects end input stream closes output streams sends control message scheduler process indicating completed execution closing output streams side effect sending end stream messages destination processes split table stream tuples control packet tuples process executing operator outgoing streams figure split table defines mapping values set destination processes gamma types split tables depending type operation performed dewi form split table split table shown figure conjunction execution join operation processors process producing tuples join apply hash function join attribute output tuple produce index split table obtain address destination process receive tuple tuples byte batches batch destination process processor port processor port processor port processor port split table figure queries executed query shown figure figure processes execute query shown flow data processes gamma configuration consisting processors disks processors disks input relations partitioned disks attached processors selection scan operators initiated processors split tables select scan operators entries processors join operation split tables selection scan identical routing tuples join attribute values hash dashed lines hash solid lines join operator executes phases phase termed building phase tuples relation inserted memory-resident hash table hashing join attribute phase completed probing phase join initiated tuples outer relation probe hash table matching tuples result relation partitioned disks split table join operator entries tuples distributed round-robin fashion scanselect join figure description simple hash join algorithm operation hybrid hash join algorithm contained section store scanselect table hash probebuild joinjoin table hash probebuild joinjoin select scan store figure main problems direct prototype data page processed required control message centralized scheduler gamma bottleneck completely avoided fact number control messages required execute query approximately equal times number operators query times number processors execute operator figure depicts flow control messages scheduler process processes processors figure identical set messages flow scheduler scheduler begins initiating building phase join selection operator relation operators completed scheduler initiates store operator probing phase join scan relation operators completed result message returned user initiate message operator port processor dispatching processes accepts incoming messages port assigns operator process process assigned replies scheduler message private port number operator process future communications operator scheduler private port number initiate initiate initiate initiate initiate scheduler joinjoin build probe hash table select scan store figure operating storage system gamma built top operating system designed specifically supporting database management systems nose multiple lightweight processes shared memory non-preemptive scheduling policy prevent convoys blas occurring nose communications nose processes reliable message passing hardware intel ipsc hypercube file services nose based wisconsin storage system wiss chou critical sections wiss protected semaphore mechanism provided nose file services provided wiss include structured sequential files byte-stream files unix indices long data items sort utility scan mechanism sequential file sequence records records vary length page length inserted deleted arbitrary locations sequential file optionally file indices map key values record identifiers records file matching indexed attribute designated clustering attribute file scan mechanism similar provided system rss astr predicates compiled query optimizer machine language maximize performance query processing algorithms selection operator relations declustered multiple disk drives parallelizing selection operation involves simply initiating selection operator set relevant nodes disks predicate selection clause partitioning attribute relation relation hash range partitioned scheduler direct selection operator subset nodes relation round-robin partitioned selection predicate partitioning attribute selection operator initiated nodes relation declustered enhance performance gamma employs page read-ahead mechanism scanning pages file sequentially clustered index mechanism enables processing page overlapped subsequent page join operator multiprocessor join algorithms provided gamma based concept partitioning relations joined disjoint subsets called buckets good kits brat applying hash function join attribute tuple partitioned buckets represent disjoint subsets original relations important characteristic tuples join attribute bucket implemented parallel versions join algorithms gamma prototype sort-merge grace kits simple dewi hybrid dewi algorithms employ concept hash-based partitioning actual join computation depends algorithm parallel hybrid join algorithm section additional information parallel algorithms relative performance found schn study found hybrid hash join performance default algorithm gamma detail section hashbased join algorithms execute non-equijoin operations operations supported remedy situation process designing parallel non-equijoin algorithm gamma hybrid hash-join centralized hybrid hash-join algorithm dewi operates phases phase algorithm hash function partition smaller relation buckets tuples bucket build in-memory hash table remaining buckets stored temporary files good hash function produces buckets ensure bucket tuples small fit main memory phase relation partitioned hash function step buckets stored temporary files tuples bucket immediately probe in-memory hash table built phase phase algorithm joins remaining buckets relation respective buckets relation join broken series smaller joins computed experiencing join overflow size smaller relation determines number buckets calculation independent size larger relation parallel version hybrid hash join algorithm similar centralized algorithm partitioning split table separates joining relations logical buckets number buckets chosen tuples logical bucket fit aggregate memory joining processors buckets intended temporary storage disk partitioned disk sites likewise joining split table route tuples respective joining processor processors necessarily attached disks parallelizing joining phase partitioning relation buckets overlapped insertion tuples bucket memory-resident hash tables join nodes addition partitioning outer relation buckets overlapped joining bucket bucket requires partitioning split table enhanced joining split table tuples bucket processors effect join remaining buckets joined joining split table needed figure depicts relation partitioned buckets disk sites bucket joined processors equal greater aggregate operations gamma implements scalar aggregates processor compute piece result parallel partial results single process combines partial results final answer aggregate functions computed steps processor computes piece result calculating partitions processors redistribute partial results hashing group attribute result step collect partial results partition single site final result partition computed update operators part update operators replace delete append implemented standard techniques exception occurs replace operator modifies partitioning attribute tuple case writing modified tuple back local fragment relation modified tuple passed split table determine site tuple transaction failure management section describe mechanisms gamma transaction failure management locking mechanisms fully operational recovery system implemented expect begin implementation 
failure management mechanism early concurrency control gamma concurrency control gamma based two-phase locking gray lock granularities file page lock modes provided site gamma local lock manager deadlock detector lock manager maintains lock table transaction wait-for-graph cost setting lock varies approximately instructions conflict instructions lock request conflicts granted group case wait-for-graph checked deadlock transaction requested lock suspended semaphore mechanism order detect multisite deadlocks gamma centralized deadlock detection algorithm periodically centralized deadlock detector sends message node configuration requesting local transaction wait-for-graph node initially period running centralized deadlock detector set time deadlock detector fails find global deadlock interval doubled time deadlock found current interval halved upper bound interval limited seconds lower bound collecting wait-for-graph site centralized deadlock detector creates global transaction wait-for-graph cycle detected global wait-for-graph centralized deadlock manager chooses abort transaction holding fewest number locks recovery architecture log manager algorithms implemented coordinating transaction commit abort rollback operate operator process updates record generates log record records change database state log record log sequence number lsn composed node number local sequence number node number statically determined system configuration time local sequence number termed current lsn monotonically increasing log records query processors log managers running separate processor merges log records receives form single log stream number log processors query processor direct log records mod log processor agra algorithm selects log processor statically query processor sends log records log processor recovery process query processing node easily determine request log records processing transaction abort page log records filled written disk log manager maintains table called flushed log table node lsn log record node flushed disk values returned nodes request piggybacked bububububu bububububububububu bububu bububu entries entries entries bucket bucket bucket processors partitioning split table disk disk partitioning logical buckets hybrid hash-join figure message query processing nodes save information local variable termed flushed lsn buffer managers query processing nodes observe wal protocol gray dirty page forced disk buffer manager compares page lsn local flushed lsn page lsn page smaller equal flushed lsn page safely written disk dirty page selected message log manager flush log record dirty page log manager acknowledges log record written log disk dirty data page written back disk order reduce time spent waiting reply log manager buffer manager pre-selected threshold clean unfixed buffer pages buffer manager notices number clean unfixed buffer pages fallen process termed local log manager activated process sends message log manager flush log records number clean unfixed pages number dirty pages safely written disk greater scheduler process query responsible sending commit abort records log managers transaction completes successfully commit record transaction generated scheduler relevant log manager employs group commit protocol hand transaction aborted system user scheduler send abort message query processors participated execution recovery process participating nodes responds requesting log records generated node log manager lsn log record originating node number log records received recovery process undoes log records reverse chronological order aries undo algorithm moha aries algorithms basis checkpointing restart recovery failure management insure availability system event processor disk failures gamma employs availability technique termed chained declustering hsia tandem mirrored disk mechanism borr teradata interleaved declustering mechanism tera cope chained declustering employs primary backup copy relation systems sustain failure single processor disk suffering loss data availability hsia show chained declustering higher degree availability interleaved declustering event processor disk failure job distributing workload broken node mirrored disk mechanism providing highest level availability poor job distributing load failed processor data placement chained declustering chained declustering nodes processor disks divided disjoint groups called relation-clusters tuples relation declustered drives form relation clusters physical copies relation termed primary copy backup copy maintained figure number disks relation cluster equal tuples primary copy relation declustered gamma partitioning strategies tuples i-th primary fragment designated stored mod -th disk drive backup copy declustered partitioning strategy i-th backup fragment designated stored mod -th disk term data replication method chained declustering disks linked fragments relation chain node primary copy backup copy chained declustering relation cluster size figure difference chained interleaved declustering mechanisms tera cope illustrated figure figure fragments primary copy declustered disk drives hashing key attribute interleaved declustering mechanism set disks divided units size called clusters illustrated figure backup fragment subdivided subfragments subfragment disk cluster disk primary fragment cluster cluster node primary copy backup copy interleaved declustering cluster size figure interleaved chained declustering sustain failure single disk processor difference mechanisms case single node processor disk failure chained interleaved declustering strategies uniformly distribute workload cluster remaining operational nodes cluster size processor disk fails load remaining node increase conclude cluster size made large overhead parallelism starts overshadow benefits obtained true chained declustering availability interleaved strategy inversely proportional cluster size failure processors disk render data unavailable doubling cluster size order halve approximately increase load remaining nodes failure occurs negative side effect doubling probability data unavailable reason teradata recommends cluster size processors figure illustrates workload balanced event node failure node chained declustering mechanism normal mode operation read requests directed fragments primary copy write operations update copies failure occurs pieces primary backup fragments read operations failure node primary fragment longer accessed backup fragment node processing queries directed requiring node process accesses chained declustering offloads -ths accesses redirecting node turn ths access node dynamic reassignment workload results increase -th workload remaining node cluster relation cluster size increased penalty make load increase small desired node primary copy --ruru ruru ruru ruru ruru ruru backup copy ruru --r ruru ruru ruru ruru ruru fragment utilization chained declustering failure node relation cluster size figure makes scheme attractive reassignment active fragments incurs disk data movement bound values pointers indices memory resident control table changed modifications quickly efficiently shown figure simplified view chained declustering mechanism balances workload event node failure reality queries simply access arbitrary fraction data fragment variety partitioning index mechanisms provided gamma software hsia describe combinations query types access methods partitioning mechanisms handled performance studies introduction experiment overview evaluate performance hypercube version gamma metrics set wisconsin bitt benchmark queries run processor configuration sizes relations million million tuples absolute performance measure database system speedup scaleup metrics multiprocessor database machines engl speedup interesting metric additional processors disks results decrease response time query subset 
wisconsin benchmark queries conducted speedup experiments varying number processors size test relations fixed million tuples set queries conducted scaleup experiments varying number processors size test relations increased million tuples scaleup valuable metric constant response time maintained workload increased adding proportional number processors disks engl describes similar set tests release tandem nonstop sql system benchmark relations experiments based standard wisconsin benchmark relations bitt relation consists tuples bytes wide constructed million million tuple versions benchmark relations copies relation created loaded noted tuples declustered hash partitioning unique attribute cases results presented represent average response time number equivalent queries gamma configured disk page size bytes buffer pool megabytes results queries stored database avoided returning data host order avoid speed communications link host database machine host processor affect results storing result relations database impact factors minimized expense incurring cost declustering storing result relations selection queries performance relative relation size set selection tests designed determine gamma respond size source relations increased machine configuration processors disks ideally response time query grow linear function size input result relations tests selection queries run sets relations million million tuples queries selectivity factor employ indices fourth queries selectivity factors clustered index locate qualifying tuples query selectivity factor employs non-clustered index locate desired tuples selection non-clustered index query gamma query optimizer chooses sequential scan query query clustered index retrieve single tuple query predicate query specifies range values input relations declustered hashing query nodes results tests tabulated table part execution time query scales fairly linear function size input output relations cases scaling perfectly linear non-indexed selection increase response time size input relation increased million tuples perfectly linear secs secs increase tuples million tuples sec sec sublinear selection clustered index increasing size input relation factor ten results ten-fold increase response time query query takes seconds million tuple relation seconds million tuple relation understand impact seek time execution time query copies relation loaded million tuple relations declustered disk drives fragments occupy approximately cylinders disk drive ten million tuple relations fill cylinders drive page result relation written disk disk heads moved current position input relation free block disk million tuple relation cost writing output page higher expected clustered b-tree index significant improvement performance observation made table relative consistency execution time selection queries clustered index notice execution time selection million tuple relation identical execution time selection million tuple relation cases tuples retrieved stored resulting identical cpu costs final row table presents time required select single tuple clustered index return host selection predicate partitioning attribute query directed single node avoiding overhead starting query processors response query increases significantly table selection queries processors disks execution times seconds number tuples source relation query description nonindexed selection nonindexed selection selection clustered index selection clustered index selection non-clustered index single tuple select clustered index relation size increased million million tuples height b-tree increases levels speedup experiments section examine response time nonindexed indexed selection queries million tuple relation affected number processors execute query ideally linear improvement performance number processors increased increasing number processors increases aggregate cpu power bandwidth reducing number tuples processed processor figure average response times non-indexed selection queries million tuple relation presented expected response time query decreases number nodes increased response time higher selection due cost declustering storing result relation store result tuples locally partitioning result relations round-robin hashed fashion ensure fragments result relation approximately number tuples speedup curves figure presented figure figure average response time presented function number processors queries selection clustered index selection clustered index selection nonrurururururururururururururururururururururururururururururururururururu million tuple relation experiments million tuple relation fit disk drive response time seconds processors disks nonindexed selection nonindexed selection speedup processors disks figure figure nonindexed selection nonindexed selection clustered index accessing million tuple relation speedup curves presented figure speedup curves presented figures queries superlinear slightly sublinear significantly sublinear selection relation scan selection non-clustered index selection clustered index discussed source superlinear speedups exhibited queries due significant differences time configurations spend seeking processor million tuple relation occupies approximately disk relation declustered disk drives occupies disk case nonclustered index selection tuple selected requires random seek processor range random seek approximately cylinders processors range seek limited cylinders seek time proportional square root distance traveled disk head gray reducing size relation fragment disk significantly reduces amount time query spends seeking similar effect clustered index selection case index locate tuples satisfying query input page produce output page point buffer pool filled dirty output pages order write output page disk head moved response time seconds processors disks clustered index selection clustered index selection non-clustered index selection speedup processors disks figure figure clustered index selection clustered index selection non-clustered index selection position input relation position disk output pages relative cost seek decreases proportionally number processors increases resulting superlinear speedup query non-indexed selection shown figure superlinear similar reasons reason query affected degree index seek time smaller fraction execution time query selection clustered index exhibits sublinear speedups cost initiating select store operator processor total seconds processors significant fraction total execution number processors increased scaleup experiments final set selection experiments number processors varied size input relations increased million million tuples shown figure response time selection queries remains constant slight increase response time due overhead initiating selection store operator site single process initiate execution query number processors employed increased load process increased proportionally switching tree-based query initiation scheme gerb distribute overhead processors response time seconds processors disks clustered index selection clustered index selection nonindexed selection nonindexed selection non-clustered index selection figure join queries selection queries previous section conducted sets join experiments join queries varied size input relations configuration processors constant join query series speedup scaleup experiments conducted tests partitionings input relations case input relations declustered hashing join attribute case input relations declustered attribute hybrid join algorithm queries performance relative relation size join query bitt joinabprime simple join relations bprime relation million million tuples bprime relation million tuples result relation number tuples bprime relation query joinaselb composed join selection number tuples join operation result relation fields input relations result tuples bytes wide selection reduces size size bprime relation joinabprime query result relation query number tuples joinabprime query million tuples joinabprime joins bprime relation million tuples 
evaluation non-equijoin algorithms david dewitt rey naughton donovan schneider abstract non-equijoin relations band join join predicate requires values join attribute fall speci band values join attribute propose algorithm termed partitionedband join evaluating band joins presenta comparison partitioned band join algorithm classical sort-merge join algorithm optimized band joins analytical model implementation top wiss storage system results show partitioned band join algorithm outperforms sortmerge memory scarce operands join equal size describe parallel implementation partitioned band join gamma database machine present data speedup scaleup experiments demonstrating partitioned band join ciently parallelizable introduction paper evaluation algorithms class non-equijoins wecall band joins band join relations attributes join join condition written constants equal twomay term band tuple joins tuple appears band size knowledge systems implement band joins nested loops sort-merge propose algorithm partitioned band join algorithm present analytic experimental evidence implementation top wiss storage system cdkk faster sort-merge wide range band join queries memory sizes desirable property partitioned band join algorithm maps shared-nothing parallel database machines present experimental scaleup results implementation gamma database machine dgs band joins arise queries require joins continuous real world domains time distance tuples representevents attributes represent times whichevents occur nding authors liations david dewitt rey naughton computer sciences department wisconsin madison donovan schneider hewlett packard labs palo alto pairs events occurred time entail band join note clocks measuring events synchronized nding events occurred time require band join band large capture skew clocks algorithmic point view band joins interesting present challenges present equijoins growing body analytic experimental evidence hash-based algorithms highly ective equijoins surpassing performance sort-merge nested-loops hash-based algorithms ine ective band joins join condition involves ranges values exact matches values hashing partition disjoint subsets disjoint subsets band join computed union joins algorithm develop paper partitioned band join algorithm works partitioning suchaway partitions overlap portions partitions portions multiple partitions basis partitioning lies nding quantiles join attribute toavoid fully sorting quantiles sampling compute number samples required quantiles required accuracy con dence kolmogorov test statistic cost sampling included analytic experimental results critical parameter band-join numberoftuplesofr band tuples band constants join attribute paper assume bands small sense number tuples band memory thisisthemostinteresting case number tuples band memory join result huge gains due clever evaluation algorithms swamped cost writing result relation disk rest paper organized section describes partitioned band join algorithm section describes adaptation sort-merge join algorithm band joins section presents analytic comparison partitioned band join algorithm classical sort-merge join algorithm applied band joins section describe implementation algorithms present results experiments implementation section section describes howthe partitioned band join algorithm adapted shared-nothing multiprocessor speedup scaleup results implementation gamma partitioned band join partitioned band join algorithm works splitting partitions computing band join joining algorithm achieves high performance carefully choosing partition sizes overlaps performing partitioning sorting cient method computing subjoins overview partitioned band join algorithm primary goal algorithm minimize number disk accesses guaranteeing pages re-read join achieve goal ensuring conditions eachofther pool tuple tuples join conditions satis join reading memory reading page time joining tuples page reading page ensure rst condition bychoosing partitioning elements sampling process fully subsection condition determines required overlaps partitions condition twoabove satis case range tuples overlaps range tuples precise requirementisthatif greatest element appearing tuple andl element appearing tuple thens tuples join attributes implies range overlap range assuming partitioning values determined sampling tuples relations partitioned twoways whichweterm hybrid grace partitioning partitioning methods hash-based equijoins dko ktmo grace partitioning works allocating number pages equal number partitions page relation read input tuple page copied page partition belongs determine partition tuple belongs binary search table partitioning values constructed sampling table join attribute values mark boundaries partitions page partition lled written disk note partitioning tuples overlapping portions partitions copied multiple pages tuples multiple consecutive partitions suppose determined consulting partitioning table fall partition suppose computing join divide partitions toseeifs belongs wecheck join attribute denoted satis noting largest smallest hybrid partitioning works grace partitioning pages allocated memory partitioning phase partitioned partition remains memory partitions disk partitioned tuple falls partition immediately joined written disk goal hybrid partitioning avoid re-reading partitioning joining phases relations partitioned band join problem reduced computing individual joins wherek total number partitions basic idea computing subjoins mentioned read read page time joining tuple current page toavoid scanning tuple rstsortr in-memory sort join tuple accomplished rst binary searching rst tuple joins scanning pass tuple joins sampling partitioning guarantee memory partition approximately equal sized partitions partition size pool straightforward partition sort scan partitioning elements incur cost full sort partitioning phase avoid randomly sample determine partitioning elements high probability close elements found sorted suppose partition equal sized disjoint partitions begin taking random samples tuples sorted sorted tuples designated order increasing partition partitions partitioning elementbetween partitioning element kolmogorov test statistic con certainty percentile partitioning elements minus suppose samples recording join attribute sample sort resulting values appears mark sorted list samples certainty appears percentile sorted list join attribute tuples note error guarantee requires assumptions distribution values kolmogorov test non-parametric test works equally distribution choosing number partitions interesting problem explained suppose jrjpages wehave jrj memory pages suppose hybrid partitioning pages required byhybrid partitioning twotypes partition partitions purposes ignore pages small size implementation ignore pages including complicates exposition ideal situation choose memory partitioning elements approximate expect partitions equal size unreasonable note larger pool correctness algorithm ected partitioning joining phases performance due pool thrashing performance reasons weneedtopick highly exceed space logical choice set case expected size jrj pages sowe left jrj jrj pages handle anyover due errors estimation partitioning elements suppose pool samples expected error quantiles quantile percentage means expected number error pages jrj quantityislessthanjrj equation ning number samples required jrj jrj implies wemust takeatleastn samples choice set analysis aboveshows case wemust takeonlyn samples expected size smaller jrj jrj jrj turn means expect jrj reads writes wesavelessby leaving smaller memory summarize tradeo reducing non-sampling bychoosing small reducing sampling bychoosing large resolve tradeo written optimization procedure takes input jrj memory size cost sample cost chooses reasonable number samples required certainty thrashing ers re-emphasize join algorithm correct correct refers pool needed interesting point note number samples required depend jrj depends ratio jrj memory implies scale jrj memory keeping ratio 
multiprocessor hash-based join algorithms david dewitt robert gerber computer sciences department wisconsin research partially supported department energy contract de-ac national science foundation grant mcs abstract paper extends earlier research hash-join algorithms multiprocessor architecture implementations number centralized join algorithms measured evaluation algorithms served verify earlier analytical results addition demonstrate bit vector filtering dramatic improvement performance algorithms including sort merge join algorithm multiprocessor configurations centralized grace hybrid hash-join algorithms presented algorithms shown provide linear increases throughput increases processor disk resources introduction classic join algorithm paper blasgen eswaran blas topic virtually abandoned research area knew nested-loops algorithm provided acceptable performance small relations large relations suitable index existed sort-merge algorithm choice ad-hoc queries year papers dewi brat join algorithms centralized relational database systems papers compared performance traditional join algorithms variety algorithms based hashing papers reached conclusion sort-merge commonly accepted algorithm ad-hoc joins fact fast join algorithms based hashing retrospect interesting observe simple good algorithm virtually simply system astr support hashing access method motivation research paper twofold dewi brat analytical evaluations wanted implement measure algorithms proposed papers common framework order verify performance hash-based join algorithms wanted results single processor extended multiple processors hash-based join algorithms dewi hybrid algorithm made effective main memory minimize disk traffic multiprocessor joins require data moved processors multiprocessor hash-based join algorithms minimize amount data moved process executing join algorithm hash-based multiprocessor join algorithms multiprocessors suggested good adopted grace database machine project kits evaluated vald papers made important contributions understanding multiprocessor hash-based join algorithms number questions remain good hard factor influence tree architecture parallel readout disks results obtained kits hand concentrates speed sort-engine performance grace hash-join algorithm finally algorithm presented vald exploits hashing partitioning process resorts pure nested loops algorithm aided bit vector filtering join phase goal research examine ad-hoc join suitable index exists ingres ston hashing ad-hoc queries limited address space pdp ingres implemented made impossible exploit large amounts memory effectively algorithm received recognition deserves multiprocessor hash-join algorithms multiprocessor environment enabled identify cpu communications bandwidth design parameters section review join algorithms analytical results presented dewi step developing multiprocessor version hash based join algorithms implemented join algorithms dewi top wisconsin storage system wiss results presented section verify analytical results presented dewi based results feel relational database systems provide hash-based join algorithm order effectively exploit main memory increasingly inexpensive algorithms section gather real numbers simulation multiprocessor join algorithms section describe multiprocessor hash join algorithms present results simulation study algorithms results extremely exciting algorithms provide close linear speedup performance increases resources section conclusions plans database machine based multiprocessor join algorithms overview hash-partitioned join operations dewi performance hashed-based join algorithms termed simple grace kits hybrid compared traditional sort merge algorithm discussion hash-partitioned join algorithms source relations named assumed smaller pages hash-join algorithms begin partitioning disjoint subsets called buckets good kits partitions important characteristic tuples join attribute share bucket term bucket confused overflow buckets hash table partitioned buckets disjoint subsets original relations tuples assigned buckets based hash function applied tuple join attribute assuming potential range hash values partitioned subsets tuple hashed join attribute falls range values put bucket similarly tuple hashes partition put bucket hash function partitioning ranges relations tuples bucket joined tuples case tuples bucket join attribute values equal tuples potential power partitioning lies fact join large relations reduced separate joins smaller relation buckets hash-join algorithms distinct phases phase relations partitioned buckets centralized environment partitioning allocating page frame buffer tuples assigned buckets page buffer filled flushed file disk represents bucket relation scanned partitioned turn end partitioning phase relations represented equal numbers bucket files written disk partitioning phase create suitable number buckets bucket relation small fit main memory size buckets single page relation resident memory time join phase phase hash-join algorithms effects actual search tuples relations matching join values traditional join methods phase realize final join result relation partitioned buckets fit memory hash-based algorithm process search matching join tuples phase referred join phase step join phase bucket build hash table main memory bucket read tuple probe hash table matches problems hash join algorithms partitioning phase ensure size buckets created relation exceed size main memory guaranteeing chosen partitioning hash values result buckets relation fit memory necessarily trivial problem buckets growing unacceptably large termed bucket overflow choice hash function tend randomize distribution tuples buckets minimize occurrence bucket overflow chosen hash function fails distribute tuples uniformly bucket overflow occurs number remedies relations partitioned hash function solution expensive alternative apply partitioning process recursively oversized buckets dewi brat net effect solution split oversized bucket smaller buckets relation partitioned relation method requires rescanning bucket overflowed range values governing partitioning relation adjusted reflect final partitioning bucket overflow handled method fail case combined sizes tuples identical join values exceeds size memory case hash-based variation nested loops join algorithm applied performance algorithm analyzed section paper solutions handle bucket overflow applied overflow hash table simple hash-join simple hash-join processes bucket time minimal amount partitioning fact partitioning join phases executed simultaneously files relations files input input tuples waiting processed current phase algorithm files output output tuples passed current phase algorithm start algorithm input input set equal relations output output initially empty partitioning basis consisting number range hash values chosen start stages algorithm buckets relation buckets sequentially build hash tables main memory hash table built start stage stage begins scan input tuple considered belongs targeted memory bucket tuple added hash table tuple written output output remaining buckets current interest input scanned sequentially tuple input hashes bucket probe hash table built bucket match found tuples joined output tuple belong bucket written output end stage simple hash-join output output file input input file stage algorithm progresses output output file progressively smaller buckets interest consumed algorithm finishes output output empty processing stage grace hash-join grace hash join algorithm good kits characterized complete separation partitioning joining phases partitioning relations completed prior start join phase ordinarily partitioning phase creates buckets relation insure hash table bucket fit memory single page frame needed output buffer bucket memory pages remain unused requisite number bucket buffers allocated grace algorithm extra pages increase number buckets generated partitioning phase partitioning phase smaller buckets logically integrated larger buckets optimal size 
building in-memory hash tables strategy termed bucket tuning kits bucket tuning method avoiding bucket overflow hybrid hash join hybrid hash join dewi partitioning finished stage algorithm fashion similar grace algorithm grace algorithm additional memory partitioning phase partition relations large number buckets hybrid additional memory begin joining process hybrid creates minimum number buckets bucket expected fit memory allocating page frame output buffer bucket hybrid algorithm utilizes remaining pages frames build hash table partitioning range adjusted create equal-sized buckets written disk independently sized bucket build hash table partitioning range relation tuples hash bucket immediately probe hash table matches partitioning phase completes hybrid hash-join completed processing part join phase tuples immediately processed written retrieved disk partitioning join phases savings significant amount memory increases sort-merge join algorithm standard sort-merge blas algorithm begins producing sorted runs tuples average long number tuples fit priority queue memory knut requires pass relation phase runs merged n-way merge large number runs produced phase phases needed final phase sorted source relations sequentially scanned matching tuples joined output comparison join algorithms figure displays relative performance join algorithms analysis parameter settings presented dewi vertical axis execution time seconds horizontal axis ratio rururururururu sizes main memory relation pages equals fudge factor account fact hash table occupy pages main memory algorithms assumed resident mass storage algorithm begins execution results advantage hash based join algorithm traditional sort merge algorithm retrospect results surprising sorting creates total ordering records files hashing simply groups related records bucket evaluation centralized hash partitioned join algorithms verify analysis presented dewi gather information cpu utilizations partitioning joining phases hashing algorithms implemented simple grace hybrid algorithms vax running berkeley unix addition hash-partitioned join algorithms popular join algorithms studied algorithms sort-merge algorithm hashbased nested loops algorithm provide context comparing performance hash-partitioned join algorithms algorithms implemented wisconsin storage system wiss chou overview wiss wiss project begun approximately years ago recognized flexible data storage system serve basis constructing experimental database management systems originally conceived replacement unix file system wiss run top raw disk unix wiss ported run crystal multicomputer dewi services provided wiss include structured sequential files byte-stream files unix indices stretch data items sort utility scan mechanism sequential file sequence records records vary length page length inserted deleted arbitrary locations sequential file optionally sequential file indices index maps key values records sequential file matching indexing mechanism construct unix-style byte-stream files pages index correspond inode components unix file stretch item sequence bytes similar file unix insertion deletion arbitrary locations supported stretch item record unique identifier rid including rid stretch item record construct records arbitrary length demonstrated chou wiss performance comparable commercially database systems summary algorithms evaluated centralized versions grace simple hybrid hash-partitioned join algorithms implemented manner section modified version nested loops algorithm termed hashed loops implemented brat hashed loops algorithms named hashing means effecting internal join tuples main memory similar algorithm version ingres ston phase hashed loops algorithm hash table constructed pages staged memory tuples probes hash table constructing hash table avoids exhaustively scanning tuples memory tuple simpler form nested loops algorithm algorithm sort merge join employed sort utilities provided wiss algorithms allocated identical amounts main memory buffering pages relation similarly algorithms accessed relations disk page time blocking disk operations completed presentation performance results join algorithms compared queries data wisconsin benchmark database bitt figure execution time join algorithm shown function amount memory relative size smaller relation relative amount memory defined number pages main memory divided size pages smaller relation elapsed times join algorithms include time required write final result relation disk tests run single user mode test machine megabytes memory paging occurred bucket overflow occur tests hash-partitioned algorithms results joining tuple relations join algorithms presented figure join produces result tuples join attribute randomly ordered byte integer tuple relations participates result relation produced join query figure presented performance results calculated analytical models figure presents measured performance actual implementations algorithms find similarity figures reassuring encouraging figure performance grace hash-join algorithm constant range memory results total separation partitioning join phases grace algorithm performance viewpoint grace algorithm memory optimally joining phase excess memory partitioning phase means creating large number buckets bucket tuning process contrast performance simple hash-join algorithm significantly affected amount memory performs smaller relation size memory performance hybrid algorithm reflects fact combines performance features grace simple hash-join algorithms hybrid completes partitioning single pass source relations performance good grace algorithm hybrid algorithm increasingly outperforms grace amount relative memory increases additional memory immediately joining tuples bucket source relation joining eliminates cost writing reading tuples disk partitioning joining phases performance hashpartitioned algorithms remains unchanged smaller relation fits memory point occurs relative memory memory equals size smaller relation results fact hash-join algorithms memory join phase structure hash table realized partitioning predictive process prudence requires additional memory accommodate fluctuations size hash tables constructed buckets performance sort-merge join algorithm constant wide range memory figure source relation fits memory sorting process completely reads writes relation sorted runs produced time sorted runs merged sortmerge join algorithm reads source relations time effect final joining tuples optimization sufficient memory sorted runs relations merged joined simultanerururururururururururururururururururururururururururururu simple hash-join algorithm performance equal hybrid algorithm relative memory values excess approximately difference performance hybrid simple hashjoin algorithms relative memory values artifact implementation ously case performance sort-merge algorithm expected similar grace algorithm algorithm access page source relation times reads write surprisingly hashed loops algorithm good performance wide range memory figure due existence hash table cost probing matches tuples relation inexpensive operation algorithm performs size smaller relation size memory situation expect case bucket overflow hash-based nested loops algorithm attractive remedy handling bucket overflow performance join algorithms join tuple relation tuple relation shown figure result relation tuples hybrid algorithm continues dominate join algorithms wide range relative memory values stepwise performance transitions sort-merge nested loops algorithms obvious environment query figure reflects performance join algorithms query figure difference figure algorithms bit vector filtering techniques babb brat vald notable performance improvements demonstrated result eliminating earlier stage processing tuples produce result tuples bit vector filtering technique hash-partitioning sort-merge algorithms similar prior initial scan relation bit vector initialized setting bits tuple join attribute hashed hashed set bit bit vector relation scanned 
bit bit vector checked bit set tuple safely discarded applying bit vector relation relation approximates semijoin relation relation net impact process depends semijoin selectivity factor relation defined ratio tuples resulting semijoin relative cardinality query figure semijoin relation semijoin selectivity factor net effect approximately tuples relation eliminated early stage processing hash-partitioned sort-merge algorithms significant savings accrue fact nonparticipating tuples stored disk partitioning joining phases hashpartitioning algorithms disk accesses saved page tuples eliminated bit bit vector filtering technique hash-partitioned sort-merge algorithms directly extendible case hashed loops names relations discussion reversed vector filtering relation hashed loops algorithm complete scan relation end query bit vector filtering approximate semijoin relation figure semijoin selectivity factor semijoin instance hashed loops algorithm doesn derive benefit applying bit vector filtering collisions occur process accessing bit vectors result non-qualified phantom tuples propagated final joining process phantom tuples eliminated final joining process number phantom tuples reduced increasing size bit vector splitting vector number smaller vectors babb separate hash function smaller bit vectors costs bit vector filtering modest test single bit vector length bytes hash-partitioning algorithms compute hashed tuple join attribute additional cost bit vector filtering algorithms amount space required bit vector multiprocessor hash-based join algorithms multiprocessor versions hybrid grace algorithms attractive number reasons ability algorithms cluster related tuples buckets natural opportunity exploiting parallelism addition number buckets produced partitioning phase activated joining phase algorithm adjusted produce level parallelism desired joining phase buckets multiprocessor versions algorithms minimize communications overhead centralized form hybrid algorithm made effective main memory order minimize disk traffic expect multiprocessor version hybrid hash join algorithm memory minimize disk communications traffic finally appears control algorithms decentralized straightforward manner horizontal partitioning relations relations assumed horizontally partitioned ries disk drives system view point raw bandwidth approach aggregate bandwidth disk striping strategies garc kim brow equal number disk drives difference approach data read processed directly transmitted interconnection network processor obvious strategies distributing tuples disks drives system approach apply randomizing function tuple key attribute tuple select disk storing tuple processor maintains independent index tuples stored disk advantage approach additions made file number tuples disk remain balanced approach cluster tuples key distribute disk drives case disks processors viewed nodes primary clustered index controlling processor acts effect root page index intend investigate traditional tree balancing algorithms provide acceptable performance environment approach similar simpler clustering approach employed mdbs mdbs backend processor examine query clustering mechanism implemented backends controlling processor real advantage approach processing queries distribution strategy tuples distributed randomly case exact match queries attribute distribute tuples processors execute query distribution strategy controlling processor maintains root page index direct query processors overhead performing function cost sending query processors fairly large database root pages indices fit controlling processor main memory distribution strategies provide approximately response time single user benchmarks expect system throughput significantly higher distribution strategy multiuser environment suitable index processors perform query description multiprocessor hybrid grace algorithms algorithms section assume relations database horizontally partitioned multiple disk drives manner disk drive processor note converse necessarily true purposes performance evaluation presented assumed processors interconnected mbit token ring demonstrate interconnection topology adequate performance processors multiprocessor version grace hash-join algorithm number alternative strategies parallelizing grace hash-join algorithm approach selected evaluated assumes set processors joining partitioning phases algorithms partitioning processors assumed disk drives joining processors assumed diskless reason find strategy attractive diskless nodes cheaper nodes disks interested exploring processors effectively utilized algorithm proceeds node disk partitions smaller relation buckets written network nodes disks nodes perform join phase algorithm joining node single hash table built tuples single bucket smaller source relation hash tables completely built larger relation partitioned buckets joining nodes buckets source relations guaranteed joining node tuples larger relation probe join node hash tables matches size smaller relation exceeds aggregate memory capacity joining nodes multiple phases unused buckets temporarily saved disks attached partitioning nodes multiprocessor grace algorithm allocate varying numbers joining nodes grace algorithms named ratio partitioning nodes joining nodes grace design allocates partitioning node joining node partitioning node joining nodes grace design finally grace design allocates partitioning nodes joining node design combinations proved optimal execution single join queries case varied combinations processors prove optimal complex queries multiprocessor version hybrid hash-join algorithm multiprocessor grace algorithm employs combination processors disks multiprocessor hybrid algorithm requires processor disk drive multiprocessor hybrid hash-join algorithm performs partitioning joining phases nodes processor partitions source relations fashion similar grace algorithms node allocates excess memory partitioning phase hash table bucket tuples source relations partitioned local hybrid processor tuples written net join node tuples belonging bucket partitioning processor immediately build probe local hash table tuples processed locally hybrid hash join algorithm generates lighter network load grace algorithm level resources hybrid multiprocessor algorithm disks fewer processors grace multiprocessor algorithm discussion simulation model evaluate performance distributed hybrid grace hash-join algorithms simulation model proposed multiprocessor architecture constructed hardware components represented model intended examples current commercially components capabilities components varied test effects combinations resources distributed hashpartitioned algorithms implemented kinds network environments processors current simulation loosely coupled token ring network hardware model simulate mip processors disk drives modeled fujistu eagle drive assumed support transfer rate mbytes combined positioning latency times modeled normal distribution milliseconds standard deviation milliseconds processor network interface assumed single output buffer kbytes similar input buffer assumed effective dma bandwidth buffers filled flushed main memory processor assumed mbits mbits mbits number derived measurements made vax proteon pronet interface prot attached unibus mbits estimate dma rate device attached internal bus vax token ring assumed bandwidth mbits mbits mbits representative local network interfaces pronet token ring mbits interface mbits dma rate representative interface digital equipment corporation multiprocessor version hybrid algorithm requires processor disk drive grace algorithm employs processors disks method computing cost configuration processors disk needed approach adopted assume mip processor cost disk drive controller relative cost mip processors computed grosch law gros relates cost processor performance speed processor performance technology constant processor cost technology constant cost exponent assigned values cost configuration calculated computing aggregate cost processors disks incorporated memory communications costs cost model cost effective memory lower speed communication device cost model calculating cost configuration processors disks straightforward reverse transformation obvious assume processors mip processors hybrid join 
xxxa axxxx xxxaxxx xxxb ixxxx xxxbxxx xxxc jxxxx xxxbxxx xxxc queries illustrate string attributes utilized query selectivity factor range tenktup retrieve stringu axxxx xxxexxx xxxq range tenktup retrieve stringu bxxxx xxxgxxx xxxe stringu bxxxx xxxlxxx xxxa stringu variables initially loaded database order generated shown sort order attribute stringu assumes string values stringu position relation randomly determined outline leftmost significant letter varies frequently rightmost significant letter varies frequently thoustup relation strings give special hardware algorithms short circuit comparison strings ample opportunity demonstrate efficacy string attribute string assumes unique values axxxx xxxaxxx xxxa hxxxx xxxhxxx xxxh oxxxx xxxoxxx xxxo vxxxx xxxvxxx xxxv string select selectivity factors partitioning integer attribute wisconsin benchmark developed standard set queries measure cost relational operations selection selectivity factors projection percentages duplicate attributes single multiple joins simple aggregates aggregate functions updates append delete modify addition queries designed variations advantage primary index secondary index typically variations obtained unique attribute case unique attribute indices queries measurements database queries built decide measure time resources consumed run decision start extensive sequence stand-alone runs made benchmarks run systems single user mode built mechanism set runs queries run time strictly sequential pattern measurements obtained performance query separate stand-alone program impact system overhead open database command diminished running similar queries sequence taking average time system evaluated provided facilities gathering detailed statistics resources cpu disk transfers consumed query consideration decided elapsed time main performance measure backend machines idm direct time elapsed time host machine effects database buffer size benchmark tests queries primarily referenced tuple relation relation approximately bytes long million bytes buffer space active portion database fits memory results tests interesting fit users view reality modified queries tuple relations approximately megabytes size addition order minimize effect buffer size running repeated queries query run ten times alternating tuple relations strategy combined megabyte buffer space allocated systems tested query leave buffer pool query benchmark measurement analysis section present subset benchmark measurements analyze results divided section subsections subsection relational operations selection projection join aggregates updates delete append modify type query describe main criteria compare systems effects attempting measure determining criteria straightforward period time running benchmarks preliminary results forced change queries order gain insight impact parameter long series benchmarks realized cost duplicate record elimination factor made comparisons meaningless alternative ways measuring time required query retrieve selected tuples relation writing disk display user terminal alternatives drawbacks command time unix vms date producing result relation ingres retrieve statement side effect checking removing duplicate tuples result relation time obtained retrieval query includes time perform duplicate elimination alternative retrieve result tuples screen case times queries retrieve large number tuples measured time transfer large amount data terminal time required database management execute query principal solution choose place result tuples relation eliminating duplicate tuples -rheap option ingres discovered duplicate elimination turned wanted examine impact communications channel idm host selected queries retrieved results screen problem faced filtering meaningful results vast quantities raw data produced original benchmark runs contained queries showing impressive overwhelming collection numbers decided choose representative sample results query type sample small presented paper omitting information support conclusions choices resulted number tables show elapsed time seconds representative queries classes analysis subsections concentrates numbers shown tables complete listing queries evaluated contained appendix iii selection queries speed database system machine process selection operation depends number factors including storage organization relation impact selectivity factor result tuples produced query impact specialized hardware cost sending result tuples screen compared cost storing relation benchmark investigated impact factors determining impact storage organization performance query evaluated storage organizations result tuples dev null unix equivalent black hole avoid measuring print speed terminal cost formatting tuples screen display measured context queries selection queries found easier isolate cost factors context heap organization unstructured storage organization tuple order corresponds order tuples loaded relation organization suitable secondary storage structures enhancing performance evaluated organization reasons information fast system process arbitrary ad-hoc query understand real systems generally index nice features relational system users pose arbitrary unanticipated queries database system addition measuring response time heap organization query run presence suitable index understand performance improvement obtained index heap organization storage organization supported direct direct designed notion massive parallelism substitute indexing efficient algorithms results presented necessarily reflect performance direct configuration processors results illustrate limitations direct design index key attribute case relation sorted clustered attribute index constructed commercial versions ingres isam organization case oracle idm b-tree mechanism case hash key attribute case tuple placement randomized applying hashing function key attribute access mechanism ingres queries returned single tuple table index non-key attribute case relation sorted attribute index constructed versions ingres dense secondary index obtain storage structure index stored isam structure oracle idm b-tree mechanism support type index determine selectivity factor query influences performance storage structure system varied selection criteria produce result relations range sizes selectivity factors considered addition measured time retrieve unique tuple table examination results tests revealed queries selectivity factors tuple representative relative performance systems impact specialized hardware evaluated running queries indices idm database accelerator dac turned results experiments shown tables response times presented represent average time based test set ten queries selectivity factor draw number conclusions results presented tables clear tables conventional disk drives parallelism reasonable substitute indexing mechanism tempted conclude results processors repeated experiments direct processors results presented table results additional processors improve situation parallel-readout disk drive dewi analysis impact parallel readout disk drive selection times table selection queries indices integer attributes result tuples inserted relation total elapsed time seconds number tuples selected tuple relation system u-ingres c-ingres oracle idmnodac idmdac direct sql table selection queries indices result tuples inserted relation integer attributes total elapsed time seconds number tuples selected tuple relation clustered index non-clustered index system u-ingres c-ingres oracle idmnodac idmdac direct sql table selection queries clustered indices integer attributes result tuples displayed screen total elapsed time seconds number tuples selected tuple relation system u-ingres c-ingres oracle idmnodac idmdac direct sql indices presentation detailed analysis performance direct scope paper preparation paper progress results analysis selection queries limiting factor disk drive back-end controller software multiport memory results reinforce conclusions made bora conventional processors hundreds processors custom vlsi components process selection queries rate conventional disk 
drives table interesting result cost coordinating processors working parallel interested direct slower idm commercial ingres selecting tuples suitable index examination direct spends time revealed seconds required execute query seconds spent passing messages query processors table time direct select tuples number processors execution time secs secs secs secs processes form back-end controller puzzled oracle poor performance executing trivial query table queries evaluated single relational operator access planner culprit size buffer pool factor page relation accessed pages buffer space minimal page hold page processed page read page page writing previous result page problem area lies access method query execution code determine problem lies obvious system performance problems estimating speedup obtained database accelerator comparing idmdac idmnodac numbers surprised find table low selection indexed attribute table interesting result illustrated tables versions ingres selecting tuples non-key index slower heap organization plausible explanation non-key non-clustered index number pages accessed multiple times byte pages source relation occupies approximately data pages scanning relation heap fashion requires page accesses hand selecting tuples selectivity factor non-key index require page accesses main conclusion drawn query optimizer failed recognize index process query table included selected measurements illustrate extra cost incurred displaying results query user screen direct idm includes moving tuples database machine host formatting display conventional systems measurements reflect cost formatting tuples display index case shown differences non-index case hidden long retrieval time show low selectivity factors single tuple user table tuples screen times obtained direct hardware modified pass messages multiport memory messages earlier version direct mbit local network messages times slow important realize cases makes message passing slow speed hardware layers software put hardware purposes reliability direct tuples moved memory idm tuples moved communication interface terms absolute time process tuples approximately additional required commercial ingres idm systems display tuples basically identical fashion conclude performance backend database machine marginally affected cost transferring result tuples host computer terms relative time significant commercial ingres slower idm dac slower idm dac slower note retrieving relation measurements account cost writing result relation disk eliminating duplicate records comparing tables comparing cost writing results disk cost formatting displaying tuples screen measuring cost duplicate elimination important isolate cost components selection queries reason chose measurement context projection queries section join queries join queries interested investigating number issues interested query complexity affected relative performance systems considered range queries degrees complexity curious join algorithms systems running join queries stand-alone basis make verify efficiently buffer management strategy system supported algorithms join algorithm determines page string knew priori indices ingres nested loops join storage structure copy relation converted hashed organization join initiated commercial ingres primarily sort-merge join techniques idm dac oracle simple nested loops join algorithm direct parallel version dewi simple nested loops join algorithm interested systems advantage secondary indices joining attributes finally wanted database accelerator impacted join times criteria mind built set ten representative join queries source relations ten thousand tuple relations selection performed join size operand relation reduced factor ten ten thousand tuples length bytes source relation substantial activity make visible effect varying input parameters query complexity join selectivity factors query complexity modeled performing join selection operations joinaselb selects relation joins selected relation joinselaselb selects join complex join query involves selections joins joincselaselb preliminary analysis decided filter results measurements present timings smaller set join queries tables names queries describe contents reader refer appendix join queries explicitly listed observation joins type queries system performance varies widely kind assumptions made indices versus indices special hardware versus special hardware complex versus simple join measurements show joins indices commercial ingres system provide acceptable performance dramatic improvement ingres due sort-merge algorithm ingres direct previous experiments results presented found idm dac achieve reasonable level performance joins indices relations smaller fit memory hand tuple relations suitable indices performance oracle idm dac unacceptable building index table join queries indices integer attributes total elapsed time minutes query system joinaselb joinabprime joincselaselb u-ingres c-ingres oracle idmnodac idmdac direct sql table join queries indices integer attributes total elapsed time minutes primary clustered index join attribute query system joinaselb joinabprime joincselaselb u-ingres c-ingres oracle idmnodac idmdac direct sql table join queries indices total elapsed time minutes secondary nonclustered index join attribute query system sjoinaselb sjoinabprime sjoincselaselb u-ingres c-ingres oracle idmnodac idmdac direct sql on-the-fly idm user smarter query optimizer obtain excellent performance query joinaselb restricted form joined produce result relation writing query idl command user forms permanent indices constructs index join attribute final performs join observed execution time query reduced hours seconds parallelism direct provided limited improvement performance selection operations parallelism significant impact join operations execution times query joinaselb processors presented table table direct joinaselb execution times number processors execution time speedup factor secs secs secs secs based preliminary analysis experiment appears back-end controller bottleneck processors clear limited parallelism dumb algorithm provide level performance smart algorithm parallelism indices exist performance idm join operations excellent dac improves idm performance factor interesting result performance commercial ingres closer idmdac complex joins simple joins joinabprime faster idmdac joincselaselb times faster query optimizer commercial ingres appears efficient case complex join queries note query joincselaselb performs selections tuple relations joins tuple relations figure cost query slightly higher cost selections secs compared secs indices curious anomaly fact joinaselb selection join ran faster joinabprime join selection commercial ingres explanation query optimizer allocated memory executing joinaselb joinabprime operand relation larger file figure figure joincselaselb bprime projection queries implementation projection operation phases pass made source relation discard unwanted attributes phase order eliminate duplicate tuples introduced side effect phase elimination attribute key part key phase requires complete scan relation phase performed steps relation sorted bring duplicate tuples sequential pass made sorted relation comparing neighboring tuples identical secondary storage structures indices performing operation initial benchmark contained queries projected attributes produced result relations variety sizes queries indicative results observed query reduces tuple relation tuples query projection tuple relation duplicate tuples eliminated result relation sorted scanned duplicates query estimate cost checking tuple result relation arbitrary query duplicates section order make estimate accurate wanted minimize effects accomplished running sequence copies query dividing total run time observation table high cost projection compared selection index idm accelerator requires seconds select tuples 
times long produce distinct tuples projection duplicate elimination interesting result speedup provided dac query results tuples speedup factor test speedup factor tuple relation fit main memory difference reflects additional cpu power provide dac finally algorithm direct employs poor performance relation fit disk cache due technical difficulties processors utilized table projection queries duplicate tuples removed total elapsed time seconds system u-ingres c-ingres oracle idmnodac idmdac direct sql brbr aggregate queries considered simple aggregate operations minimum attribute complex aggregate functions tuples relation partitioned non-overlapping subsets partitioning aggregate operation min computed partition complex aggregate functions repeated experiments wide range partition sizes selecting partitioning attribute attributes selectivity factors tables retained results representative queries minimum key attribute aggregate functions partitions objective queries examine query optimizers attempt indices reduce execution time queries min key query smart query optimizer recognize query executed index aggregate function queries anticipated attempt secondary non-clustered index partitioning attribute slow query scan complete relation index generally result data page accessed times alternative algorithm ignore index sort partitioning attribute make final pass collecting results algorithm works number partitions large make single pass relation hashing partitioning attribute table aggregate queries indices total elapsed time seconds query type system min scalar min aggregate sum aggregate aggregate function function partitions partitions u-ingres c-ingres oracle idmnodac idmdac direct sql table aggregate queries indices total elapsed time seconds query type system min scalar min aggregate sum aggregate aggregate function function partitions partitions u-ingres c-ingres oracle idmnodac idmdac direct sql mixed results tests puzzled relative performance ingres commercial ingres page size commercial ingres ingres discussion results staff relational technology revealed aggregate function code changed speculate difference performance consequence fact unix read-ahead write-behind sequential access file vms indices appears ingres idm query optimizer chose ignore index cases decision leaves systems slow scalar aggregate operation alternative execution aggregate functions finally dac reduces time scalar aggregate proportion similar selection queries speedup observed improves significantly performance aggregate functions speedup update queries numbers presented tables obtained stand-alone updates delete append modify principal objective queries impact presence clustered clustered indices cost updating appending deleting tuple realistic evaluation update queries require running benchmarks multiprogramming environment effects concurrency control deadlocks measured results expected systems advantage index locate tuple modified overshadows cost updating index compare times delete tuple modify tuple tables noted updates performed significant reorganization index pages reader aware indices table update queries indices total elapsed time seconds query type system append delete modify tuple tuple tuple key attr u-ingres c-ingres oracle idmnodac idmdac sql updates broken direct benchmarks run predict appending tuple direct seconds deleting modifying tuple approximately seconds time scan relation table table update queries indices total elapsed time seconds query type system append delete modify modify tuple tuple tuple tuple key attr non-key attr u-ingres c-ingres oracle idmnodac idmdac sql constructed updated relation clustered index secondary indices observation surprised low cost append compared cost delete no-index case explanation discrepancy systems append tuples checking present relation appending tuple involves writing tuple deleting tuple requires scanning entire relation hand clustered index deleting faster appending tuple apparently index modified tuple physically deleted performance systems modify non-key modify tuple identified qualification non-key attribute demonstrates efficient secondary index locate tuple argue algorithm query require verifying modified tuple introduce inconsistency duplicating existing tuple conclusions future research paper presented design customized database comprehensive set queries systematic benchmarking relational database systems designing database set carefully tuned benchmarks represents attempt developing scientific methodology performance evaluation database management systems paper presented interpreted results applying tests conventional database management systems database machines main limitation present study addresses single user case point admit benchmark exhaustive comparison systems realistic approximation measurements multiuser environment found limiting experiments standalone queries systematic isolate effects specific hardware configurations operating system features query execution algorithms reason single user case constitutes baseline measure interpretation multiuser benchmark results recently begun benchmark systems multiuser environment identified main parameters intend explore multiprogramming level degree concurrently executing transactions relations query mix acknowledgments large number people deserve making paper rakesh agrawal helped design relations queries benchmark allen bricker don neuhengen deserve direct britton-lee incorporated relational technology incorporated tektronix support benchmarking process handful database accelerators running began benchmarking process britton-lee generously made dac mike ubell britton-lee helping run benchmarks remotely derek frankforth bob kooi trudi quinn larry rowe rti bringing benchmark vms donna murphy glen fullmer tektronix deserve oracle finally haran boral suggestions earlier drafts paper babb babb implementing relational database means specialized hardware acm tods vol march bane banerjee baum hsiao concepts capabilities database computer acm tods vol dec bitt bitton dewitt duplicate record elimination large datafiles acm transactions database systems bora boral dewitt friedland jarrell wilkinson implementation database machine direct ieee transactions software engineering november bora boral dewitt database machines idea time passed critique future database machines proceedings international workshop database machines munich germany september cham chamberlin boyce sequel structured english query language proceedings acm sigmod workshop data description access control dewi dewitt direct multiprocessor organization supporting relational database management systems ieee transactions computers june dewi dewitt hawthorn performance evaluation database machine architectures invited paper large database conference september epst epstein hawthorn design decisions intelligent database machine proceedings national computer conference hawt hawthorn dewitt performance evaluation database machines ieee transactions software engineering march idm idm manual britton-lee los gatos california mcgr mcgregor thomson dawson high performance hardware database systems systems large databases north holland ozka ozkarahan schuster smith rap associative processor database management afips conference proceedings vol ozka ozkarahan schuster sevcik performance evaluation relational associative processor acm transactions database systems vol june ston stonebraker wong kreps design implementation ingres acm tods september ston stonebraker retrospection database system acm tods june ston stonebraker operating system support database management communications acm july stanley jack lipovski cassm cellular system large data bases proceedings vldb conference pages ubel ubell intelligent database machine database engineering vol dec appendix schema specification ingres benchmark create onektup unique unique twoa foura tena twentya hundreda thousanda twothousa fivethousa tenthousa odd stringu stringu string create twoktup unique unique twob fourb tenb twentyb hundredb thousandb twothousb fivethousb tenthousb odd stringu stringu string create fivektup unique unique twoc fourc tenc 
twentyc hundredc thousandc twothousc fivethousc tenthousc odd stringu stringu string create tenktup unique unique twod fourd tend twentyd hundredd thousandd twothousd fivethousd tenthousd odd stringu stringu string create tenktup unique unique twoe foure tene twentye hundrede thousande twothouse fivethouse tenthouse odd stringu stringu string queries construct bprime bprime range tenktup retrieve bprime unique range tenktup retrieve bprime unique appendix specification storage structures ingres benchmark query table column modify tenktup hash unique modify tenktup hash unique queries indices modify tenktup isam unique index tenktup unique index tenktup hundredd modify isam unique modify isam hundredd modify tenktup isam unique index tenktup unique index tenktup hundrede modify isam unique modify isam hundrede appendix iii benchmark queries ingres format range tenktup range tenktup selection selectivity factor table column table column retrieve skr unique retrieve skr unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique selection selectivity factor table column table column retrieve skr unique retrieve skr unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique selection selectivity factor non-clustered index table column retrieve skr unique retrieve skr unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique selection selectivity factor non-clustered index table column retrieve skr unique retrieve skr unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique retrieve skr unique unique select tuple screen table column retrieve unique retrieve unique retrieve unique retrieve unique retrieve unique retrieve unique retrieve unique retrieve unique retrieve unique retrieve unique selection selectivity factor retrieve screen table column retrieve unique retrieve unique retrieve unique unique retrieve unique unique retrieve unique unique retrieve unique unique retrieve unique unique retrieve unique unique retrieve unique unique retrieve unique unique joinaselb table column table column range tenktup range tenktup retrieve tmpj unique unique unique range tenktup range tenktup retrieve tmpj unique unique unique joinabprime table column table column range tenktup range bprime retrieve tmpj unique unique range tenktup range bprime retrieve tmpj unique unique joincselaselb table column table column range onektup range tenktup range tenktup retrieve tmpj unique unique unique unique unique unique range onektup range tenktup range tenktup retrieve tmpj unique unique unique unique unique unique sjoinaselb table column range tenktup range tenktup retrieve tmpj unique unique unique range tenktup range tenktup retrieve tmpj unique unique unique sjoinabprime table column range tenktup range bprime retrieve tmpj unique unique range tenktup range bprime retrieve tmpj unique unique joincselaselb table column range onektup range tenktup range tenktup retrieve tmpj unique unique unique unique unique unique range onektup range tenktup range tenktup retrieve tmpj unique unique unique unique unique unique projection query selectivity factor table column range tenktup range tenktup retrieve pro twod fourd tend twentyd hundredd string retrieve pro twoe foure tene twentye hundrede string projection query table column range onektup retrieve unique pro scalar aggregate table column table column range tenktup range tenktup retrieve min min unique retrieve min min unique retrieve min min unique retrieve min min unique aggregate function min table column table column range tenktup range tenktup retrieve min min twothousd hundredd retrieve min min twothouse hundrede retrieve min min twothousd hundredd retrieve min min twothouse hundrede aggregate function sum table column table column retrieve sum sum twothousd hundredd retrieve sum sum twothouse hundrede retrieve sum sum twothousd hundredd retrieve sum sum twothouse hundrede deletion queries table column table column range tenktup range tenktup delete unique delete unique delete unique delete unique delete unique delete unique delete unique delete unique delete unique delete unique modify key attribute table column table column range tenktup range tenktup replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique modify non-key attribute table column replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique replace unique unique append queries table column table column append tenktup unique unique twod fourd tend twentyd hundredd thousandd twothousd fivethousd tenthousd odd stringu stringu string append tenktup unique unique twoe foure tene twentye hundrede thousande twothouse fivethouse tenthouse odd stringu stringu string append tenktup unique unique twod fourd tend twentyd hundredd thousandd twothousd fivethousd tenthousd odd stringu stringu string append tenktup unique unique twoe foure tene twentye hundrede thousande twothouse fivethouse tenthouse odd stringu stringu string append tenktup unique unique twod fourd tend twentyd hundredd thousandd twothousd fivethousd tenthousd odd stringu stringu string append tenktup unique unique twoe foure tene twentye hundrede thousande twothouse fivethouse tenthouse odd stringu stringu string append tenktup unique unique twod fourd tend twentyd hundredd thousandd twothousd fivethousd tenthousd odd stringu stringu string append tenktup unique unique twoe foure tene twentye hundrede thousande twothouse fivethouse tenthouse odd stringu stringu string append tenktup unique unique twod fourd tend twentyd hundredd thousandd twothousd fivethousd tenthousd odd stringu stringu string append tenktup unique unique twoe foure tene twentye hundrede thousande twothouse fivethouse tenthouse odd stringu stringu string 
sigmod partition based spatial merge join jignesh patel computer sciences department wisconsin madison jignesh wisc david dewitt computer sciences department wisconsin madison dewitt wisc abstract paper describes pbsm partition based spatial merge algorithm performing spatial join operation algorithm effective inputs join index joining attribute situation arise inputs join intermediate results complex query parallel environment inputs dynamically redistributed pbsm algorithm partitions inputs manageable chunks joins computational geometry based plane sweeping technique paper presents performance study comparing traditional indexed nested loops join algorithm spatial join algorithm based joining spatial indices pbsm algorithm comparisons based complete implementations algorithms paradise database system handling gis applications real data sets performance study examines behavior spatial join algorithms variety situations including cases inputs join suitable index study examines effect clustering join inputs performance join algorithms performance comparisons demonstrates feasibility applicability pbsm join algorithm introduction increasing popularity automated processes fields earth sciences cartography remote sensing land information systems rapid increase availability data wide variety sources satellite images mapping agencies simulation outputs decade witnessed increase demands systems store manage manipulate spatial data increasingly database system employed meet requirements examples commercial database systems applications arc info arc intergraph mge cor illustra ube data stored spatial database systems includes simple geometric types points lines polygons surfaces work partially supported nasa contracts usra nagw nagw ibm research initiation grant complex types swiss cheese polygons polygons holes derived simpler geometric types spatial database system support queries spatial objects efficiently spatial database users frequently combine spatial inputs based spatial relationship objects inputs map overlap requires combining maps produce important operation spatial database bur mgr operation combining inputs based spatial relationship called spatial join spatial joins counterparts relational system expensive operation efficient spatial join algorithms critical component spatial database system representation spatial object large spatial object representing swiss cheese polygon require thousands points represent exact geometric shape spatial operations including spatial join typically operate steps ore filter step step approximation spatial object minimum bounding rectangle eliminate tuples part result step produces candidates superset actual result candidates represented pair object identifiers refinement step step candidate examined requires fetching pair objects disk check part result check generally requires running cpu intensive computational geometry algorithm numerous algorithms proposed execute filter step spatial join earlier algorithms based transforming approximation spatial object domain dimensional domain performing filter step domain ore bhf drawback approach domain spatial proximity information lost making algorithms complex efficient newer algorithms based spatial indices performing filter step spatial join bks require spatial index join inputs tree join algorithms synchronized depth sigmod searches indices depth searches guided hints spatial indices exist inputs join base relations situations join input spatial index built situation arise inputs join intermediate results complex query parallel environment inputs dynamically redistributed spatial dbms evaluate joins efficiently solution problem build spatial index inputs tree join algorithm solution problem vlsi domain compute pairwise intersection potentially large sets rectangles don fit main memory vlsi algorithms generally efficient respect number disk paper makes contributions presents spatial join algorithm called partition based spatial merge pbsm join require indices inputs algorithm partitions inputs manageable chunks joins chunks computational geometry algorithm considered spatial equivalent sort merge algorithm incorporates complete solution spatial join problem performs filter refinement step includes results comprehensive performance study spatial join algorithms simple indexed nested loops based join algorithm tree based join algorithm pbsm algorithm performance study based actual implementations algorithms paradise dkl experimental gis database system real data tiger tig sequoia sfgm data sets study examines behavior algorithms variety situations including cases inputs join suitable index study investigates effect clustering join inputs tree based join algorithms considered earlier performance studies multiple inserts build index fact bulk loading index efficient performing multiple inserts construct buffer pool size paradise takes seconds bulk load objects -tree index seconds build index multiple inserts study indexed nested loops tree based join algorithms required indices built paradise bulk loading mechanism remainder paper organized section summarizes related work area section describes pbsm algorithm performance study comparing spatial join algorithms presented section finally section conclusions future plans related work mentioned introduction spatial join algorithms operate steps filter step refinement step spatial join algorithms proposed previously solve filter step section summarize relevant work area section term spatial join refer filter step spatial join ore orenstein proposes approach based approximate geometry universe spatial data regularly decomposed superimposing grid element grid called pixel spatial objects approximated pixels overlap pixel spatial location transformed dimensional domain applying mapping called order transformed values called values spatial join algorithm merges sequences values values dimensional values stored traditional indexing structures tree performance spatial join algorithm values found sensitive choice grid ore choosing fine grid increases efficiency filtering technique increases space requirement larger number values required approximate object relational domain val proposed join indices improve performance relational join operator drawing analogy rotem rot proposed spatial join index partially precomputes results spatial join algorithm building spatial join index requires grid files indexing spatial data grid files compute spatial join index grid files nhs trees ben ben employed evaluating multi attribute joins relational domain kht hnkt bhf methods evaluating filter step storing bounding box spatial objects points higher dimension bhf recently spatial index structures trees gut trees cfr trees bkss pmr quad trees speed evaluation spatial join analytical models unther compares join algorithms generalization trees class tree structures includes r-tree -tree tree nested loops join join indices study concludes low join selectivities join indices provide join performance higher join selectivities generalization trees efficient proposed join algorithm generalization trees similar join algorithm trees proposed brinkhoff kriegel seeger bks algorithm tree index exists join inputs synchronized depth search indices depth searches guided hints similar tree joins proposed sigmod require index operate index transform values join indices rot approximation grid files hnkt bhf values ore dimension trees kht hnkt approximation synchronized tree external vlsi algo directly traversal bks pbsm dimensional space build indices joining spatial hash join table classification spatial join algorithms data structures hoel samet propose tree join algorithm pmr quad tree compare efficiency variants pmr quad tree variants tree inputs spatial join spatial index ravishankar propose building seeded 
configuration cost consist processors disks grace configuration partitioning processors join processor cost consist partitioning processors disks joining processors grace configuration cost configuration partitioning nodes disks joining nodes cost configuration cost likewise grace configuration cost closest partitioning processors disks join processors facilitate interpretation results presented summarized table resource costs alternative hardware configurations assuming mip processors algorithms hybrid grace configurations evaluated mip processors cost configuration cases table determine hardware configuration data point software operation simulated processor controlled simple operating system kernel preemptive scheduler processes priorities resolve contention system resources price performance relationship ibm system series correlates cost exponent siew note case grace algorithm performance processors partitioning joining nodes resource hybrid grace grace grace cost number processors number disks number partitioning processors number joining processors table resource costs hash-join configurations mip processors minimize overhead disk transfers track kbytes time garc addition double buffer open file process processing track track read maximum packet size supported network assumed bytes proposed multiprocessor join algorithms require large blocks data transferred communications device end model built modified sliding window protocol insures reliable delivery large blocks data enhancing effective throughput network transfers control contention receivers higher-level connection-based communications protocol incorporated simulation model issue memory size bucket overflow preliminary results presented assume smaller relations joined fits aggregate memory processors joining assumption true number cases base design machine assumption assume processors partitioning rams megabyte memory boards common rams typical memory board hold megabytes data memory boards aggregate megabytes holding buckets assumes smaller relation produced applying selection operation megabytes hold temporary relations addressed issue bucket overflow size bucket larger memory joining processor bucket assigned occur case size smaller relation total memory preliminary results evaluate performance algorithms tuple relations joined result relation contained tuples mip processors network bandwidth dma rate held constant varying resources multiprocessor hybrid join algorithm configurations multiprocessor grace algorithm throughput measured terms queries minute performance metric conducted wide range tests included results obtained network bandwidth mbits dma rate mbits summary results obtained configurations contained section cost displaying saving result relation configuration results displayed performance obtained multiprocessor hybrid join algorithm configurations multiprocessor grace algorithm displayed figures mip processors results exciting represent breakthrough designing architecturally simple high speed database machine type processor linear speedups obtained increasing level resources mip processors grace configuration higher throughput rate wide range resources principal reason mip processors average cpu utilization hybrid design grace design larger number processors resource cost level cpu bound total resource cost equal grace design partitioning nodes join nodes disks comparison resource cost hybrid design processors disks average disk utilization approximately hybrid design grace design hybrid advantage source relations partitioned larger number disks resource cost level significant factor figure presents throughput results case processors assumed mip processors test hybrid processors longer cpu bound hybrid algorithm outperforms grace design combinations balanced nature processing requirements query favor hybrid grace designs allocate balanced processor resources grace designs perform lower processor utilizations resulting mismatch processor resources figure presents throughput results mip processors increased processor performance favors hybrid design processes bucket relation local processor grace designs utilize increased processor performance magnitude network data transfers impediment increased performance resource utilizations mip processors performance multiprocessor hash-join algorithms necessarily depend algorithms utilize hardware resources hybrid algorithm intrinsic advantage sending smaller number tuples communications network hand hybrid algorithm imposes greater load processors figure presents resource utilization levels multiprocessor hybrid algorithm mip processors high cpu utilization levels reflect fact processor hybrid algorithm partitioning joining phases algorithm initial increase cpu utilization caused transition algorithm single processor processors single processor hybrid design utilize network processor hybrid design expend substantial amount processing effort transferring buckets tuples processors additional processors added hybrid algorithm cpu utilization processors begins decline decline corresponds increased level contention network level contention network increases processors frequently query grace designs transfer larger amount data network hybrid design blocked waiting transfer blocks data network increased levels network contention result increase total utilization network low disk utilizations result fact data read disk track time disk blocking factor disk frequently idle previously read tuples partitioned figure presents resource utilizations grace multiprocessor algorithm design mip processors relative cpu utilizations partitioning nodes joining nodes reflect fact partitioning phase computationally expensive phase hash-join algorithm cpu utilizations partitioning nodes joining nodes decrease levels network contention increase cpu utilizations grace processors lower cpu utilizations presented hybrid algorithm due fact resource level grace algorithm greater number processors hybrid algorithm conversely fact grace algorithm fewer disks hybrid algorithm resource level leads higher disk utilizations grace algorithm tests similar results obtained varied network bandwidth dma rate network bandwidth mbits dma rate mbits slowest configuration tested linear speedups obtained approximately resource cost point network tended completely utilized throughput remained constant chosen type processors partitioning joining nodes alternative grace designs join queries varied distributions join attribute values provide possibility altering balance performance processing joining nodes plan investigating alternative disk blocking factors reduced low kbytes significantly altering performance algorithms actual point varied mip rate processors conclusions future research paper hash-join algorithms presented dewi extended multiprocessor architecture step algorithms dewi implemented wiss chou running vax running berkeley unix addition providing cpu utilization figures simulation multiprocessor algorithms centralized experiments provided interesting results measured performance algorithms similar predicted analytically dewi bit vector filtering babb shown provide dramatic reduction execution time algorithms including sort merge join algorithm fact query tested bit-vector filtering algorithms virtually execution time extended centralized grace hybrid hash-join algorithms common multiprocessor configuration centralized algorithms chosen provide natural point separating joining partitioning phases algorithm multiprocessor hybrid algorithm multiprocessor configuration consisting nodes disk drive nodes partitioning join phases algorithm configurations multiprocessor grace algorithm evaluated grace grace grace design diskless joining processor allocated partitioning processor design allocates partitioning nodes diskless joining node design partitioning node diskless joining nodes results simulation experiments algorithms encouraging algorithms provide linear increases throughput increases processor disk resources interesting extensions research exploring term adjustable join parallelism adjusting partitioning algorithms number buckets produced adjusted turn effects parallelism joining phase partitioning phase produces buckets processors joining phase number cases technique load balancing heavy loads constrained requirement bucket expected fit memory joining processor equivalently multiple buckets assigned join processor bucket active time 
tree index input seeded tree tree allowed height unbalanced algorithm constructing seeded tree existing index inputs starting point minimize number random incurred tree construction indices joined tree join algorithm bks ravishankar extend work handle case inputs index approach spatial sampling techniques constructing seeded trees inputs seeded trees joined tree join algorithm bks problem finding pairwise intersection sets rectangles extensively studied vlsi domain numerous solutions exist case input set rectangles fit memory uting shilling examine rectangle intersection problem inputs large fit memory analyze time space complexity algorithms based external computational geometry algorithms algorithms efficient respect number disk cases require logarithmic number passes input concurrent work pbsm ravishankar proposed spatial hash join algorithm aspects similar pbsm spatial hash algorithm partitions inputs joins partitions upper levels seeded tree partition function filtering technique employed partitioning phase performance study based counting number disk presented ignores expensive refinement step summarize classify algorithms shown table partition based spatial merge join section describes algorithm called partition based spatial merge pbsm join evaluating spatial join sake concreteness denote inputs join assume inputs sequence tuples tuple spatial attribute join condition assume system unique identifier tuple unique identifier referred oid tuple pbsm algorithm operates steps filter step spatial attribute involved join complex spatial feature polygon polyline swiss cheese polygon step pbsm algorithm makes approximation spatial feature rough estimate characteristics spatial attribute minimum bounding rectangle mbr approximation step filter step partitioning partition large inputs smaller chunks computational geometry plane sweeping technique join chunks result filter step set oid pairs oid pair refers tuple input oid refers tuple input pair mbr spatial join attribute tuple overlaps mbr spatial join attribute tuple refinement step overlapping spatial features overlapping mbrs filter step joins inputs based mbr joining attributes filter step generally produce superset join result refinement step tuples represented oid pair produced previous step fetched disk join attributes examined determine join predicate satisfied section describes filter step detail section describes refinement step filter step filter step pbsm algorithm begins reading tuples input tuple input mbrof joining attribute oid tuple collectively called key pointer element appended temporary relation disk denote relation similarly input read relation produced goal filter step pair tuples mbrs join attributes overlap mbrsfor join attributes inputs problem simplifies sigmod finding mbrs intersect mbr rectangle intersection mbrs rectangles extensively studied computational geometry field sets rectangles sets fit main memory efficient computational geometry algorithms based plane sweeping techniques exist reporting pairs intersecting rectangles sets fit memory plane sweeping algorithm find pairs ofr ands key pointer elements overlappingmbrs matching key pointer elements pairs oid information extracted oid pair added output step large fit memory divided disjoint partitions partitions formed key pointer element partition key pointer elements overlapping mbrare present partition size partitions fit simultaneously memory form partitions spatial partitioning function spatial partitioning function works catalog information joining attribute input algorithm estimates universe input universe spatial join attribute rectangle minimum cover join attribute tuples input universe decomposed subparts number partitions figure number partitions finally spatial partitioning function section details applied mbr key pointer element partitioning function determines subparts universe mbr overlaps inserts key pointer element partition subparts mbr overlaps multiple subparts universe inserted multiple partitions key pointer element object shown figure inserted partitions universe polygon attribute mbr partition partition partition partition figure spatial partitioning function inputs partitioned algorithm joins partitions computational geometry based plane sweeping technique technique bks joining entries tree nodes thought spatial equivalent sort merge algorithm details algorithm merging partitions mbr xlrepresent lower x-coordinate mbr mbr xurepresent upper x-coordinate inputs sequence key pointer elements sorted lower values mbr mbr mbrsfrom key pointer elements examined mbr smaller mbr selected denote mbr assume belongs inputr key pointer elements input scanned key pointer element mbrhas mbr xlvalue greater reached effectively elements overlap axis scanned elements checked overlap axis overlap exists oid pair oids key pointer elements added result result filter step set oid pairs marked processed removed consideration input algorithm continues picking unprocessed part inputs element smallest mbr smallest element joined elements input continues inputs fully processed refinement step checking candidate oid pairs exact match joining pair partitions result relation tuples form oid oid mbrof joining attribute tuple oid overlaps mbrof joining attribute tuple oid partitioning filter step insert tuple multiple partitions duplicates relation refinement step eliminates duplicates examines actual tuples determine attributes satisfy join condition avoid random seeks fetching tuples strategy similar val employed oid pairs sorted oid primary sort key oid secondary sort key duplicates entries eliminated sort tuples fit memory read disk array oid oid pairs theoid part array swizzled point tuples memory array sorted onoid makes accesses sequential tuples read sequentially memory join attributes tuple checked determine satisfy join condition check overlap speeded organizing mbrsof overlap axis interval tree sigmod determining number partitions number partitions pbsm algorithm estimated follow jjrjj represent cardinality input jjsjj represent cardinality input represent size main memory bytes size key ptr denote size key pointer element mbr oid pair bytes plane sweep algorithm merging partitions requires partitions fit memory number partition computed jjrjj jjsjj size key ptr choosing spatial partitioning function explore alternatives exist selecting spatial partitioning function spatial partitioning function section decomposes universe subparts number partitions determined equation presence uniform distribution partitioning function produce partitions large differences sizes figure number partitions tuples top left corner spatial partitioning function map tuples partition partitions hand tuples universe partition partition partition partition figure spatial partitioning skew remedy situation partitioning function pbsm decomposes universe regularly tiles greater equal starting upper left corner tiles numbered tile mapped partition scheme round robin hashing figure universe divided tiles number partitions tiles mapped partitions round robin scheme tiles mapped partition tiles mapped partition tiles mapped partition apply spatial partitioning function mbr tiles overlap mbr determined tile key pointer element mbr inserted partition mbr overlaps tiles multiple partitions key pointer element inserted partitions key pointer element object shown figure inserted partitions universepolygon attributembr tile part tile part tile part tile part tile part tile part tile part tile part tile part tile part tile part tile part figure spatial partitioning function tiles spatial partitioning function spatial analog virtual 
constant cost sampling relative cost reading relation diminishes sort-merge band join standard sort-merge join algorithm equijoins adapted handle band joins case band joins algorithm expected backup case equijoins scans pick joining pairs tuples implementation sort-merge complicated optimization skipping nal merge sort performing join nal set runs completely sorted relations detail optimization band sort-merge algorithm general section focus question handle backing-up nal joining merge suppose wehave sorted nal set runs merge produce sorted relations general idea band merge-join times wehave memory ers page run page run window pages fully sorted relation pages window sorted relation numbered recent page tuples merged runs atany time tuple smallest anyofther sorted runs wewere proceeding nal merge sort thenr tuple added output tuple probe tuples window searching joining tuples join tuples page eliminated pool subsequent tuple join tuple note write disk referred joins tuple sorted order page page tuples merged runs finally deleted page run whichitwas tuple page page run read memory analytic comparison section give simple cost formulas evaluating relative performance sort-merge band join variants partitioned band join algorithm hybrid grace partitioning formulas omit cost creating answer tuples writing answer cost similar algorithms algorithms set parameters comp compare keys keyswap exchange twokeys move moveatuple swap swap tuples ioseq sequential iorand random assume tuples page jrj pages jsj pages fraction pages memory sort-merge band join assuming memory large relations sorted passes cost consists parts jrj jsj ioseq read relations jrj jsj ioseq write initial runs jrj jsj iorandto re-read initial runs assuming forming initial runs sort join attribute pointer pairs nlogn internal sort copy runs sorted order memory cpu cost algorithm jrj log jrj keyswap comp form initial runs jsj log jsj keyswap comp form initial runs jrj jsj move copy sorted positions jrj log jrj comp swap merge runs jsj log jsj comp swap merge runs total cost algorithm sum cpu costs grace partitioned algorithm consists parts letting number samples number partitions cost iorand initial sampling jrj jsj ioseq read relations jrj jsj iorand write partitions jrj jsj ioseq re-read partitions cpu cost jrj jsj log comp partition jrj jsj move copy output partition jrj log keyswap comp sort partitions jrj move copy sorted order jsj log comp rst joining tuple total cost sum cpu costs finally hybrid partitioning cost iorand initial sampling jrj jsj ioseq read relations jrj jsj iorand write partitions jrj jsj ioseq re-read partitions cpu cost cpu cost grace partitioning total cost sum cpu costs tested equations wide variety parameters tested similar cost formulas algorithms nested-loops variant partitioned band join algorithm bothr sorted simultaneously memory resident algorithms worse sort-merge basic partitioned band join algorithms pursue representative graph cost formulas fractions tting memory appears figure graph pages time sec percentofrinbu ers figure model comparison tuples page optimal number samples partitions eachmemory con guration computed optimization procedure implementation partition band join algorithm model gave performance results similar implementation defer discussion performance results section implementation details order evaluate relative performance sort-merge partitioned band join algorithms eachwasimplemented single user version ofwiss cdkk services provided wiss include sequential les byte-stream les unix tree indices long data items external sort utility scan mechanism sequential sequence records mayvary length page inserted deleted arbitrary locations optionally mayhave indices map key values record identi ers records matching indexed attribute designated clustering attribute standard wiss pool lru replacement policy data pages join algorithms explicitly managed space factors motivated decision simpli task varying amount space query recompile wiss time wiss sort code whichweintended basis sort-merge band join algorithm managed space thing partitioning algorithms fairest thing finally allowing algorithm carefully manage replacement pages directly ensures algorithm evaluated light order avoid culties gathering reproducible results time-shared system multiple users system ering virtual memory paging elected single node ipschypercube gamma database system implemented node processor megabytes memory megabyte disk details section hybrid grace partitioned band join algorithms section hybrid grace band join algorithms begin splitting relations joined partitions inputs partitioning operator include number partitions description partitioning join attribute type length set n-element partitioning vector speci upper lower bounds partition discussed section bounds produced sampling relation number pages hold tuples partition splitting process hybrid algorithm typically page allocated partitions remaining space partition case grace algorithm partition allocated number ers typically depending number partitions selected sampling phase sampling implemented randomly generating key relation retrieving tuple implementational convenience weuseda dense index key attribute purpose ability random samples relation depend assumption orx sampling technique ectively means sample pages forming upper levels index resident pool optionally sample page level tuples page brought page level sampling proposed hot purpose join selection selectivity estimation tuples page correlated join attribute page level sampling ective reduce sampling overhead algorithms factor equal numberoftuplesper page implement alternative performance gures worstcase numbers sampling partitioning relations proceeds section important optimization relation partitioned range-vector lter formed actual minimum maximum attribute values partition tuple added partition join attribute compared current minimum maximum values partition determine constitutes minimum maximum signi rst partitions range-vector upper bound join attribute values tuples rst partition actual smallest appearing join attribute rst partition band thenany tuple outer relation join attribute discarded possibly join tuple relation lter employed partitioning outer relation bit vector lters processing equijoins relations partitioned actual join proceeds erences grace hybrid algorithms discussed partition pages partition relation read memory sorted sorting entire tuples pointers tuples sorted pages outer partition processed outer tuple lower upper bound computed subtracting adding band tuple join attribute lower bound perform binary search sorted partition determine starting tuple beginning tuple outer tuple joined subsequent tuples join attribute values greater computed upper bound result tuples produced blocked pages written result relation grace algorithm partitions treated identically case hybrid algorithm partitioning relation sorts partition leaves resident memory writing back disk outer relation partitioned tuples overlap range partition joined immediately written disk partitions processed wayasthey grace algorithm sort merge band join algorithm sort-merge equijoin algorithm begins sorting relations join attribute sorted relations scanned joining tuples equal join attribute values tuple outer relation examined join attribute values outer relation unique scan relation backed order produce correct result mentioned section adapting algorithm handle band joins 
straightforward outer tuple joins band tuples relation scan relation backed single outer tuple past comparisons relative performance sort-merge hybrid equijoin algorithms criticized gra totally fair rst observed improve performance sort-merge join algorithm equiand band-joins combining nal merge phase sort steps actual join phase avoiding reading writing nal runs sorted relations paper implemented modi merge-join algorithm discussed sort-merge band join algorithm operates hybrid grace algorithms algorithm manages space replacement pages directly controlled algorithm begins performing partial external merge sort relation page initial runs pages sorted memory pointer-based quick-sort algorithm sort partitions partitioning algorithms runs merged k-way merge rst pages nal sorted run produced implicitly assumes tuples page tuples band true test cases atthispointthe sort relation suspended tuples needed clearer sort outer relation initiated sort processed similar fashion sort relation nal sorted run formed outer tuples immediately joined tuples relation additional tuples relation produced needed join process reactivating sort relation produce page sorted tuples ect sort relation sort join outer relation implemented co-routines pages sorted relation discarded safely determined tuples possibly join additional tuples outer relation result tuples blocked pages written output relation important understand performance optimization totally free join phase allocate input ers runs outer relations ers merged input tuples output tuples uniprocessor experiments section describe series experiments ran uniprocessor implementation band join algorithms cases test relations based wisconsin benchmark relations bdt elds modi testing band joins elds discussed experiments tuple size bytes eachofthe experiments belowananswer tuple ned concatenation pair tuples joined produce answer tuples bytes long cases symmetric band forthe rst experimentweran twoattributes hundredsand hundredsplus relation tuples attribute hundreds numbers random order hundredsplus numbers random order experiment relation tuples joined column hundreds hundredsplus band size means tuple joins tuple vice-versa figure results memory sizes ranging memory memory curve sort-merge labeled curves grace partitioned band join hybrid partitioned band join labeled note similarity shapes relative positions curves generated analytical model shown figure absolute values plots graphs number reasons primarily graph figure omits cost forming writing answer wemadeno attempt exact match hardware parameters model hardware parameters implementation high cost grace hybrid partitioned band join algorithms pool due sampling overhead table percentage execution time due sampling grace partitioned band join curve figure note implemented page-level sampling section overhead reduced factor number tuples page experimentwe ran designed test performance algorithms input relation sizes purpose relation tuples relation tuples join attribute twenties attribute twentywrap attributes ned relation sizes tuples join attribute values random order join attribute values abandofsize tuple joins tuples tuples time sec percentofrinbu ers figure tuples join tuples answer tuples mem size sampling time percent total sec sec sec sec sec table sampling costs percentage running time join tuple tuples join tuple giving result size graph results experiment presented figure note tuples join tuple ranges join attributes essentially rangeltering ect graph illustrates important properties algorithms obvious bene partitioned band join algorithms gain sort relation apparent small memory data points memory equal pages sort-merge makemultiple passes beginning nal merge wasn memory equal large relation sorted passes join computed pass clear hybrid performs grace large memory sizes reasons rst hybrid doesn re-read portion falls signi cost re-reading part tuples dwarfed cost reading tuples writing answer tuples large tuples importantly case portion falls written disk read back tuples immediately joined partitioning phase algorithm nal experimentwe ran designed demonstrate ect range ltertime sec percentofrinbu ers figure band answer tuples ing section joined tuples tuples time join attribute contained values random order join attribute contained values random order band size tuples join tuples remaining tuples join tuples answer size tuples case range join attribute relation range join attribute relation range ltering signi ect result graph experiment appears figure grace hybrid lter tuples means tuples read thrown hybrid grace large memory sizes doesn re-read joins writing re-reading hybrid successful large memory sizes tuples fall ltered result join computed reading pages relation writing multiprocessor experiments section execution band joins parallel environment order simplify implementation ort implemented parallel version hybrid partitioning band join algorithm parallel hybrid partitioning band join gamma database machine dgs served experimental vehicle gamma falls class shared-nothing sto architectures hardware consists processor intel ipsc hypercube processor con gured cpu megabytes memory megabyte maxtor disk drive disk drive embedded scsi controller whichprovides kbyte ram acts disk cache sequential read operations time sec percentofrinbu ers figure tuples join tuples answer tuples nodes hypercube interconnected form hypercube custom vlsi routing modules module supports full-duplex serial reliable communication channels operating megabytes sec custom operating system nose tailored database processing runs processor gamma relations horizontally partitioned declustering lkb disk drives order increase aggregate bandwidth provided hardware query language gamma user alternative declustering methods experiments user determined tuples reside site based range predicate applied partitioning attribute tuple relation collection tuples stored processor referred fragment relation extending sequential version hybrid partitioning band join algorithm parallel environmentwas straightforward simplify implementation partition mapped individual processor addition assumed partition relation small processor pool parallel version hybrid partitioned band join algorithm processor randomly samples local fragment relation sends join attribute values sampled tuples central coordinator coordinator sorts sampled values determines partitioning elements relation divided buckets processors coordinator sends copy partitioning elements processor disk fragment relation processor reads local fragment relation re-distributes network partitioning elements tuples relation arrive processor stored memory subsequently sorted phase complete outer joining relation similarly re-distributed network partitioning elements derived joining relation tuples fall neighboring bucket due width band replicated processor handling bucket parallel environment increase size band results increased network tra tuples outer relation arriveat processor binary search sorted tuples compute output tuples uni-processor version algorithm problem overcome parallel algorithm correctly ciently sample relation parallel order determine partitioning elements correctness relation sampled randomly stored single processor tuple processor stored equally sampled note samples acceptable haveeach processor samples result random sample note processor takes samples set samples tuples single processor portion database totake random sample making parallelism implementation processor attempts sample tuples local fragment relation processor random number generator seed ciency processor checks local catalog information determine tuple sample stored local disk tuple retrieved disk join attribute sampled tuple stored locally sample terms disk ect central 
joinaselb selection restricts million tuples million tuples joins result variation join queries tested involved indices non-partitioning attribute join selection attributes join performed input relations redistributed hashing join attribute tuple results tests contained rows table variation join queries employ indices case relations hash partitioned joining attribute enabling redistribution phase join skipped results tests contained rows table results table execution time join query increases fairly linear fashion size input relations increased gamma exhibit linearity million tuple queries size relation megabytes large total space hash tables hybrid join algorithm buckets process queries tuples bucket directly memory-resident hash tables bucket written disk section expected version query partitioning attribute join attribute ran faster results estimate lower bound aggregate rate data redistributed intel ipsc hypercube version joinabprime query million tuple relation table join queries processors disks execution times seconds number tuples relation query description joinabprime non-partitioning attributes join attributes joinaselb non-partitioning attributes join attributes joinabprime partitioning attributes join attributes joinaselb partitioning attributes join attributes joined tuple relation query requires seconds join partitioning attribute execution query million byte tuples redistributed hashing join attribute yielding aggregate total transfer rate megabytes processing query construed accurate estimate maximum obtainable interprocessor communications bandwidth cpus limiting factor disks limiting factor table estimate aggregate bandwidth disks megabytes speedup experiments join speedup experiments joinabprime query million tuple relation tuple bprime relation number processors varied thirty fewer processors buckets needed including execution time processor buckets made response times processors artificially fast resulting superlinear speedup curves resulting response times plotted figure speedup curves presented figure shape graphs obvious execution time query significantly reduced additional processors employed factors prevent system achieving perfectly linear speedups response time seconds processors disks speedup processors disks figure figure hash partitioned hash partitioned non-join attribute join attribute hash partitioned hash partitioned non-join attribute join attribute cost starting operator tasks scans join store processor increases function number processors effect short-circuiting local messages diminishes number processors increased processor configuration non-partitioning attribute version joinabprime query processor repartitions tuples hashing join attribute input tuples processes destined short-circuited communications software addition query produces tuples result relation partitioned round-robin manner short circuited number processors increased number short-circuited packets decreases point processors packets short-circuited intra-node packets expensive inter-node packets smaller configurations benefit short-circuiting case partitioning-attribute joins input tuples short-circuit network fraction output tuples scaleup experiments joinabprime query join scaleup experiments tests number processors varied size relation varied million million tuples increments million tuples size bprime relation varied tuples increments configuration join bucket needed results tests presented figure factors contribute slight increase response times task initiating processes site performed single processor number processors increases effects short-circuiting messages execution queries diminishes case join attribute partitioning attribute finally response time limited speed communications network response time seconds processors disks hash partitioned join attribute figure hash partitioned non-join attribute aggregate queries aggregate tests included mix scalar aggregate aggregate function queries run processor configuration query computes minimum non-indexed attribute queries compute sum minimum attribute partitioning relation subsets sizes input relations million million tuples results tests contained table scalar aggregates aggregate function operators executed algorithms similar selection join operators speedup scaleup experiments conducted table aggregate queries processors disks execution times seconds number tuples source relation query description scalar aggregate min aggregate function partitions sum aggregate function partitions update queries set tests included mix append delete modify queries sizes relations million million tuples results tests presented table gamma recovery mechanism operational results viewed query appends single tuple relation indices exist appends tuple relation index exists query deletes single tuple relation clustered b-tree index locate tuple deleted query indices exist indices updated queries index updated fourth sixth queries test cost modifying tuple ways tests non-clustered index exists unique attribute addition clustered index exists unique attribute case modified attribute partitioning attribute requiring modified tuple relocated tuple relocated secondary index updated modify query modifies non-partitioning nonindexed attribute modify query modifies attribute non-clustered index constructed index locate tuple modified table update queries processors disks execution times seconds number tuples source relation append tuple indices exist append tuple index exists delete tuple modify tuple modify tuple modify tuple conclusions future research directions paper design implementation gamma database machine gamma employs shared-nothing architecture processor disks processors communicate sending messages interconnection network previous version gamma software ran collection vax interconnected mbit token ring system runs intel ipsc hypercube processors disk drives gamma employs key ideas enable architecture scaled processors relations horizontally partitioned multiple disk drives attached separate processors enabling relations scanned parallel specialized hardware addition order enable database design tuned application alternative partitioning strategies provided major contribution gamma software extensive hash-based parallel algorithms processing complex relational operators joins aggregate functions finally system employs unique dataflow scheduling techniques coordinate execution multioperator queries techniques make control execution complex queries minimal coordination necessity configurations involving large number processors addition describing design gamma software presented performance evaluation ipsc hypercube version gamma sets experiments performed constant machine configuration processors response standard set wisconsin benchmark queries measured sizes relations subset queries measured performance system relative number processors employeed sizes input relations constant speedup sizes input relations increased proportionally number processors scaleup speedup results obtained selection join queries perfectly linear doubling number processors halves response time query scaleup results obtained encouraging reveal constant response time maintained selection join queries workload increased adding proportional number processors disks number projects underway plan implementing chained declustering mechanism evaluating effectiveness respect processing queries designed schn evaluating alternative strategies processing queries involving multiple join operations query involving joins machine processors processors join allocating memory processor join processors join case join operator full memory processor finally studying partitioning mechanisms combine features hash range partitioning strategies acknowledgements large systems projects large number people listed authors made paper bob gerber deserves special recognition work design gamma leadership implementation prototype query optimizer implemented muralikrishna rajiv jauhari implemented read-ahead mechanism improve performance sequential scans anoop sharma implemented aggregate algorithms embedded query interface goetz graefe joanna chen implemented predicate compiler deserve special credit debug machine code produced compiler jim gray susan englert tandem computers wisconsin benchmark relation generator generator tests conducted simply previously generating relations larger million tuples agra agrawal dewitt 
recovery architectures multiprocessor database machines proceedings sigmod conference austin astr astrahan system relational approach database management acm transactions database systems vol june bitt bitton dewitt turbyfill benchmarking database systems systematic approach proceedings large database conference october blas blasgen gray mitoma price convoy phenomenon operating system review vol april borr borr transaction monitoring encompass reliable distributed transaction processing proceedings vldb brat bratbergsengen kjell hashing methods relational algebra operations proceedings large database conference august chou chou h-t dewitt katz klug design implementation wisconsin storage system wiss software practices experience vol october cope copeland alexander boughter keller data placement bubba proceedings acm-sigmod international conference management data chicago cope copeland keller comparison high-availability media recovery techniques proceedings acm-sigmod international conference management data portland oregon june dewi dewitt direct multiprocessor organization supporting relational database management systems ieee transactions computers june dewi dewitt katz olken shapiro stonebraker wood implementation techniques main memory database systems proceedings sigmod conference boston june dewi dewitt finkel solomon crystal multicomputer design implementation experience ieee transactions software engineering vol seno august dewi dewitt gerber multiprocessor hash-based join algorithms proceedings vldb conference stockholm sweden august dewi dewitt gerber graefe heytens kumar muralikrishna gamma-a high performance dataflow database machine proceedings vldb conference japan august dewi dewitt ghandeharizadeh schneider performance analysis gamma database machine proceedings acm-sigmod international conference management data chicago engl englert gray kocher shah benchmark nonstop sql release demonstrating near-linear speedup scaleup large databases tandem computers technical report tandem part ensc enscribe programming manual tandem part tandem computers march gerb gerber dewitt impact hardware software alternatives performance gamma database machine computer sciences technical report wisconsinmadison july ghan ghandeharizadeh dewitt multiuser performance evaluation selection queries single processor database machine july submitted ghan ghandeharizadeh dewitt performance analysis alternative declustering strategies proceedings international conference data engineering los angeles february good goodman investigation multiprocessor structures algorithms database management california berkeley technical report ucb erl grae graefe volcano compact extensible dynamic parallel dataflow query evaluation system working paper oregon graduate center portland february gray gray notes database operating systems ibm research laboratory san jose california february gray gray sammer whitford shortest seek shortest service time scheduling mirrored disks tandem computers december hsia hsiao dewitt chained declustering availability strategy multiprocessor database machines proceedings international conference data engineering los angeles february jark jarke koch query optimization database system acm computing surveys vol june kim kim synchronized disk interleaving ieee transactions computers vol november kits kitsuregawa tanaka moto-oka application hash data base machine architecture generation computing vol livn livny khoshafian boral multi-disk management algorithms proceedings sigmetrics conference banff alberta canada moha mohan haderle linsay pirahesh schwarz aries transaction recovery method supporting fine-granularity locking partial rollbacks write-ahead logging ibm almaden research center san jose california january patt patterson gibson katz case redundant arrays inexpensive disks raid proceedings acm-sigmod international conference management data chicago prot proteon associates operation maintenance manual pronet model waltham mass ries ries epstein evaluation distribution criteria distributed database systems ucb erl technical report berkeley schn schneider dewitt performance evaluation parallel join algorithms shared-nothing multiprocessor environment proceedings sigmod conference portland june schn schneider dewitt design tradeoffs alternative query tree representations multiprocessor database machines computer sciences technical report wisconsinmadison august submitted seli selinger access path selection relational database management system proceedings sigmod conference boston ston stonebraker case shared database engineering vol ston stonebraker katz patterson ousterhout design xprs proceedings fourteenth international conference large data bases los angeles august tand tandem performance group benchmark non-stop sql debit credit transaction proceedings sigmod conference chicago june tera teradata dbc database computer system manual release document teradata corp nov wagn wagner indexing design considerations ibm system journal vol dec 
performance analysis gamma database machine david dewitt shahram ghandeharizadeh donovan schneider computer sciences department wisconsin research partially supported defense advanced research projects agency contract -cby national science foundation grants dcrmcs mcs digital equipment corporation external research grant abstract paper presents results initial performance evaluation gamma database machine based expanded version single-user wisconsin benchmark experiments measured effect relation size indices response time selection join aggregation queries single-tuple updates teradata dbc database machine similar size basis interpreting results obtained analyze performance gamma relative number processors employeed study impact varying memory size disk page size execution time variety selection join queries analyze interpret results experiments based understanding system hardware software conclude assessment strengths weaknesses machines introduction report presents results single-user performance evaluation gamma database machine dewi gerb gerb evaluation based principal metrics absolute performance achieved gamma performance relative number processors basis determining absolute performance gamma results obtained similar study dewi teradata dbc database machine tera tera tera interpreting results presented reader remember gamma commercial product results slightly queries full recovery mechanism implemented gamma distributed concurrency control provided results presented basis comparing storage organizations multiprocessor algorithms database machines basis drawing conclusions machine objective part evaluation determine performance gamma relative number processors simply increasing number processors side effect increasing amount buffer space processing join operations join join hash table overflow processors result overflows query executed single processor change size test relations avoid problem decided total summed processors amount buffer space constant varying number processors separate set tests number processors constant varying total amount buffer space final suite tests number buffer pages processors constant varying disk page size sections describe gamma teradata configurations evaluated section presents overview database benchmark types tests conducted selections joins aggregates updates description exact queries results obtained query contained sections conclusions presented section overview gamma database machine section present overview gamma database machine including description current hardware configuration software techniques implementation detailed descriptions algorithms implementing relational operations presented sections performance results obtained benchmarking process complete description gamma dewi gerb hardware configuration presently gamma consists vax processors megabytes memory megabit token ring prot connect processors vax running berkeley unix processor acts host machine gamma attached processors megabyte fujitsu disk drives database storage diskless processors reserved query scheduling global deadlock detection remaining diskless processors execute join projection aggregate operations selection update operations executed processors disk drives attached software overview physical database design gamma relations horizontally partitioned ries disk drives system alternative ways distributing tuples relation provided round-robin hashed range partitioned user-specified placement key range partitioned uniform distribution implied strategy tuples loaded relation distributed round-robin fashion disk drives default strategy gamma relations created result query hashed strategy selected randomizing function applied key attribute tuple select storage unit teradata database machine technique tests conducted tuple distribution strategy strategy user specifies range key values site partitioning strategy user specifies partitioning attribute system distributes tuples uniformly sites query execution gamma traditional relational techniques query parsing optimization seli jark code generation queries compiled tree operators predicates compiled machine language processors megabytes memory join query speedup tests conducted causing hash table overflow occur processors parsed optimized compiled query host software idle scheduler process dispatcher process dispatcher process controlling number active schedulers implements simple load control mechanism based information degree cpu memory utilization processor scheduler process turn activates operator processes query processor selected execute operator task assigning operators processors performed part optimizer part scheduler assigned control execution query operators leaves query tree permanent relations query schema information optimizer determine assigning operators processors results query returned host stored relation database gamma algorithms operators written run single processor shown figure input operator process stream tuples output stream tuples demultiplexed structure term split table initiated query process waits control message arrive global well-known control port receiving operator control packet process replies message identifies scheduler process begins execution continuously reads tuples input stream operates tuple split table route resulting tuple process split table case selection operation producing tuples subsequent join operation join executed processes split table selection outgoing streams operator executing process tuples control packet stream tuples table split figure process entries tuple satisfying selection predicate selection process apply hash function join attribute produce index split table obtain address machine port join process receive tuple process detects end input stream closes output streams sends control message scheduler indicating completed execution closing output streams side effect sending end stream messages destination processes exception control messages execution operator completely self-scheduling data flows processes executing query tree dataflow fashion result query relation operators root query tree distribute result tuples round-robin basis store operators disk site store operators assume responsibility writing result tuples disk enhance performance operations array bit vector filters babb vald inserted split table case join operation join process builds bit vector filter hashing join attribute values building hash table relation brat dewi dewi vald hash table relation completed process sends filter scheduler scheduler received filters sends processes responsible producing outer relation join processes set filters eliminate tuples produce tuples join operation operating storage system gamma built top operating system developed specifically supporting database management systems nose lightweight processes shared memory reliable datagram communication services nose processes gamma processors unix processes host machine multiple bit sliding window protocol tane messages processes processor short-circuited communications software file services nose based wisconsin storage system wiss chou services include structured sequential files indices byte-stream files unix long data items sort utility scan mechanism sequential file sequence records records vary length page length inserted deleted arbitrary locations sequential file optionally sequential file indices index maps key values records sequential file matching indexed attribute clustering attribute file scan mechanism similar provided system rss astr predicates compiled machine language teradata hardware software configuration teradata machine tested consists interface processors ifps access module processors amps disk storage units dsus ifps communicate host parse optimize direct execution user requests amps perform actual storage retrieval data dsus ifps amps interconnected dual redundant tree-shaped interconnect called y-net tera nech y-net aggregate bandwidth megabytes intel processors ifps amps gamma processors amp megabytes memory megabyte unformatted hitachi disk drives model host processor amdahl running mvs operating system software release 
tests conducted relations teradata machine horizontally partitioned ries multiple amps limit number amps relations partitioned amps tests presented tuple inserted relation hash function applied primary key relation select amp storage hash maps y-net nodes amps hash buckets reside amp tuple arrives site amp applies hash function key attribute order place tuple fragment tuples hash relation hash sequence number concatenated form unique tuple tera entire relation loaded tuples horizontal fragment termed hash-key order key attribute locate tuple single disk access assuming buffer pool hits physical file organization supported present time important note organization kind indices construct dense secondary indices index termed dense entry tuple indexed relation termed secondary index order key software treats drives single logical unit primary key relation created order file rows index hashed key field sorted key order range query indexed attribute performed entire index scanned description benchmark relations benchmark relations based standard wisconsin benchmark relations bitt relation consists thirteen -byte integer attributes -byte string attributes tuple bytes long order meaningfully stress database machines constructed tuple versions original tuple benchmark relations unique unique attributes relations generated guarantee tuple unique attributes correlation values unique unique single tuple copies relation created loaded unique key partitioning attribute cases total database size approximately megabytes including indices teradata machine test relations loaded fallback mode fallback option mechanism continue processing face disk amp failures automatically replicating tuple sites measure cost keeping copies tuple consistent elected fallback feature noted results queries stored database avoided returning data host afraid end measuring speed communications link host database machine host processor storing results database factors minimized measurements hand ended measuring cost storing result relations storing result query relation incurs costs incurred resulting tuples returned host processor tuples result relation distributed processors disks case teradata database machine unique primary key source result relations expected communications overhead incurred storing result tuples low-level communications software recognize situation execution times presented include cost redistributing result tuples current version gamma redistributes result tuples round-robin fashion machines incur redistribution overhead storing result query relation cost storing result query relation impact recovery software rate tuples inserted relation case substantial differences systems gamma extended version query language quel ston construct retrieve result relation result query stored relation semantics construct relation exist query executed reason transaction running query aborted action recovery manager delete files result relation query language teradata database machine based extended version sql order execute sql query stores result tuples relation explicitly create result relation result relation created syntax insert result relation select source relation cases result relation tuples case insert acts union code insert log inserted tuples carefully transaction aborted relation restored original state teradata insert code optimized single tuple bulk updates incurred tuple inserted dewi complete description problem straightforward optimization insert code recognize operating empty relation enable code process bulk updates efficiently simply releasing pages result relation insert aborted selection section explore gamma performance variety selection queries size input relations increased results obtained compared results running set queries teradata database machine subset queries varied number processors disk page size determine factors affect performance performance relative relation size selection queries designed objectives mind wanted teradata gamma machines respond size source relations increased ideally constant machine configurations response time grow linear function size input result relations interested exploring effect indices execution time selection machine holding selectivity factor constant tests sets selection queries selectivity selectivity gamma sets queries tested storage organizations heap index clustered index key attribute index order key order non-clustered index non-key attribute index order key order teradata machine tuples relation organized hash-key order construct clustered index indices key attribute dense nonclustered indices table tabulated results testing types selection queries sizes relations tuples main conclusions drawn table machines execution time query scales linear fashion size input output relations increased expected clustered b-tree organization significant improvement performance discussed dewi results selection non-clustered index rows table teradata machine puzzling queries selected tuples table selection queries execution times seconds number tuples source relation query description teradata gamma teradata gamma teradata gamma nonindexed selection nonindexed selection selection non-clustered index selection non-clustered index selection clustered index selection clustered index single tuple select predicate unique attribute attribute constructed non-clustered index case selection optimizer decided correctly index case observed execution time identical result obtained nonindexed case results contradict query plan produced optimizer states non-clustered index unique execute query storage organization indices teradata machine partial explanation index entries hash-based sorted order entire index scanned sequentially scanning portion range query number attribute comparisons index scans sequential scans expected number required scan index fraction number required scan relation apparently response time reduced significantly index scanned sequentially access relation requires random seek gamma supports notion non-clustered indices b-tree structure top actual data file table case selection gamma optimizer decides index case index scan selectivity factor tuple relation non-clustered index worst case required assuming tuple page fault hand segment scan chosen access data tuples data page pages data read difference number significant confirmed difference response time entries gamma rows table gamma clustered indices underlying relation sorted key attribute b-tree search structure built top data response time selections clustered index presented rows table tuples sorted key order index order portion relation range query scanned results reduction number compared search file scan non-clustered index saving confirmed lower response times shown table important observation made table relative consistency cost selection clustered index gamma notice response time selection tuple relation selection tuple relation clustered index seconds reason cases tuples retrieved stored resulting cpu costs selection results reveal important limitation teradata design clustered indices non-clustered indices small number tuples retrieved system resort scanning entire files range selections hash files optimal file organization exact-match queries types applications range queries important cases database administrator storage organization suited application final row table presented times required machines select single tuple return host teradata machine key attribute selection condition hashing constant select amp amp software hash constant select hash bucket holds tuple case gamma clustered index key attribute ran test tuple relation teradata machine expect comparable times tuple tables results clustered indices comparable performance hash files single tuple retrieves providing superior performance range queries discussed section 
level parallelism controlled low priority queries joins small relations parallelism doesn make sense relations joined small promising area bit filtering multiprocessor hash join algorithms number ways bit filtering babb kits exploited multiprocessor hashing algorithms joining node build bit vector simultaneously construction hash table completed bit vectors distributed partitioning processors partitioning processors maintain bit vectors bucket basis alternately partitioning nodes merge bucket bit vectors single bit vector bit vector applied partitioning relation strategy number bit vector filtering strategies promising finally intend algorithms part gamma project gamma database machine project begun recently gamma provide test vehicle validating multiprocessor hash-join results gamma built crystal multicomputer dewi wiss chou basis crystal multicomputer project funded part national science foundation coordinate experimental research program crystal network bare vax processors twenty eventually forty serving nodes connected mbit token ring proteon associates prot ring upgraded mbit ring node machines attached disks file database services provided crystal users wiss crystal software simple operating system nose multiple lightweight processes shared memory reliable connections nose processes node machines unix processes host machines vax running unix wiss runs top nose crystal nose wiss operational production astr astrahan system relational approach database management acm transactions data systems volume june babb babb implementing relational database means specialized hardware acm transactions database systems volume bitt bitton dewitt turbyfill benchmarking database systems systematic approach proceedings large database conference october blas blasgen eswaran storage access relational data bases ibm systems journal brat bratbergsengen kjell hashing methods relational algebra operations proceedings large database conference august brow browne dale leung jenevein parallel multi-stage architecture self-managing disk cache database management applications proceedings international workshop database machines march chou chou h-t dewitt katz klug design implementation wisconsin storage system wiss software practice experience computer sciences department wisconsin technical report november dewi dewitt katz olken shapiro stonebraker wood implementation techniques main memory database systems proceedings sigmod conference boston june dewi dewitt finkel solomon crystal multicomputer design implementation experience submitted ieee transactions software engineering computer sciences department technical report wisconsin september garc garcia-molina kenneth salem disk striping proceedings sigmod conference dept electrical engineering computer science technical report december good goodman investigation multiprocessor structures algorithms database management california berkeley technical report ucb erl gros grosch high speed arithmetic digital computer research tool journal optical society america volume april implementation multibackend database systems mdbs advanced database machine architecture edited david hsiao prentice-hall kim kim parallel operation magnetic disk storage devices proceedings international workshop database machines march kits kitsuregawa tanaka moto-oka application hash data base machine architecture generation computing volume kits kitsuregawa tanaka moto-oka relational algebra machine grace rims symposia software science engineering lecture notes computer science springer verlag kits kitsuregawa tanaka moto-oka architecture performance relational algebra machine grace tokyo technical report knut knuth art computer programming sorting searching volume iii prot proteon associates operation maintenance manual pronet model unibus waltham mass ries ries epstein evaluation distribution criteria distributed database systems ucb erl technical report berkeley siew siewiorek bell newell computer structures principles examples mcgraw hill ston stonebraker michael eugene wong peter kreps design implementation ingres acm transactions database systems volume september vald valduriez gardarin join semi-join algorithms multiprocessor database machine acm transactions database systems volume march 
processor round robin partitioning handling skews parallel relational joins dnss similar partitioning function independently proposed redundancy baseddeclustering spatial objects parallel spatial database proposal number tiles equals number partitions design space choosing spatial partitioning function axes number tiles partitioning function tile partition mapping scheme decomposing universe small tiles produces small containers easier pack partitions produce uniform partition distribution spatial objects span tiles multiple partitions replicated partitions increasing replication overhead tile partition mapping scheme round robin hashing tile number explore alternatives chosen data sets data set derived tiger line files tig represents roads state wisconsin data set size tuples data set polygon data sequoia benchmark sfgm data set polygons size explore design space spatial partitioning function tiger data figure shows effect increasing number tiles choosing tile partition mapping schemes graph coefficient variation distribution tuples partition metric perfect spatial partitioning function assigns equal number tuples partition coefficient variation distribution tuples partition figure observations made large number tiles hashing tile number good partitioning function partitioning functions improve number tiles increased larger number tiles dense regions subdivided tiles tiles mapped partitions number tiles partitioning function yields uniform distribution coefficient variation defined standard deviation divided sigmod number tiles coefficient variation hash tile number partitions hash tile number partitions round robin partitions round robin partitions number tiles replication overhead increase tuples hash tile number round robin number tiles replication overhead increase tuples hash tile number round robin figure spatial partitioning function alternatives tiger road data figure replication overhead tiger road data partitions figure replication overhead sequoia polygon data partitions smaller number partitions compare graphs hashing partitions distribution tiles cover dense regions smaller number partitions universe decomposed tiles tiles cover data tiles spread partitions uniformly partitions result coefficient variation partitions lower partitions figure measures replication overhead increase number tuples created due replication partitioning number tiles figure shows tiger data set replication overhead modest large number tiles increasing number tuples tiles figure shows spikes curve round robin round robin number tiles integral multiple number partitions entire column mapped single partition equivalent fewer number tiles column behaves single tile fewer tuples replicated points partitions produced partitioning function balanced observe jumps figure round robin nodes sequoia data found effect increasing number tiles tile partition mapping scheme similar effect tiger data replication overhead shown figure higher handling partition skew similar partition skew problem grace join pbsm algorithm end partition pairs fit memory data concentrated small cluster handle dynamically repartition overflown partition pair alternative increase number partitions limited schemes similar adaptive hash join algorithm current implementation pbsm incorporate techniques performance evaluation section compare pbsm join algorithm spatial join algorithms algorithm based traditional indexed nested loops algorithm based tree join algorithm bks algorithms spatial indices chosen spatial databases support form spatial indexing trees illustra ube systems easily index based join algorithms study meant comprehensive performance study spatial join algorithms refer table classification spatial join algorithms algorithms study alternatives spatial database system transform approximations spatial objects domain dimensional domain knowledge commercial spatial database systems transform approximations spatial objects domain arc info arc illustra ube remainder section organized index nested loops tree based join algorithms description methodology study finally results study presented indexed nested loops join denote relations joined assume fewer tuples join input index joining attribute indexed nested loops join algorithm builds index smaller input index built bulk loading mechanism reads extent extracts key pointer information mbr oid tuple key pointer information spatially sorted based mbr spatial sorting accomplished transforming center point sigmod data total tree type objects size size road hydrography rail table wisconsin tiger data mbrinto hilbert ordering key pointer information sorting brings key pointers joining attributes spatially close spatial index case tree built bottom fashion dkl building index join attribute scan started tuple probe index result probe set possibly empty oids tuples oids fetched disk checked tuple determine join condition satisfied fetching tuple disk generally incur random disk tree based join algorithm algorithm bulk loading build tree index joining attribute input relations indices joined tree join algorithm proposed bks tree join algorithm performs synchronous depth traversal trees traversal starts roots trees moves levels trees tandem leaf nodes reached step nodes tree joined joining nodes requires finding bounding boxes node intersect bounding box node child pointers matching bounding boxes traversed resulting depth traversal tree join algorithm bks performs filter step spatial join produces set candidate oid pairs objects mbrs intersect objects oids fetched checked determine join predicate satisfied technique pbsm join algorithm refer section methodology performance comparison implemented algorithms indexed nested loops join tree based join pbsm join paradise dkl paradise database system handles gis type applications paradise supports storing browsing querying geographic data sets extended relational data model supports extension sql query language paradise shore cdf storage manager persistent objects machine study sun sparc mbytes memory running sunos release seagate gbyte disk scsi model data total tree type objects size size polygons islands table sequoia data raw device hold database log system gbyte seagate disk performance study pbsm algorithm tiles spatial partitioning function explored effect number tiles execution time pbsm found changing number tiles small effect execution time full length version paper presents result performance study carried parts part examined performance algorithms join input pre existing index part examined performance algorithms indices existed join inputs parts study collections data sets collection derived tiger line files tig state wisconsin tiger data developed distributed bureau census detailed geographic cartographic information united states tiger files data sets extracted table data set called road represents roads data set called hydrography represents basic hydrography features includes rivers canals streams data set rail represents railroads polyline attribute describes spatial feature tuple collection attributes describes classification address ranges spatial feature average number points spatial feature road hydrography rail tuple queries run collection query joined road data set hydrography data producing result intersecting road hydrography features result relation consists tuples query performed join road rail data produced result relation tuples query examine performance algorithms size input relations differ significantly study effect clustering join inputs collection formed spatially sorting objects collection collection islands polygon data sets sequoia storage benchmark sfgm polygon 
data set represents regions homogeneous landuse characteristics state california nevada island data set represents holes polygon data lake park average number points polygon tuple average number sigmod buffer pool size execution time seconds pbsm join r-tree based join idx nested loops buffer pool size execution time seconds pbsm join r-tree based join idx nested loops buffer pool size execution time seconds pbsm join r-tree based join idx nested loops figure tiger data join road hydrography figure tiger data join road rail figure clustered tiger data join road hydrography points islands tuple query experiment joined polygons islands producing result islands contained polygons result contained tuples size characteristics data shown table joins indices pre exist section presents results performance evaluation join input pre existing index case indexed nested loops algorithm builds index smaller inputs probes tree based algorithm builds indices joins tree join algorithm comparison tiger data experiment road data set joined hydrography data set figure shows execution times spatial join algorithms function buffer pool size query pbsm algorithm faster tree based join algorithm faster indexed nested loops algorithm indexed nested loops builds index hydrography probes tuples road data set probing index tuple indexed nested loops join fetches matching hydrography tuple examines determine join predicate satisfied smaller buffer pool sizes fetching matching hydrography tuple generally requires disk size buffer pool increases larger portions hydrography data reside buffer pool result performance indexed nested loops join improves significantly performance algorithms compared joining road data rail data figure size rail data index index data fit buffer pool rail data pages compete road data pages buffer pool frames result indexed nested loops performs tree based join algorithm cost tree based join algorithm dominated cost building index larger road data algorithm spends total time building index effect clustering investigate effect clustering ran query joins roads hydrography clustered tiger data clustering similar effect join road rail results found results experiment shown figure experiment pbsm faster tree based join algorithm faster indexed nested loops comparing figures observe inputs join clustered performance join algorithms improve understand behavior figures detailed cost breakdowns clustered clustered scenarios tree based join algorithm total join cost includes cost building indices cost joining indices cost fetching road hydrography tuples disk examining determine join predicate satisfied refinement step indexed nested loops join total cost consists building index hydrography probing repeatedly tuples road data set pbsm algorithm total join cost includes cost forming partitions cost merging partitions cost refinement step individual costs tree based join algorithm figure index building costs indices join built bulk loading refer section detailed description bulk loading bulk loading index costs cost extracting key pointers input sorting key pointers building index sorted key pointers input clustered sorting key pointers avoided reducing cost building index sigmod buffer pool size execution time seconds build index hydrography build index road join r-trees refinement step clustered clustered clustered buffer pool size execution time seconds build index hydrography probe index clustered clustered clustered buffer pool size execution time seconds partition hydrography partition roads merge partitions refinement step clustered clustered clustered figure tree based algorithm tiger data join road hyd clustered clustered scenario figure indexed nested loops algorithm tiger data join road hyd clustered clustered scenario figure pbsm algorithm tiger data join road hyd clustered clustered scenario tree joining cost bulk loading sorts keys clustered scenario trees built clustered clustered scenarios algorithm joining trees performs steps cases result clustering effect time joining indices refinement step cost refinement step tuples scanned tuples scanned multiple times refinement step refer section reads bunch tuples physically clustered disk reads tuples spatially match tuples physical order tuples disk spatial order fetches tuples scan small portion relation refinement costs improve spatial clustering due large reduction index building costs tree based join benefits significantly input relations clustered join attribute indexed nested loops join figure clustering similar effect index building cost sorting keys avoided small buffer pool sizes index hydrography fit memory index probe cost significantly reduced data clustered effect similar behavior indexed nested loops join relational domain sorting relation probe index improves performance join reduction refinement cost clustering reduces partitioning costs pbsm algorithm figure difference partitioning costs pronounced smaller buffer pool sizes behavior due partitions written disk pbsm algorithm manage partition buffers simply writes tuples partition files relies shore storage manager flush pages partition files disk spatial partitioning function decomposes universe tiles refer section maps tiles partitions input clustered consecutive tuples tile result mapped partition phase incurs disk seek tile data clustered partitions fill random order result writing partitions involve disk seeks partition files interesting point note figures pbsm tree based join algorithm elapsed time performing refinement step pbsm refinement cost constitutes join cost tree based algorithm refinement cost join cost performing refinement step case requires examining polylines intersection plane sweeping algorithm cost refinement step increases comparison sequoia data performance algorithms compared sequoia data set figure shows result comparison data set pbsm faster tree based join faster indexed nested loops join sequoia data set observed cost refinement step dominating factor pbsm tree based join contributing pbsm join cost tree based join cost detailed cost break data set appears full length version paper refinement step query involves checking island polygon contained landuse polygon check containment implemented paradise naive algorithm number points polygon number techniques reducing cost part sigmod buffer pool size execution time seconds pbsm join r-tree based join idx nested loops buffer pool size execution time seconds pbsm join rtree-indices indices exist rtree-largeidx index road exists inl-largeidx index road exists rtree-smallidx index hyd exists inl-smallidx index hyd exists buffer pool size execution time seconds pbsm join rtree-indices indices exist rtree-largeidx index road exists inl-largeidx index road exists rtree-smallidx index rail exists inl-smallidx index rail exists figure sequoia data set figure comparison join algorithms indices tiger data join road hydrography figure comparison join algorithms indices tiger data join road rail join bkss order magnitude cases techniques rely filter refinement step extra information precomputed stored spatial feature polygon store minimum bounding rectangle mbr maximal enclosed rectangle mer rectangle fully contained polygon refinement step determine polygon contained polygon mbr examined 
client server paradise david dewitt navin kabra jun luo jignesh patel jie-bing computer sciences department wisconsin madison paradise wisc abstract paper describes design implementation paradise database system designed handling gis type applications currentversion paradise client server architecture extended relational data model modeling gis applications paradise supports extended version sql graphical user interface querying browsing database describe results benchmarking paradise sequoia storage benchmark introduction years interest geographic information systems gis increased signi cantly existing systems represent integration ideas erent elds including remote sensing photogrammetry computer cartography mgr turn application domains additional demands existing systems gis systems store process vast amounts remote sensed data gathered sensors satellites satellites scan surface earth measuring electromagnetic properties surface information radioed receiving station surface process completely automated continues non-stop data volumes enormous addition storing raw data receiving station generally reprocesses data set standard data products made scientists world work partially supported nasa contracts usra nagw ibm research initiation grant permission copy feeallorpart material grantedprovided copies made distributedfor direct commercial advantage vldb copyright noticeand title date notice copying permission large data base endowment tocopy republish requires fee special permission endowment proceedings vldb conference santiago chile addition store manage large volumes data gis systems capable handling variety erent data query types gis applications provide support forms spatial data raster vector data raster data representedasatwo dimensional array integer oating point values readings sensor satellite vector data hand generally composed set lines representing outline region type queries posed system frequently include predicates involving spatial relationships spatial overlap containment addition providing expressive data model query language gis provide cientmechanism performing operations spatial data successfully process spatial queries large volumes data existing gis systems employ variety architectures systems grass sea store alldata normaloperatingsystem les providing library functions retrieving manipulating displaying data traditional database perspective systems limited terms offunctionality respect query optimization processing transaction support concurrency control physical data independence gis systems mor hhk employ hybrid approach traditional relational database manager store non-spatial data spatial data system arc info spatial data manager papyrus hybrid approach successful complicates query optimization execution multiuser environment approach exempli bypostgres gral montage ube geo vvo paradise integrated approach data stored database system began paradise parallel data information system project early dlpy response challenges posed sequoia benchmark sfgm goal paradise project apply object oriented parallel database technology developed part exodus cdf gamma dgs projects task implementing parallel gis system capable managing extremely large multi-terabyte data sets produced upcoming nasa eosdis project car project focusing resources algorithms processing storage techniques makingnew contributionsto datamodeling query language user interface domains paradise supports storing browsing queryingof geographic data sets data model extended relational data model extended raster polygon polyline adts typed extension sql provided support hoc queries extents persistent objects paradise shore cdf storage manager persistent objects graphical user interface built public domain toolkit outset organized paradise project phases goal rst phase produce client-server version paradise phase project parallelize paradise server operate shared sto multiprocessor target multiprocessor platform processor disk intel paragon rst phase complete paper addition allowing feet wet gis domain phase project produced usable client server version system performance functionality comparable integrated systems remainder paper organized section describes paradise data model query language software architecture system including techniques dealing spatial data presented section section performance evaluation system sequoia benchmark finally section conclusions future plans data model query language data model paradise extended relational data model modeling gis applications type constructors provided extent tuple extent consists set objects type aparadise database consists extents objects ned tuple type constructor attribute instance standard base type integer oat string prede ned gis speci abstract data types adts including polygon polyline raster typed object extents typed objects nition fairly rich set complex objects addition functions adts predicate query adts functions operators methods ned coded type system extended inheritance existingadtsorby ning adts rst registered catalog manager object types weather database shown figure text raster date polyline polygon prede ned adts fairly rich paradise data model restricted full object-oriented database system provide abd paradise directly support set valued attributes made simplifying decision order avoid implementation complexities full object oriented data model shoreimplementation odmg standard cat object oriented data model odl operational plan switching create extent instrument string type integer manual text create extent cloudcover clouddensity raster measuringdevice ref instrument date date create extent rivers string shape polyline flood plain polygon water level integer levee status integer create extent cities boundary polygon string population integer figure sample paradise schema query language query language paradise extended version sql sql wehave added abilityto invoke methods ned adts ability followinter-object standard nested dot notation zan accessing components complex objects schema shown figure tolocate cities ected oods mightpose query note query performs spatial join cities rivers extents select cities rivers cities boundary overlaps rivers flood plain rivers levee status weak query executed rst selecting rivers tuples satisfy predicate levee status index exists boundary attribute cities extent nested loops index join performed flood plain attribute selected rivers tuples lter matching cities tuples query nding current cloud coveroverall large cities severe thunderstorm warning issued select clouddensity clip boundary cities cloudcover boundary area date clouddensity clip boundary average area function ned polygon adt average function ned raster adt clip function raster adt takes polygon argument query selects cities area greater miles joins cloudcover tuple scanned join result tuples average clouddensity greater units produced result tuples result tuples attributes city raster image cloud cover city note dot notation expression clouddensity clip boundary average expression implies function clip applied cloudcover clouddensity attribute cities boundary argumentfor clip function returns type raster return average function applied return function evaluating predicate software architecture system overview version paradise employs conventional client server architecture shown figure server includes tuple manager extent manager catalog manager query optimizer scheduler front end graphical user interface supports querying browsing updating paradise objects graphical textual interfaces case front end transforms query extended sql syntax ships paradise server execution executing query server ships result objects backtothe client process postgres portal mechanism gro communication front end server processes form remote procedure calls running tcp paradise adts paradise adts paradise tuple 
cache paradise user front end meta data cache catalog manager shore storage manager extent mgr tuple mgr scheduler query optimizer paradise sql queries result paradise tuples paradise client process paradise server paradise servers figure paradise process architecture paradise user front-end user interface important componentofany database system important part gis gis provide convenient graphical interface visualization manipulation spatial data front end capable graphically querying browsing updating spatial objects stored database address complex user requirements spatial processing analysis section describe approach developing user front end paradise rst attempt front end geo based graphical user interface geographical database systems vov geo class libraries based displayvehicle postgres underlying spatial database management system geo graphical browser viewing spatial data graphical interface composing hoc queries weconverted geo paradise postgres database server approachenabled rapidly produce working graphical user interface paradise encontered number signi problems geo designed speci cally run top postgres eachobjectreturned paradise server geo front end convertedfromits paradiserepresentationto postgres representation needless performance approachwas good problem version geo displaymultiple spatial attributes object polygon point attributes geo requires result join attributes input relations finally modi library geo display library extremely complex public domain wide varietyof obvious solution converting geo understand paradise object format determined cult platforms limitations reluctantly decided solution write interface approachwas simple clone geo feel avoiding limitations current geo implementation paradise front end implemented ous publicly toolkit based lightweight interpretive command language tcl ous interviews lcv resulted dramatic reduction size complexity front end apparently sacri cing performance key features paradise front end include display objects spatial attributes map objects multiple spatial attributes spatial attributes position object screen spatial adts supported include points closed polygons polylines raster images layered display overlapping spatial attributes erent queries extents displaycity objects satisfy predicate population layer top layer country objects querying graphical interface implicitly issuing spatial queries zooming clicking sketching rubber banded boxonthe dmap querying explicitly composing ad-hoc queries paradise extended sql syntax browsing objects extent mode attributes displayed ascii strings updating paradise objects object updated selected bypointing clicking map selecting textual browser general catalog operations including browsing creating databases ning extents creating indices attributes bulk loading data extents unix system structure paradise user front end shown figure consists components map view responsible displaying manipulating objects contained layers current position cursor continuously displayed window units map projection system users point click displayed objects view non-spatial attributes approximately reduction number lines code user paradise server map view layer manager browser composer meta cache object cache query executor tuple manager tuplesquery paradise front end figure architecture paradise front-end addition users zoom selected region bysketching rubber banded box layer manager responsible adding deleting hiding reordering layers displayed map view eachlayer corresponds extent objects produced executing query extent browser user view anyparadise extent adjust displayed map view selected extent layer spatial attributes displayable map view query composer user compose sql query simple text editor query executor interface paradise server ships sql queries paradise server execution retrieves result tuples object cache object cache caches result query formats understood tcl meta cache stores catalog information open database screen dump paradise front end shown figure paradise server paradise server shore cdf underlying persistent object manager paradise server implemented shore added server vas directly top shore storage manager basic shore server paradise adds catalog manager extent manager tuple manager query optimizer execution engine support point polyline polygon raster adts shore server designed run shared multiprocessors task extending figure map view paradise front-end paradise suchanenvironment signi cantly simpli execution query paradise proceeds submission query sentby front end paradise server execution query parsed optimized execution plan generated parser optimizer consult catalog manager obtain type information statistics query plan generated plan forwarded query scheduler executor execution result tuples produced packed pages shipped client process display subsequent manipulation arrival client process objects undergo transformations coordinate projection conversion prior display processing designing implementing paradise server careful attention paid insure system ciently process queries involving spatial attributes large volumes data sections wedescribeseveral interesting design implementation issues encountered implementation phase spatial access trees order support cient retrieval objects spatial attributes trees bkss full concurrency control recovery added shore storage manager trees selected cacy relative ease implementation reuse lot existing shore tree code grid les nhs kdb trees rob considered multidimensional access methods good job handling point spatial data gre trees variant tree gut reduce overlap nodes duplicating spatial objects erent nodes full node tree split split propagated upwards direction signi cantly complicates implementing concurrency control recovery finally trees provide support forced reinsert bkss whichmakes dynamically clustering spatial objects index feel feature important order avoid performance degradation dynamically changing environment bulk loading trees importantcharacteristic access method ability perform initial index construction bulk load adise designed ciently handle large volumes spatial data respect trees requires load data fast rate produce good clustering rectangles resulting index systems bulk loading tree multiple insertions tuple results long load times tree split repeatedly insertions bulk loading builds index bottom guarantees index page processed order improve bulk load time retaining ectiveness resulting tree tree packing algorithm bulk load algorithm spatial sorting hilbert curve hilbert curve selected performance spatial ordering curves ordering grey code column scan spatial query processing domain jag unlike algorithm pack leaves tree utilization discovered simulation generate awell structured tree input data distributed uniformly algorithm special mechanisms make resilient erent spatial data distributions heuristic approach rectangle packing guide packing process heuristic decide stop adding entries currentnode move node heuristic parameters factor monitoring utilization currentnodeand expansion factor measuring increase size minimum bounding box node occur rectangle added factor reaches minimum threshold expansion factor reachesa maximum threshold packing process ushes current node starts adding entries node optimization designed achieve spatial clustering packing spatially close objects node maximum extent means incurring decrease storage utilization spatially clustered nodes overlap minimum bounding boxes caching repacking eachpacked node produced added small size cache recently packed nodes written disk nodes cache packed independently minimum bounding boxes overlap rectangles nodes cache inserted single large node node resplit smaller nodes standard tree splitting algorithm process combining splitting improves spatial clustering minimizes overlap nodes cache finally cached node smallest hilbert curve 
semantics quel sql results presented table slightly misleading times machines directly comparable teradata treats insertion separate operation dewi time required insert tuples result relation accounts significant fraction execution time query gamma hand pipelines output selection handling bulk update decided separate processing time queries time insert tuples result relations calculated rate tuples redistributed inserted machine dividing difference number tuples selected difference time select tuples index measure processing time subtracted approximate time redistribute store result relation number tuples retrieved multiplied average cost insertion tuple entry table table analysis selection performance gamma section study response time nonindexed indexed selection queries tuple relations affected number processors disk page size ideally average insertion rate computed averaging obtained relation sizes table adjusted selection queries execution times seconds number tuples source relation query description teradata gamma teradata gamma teradata gamma nonindexed selection nonindexed selection selection non-clustered index selection non-clustered index selection clustered index selection clustered index linear improvement performance relative number processors constant page size varying configuration set experiments disk page size kbytes number processors disks increased number processors increased number tuples stored site reduced proportionally nonindexed selections index data pages relation read disk processed increasing number processors process non-indexed selection increases aggregate cpu power bandwidth reducing number tuples processed processor figure average response time selections tuple relation presented function number processors disks expected response time queries decreases number sites increased response time queries selectivity factors worse query due cost transmitting storing result tuples selection-only queries store result tuples locally partitioning result relations round-robin hashed fashion insure fragment result relation approximately number tuples speedup curve figure presented figure shown figure linear figure figure processors disks selectivity selectivity selectivity selection selection selection speedupresponse time seconds processors disks speedup obtained queries reason selection query achieve perfect speedup number end stream messages section processor send increases processors added system selectivity speedup curve close linear curves due effects short-circuiting section single processor result tuples shortcircuited low-level communications software processors fraction tuples shortcircuited decreases processors ruru result tuples short-circuited actual network bottleneck gerb gerb bandwidth memory communications network limited speed megabits unibus vax selectivity factor query increased number short circuited tuples decreases path network bottleneck fact illustrated differences curves figure indexed selections suite tests constructed clustered non-clustered indices unique unique attributes tuple relations figure average response time plotted function number processors disks queries selection clustered index selection clustered index selection non-clustered index speedup curves presented figure speedup curve obtained selection non-clustered index results presented non-clustered index selection optimizer chooses segment scan query clustered index selection figure figure processors disks speedup clustered index selection clustered index selection non-clustered index selection non-clustered index selection clustered index selection clustered index selection response time seconds processors disks speedup curves presented figure reveal number interesting insights effects increasing amount parallelism indices employed case selection query response time query increases seconds number processors increased cost initiating select store operator processor appears slightly higher cost performing operations search index discovering tuples satisfy predicate remaining queries selection non-clustered index close achieving linear speedup index queries obtained linear speedups selection query index processor executing query produce network packet kbytes result tuples approximately kbyte pages reads disk kbyte disk pages system bound query executed clustered index page qualifying tuples found subsequent page read disk completely full result tuples data page read communication packets number processors increased fraction packets short circuited decreases disk producing packets faster communications interface place network performance degrades case selection clustered index effect occurs number processors increased time initiate query process levels index sites seconds significant fraction total execution time query seconds finally reason selection non-clustered index achieves close linear speedup disk page read requires random seek significantly reducing rate disk produces pages effect disk page size selection performance experiment configuration size constant processors disks disk page size varied kbytes kbytes sequential index scans tuple relations nonindexed selections non-indexed selections selectivity factors executed disk pages sizes ranging kbytes response times queries plotted figure speedup curves presented figure results selection curve generate network traffic kbyte disk page system disk bound page size increased kbytes system cpu bound vax cpu mip increase size disk page bytes effect response time query repeating experiments faster cpu interesting results presented figures provide evidence network interface bottleneck kbyte page size response time selection percent slower response time selection kbyte page size selection percent slower selection clear increases rate result tuples produced increasing size disk page clustered index network interface increasingly bottleneck selection selection selection selection selection selection selection selection disk page size kbytes speedup disk page size kbytes response time seconds figure figure indexed selections repeated set experiments constructing clustered index unique attribute non-clustered index unique attribute tests increasing size disk page increases fan nodes b-tree index average response time speedup curves queries tested presented figure interesting results obtained selection non-clustered index figures increase disk page size degrades performance query tuple retrieved requires fetching index pages data page longer transfer time larger pages dominates advantage provided terms fan-out kbyte disk page transfer time milliseconds close time required perform random disk seek disk kbyte track size clustered index employed degradation performance occur proper leaf page index located subsequent tuples page subsequent leaf pages satisfy query selection continues show improvement larger disk pages response time selection increases slightly page size increased kbytes longer transfer time source problem processors site produce approximately tuples kbyte pages page hold approximately tuples tuples satisfying query span pages expected case tuples read satisfy query join queries goals mind designed experiments testing join performance gamma wanted typical gamma configuration performs fixed set join queries size input relations increased point results running set queries processor teradata database machine presented wanted explore gamma performance affected number processors disks increased disk page size increased amount memory reduced join algorithms teradata machine alternative join algorithms tera computes outerjoin special cases relation single tuple fourth commonly join method involves redistributing source relations hashing join attribute amp receives tuples stores temporary files sorted hash-key order non-clustered index selection figure non-clustered index selection clustered index selection clustered index selection disk page size kbytes response time seconds non-clustered index selection clustered 
processor generated random keys processor keys tuples partition stored uni-processor experiments b-tree index ciently retrieve tuple sample note optimization require join attribute relation identical attribute partition relation relation creation requires attribute fetch random tuple attribute partition relation relation creation catalog information algorithm works correctly performance degradation due unsuccessful searches index tuples stored processors experiments results scaleup speedup metrics evaluating multiprocessor database machines scaleup interesting metric multiprocessor database machines constant response time maintained workload increased adding proportional number processors disks speedup interesting metric additional processors disks result decrease response time query similar set experiments reported egks equi-join queries release tandem nonstop sql system dgs equi-join queries gamma scaleup scaleup experiments wevaried number processors disk processor tuple relation joined tuple relation processors relations scaled tuples tuples similarly processors sizes relations joined tuples con guration relations joined time sec number processors band band figure scaleup performance evenly distributed relation creation processors applying range predicate unique attribute values range relation cardinality minus join query tested twenties join twentywrap uniprocessor experiment section figure presents scaleup results parallel hybrid partitioning band join algorithm band sizes factors contribute slight increase response times task initiating processes site relation scans join store sampling operator performed single processor number processors increase ects short-circuiting dgs messages execution query diminishes processor con guration approximately tuples input relations result relation process processor short-circuiting communications network number processors increased number short-circuited packets decreases point processors packets short-circuited intra-node packets expensive inter-node packets smaller con gurations bene short-circuiting finally processors added larger skew sizes subjoins allocated processor demonstrates interesting tradeo sampling time execution time roughly speaking sampling lower skew faster execution time exclusive sampling sampling higher overhead sampling detail increase workload total relation size increases errors sizes partitions proportional size total relation means total number samples constant expected error partitions increase implementation scaled number samples number processors keeping expected number samples processor constant processor join times samples processor join error inversely proportional square root number samples scaling number samples linearly cienttokeep expected error partitions constant whywesaw larger skews larger con gurations tokeep skew constantaswe add processors wewould havetoscalethenumber samples quadratically number processors number processors grows linearly means expected number samples processor grow linearly node con guration skew processor case processor average times samples node case implies good scaleup processors parallel hybrid partitioning band join algorithm scale inde nitely speedup speedup experiments wekept size relations joined constantat tuples varying number processors held constant number samples determine partitioning elements twentiesjoin twentywrapquery band size test query processors execution time speedup table speedup results response time speedup band join size result relation size tuples shown table obvious adding additional processors signi cantly reduces execution time query factors prevent system achieving perfectly linear speedups important note base case processors perfect speedup factor processors case scaleup experiments performance limited bythe overhead scheduling operators query tree ects short-circuiting ects skew size subjoins allocated processor demonstrate ect skew measured number tuples produced join site maximum values measured ered optimal assuming perfectly uniform distribution processor con guration maximum skew approximately processor con guration maximum skew found optimal multiprocessor performance limited slowest site increase skew processors added results sublinear speedups conclusions twovariants partitioned band join algorithm grace hybrid compare favorably optimized sort-merge band join algorithm encouraging surprising previously demonstrated equijoin hash-based join algorithms outperform sort-merge initially obvious algorithms ective band joins hash based algorithms equijoins compared hash-based equijoin algorithms partitioned band join algorithms signi cantly work equijoin algorithm hashes bucket relation partitioned band join algorithm sorts partition relation equijoin algorithm hash-based lookup partitioned band join algorithms binary search nally equijoin algorithms equivalent sampling overhead partitioned band join algorithms unlike situation hybrid grace hashed equijoin algorithms grace partitioned band join dominate sort-merge hybrid partition band join dominate grace partitioned band join reason added cost sampling memory scarce grace hybrid variants partitioned band join algorithm lot samples ensure errors partition sizes thrashing pool small memory sizes hybrid sample grace ectively memory hybrid partitioning partitions grace algorithm implies system algorithms performing band joins optimizer decide algorithm band join partitioned band join algorithms perform cases signi fraction operands memory input relation sizes erent important case occur band join part query form finally wehave demonstrated partitioned band join algorithm ective multiprocessor systems achieving good speedy scaleup con gurations processors maximum measure acknowledgements researchwas funded ibm research initiation grant wewould rick rasmussen porting uniprocessor version algorithms hypercube locating nasty gamma bug bdt bitton dewitt turby benchmarking database systems systematic approach proc ninth vldb conf pages cdkk h-t chou dewitt katz klug design implementation wisconsin storage system software practiceand experience october con conover practical nonparametric statistics john wiley sons york dewitt gerber multiprocessor hash-based join algorithms proc twelfth vldb conf pages dewitt gray parallel database systems future database processing passing fad sigmod record dgs dewitt ghandeharizadeh scneider bricker hsiao rasmussen gamma database machine project ieee trans knowledge data engineering dko dewitt katz olken shapiro stonebraker wood implementation techniques main memory database systems proc sigmod conf egks englert gray kocher shah benchmark nonstop sql release demonstrating near-linear speedup scaleup large database technical report tandem part tandem computers gra goetz graefe personal commuication hot hou ozsoyoglu taneja statistical estimators relational algebra expressions proc pods conf ktmo kitsuregawa tanaka moto-oka application hash data base machine architecture gen comp lkb livny khosha boral multi-disk management algorithms proc sigmetrics conf olken rotem random sampling -trees proc fifteenth vldb orx olken rotem random sampling hash les proc acm sigmod conf pages ries epstein evaluation distribution criteria distributed database systems technical report ucb erl tech rep ucberkeley schneider dewitt performance evaluation parallel join algorithms shared-nothing multiprocessor environment proc sigmod conf sto stonebraker case shared database engineering 
nested loops revisited david dewitt rey naughton joseph burger abstract research communityhas considered hash-based parallel joinalgorithmsthe algorithmsofchoice almosta decade almostnone ofthe commercialparallel database systems hashing-based join algorithms usinginstead nested-loops withindex sort-merge research literature abounds comparisons hash-based sort-merge join algorithms knowledge published comparison parallel hash-based algorithms parallel nested loops algorithm index paper present comparison variants parallel index nested loops algorithms parallel hybrid hash algorithm conclusions experiments analytic model implementation gammaparallel database system parallel hybrid hash method choice cases nested-loops index wins big systems pro implementing algorithms experiments show nested loop algorithms subset nestedloops sorting dominates introduction research communityhas longconsidered hash-based joins method choice performing joins multiprocessor database systems line reasoning roughly long uniprocessor systems sort-merge beats nested loops index hybrid-hash beats sort-merge uniprocessor multiprocessor case dko transitively expect department computer sciences wisconsinmadison researchwas supported donations dec ibm ibm research initiation grant ncr tandem work supported part nsf grant irihybrid hash out-perform nested-loops index hybrid hash sort merge algorithms execute join query joins whichatleastoneofthetwo relations joined base relation multiprocessor case interesting asymmetry arises nested-loops index algorithm onlyoneofthe operand relationsina two-relation join partitioned network suggests parallel nested loops index maybeable exploit asymmetry parallel environmentto provide higher performance parallel hybrid hash partitions relations case relation declustered joining attribute wasourgoalinthisresearch explore performance parallel nested-loops index join algorithm determine signi erences variants parallel index nested loops cases parallel nested loops index performance parallel hybrid hash cases signi cantistheperformance erence cases parallel hybrid-hash perform parallel nested loops index howsignificant erence answers questions determine ofthese joinalgorithmsneeds included parallel database system ofmorethan academicinterest aware commercialparallel dbmss employ parallel nested loops index two-pronged approach order answer questions built simple analytic model predicting performance parallel hybrid hash join versions parallel index nested loops analytic model quickly exploring relative performance algorithms wide range hardware join operand parameters opinion analytic model provide detailed insightand con dence engendered actual implementation implemented algorithms gammaparallel database system dgs results analytic model implementation demonstrate parallel nested loops index perform parallel hybrid hash relations small relation clustered index join attribute relation index join attribute memory cases hybrid hash signi cantly parallel nested loops algorithms results show version parallel index nested loops algorithms subset nestedloops sorting clearlydominates related work dewitt gerber investigated performance parallel hashing join algorithms schneider dewitt compared parallel hashing algorithms parallel sortmerge kitsuregawa ktmo proposed algorithm based hashing redistribution sort-merge intended advantage specialpurpose sorting hardware papers compared hashing join algorithms nested loop index algorithms valduriez gardarin compared parallel join semijoin algorithms based hashing sort-merge nested loops nested-loops index tandem group egks state nonstop sql system variant parallel nested loops index algorithm indices exist relations small hashing sort-merge compare algorithms wolf wdyt wdy performance parallel hashing sort-merge algorithms presence skew parallel nested loop algorithms early work blasgen eswaran compared sort-merge nested-loops index uniprocessors concluded sort merge wins clustered index join operands recently shekita carey compared number uniprocessor join algorithms including pointer based join algorithms nested-loops index sort-merge hybrid hash portion work relevant paper found index nested loops works relations small valduriez val proposed auxiliary data structure called join index join processing showed cases join algorithm join index out-perform hybrid hashing term index join index algorithmdi ers signi cantly fromthe nested loops index algorithms join index essentially precomputes join storing pairs tuple pair tuple tuple join result indices nested-loop index usual b-tree indexes built current relational dbms omiecinski lin join indices parallel environment remainder paper organized describe hybrid-hash algorithm variants nested loops index section section describes analytic model section describes results derived model section describes implementation experiments gamma conclusions contained section algorithms throughoutthis paper willadoptthe conventionthat relations joined join condition assumethatthere isanindex onthe attribute uniprocessor nested loops index join algorithm tuple lookup index tuple returned lookup output answer tuple endfor endfor wenow implementaversion algorithm shared-nothing parallel database system sto mapping algorithm sharednothing parallel system rst howthe relations stored system assume declustered processors system attributes priori relationship tuple attribute tuple stored system similarly location tuple independentofthevalue appears immediately creates problem howtoensure tuple meets tuple considered mechanisms guarantee replication mapping dealt subsection replicating parallel nested loops obvious solution broadcast tuple site multiprocessor broadcasting site multiprocessor joins local fragmentofs indexed nested loops perform local join high-level pseudocode algorithm processor broadcasts local fragment processors processor joins local fragment indexed nested loops call algorithm replicating nested loops index abbreviate rnl rnl similar distributed database join algorithm fragment-replicate originallyproposed esw fragment phase ano-op algorithmbegins fragmented sites system rnl algorithm bytandem index exists relations small join key small relation egks recently stamos young proposed improvementon full fragment-replicate algorithm partially replicates redistributes input relations algorithm improves network cost full fragment-replicate rnl redistribute portions eliminates possibility preconstructed index subsetting parallel nested loops replicate nested loops algorithm disadvantage tuples shipped sites nomatchings tuples fact inthe case tuple joins tuple foreign key-key join processor system tuples site matching tuple subsetting parallel nested loops algorithm seeks avoid wasted ort determining tuple subset sites whichmatching tuples reside abbreviate subsetting nested loops index snl culty assume anyassociation attribute values partitioning attribute information system catalogs determine whichsubsetof sites tuple solution build additional relation whichwe call maps maps join attribute values partitioning attribute values detail suppose range hash partitioned dgs attribute key relation maps schema maps semantics tuple maps tuple intentionisthatinamaps tuple attribute surrogate tuple maps tuple tuple general maps large replicate sites reason maps declustered hashing system attribute maps concept sucha mapping relation attributes surrogates introduced copeland khosha decomposition storage model remainder paper simplicitywe assume key sowecanusep note maps join index val join index entry pair tuples suchthatr join maps pairs join attribute values partitioning attribute values independentofr maps relation subset sites tuple mapped two-step process send site maps tuples note consulting system catalogs maps hash range partitioned tuple sendr site tuples note accomplish consulting system catalogs partitioned attribute redistributed fashion snl proceeds rnl broadcast site nested-loops index join subset mapped subset stored sorting variants investigated ect sorting tuples joining rnl snl maps tuples snl denote resulting algorithms rnl-s snl-s sorting outer relation well-known optimization nested loops index algorithms relation fragment site clustered index join attribute sorting tuples joining insure data index pages 
arereadonly join process similarly ifmaps clustered maps thenby sorting incoming tuples avoid re-reading data index pages maps snl-s algorithm wesortther tuples rst mapping site joining site reason processor actual join receiving tuples mapping phase algorithm joining general processor stream incoming tuples processors system stream chunked sequence messages tuples message sorted sorted mappingprocessor sentthat message guarantee tuples combined stream messages sorted order guarantee relationship tuples message processor tuples message optimization technique discussed subsection hybrid hash hybridhash joinalgorithmhas detail literature dko wegive top-level overview importantaspects parallel hash join algorithms denote hybrid hash basic parallel hash join join condition begins redistributing hash function chosen redistribution tuple processor determined similarly atuples processor determined subset mapped processor denoted subset mapped denoted redistributing processor joins local fragments local joins performed hashing hash function chosen build in-memory hash table tuples attribute in-memory hash table probed tuple based attribute ers basic hash algorithm attempts tuples memory redistribution stage tuples don havetobe re-read disk join phase detail fraction retained memory ofr written disk joining processor equally importantly ofs written disk joining processor tuples join memory-resident portion joined discarded alternatives parallel nested loop algorithms hybrid hash algorithm viewed consisting twosomewhat orthogonal subtasks redistributed relations parallel hybrid hash hash partitioning redistribute input relations parallel nested-loops algorithms redistribute relations replicating relation subsetting local joins redistribution parallelhybridhash hybrid hash local joins whileparallelnested loops withindex nested loops index algorithm fromthis perspective clear twoother classes algorithms hashing-redistribution ofboth relations followedby indexed nested loops sites replicating mapping relations byhybrid hash sites explore algorithms perform hash-based redistribution indexed nested loops perform parallel hybrid hash cost creating clustered index whichmust query evaluation time redistribution higher cost building hash table broadcast mapping redistribution relations byhybrid hashing perform parallel nested loop index algorithmsbecause ignores pre-existing index join attribute completely process relations local joins site redistribution analytic model section wedevelop analytic model intended predict performance join algorithms purpose model predict absolute performance identify important trends characteristics relative performancesof algorithms algorithmin turn case separate cost algorithm cpu network case omit cost writing answer relation cost algorithms include cost reading input relation cost ers algorithms assume messages eachcontain page make simplifyingassumptionthat running time parallel algorithm calculated computing time required single site isolation complete tasks required algorithm model takes input parameters describing input relations jrj number pages krk numberoftuplesinr jsj number pages ksk numberoftuplesins explicitlynoted assume join foreign key-key meaning tuple joins tuple assume tuple joins randomly chosen tuple means tuples join tuple parameters describe hardware conguration procs number processors mem numberofmemorypages time read write msg time send receive message hash time compute hash function insert time insert hash table probe time probe hash table hybrid hash critical parameter performance parallel hybrid hash percentage memory percentage processed writing tuples disk repartitioning model belowwe refer fraction part frac partition fraction read local partition jrj procs write jrj procs part frac read local partition jsj procs write jsj procs part frac network cost hybrid hash net send jrj procs msg receive jrj procs msg send jsj procs msg receive jsj procs msg finally cpu cost hybrid hash cpu destination jrj procs hash insert hash table jrj procs insert lookup hash table jsj procs probe intended cover cpu costs covered expressions network times cpu cost accurate model fortunately accuracy model smallest component total cost algorithm replicating nested loops rnl coming expression running time nested loop index algorithms slightly complex case hybrid hash totalnumberofi determined algorithm case hybrid hash determined bythe combination algorithm pool size replacement policy replicating nested loops index algorithm assume pool pages allocated decreasing priority index pages data pages data pages motivation policy index pages memory resident duration algorithm read multipletimes page memoryit spooled disk arrives join site re-read tuples page joined index general smaller sokeeping index memory costs fewer pages keeping memory priority index pages data pages roughly approximates behavior algorithmunder lru managementpolicy index pages expected hotter data pages mind cost replicating nested loops algorithm formula quantities indexreads sreads rreads quantities ned formula rnl initrreads indexreads sreads rjoinreads initrreads jrj procs read original fragments recall rnl replicates processor process calculate number index page reads weassume initiallythere index pages pool anygiven timeduring execution algorithm probability tuple hits pool ratio numberofindex pages memoryto total number index pages tuple misses pool frames number resident index pages incremented calculationfor numberofs page reads isidentical memory initially availableto memoryleft tting index memory finally number rjoinreads calculated rst number pages jrj minus number pool pages tting index memory read write page joinreads pages owpages pages remain pool join network cost replicating nested loops algorithm easy calculate rnl net broadcast fragment jrj msg receive jrj msg processor send receive jrj messages jrj procs rnl fully replicates assuming site broadcast jrj procs pages requires sending total jrj procs procs jrj pages finally cpu cost replicating nested loops rnl cpu cost index probes krk cpuindex case hybrid hash cpu cost unaccounted network costs model hybrid hash cpu cost small fraction total cost replicating nested loops sorting rnl-s index join attribute clustered index rnl sped sorting joining case total number reads number pages tuple joins tuple calculate quantity numsreads assuming tuples join tuples randomly distributed pages viewpoint classical balls bins problemfromelementary probabilitytheory numberofs index reads numsindexreads computed analogous number reads initial scan read join assuming sort leaves disk subsection discusses optimization snl-s avoids muchof cost sort required number reads writes sort analytic model weassume sorted passes modern memory sizes gbyte relation sorted passes stg means cost replicating nested loops sorting rnl-s scan initial fragment jrj procs two-pass sort jrj reads actual join jrj reads numsreads index reads numsindexreads network cost identical network cost replicate nested loops sorting cpu cost replicate nested loops replicate nested loops additional cpu sort analytical model formula dko krk logkrk keyswap move subsetting nested loops snl recall snl broadcasting processors tuple rst senttoanintermediate processor lookup maps relation forwarded processors tuples join reason subsetting nested loops algorithmwe numberofs tuples join tuple model assume number constant fanout assume model tuple joins tuples tuples located distinct processors rnl number reads snl depends interaction algorithm pool top level total time expression snl initrreads mapsreads rmapreads 
index selection clustered index selection speedup disk page size kbytes figure redistribution phase completes amp conventional sort-merge join algorithm complete join test queries algorithm gamma partitions source relations hashing join attributes sort-merge effect join gamma employs algorithm based hashing kits dewi dewi gerb phase algorithm gamma partitions smaller source relation hashing joining attribute builds main-memory hash tables phase gamma partitions larger source relation tuples immediately probe hash tables built phase main-memory hashing danger hash-table overflow gamma distributed version simple hash-partitioned join algorithm dewi handle phenomenon basically processor detects hash-table overflow spools tuples temporary file based hash function hash table successfully built query scheduler passes function subpartition hash table select operators producing probing tuples probing tuples tuples overflow partition spooled temporary file tuples probe hash table normal overflow partitions recursively joined procedure overflow partitions created join fully computed gamma run joins variety modes selection operators run disk sites hash tables built processors disks diskless processors sets processors alternatives referred local remote allnodes queries join queries formed basis join tests join query joinabprime simple join relations bprime relation tuples bprime relation tuples query joinaselb performs join selection number tuples selection reduces size size bprime relation joinabprime query tuples joinabprime joins bprime relation tuples joinaselb selection restricts tuples joins result join query joincselaselb joins restricts restricted original size tuples joined tuple joins tuple join yields intermediate relation equal size input relations intermediate relation joined relation number tuples result relation tuples assume tuples relations resulting selections tuples join results intermediate relation tuples relation joined relation tuples result query tuples performance relative relation size variation queries tested involved indices non-key non-partitioning non-indexed attribute unique unique join selection attributes source relations distributed key attribute join algorithms machines required redistribution phases results tests contained rows table series tests results presented table gamma kbyte disk pages join queries performed remote mode joins diskless processors variation join queries key attribute unique unique join attribute rows table results case relations distributed join attribute teradata machine demonstrated substantial performance improvement redistribution step join algorithm skipped case gamma relations redistributed diskless processors joins results table conclude execution time queries increases fairly linear fashion size input relations increased gamma exhibit linearity million tuple queries size building relation megabytes exceeds total memory hash tables megabytes simple hash-partition overflow algorithm deteriorates exponentially multiple overflows fact computation million tuple join queries required partition overflow resolutions diskless processors section explore detail impact limited memory performance join queries gamma observant reader noticed teradata joinabprime faster joinaselb opposite true gamma explain difference analyzing table table join queries execution times seconds number tuples source relation query description teradata gamma teradata gamma teradata gamma joinabprime non-key attributes join attribute joinaselb non-key attributes join attribute joincselaselb non-key attributes join attribute joinabprime key attributes join attribute joinaselb key attributes join attribute joincselaselb key attributes join attribute table adjusted join queries execution times seconds number tuples source relation query description teradata gamma teradata gamma teradata gamma joinabprime non-key attributes join attribute joinaselb non-key attributes join attribute joincselaselb non-key attributes join attribute joinabprime key attributes join attribute joinaselb key attributes join attribute joincselaselb key attributes join attribute tuple joins selection propagation gamma optimizer reduces joinaselb joinselaselb means tuple relations read entirety relations network participate join joinabprime reads tuple relation send tuples diskless processors effect join cost distribute probe tuples outweigh difference reading tuple file hand teradata database machine compute joinabprime reading sorting tuple relation tuple relation merging joinaselb read tuple relations sort merge tuple relation joinaselb slower difference reading tuple relations analysis join performance gamma section explore effects changing size disk page reducing amount buffer space join hash tables performance join queries relative number processors preferred million tuple relations experiments aggregate memory execute million tuple join queries experiencing partition overflow cost processing overflows impact test conducted chose run experiments tuple relations constant memory constant page size varying configuration series tests wanted explore joins performed increased number processors disks attached order concentrate effects changing gamma configuration disk page size constant bytes amount memory join hash tables large insure partition overflow occur figures present response time joinabprime query joining attributes key partitioning attributes partitioning attributes shape graphs obvious gamma significantly reduces response time additional processors added expect remote joins fast local joins remote joins remember add processor disk add processor disk diskless processors exploited remote allnodes joins processors pointed dewi case building probing phases join operator overlapped response time query bounded sum elapsed time phases multiuser environment expected offloading join operators remote processors processors disks effectively support concurrent selection store operators validity expectation determined future multiuser benchmarks gamma database machine interesting feature figures larger configurations relative performance local allnodes joins mirrored respect remote joins remain constant joins partitioning attributes local configuration fastest allnodes remote joins attribute partitioning attribute joining attribute remote configuration fastest allnodes finally local graphs identical single processor configuration relations stored single disk partitioning data occurs mirror-like performance function occurs gamma hash function partition relations loaded joined joining partitioning join attrs partitioning attrs joinabprime query tuple relations kbyte disk pages constant memory overflow system response time seconds processors disks allnodes joins remote joins local joins local joins remote joins allnodes joins processors disks response time seconds system constant memory overflow kbyte disk pages tuple relations query joinabprime join attrs partitioning attrs figure figure attributes local joins short-circuit input tuples gain performance advantage conversely joins performed non-partitioning attributes local joins perform worst short-circuiting benefit substantially increased contention cpus disks building probing hash tables competes selection store operators performance allnodes configuration falls remote local configurations shares benefits drawbacks speedup curves joinabprime queries shown figures notice linear speedups obtained speedup curves plotted response time processors point order reduce skewing curves due short-circuiting explained single-processor configuration joins non-partitioning attributes local joins tuples short-circuit network processors approximately half tuples short-circuited general number processors increased number short-circuited packets reduced proportionally intra-node packets expensive internode packets smaller configurations benefit short-circuiting intent plotting join attrs partitioning attrs joinabprime query tuple relations kbyte disk pages constant memory overflow system speedup processors disks allnodes joins remote joins local joins local joins remote joins allnodes joins 
ushed disk leaving room node produced implementation paradise adts paradise adt erent representations memory format database format external format memory representation format adts stored user space database representation format stored disk tape database external representation ascii representation data input initial loading output output query viewed query browser front end adts haveconversionmethods switchbetween erent representations base adt type super class paradise adts super class set low level memory management routines memory resident adt instances standard interface common conversion modules paradise adts classi broad categories spatial spatial spatial adts points polygons polylines provide spatial methods operators deal spatial analysis suchasoverlap containment adjacency addition operatorscan applied erent types spatial adts determine polygon polyline overlap spatial functions minimum bounding box geometric size calculations supported spatial adt instance stores coordinate projection system adt classes provide methods converting erent projection systems raster adt unique operations including polygon clip lower resolution raster adt detail raster adt raster images tessellate space regular shaped cells assign cell eachcell generally corresponds readings satellite sensor raster images specially studying large portions earth surface big national oceanographic atmospheric administration noaa advanced high resolution radiometer avhrr cell size approximately nadir mgr size cell bytes raster image region united states consume mbytes space order make operations large images cient raster adt paradise employs techniques improve performance techniques sections separation raster header data implementing raster adt paradise decided break raster adt instance pieces raster header actual raster image raster header store descriptive data raster image actual raster image consists dimensional array values cell stored separate object shore storage manager rasterheader shore oid object identi raster image size raster image bounding box raster image figure shows paradise stores objects cloudcover extent weather database figure database schema cloudcover instance attributes dateof type date measuringdevice instrument object raster physicallyeach object extent consists values date oid instrumentusedtotake measurement raster header clouddensity attribute objects raster images cloudcover extent stored large objects separate shore approach number signi advantages illustrated figure objects disk tape raster image oid raster image bounding box tile size date ref instument tuple extent cloudcover raster image raster image tuple tuple tuple raster header clouddensity attribute figure physical representation cloudcover extent actual raster images transparently migrate secondary tertiary storage storing raster images large objects separate shore tuples primary extent remain physically clustered signi cantly improving performance sequential scan extent finally queries involving raster attribute raster images broughtinto memory clip operation polygon raster attribute determine object satis predicate check bounding box information stored raster header part tuple tuple satisfy clip predicate raster images fetched lazily image manipulated displayed enhance performance operations raster images raster image decomposed regular rectangular shaped regions called tiles data tile stored separate shore object map table raster image maintaining correspondence tile objects region raster image tile object raster header simply stores oid map table object decomposition raster image tiles paradise fetch portions required execute operation figure illustrates raster image clipped polygon required query section raster attribute rst needed performing clip operation mapping information raster image read disk oid part raster header swizzled pointtothe memory mapping information spatial position polygon mapping table wecan precisely calculate tiles raster image disk tape tuple extent cloudcover tuple tuple legend bounding box polygon polygon clipping raster image tuple date ref instrument tile size bounding box main memory raster header cloudcover attr raster image map table raster image map table raster image map table map table map table disk reads tile data cache result clip figure processing clip function attributes type raster needed clip operation relevant tile input read disk processed clip operation compression optimization strategy compression techniques widely image processing domains occasionally integrated directly database system swkh problems arise integration attempted unit compression generally entire image approach makes sense entire image required piece image needed cost uncompressing entire image mayovershadow improvement performance resulting read data disk situation worse part image updated asthe entire objectwill haveto read uncompressed updated recompressed written back disk problem unpredictability ectiveness compression algorithms handling kinds data compression ratio ned data size compression data size compression istoolow added cost compression decompression process degrade system performance paradise wecombine lossless compression techniques decomposition solve rst problem discussed raster images stored secondary tertiary storage number smaller tiles tile serves basic unit compression raster image large object compressed tiles subcomponents mapping position image tile performed mapping table stored tiles handle unpredictability compression algorithm monitor ectiveness compressed tile created compression reduce size tile signi cantly store tile uncompressed form mapping table tile compressed basic lzw algorithm wel compression raster objects decomposed rectangular shaped tiles future plan adding fancier domain speci compression algorithms adopting quadtree sam approach additional advantage improving performance types spatial analysis raster objects performance evaluation toevaluate performance paradise weusedthe sequoia storage benchmark sfgm sequoia benchmark real data sets nes suite queries chosen representativeof queries earth scientists frequently pose system benchmark erent scales data purpose benchmarking paradise wechose regional benchmark data benchmark fairly big gbyte single disk stages project intend run national earth benchmark national benchmark gbyte theearthbenchmark multiple terabytes national benchmark moderate size secondary storage system earth benchmark requires tertiary storage system description regional benchmark details readers referred original benchmark paper sfgm description regional benchmark regionalbenchmark comprisesof data rectangular region covering parts california nevada data set benchmark primarily consists erent data sets raster data corresponds readings earth surface sensors satellite raster image consists bit cell area scanned size cell raster image mbytes image time eld reading frequency eld frequency instrument taking reading raster data set total readings polygon data consists set regions boundaries ned collection lines region integer typed landuse pointdata consists location pairs correspond geographic points havespeci geographic features directed graph data data set information drainage networks river represented collection line segments paradise schema sequoia benchmark consists extents create extent raster time integer frequency integer data raster create extent polygon landuse integer shape closedpolygon create extent point location point string create extent graph shape polyline description queries details sfgm terms query capitals freq rect constants query loads data les builds clustered tree point location polygon shape clustered tree indices constructed raster frequency raster time point polygon landuse query involves 
clipping portion raster images sensor select raster data clip rect raster time raster frequency freq query computes average clipped portion raster images time select average raster data clip rect raster time time query query selects raster image raster image time frequency clipped rectangular region study result tuple stored lower resolution create extent rastertemp time integer frequency integer data raster insert rastertemp select time frequency data clip rect val lower res res val raster time time frequency freq query query selects point select point point-name query query select stores polygons overlap speci rectangular region create extent polygontemp landuse integer shape closedpolygon insert polygontemp select polygon shape overlaps rect query query nds polygons greater area contained circle select polygon shape containedin circle loc radius shape area area query query selects polygons overlap rectangular region point note query involves spatial join point polygon data select polygon location polygon landuse polygon point point point-name polygon shape overlaps point location makebox side val query query selects raster images polygons landuse query spatial join polygon raster extents select polygon shape raster data clip polygon shape polygon raster polygon landuse landuse raster frequency freq raster time time query query performs spatial join point polygon data selecting points overlap polygons speci landuse query executed parts rst part select points overlap selected polygons part remove selected points points overlap islands create extent pointsfoo location point string create extent pointsresult location point string insert pointsfoo select distinct point point location polygon point polygon landuse landuse polygon shape overlaps point location insert pointsresult select pointsfoo minus select distinct pointsfoo pointsfoo location islands pointsfoo islands shape overlaps pointsfoo location ectiveness compression conjunction tiling section evaluate ectiveness compression choice tile size raster adt compression bene reducing amount data stored read disk hand compression incurs cpu overhead compressing decompressing data compression ective yields larger compression ratios unit compression large tile basic unit compression argues larger tile sizes larger tile size implies operations clip operation fetch redundant data quantify tradeo ran raster queries queries sequoia benchmark con gurations rst con uration tile size shore page size con guration represents case compression small tile size minimizes amountofredundant data read disk con guration large tile size conjunction compression con guration lies middle spectrum compression tile size execution time running queries shown table system con guration section table compression increases database loading time query tile size average compression ratio observed implying reduction amount data written disk tile size con guration similar compression ratio implying reduction amount data written disk query compr compr compr tiles tiles tiles sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec table ect compression tile size compression reduced amount data written disk cpu overhead compression outweighed savings disk increasing load time query execution times table observe move tile size con guration tile size compression query execution times alwaysimprove movingto kbtile size degradesthe performance redundant data fetched compression ratio increases slightly ectiveness building clustered spatial indices mentioned section paradise mechanism building spatially clustered trees clustered indices advantage fewer data pages fetched objects close page hand building clustered spatial index requires tuples clustered based spatial position clustered index requires sorting oid bounding box pairs tuple clustered spatial index speeds evaluation queries incurring load time penalty quantify tradeo ran experiment parts clustered index created shape attribute polygon extent clustered index created attribute results experimentare shown table query non-clust clust speedup tree tree load sec sec sec sec sec sec sec sec table ect clustering load time shown includes time load polygon data time build tree observe penalty loading data obtain performance improvement query query retrieves polygon result erence cases queries havealow selectivity retrieve tuples larger selectivity observed bigger erence performance cases comparison systems section compare paradise systems postgres illustra called montage ube sto shown systems outperformed grass ipw popular gis systems machine benchmark sun sparc mbytes memory running sunos release seagate gbyte disk scsi model hold database illustra postgres unix paradise raw disk data volume illustra postgressupportsthe arawdiskforthedata volume seagate gbyte disk hold raw input data log system binaries system stored disk scsi model served system swap disk free disk space left disk ensure systems paid unrealistically high cost due swapping weusedversion postgres version illustra paradise compression turned tile size raster adt paradise illustra run pool performance postgres pool pool pool postgres polygon data pre processed large polygons points broken smaller polygons current version paradise version postgres wewere handle large polygons illustra handle ensureafaircomparison weused thesamepre processed data systems systems ran benchmark queries times average middle numbers run starting client sequentially issued queries benchmark query run separate transaction runs ran client paradise handle large objects problems spatial sorting large objects executable times row scripts running benchmark anonymous ftp paradise directory ftp wisc scripts postgres illustra modi versions scripts received developers modi cation made scripts provided postgres illustra order match benchmark originally speci sfgm scripts received meters constant side val query refer section query speci original benchmark sfgm meters paradise run query minus operator implemented numbers systems shown table query paradise illustra post gres sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec sec table sequoia benchmark numbers query paradise generally performance raster queries bene performance enhancing techniques tiling compression polygon point queries bene clustered indices spatial attributes conclusions future directions paper describes client-server version paradise gis development wisconsin paradise extendedrelational data model support point raster polygon polyline adts extended version sql formulating hoc queries graphical user interface based toolkit user query browse graphically facilitate handling large collections large raster satellite images paradise incorporates performance optimizations including transparent separationof raster images associatedmetadata division raster images tiles minimize unnecessary automatic application lossless compression decompression tile tile basis paradise performance competitive othersystems executingqueriesfrom sequoia benchmark phase project add support tertiary storage extend software run shared multiprocessors sto acknowledgement tan mike zwilling patiently answering questions shore storage manager developers sequoia benchmark providing realistic benchmark real data sets paul brown postgres shel finkelstein assistance illustra acknowledge joe 
hellerstein answering postgres questions helping install montage machines naughton deserves special suggestions project abd atkinson bancilhon dewitt dittrich maier zdonik object-oriented database manifesto international conference dood japan bkss beckmann hans-peter kriegel schneider seeger -tree cient robust access method points rectangles proceedings acm-sigmod conference june car carlone nasa eosdis development approach technical report united states general accounting february cat cattell editor object database standard odmg morgan kaufmann publishers san mateo california contributions byt attwood duhl ferran loomis wade cdf carey dewitt frank graefe muralikrishna richardson shekita architecture exodus extensible dbms inproceedings vldb conf september cdf carey dewitt franklin hall mcauli naughton schuh solomon tan tsatalos white zwilling shoring persistent objects proceedings acm-sigmod conference minneapolis minnesota dgs dewitt ghandeharizadeh schneider bricker hsiao rasmussen gamma database machine project ieee transactions knowledge data engineering march dlpy dewitt luo patel paradise parallel geographic information system proceedings acm workshop advances geographic information systems arlington virginia november faloutsos kamel packed trees fractals conference intelligence knowledge management november famma weinand introduction installation ubilab union bank switzerland gre greene implementation performance analysis spatial data access methods proc data engineering conf gro postgres group postgres manual california berkeley graefe shapiro data compression database performance proceedings acm ieee-computer science symposium applied computing gut gutman r-trees dynamic index structure spatial searching proceedings acm-sigmod conference boston mass june uting gral extensible relational database system geometric applications proceedings vldb conf august hhk hasan heytens kolovson neimat potamianos schneider papyrus gis demonstration proceedings acmsigmod conference washington jag jagadish linear clustering objects multiple attributes proceedings acmsigmod conference lcv linton calder vlissides interviews graphical interface toolkit technical report csl-tr- stanford july mgr maguire goodchild rhind geographic information systems volume longman scienti technical copublished john wiley sons york mor morehouse arc info geographic information system computers geosciences international journal august medeiros pires databases gis sigmod record march nhs nievergelt hinterberger sevcik grid file anadaptable symmetricmultikeyfile structure acm transactions database systems march ous ousterhout tcl embeddable command language proceedings winter usenix conference ous ousterhout toolkit based tcl language proceedings winter usenix conference rob robinson k-d-b tree search structure large multidimensional dynamic indexes proceedings acm-sigmod conference april sam samet design analysis spatial data structures addison-wesley sea michael shapiro grass programmer manual army consrtuction engineering research laboraroty sfgm stonebraker frew gardels meredith sequoia storage benchmark proceedings acm-sigmod conference washington stonebraker rowe design postgres proceedings acm-sigmod conference sto stonebraker case shared database engineering sto stonebraker editor readings database systems pages morgan kaufmann swkh stonebraker wong kreps held design implementation ingres pages morgan kaufmann faloutsos sellis roussopoulos tree dynamic index multi dimensional objects proceedings vldb conf september ube ubell montage extensible datablade architecture proceedings acmsigmod conference vov van oosterom vijlbrief building gis top open dbms postgres proceedings egis european conferenceongeographical information systems april vvo vijlbrief van oosterom geo system extensible gis proceedings international symposium spatial data handling charleston south carolina august wel welch technique high-performance data compression ieee computer zan zaniolo database lanaguage gem proceedings acm-sigmod conference 
tradeoffs processing multi-way join queries hashing multiprocessor database machines donovan schneider david dewitt computer sciences department wisconsin research partially supported defense advanced research projects agency contract -cby national science foundation grant dcrby digital equipment corporation external research grant research grant tandem computer corporation funding provided darpa nasa sponsored graduate research assistantship parallel processing abstract past years design implementation evaluation join algorithms exploit large main memories parallel processors received great deal attention work addressed problem executing joins involving relations paper examine problem processing multi-way join queries hash-based join methods shared-nothing database environment discuss choice format complex query significant effect performance multiprocessor database machine experimental results obtained simulation study presented demonstrate tradeoffs left-deep right-deep scheduling strategies complex join query evaluation results demonstrate right-deep scheduling strategies provide significant performance advantages large multiprocessor database machines memory limited introduction important trends occurred ten years combined change traditional view database technology microprocessors faster simultaneously cheaper memory capacities risen costs declined finally high-speed communication networks enabled efficient interconnection multiple processors technological combined make feasible construction high performance multiprocessor database machines technology open questions ways exploit capabilities multiprocessor database machines order achieve highest performance join operator critical operation relational dbms number papers addressed parallel implementations join operation including baru brat dewi dewi kits schn papers addressed processing queries joins performance impact alternative formats representing multi-way join queries received attention context environment related work discussed section paper examine tradeoffs imposed left-deep right-deep bushy query trees multiprocessor environment focussed hash-based join methods performance demonstrated superior systems large memories brat dewi schn shap include discussion sort-merge join algorithm tradeoffs include potential exploiting intra-query parallelism effect performance resource consumption primarily memory support dataflow processing cost optimization examination tradeoffs demonstrated feasibility right-deep representation strategy resulted algorithms processing query trees format providing superior opportunities exploiting parallelism query tree right-deep representation strategy reduce importance correctly estimating join selectivities analysis tradeoffs alternative query tree representation strategies description algorithms processing right-deep query trees presented section left-deep right-deep representation strategies present extreme cases alternative query representation strategies interested quantitatively examining performance tradeoffs strategies perform analysis constructed multiprocessor database machine simulator implemented scheduling algorithms tree formats description simulation model validation experimental results obtained contained section results experimental analysis confirm qualitative results right-deep trees provide substantial performance improvements experimental conditions strategy optimal circumstances conclusions plans future work presented section degrees parallelism ways utilizing parallelism multiprocessor database machine parallelism applied operator query ten processors work parallel compute single join select operation form parallelism termed intra-operator parallelism studied extensively previous researchers inter-operator parallelism employed execute operators query concurrently finally inter-query parallelism refers executing queries simultaneously paper specifically address issues involved exploiting inter-operator parallelism queries composed joins defer issues inter-query parallelism future work query tree representations instrumental understanding process complex queries understanding query plans generated query compiled tree operators formats exist structuring tree operators shown formats offer tradeoffs query optimization query execution formats exist query tree construction range simple complex simple query tree format format tree restricted manner reasons wanting restrict design query tree optimization space alternative query plans searched order find optimal query plan format query plan restricted manner search space reduced optimization expensive danger restricted query plan capable representing optimal query plan query tree formats offer tradeoffs runtime instance tree formats facilitate dataflow scheduling techniques improves performance simplifying scheduling eliminating store temporary results formats dictate maximum memory requirements important performance join algorithms depends heavily amount memory dewi schn shap finally format query plan determinant amount parallelism applied query left-deep trees right-deep trees represent extreme options restricted format query trees bushy trees hand restrictions construction comprise design space left-deep right-deep query trees benefits drawbacks strategies problems instance harder synchronize activity join operators arbitrarily complex bushy tree examine tradeoffs query tree formats closely sections refer figures examples left-deep join join join join join join result left-deep query tree result right-deep query tree figure figure join join join result bushy query tree figure right-deep bushy query trees query join join join note character denote relational join operator assumptions discussion make key assumptions assume hash-based join algorithm assume existence sufficient main-memory support concurrent join operations required assume optimizer perfect knowledge scan join selectivities portions paper relax assumptions survey related work gerb describes issues involved processing hash-based join operations multiprocessor database machines inter-operator intra-operator concurrency issues discussed discussion intra-query inter-operator parallelism tradeoffs left-deep right-deep bushy query tree representations regard parallelism pipelined data flow resource utilization primarily memory addressed gerb defines basic issues involved processing complex queries multiprocessor environment explore tradeoffs alternative query tree representation strategies great depth grae supports alternative query tree formats shared-memory database machine volcano tradeoffs discussed detail paper demonstrate interesting algorithms developed scheduling query trees alternative tree formats grae considers tradeoffs left-deep bushy execution trees single processor environment analytic cost functions hash-join index join nested loops join sort-merge join developed compare average plan execution costs query tree formats optimizing left-deep query trees requires resources memory cpu execution times resulting plans close bushy queries queries limited complexity queries joins execution costs left-deep trees order magnitude expensive ston describes xprs project plans utilizing parallelism shared-memory database machine optimization query compilation assumes entire buffer pool order aid optimization runtime query tree divided fragments fragments correspond operator subgraphs section runtime desired amount parallelism fragment weighed amount memory insufficient memory techniques reduce memory requirements fragment decomposed sequential fragments requires spooling data temporary files decomposition number batches hybrid join algorithm dewi increased finally level parallelism applied fragment reduced tradeoffs alternative query tree representations section discuss alternative query tree formats affects memory consumption dataflow scheduling ability exploit parallelism multi-way join query discussion includes processing queries case unlimited resources realistic situations memory limited strategies proposed process multi-way join queries memory limited good comparing tradeoffs alternative query tree representations construction operator dependency graphs representation strategy dependency graph query tree subgraph nodes enclosed dashed line represent operators scheduled directed lines subgraphs producer consumer relationship operators bold directed arcs subgraphs show sets operators executed sets operators executed determining maximum level parallelism resource requirements memory query scheduling set operators enclosed subgraphs failing schedule sets operators dependencies result spool tuples intermediate relations disk operator dependency graphs 
containment mer containment holds guaranteed lie skip processing techniques implemented relative performance pbsm algorithm improve summary pre existing index case summary pbsm algorithm performance tree indexed nested loops based algorithms sizes inputs differ significantly indexed nested loops performs tree based algorithm finally performance algorithms improve join inputs clustered joins presence pre existing indices section investigate performance spatial join algorithms inputs join index experiment index exists index nested loops probes index tree based join algorithm builds index input proceeds join indices indices exist index nested loops probes smaller index tree based join skips building indices results experiment shown figures indices pre exist inputs tree based algorithm performance building index smaller input expensive tree based algorithm performance index exists larger input graphs compare pbsm rtree largeidx inl largeidx index exists larger input indexed nested loops encounters buffer misses probing index chose build index smaller input probe index probing cost greater tree join cost compare rtree largeidx inl smallidx case index exists smaller input pbsm join performs tree indexed nested loops based joins figures compare pbsm rtree smallidx inl smallidx small buffer pool sizes joining hydrography roads figure tree based algorithm labeled rtree smallidx performs indexed nested loops labeled inl smallidx buffer pool size increases respect index size performance indexed nested loops improves rapidly outperforming tree based join large buffer pool sizes figure buffer pool sizes figure performance algorithms clustered tiger data qualitatively matched results clustered case performance algorithms sequoia data qualitatively matched results shown figure numbers omitted paper summary index exists larger input inputs pre existing index tree based join algorithm performance index exists smaller input pbsm algorithm performance cpu costs examine cpu costs involved spatial join algorithms table shows costs incurred joining road hydrography data tiger data set note component join algorithm component starts sigmod algocomponent buffer pool buffer pool buffer pool rithm total con total con total con algorithm cost cost tribution cost cost tribution cost cost tribution partition road partition hyd pbsm merge partitions refinement total build hyd index build road index r-tree join indices join refinement total build hyd index nl-idx probe index total table detailed cost breakdown tiger data join roads hydrography times seconds dirty pages left buffer pool previous component table shows algorithms cpu costs dominate costs large amount cases reason folds performing spatial operations probing -tree index joining partitions plane sweep algorithm spatial sorting bulk loading index computationally intensive shore storage manages works hard minimizing costs dirty page flushed disk storage manager forms sorted list dirty pages buffer pool find pages consecutive disk pages written disk cpu costs found dominating factor spatial joins clustered tiger sequoia data sets due space constraints omitted graphs paper conclusions future work paper describes partition based spatial merge pbsm join algorithm performing spatial join algorithm require indices joining attribute inputs situation arise inputs join intermediate results complex query parallel environment inputs dynamically redistributed algorithm efficient computational geometry based plane sweeping technique performing join inputs algorithm large fit memory spatial partitioning function partition inputs chunks fit memory paper results comprehensive performance study based actual implementation spatial join algorithms paradise database system handling gis applications algorithms traditional indexed nested loops algorithm previously proposed algorithm spatial indices inputs evaluate join pbsm algorithm performance comparison real data sets show pbsm algorithm efficient inputs join spatial index index exists smaller input pbsm algorithm performs algorithms tree based algorithm performance index exists larger input inputs pre existing index part future work plan investigating parallelism evaluate spatial joins pbsm hash based relational joins partitioning break large inputs smaller parts expect pbsm algorithm parallelize efficiently parallelizing pbsm require strategy declustering spatial objects spatial partitioning function pbsm partitioning large inputs declustering spatial data examining issues broader context extending paradise dkl run shared architectures sto parallel spatial databases emerging attractive solution storing manipulating large volumes spatial data dlpy techniques declustering spatial data recently proposed spatial data uniformly distributed techniques result unbalanced partitions feel spatial partitioning function tiling spatial equivalent virtual processor partitioning parallel relational system dnss adapt data distributions evaluating tradeoffs declustering spatial data spatial partitioning function map input object multiple outputs replicate objects replicate spatial approximation minimum bounding rectangle object replicated entirety remote fetches required object fully replicated remote fetches avoided expense increase amount storage tradeoff depend characteristics input data sigmod queries acknowledgement jie bing patiently answering questions shore navin kabra praveen seshadri joe hellerstein sigmod referees provided feedback earlier drafts paper arc esri redlands arc info world gis esri white paper march ben bentley multidimensional binary search trees associative searching communication acm volume september ben bentley multidimensional binary search trees database applications ieee transactions software engineering volume bhf becker hinrichs finke algorithm computing joins grid files ieee transactions knowledge data engineering bks brinkhoff kriegel seeger efficient processing spatial joins r-trees proceedings acm-sigmod conference washington bkss beckmann kriegel schneider seeger -tree efficient robust access method points rectangles proceedings acm-sigmod conference june bkss brinkhoff kriegel schneider seeger multi step processing spatial joins proceedings acm-sigmod conference minneapolis bur burrough principles geographic information systems land resources assessment oxford press cdf carey dewitt franklin hall mcauliffe naughton schuh solomon tan tsatalos white zwilling shoring persistent applications proceedings acmsigmod conference minneapolis minnesota cfr sellis faloutsos roussopoulos analysis object oriented spatial access methods proceedings acm-sigmod conference san francisco cor intergraph corporation gis information http intergraph utilmap shtml dkl dewitt kabra luo patel client server paradise proceedings vldb conf santiago chile september dlpy dewitt luo patel paradise parallel geographic information system proceedings acm workshop advances geographic information systems arlington virginia november dnss dewitt naughton schneider seshadri practical skew handling parallel joins proceedings vldb conf august uting shilling practical divide conquer algorithm rectangle intersection problem information sciences volume unther efficient computation spatial joins ieee transactions knowledge data engineering gut gutman r-trees dynamic index structure spatial searching proceedings acm-sigmod conference boston mass june hnkt harada nakano kitsuregawa takagi query processing methods multi attribute clustered relations proceedings vldb conf brisbane australia hoel samet benchmarking spatial join operations spatial output proceedings vldb conf zurich switzerland september kht kitsuregawa harada takagi join strategies kd-tree indexed relations ieee transactions knowledge data engineering 
ravishankar spatial joins seeded trees proceedings acm-sigmod conference minneapolis ravishankar generating seeded trees data sets proceedings fourth international symposium large spatial databases portland august ravishankar spatial hash joins proceedings acm-sigmod conference montreal canada june mead conway introduction vlsi systems addison wesley reading mass mgr maguire goodchild rhind geographic information systems volume longman scientific technical copublished john wiley sons york nhs nievergelt hinterberger sevcik grid file adaptable symmetric multikey file structure acm transactions database systems march nelson samet consistent hierarchical representation vector data computer graphics volume august orenstein merrett class data structures associative searching proceedings acm sigact sigmod symposium principles database systems orenstein manola probe spatial data modeling query processing image database application ieee transactions software engineering volume ore orenstein spatial query processing object oriented database system proceedings acmsigmod conference ore orenstein redundancy spatial databases proceedings acm-sigmod conference ore orenstein comparison spatial query processing techniques native parameter spaces proceedings acm-sigmod conference patel dewitt partition based spatial merge join http wisc paradise paradise papers html preparata shamos editors computational geometry springer rot rotem spatial join indices ieee transactions knowledge data engineering kobe april sfgm stonebraker frew gardels meredith sequoia storage benchmark proceedings acm-sigmod conference washington sto stonebraker case shared database engineering tig bureau census washington tiger line files technical documentation tan performance study declustering strategies parallel spatial databases international conference database expert systems applications dexa london united kingdom september ube ubell montage extensible datablade architecture proceedings acm-sigmod conference val valduriez join indices acm tods volume zeller gray adaptive hash join algorithm multiuser environments proceedings vldb conf brisbane australia 
presented section based hash-join algorithm join method paper hash-join methods simple hash-join hybrid hash-join dewi assumed reader familiar join methods description included description join relations smaller joining relation simple hash-join method naive algorithm assumes tuples smaller joining relation termed building relation staged main memory hash table assumption fails overflowing tuples dynamically staged temporary file disk tuples processed tuples larger relation probing relation processed tuple read disk tuple probe hash table tuples written back disk hash-table overflow occurred building hash table schn details hash-table overflow occurred overflow partitions recursively joined procedure hybrid hash-join algorithm developed order prevent overflow processing discussed effectively utilizing memory key idea recognize priori join exceed memory capacity partition joining relation disjoint buckets bucket fit memory main memory hashing compute smaller bucket joins enhancement portion join result computed joining relations partitioned buckets hash-join algorithms computation join operation viewed consisting phases phase hash table constructed tuples produced left input stream relation examples phase tuples input stream relation probe hash table matches order compute join operation completely precede operation join operator viewed consisting separate operators build operator probe operator dependency graphs model phase computation hash-joins representing join consisting operators section discuss modifications supporting sortmerge join algorithm reader mind intra-operator parallelism issues paper discuss executing operators concurrently assumed implicitly operator computed multiple processors schn description parallel implementations hashjoin algorithms smaller relation building relation hash join algorithm order minimize number times outer relation read disk smaller relation building relation maximizes probability outer relation read left-deep query trees figure shows n-join query represented left-deep query tree operator dependency graph presented figure dependency graph obvious scan operators executed concurrently dependencies force unique query execution plan step scan build step scan probe build step scan probe build step scan probe jn- build step scan probe schedule demonstrates scan join operators active point time step schedule prior initiation scan hash table constructed output join scan initiated tuples produced scan immediately probe hash table produce join output tuples join output tuples immediately streamed hash table constructed join hash table space join reclaimed tuples scan probed hash table computed join stored join computation hash table figure figure dependency graph left-deep query tree generic left-deep query tree jnjn bnpn- jnj maximum memory requirements query point execution consist space needed hash tables adjacent join operators limited memory left-deep query trees require hash tables adjacent join operators memory resident point time execution complex query relations staged memory resident hash tables result intermediate join computations expected difficult predict size size intermediate relations accurately predicted multi-user environment expected optimizer exact amount memory query executed memory extremely scarce sufficient memory exist hold hash tables join operators active point time issues addressed order achieve optimal performance grae proposes solution general problem optimizer generate multiple query plans runtime system choose plan current system environment similar mechanism proposed starburst haas problem strategy number feasible plans large complex join queries envision generate plans incorporate memory requirements individual join operator optimizer recognize consequences intra-query parallelism join operator optimized memory system higher join operator query tree starved memory modify query plan runtime performance suffer simpler strategy runtime query scheduler adjust number buckets hybrid join algorithm order react amount memory enhancement strategy statistics size intermediate join computations stored hash tables information adjust number buckets join operators higher query tree finally significantly memory runtime expected beneficial perform type query tree transformation effectively exploit resources entire query tree parts transformed right-deep query tree format right-deep query trees figure shows generic right-deep query tree n-join query figure presents dependency graph dependency graph easily determined operators executed concurrently execution plan devised exploit highest levels concurrency step scan build scan build scan build step scan probe probe probe schedule obvious scan operators build operators processed parallel phase completed scan initiated resulting tuples probe hash table output tuples percolate tree demonstrated high levels parallelism strategy operator generally intra-operator parallelism applied query require memory hold hash tables join operators duration query question arises performance implications scheduling scans concurrently operators access relations declustered set storage sites initiating scans concurrently detrimental increased contention disk ghan large database machine relations declustered storage sites cope declustering eventually detrimental performance costs controlling execution query eventually outweigh benefits adding additional disk resources gerb cope dewi section present experimental results illustrate performance implications data declustering strategy figure figure dependency graph right-deep query tree right-deep query tree jnj pnbn pnbn- jnbu limited memory right-deep trees require hash tables co-resident present set problems memory intensive respective left-deep trees afford opportunity runtime query modifications scan initiated data flows query tree completion expected accurate estimates memory requirements right-deep query tree left children building relations base relations result applying selection predicates base relation left-deep tree building input join result preceding join operation expect memory limited scan selectivities under-estimated number hash tables experience overflow resulting performance extremely poor case costs overflow processing magnified succeeding join loss dataflow processing overflow processing assumed sufficient space hash tables concurrently developed alternative techniques exploiting potential performance advantages right-deep query trees strategy similar proposed stone involves optimizer runtime scheduler break query tree disjoint pieces sum hash tables joins piece expected fit memory splitting query tree require temporary results spooled disk join computed boundary pieces hash table space reclaimed query continue execution time taking right-child input temporary relation scheduling strategy called static right-deep scheduling dynamic strategy called dynamic bottom-up scheduling schedules scans figure strict bottom-up manner scan initiated tuples generated scan construct hash table join operator scan completes memory manager queried memory stage tuples expected result scan sufficient space exists scan initiated procedure scans query tree memory exhausted scans processed remains scan initiated start process probing hash tables case scans processed pass scan initiated results join computation join stored temporary file processing query tree proceeds identical manner scan scheduled scan start generation probing tuples initiated temporary file strategies share common feature dealing limited memory breaking query tree points breaking query tree significant impact performance benefits data flow processing lost results temporary join computation spooled disk assumed memory hold relation individually relations simultaneously case alternative approach preprocess input relations order reduce memory requirements hybrid join algorithm attempts discuss 
hybrid join algorithm processing complex query trees represented right-deep query trees illustrate algorithm join relations presented shown figure right-deep hybrid scheduling right-deep query trees query processing interesting hybrid join algorithm termed right-deep hybrid scheduling right-deep join query figure assume join broken buckets bucket staged immediately memory bucket denoted join bucket compute half right-deep tree inclination probe hash table output tuples immediately join attribute case output tuples rehashed join bucket hash function composed buckets directly map memory probing segment tuples rehashed tuples bucket half tuples assuming uniformity immediately probing hash table built output tuples portion written buckets output tuples percolating tree number reduced succeeding level based number buckets respective building relation query execution continue join respective buckets joined remaining buckets joined processing entire query tree proceed manner shown right-deep hybrid scheduling rdhs tuples right-deep query tree result left-deep query tree result join join join join join join figure delivered host result joining buckets relations lowest level query tree analogous left-deep query tree user submitting query quicker feedback correspond faster response time time compute entire result identical case application program submitting query beneficial provide result data sooner stream opposed dumping entire result join computation step computation application overlapped data processing backend machine questions arise allocate memory right-deep query trees rdhs join algorithm correctness bucket building relations resident memory requirement relations distributed number buckets relation large relation small bucket relation additional buckets relations intermediate relation staged disk form exist solely stream tuples level query tree rdhs alternative static dynamic bottom-up scheduling algorithms algorithms assumed memory hold relation individually relations simultaneously rdhs algorithm potentially reduces memory requirements retaining dataflow entire query tree rdhs single bucket relation static right-deep scheduling algorithm remains open question scheduling strategy outperform case right-deep query trees shown previously right-deep query trees provide potential exploiting parallelism concurrent scans hash table build operations case results intermediate join computations stored disk inserted memory resident hash tables intermediate join results exist stream tuples flowing query tree size building relations accurately predicted cardinality estimates based predicates applied base relation opposed estimates size intermediate join computations bushy trees potentially re-arrange joins minimize size intermediate relations best-case right-deep tree store larger intermediate relations disk extra cpu network costs incurred larger intermediates strategies proposed deal limited memory situations offer range interesting tradeoffs breaking query tree represents static approach dynamic bottom-up scheduling algorithm reacts amount memory run-time rdhs strategy deliver tuples sooner constant stream user application similar left-deep query tree right-deep trees generally assumed memory intensive query tree format case join relations shown figure left-deep right-deep query tree format assume size relations pages assume size pages size pages point execution left-deep query tree results simultaneously reside memory pages memory required order execute query efficient manner right-deep query tree relations reside memory optimal query processing relations consume pages memory left-deep tree requires memory right-deep tree size intermediate relations grow left-deep trees case attributes added result additional join intermediates stored memory hash tables memory requirements increase note width tuples intermediate relations increase right-deep trees tuples probe hash tables don consume memory duration join bushy query trees complex query tree representations bushy query tree eight-way join shown figure schedules devised execute query clarifying possibilities construction operator dependency graph figure dependency graph join query shown figure directed arcs shown longest path graph comprised subgraphs scan operators bushy query tree figure dependency graph bushy query tree figure subgraphs operators executed serially order maximize dataflow processing prevent writing tuples temporary storage execution plan consist steps schedule step scan -build scan -build scan -build scan -build step scan -probe -build scan -probe -build step scan -probe -probe -build step scan -probe -probe -probe notice non-critical-path operations scan build delayed step violating dependency requirements fact scheduling options exist demonstrates runtime scheduling complicated bushy trees tree formats case query tree designs order operators scheduled obey dependency constraints tuples intermediate relations spooled disk re-read time limited memory intelligently scheduling operators reduce memory demands query previous schedule executing join query execution step hash tables resident memory step completes memory reclaimed hash tables join operators hash tables join operators constructed execution step memory requirements reduced hash tables reduce memory consumption query constructing schedule execution schedule noted hash table space reclaimed step scan -build step scan -probe -build -release scan -build step scan -probe -probe -build -release step scan -build step scan -probe -build -release scan -build step scan -probe -probe -probe -release execution plan requires steps maximum memory requirements reduced execution query maximum hash tables maximum hash tables types execution plan modifications insufficient reducing memory demands techniques subsections left-deep right-deep query trees employed issues sort-merge join algorithm hash-join method affected discussion achievable levels parallelism alternative query tree designs reconsider left-deep query tree operator dependency graph figures sort-merge algorithm join method scan necessarily precede scan scan sort scheduled parallel scan sort final merge phase join proceed slower operations completed contrast strictly serial execution scans order hash join algorithm work properly modifications operator dependency graphs required support sort-merge join method found schn modifications simple presented due space limitations interesting point note sort-merge join algorithm left-deep right-deep query tree representations equivalent base relations scanned sorted concurrently strategy hash-join algorithm ordering dependency specifies left-child input completely consumed right-child input initiated relaxed assumptions non-hash-join join methods hash-join method affected discussion achievable levels parallelism alternative query tree designs reconsider left-deep query tree operator dependency graph figures sort-merge algorithm join method scan necessarily precede scan scan sort scheduled parallel scan sort final merge phase join proceed slower operations completed contrast strictly serial execution scans order hash join algorithm work properly modifications operator dependency graphs required support sort-merge join method found schn modifications simple presented due space limitations interesting point note sort-merge join algorithm left-deep right-deep query tree representations equivalent base relations scanned sorted concurrently strategy hash-join algorithm ordering dependency specifies left-child input completely consumed right-child input initiated limited memory environments discussion alternate query tree formats section assumed sufficient memory hold building relation concurrent join operators addressing hash-joins trend database machines larger numbers processors larger memories expected hash tables complex join queries accessing large datasets fit completely memory time 
right-deep query trees employed left-deep query trees stated previously left-deep query trees require hash tables join operators memory resident point time execution complex query relation lowest level query tree relations staged memory resident hash tables result intermediate join computations expected difficult predict size size intermediate relations accurately predicted multi-user environment expected optimizer exact amount memory query executed memory extremely scarce sufficient memory exist hold hash tables join operators active point time issues addressed order achieve optimal performance grae proposes solution general problem optimizer generate multiple query plans runtime system choose plan current system environment similar mechanism proposed starburst haas problem strategy number feasible plans large complex join queries envision generate plans incorporate memory requirements individual join operator optimizer recognize consequences intra-query parallelism join operator optimized memory system higher join operator query tree starved memory modify query plan runtime performance suffer simpler strategy runtime query scheduler adjust number buckets hybrid join algorithm order react amount memory enhancement strategy statistics size intermediate join computations stored hash tables information adjust number buckets join operators higher query tree finally significantly memory runtime expected beneficial perform type query tree transformation effectively exploit resources entire query tree parts transformed right-deep query tree format right-deep query trees right-deep trees require hash tables co-resident present set problems memory intensive respective left-deep trees afford opportunity runtime query modifications scan initiated data flows query tree completion expected accurate estimates memory requirements right-deep query tree left children building relations base relations result applying selection predicates base relation left-deep tree building input join result preceding join operation expect memory limited scan selectivities under-estimated number hash tables experience overflow resulting performance extremely poor case costs overflow processing magnified succeeding join loss dataflow processing overflow processing assumed sufficient space hash tables concurrently developed alternative techniques exploiting potential performance advantages right-deep query trees strategy similar proposed stone involves optimizer runtime scheduler break query tree disjoint pieces sum hash tables joins piece expected fit memory splitting query tree require temporary results spooled disk join computed boundary pieces hash table space reclaimed query continue execution time taking right-child input temporary relation scheduling strategy called static right-deep scheduling dynamic strategy called dynamic bottom-up scheduling schedules scans figure strict bottom-up manner scan initiated tuples generated scan construct hash table join operator scan completes memory manager queried memory stage tuples expected result scan sufficient space exists scan initiated procedure scans query tree memory exhausted scans processed remains scan initiated start process probing hash tables case scans processed pass scan initiated results join computation join stored temporary file processing query tree proceeds identical manner scan scheduled scan start generation probing tuples initiated temporary file strategies share common feature dealing limited memory breaking query tree points breaking query tree significant impact performance benefits data flow processing lost results temporary join computation spooled disk assumed memory hold relation individually relations simultaneously case alternative approach preprocess input relations order reduce memory requirements hybrid join algorithm attempts discuss hybrid join algorithm processing complex query trees represented right-deep query trees illustrate algorithm join relations presented shown figure right-deep hybrid scheduling right-deep query trees query processing interesting hybrid join algorithm termed right-deep hybrid scheduling right-deep join query figure assume join broken buckets bucket staged immediately memory bucket denoted join bucket compute half right-deep tree inclination probe hash table output tuples immediately join attribute case output tuples rehashed join bucket hash function composed buckets directly map memory probing segment tuples rehashed tuples bucket half tuples assuming uniformity immediately probing hash table built output tuples portion written buckets output tuples percolating tree number reduced succeeding level based number buckets respective building relation query execution continue join respective buckets joined right-deep query tree result left-deep query tree result join join join join join join figure remaining buckets joined processing entire query tree proceed manner shown right-deep hybrid scheduling rdhs tuples delivered host result joining buckets relations lowest level query tree analogous left-deep query tree user submitting query quicker feedback correspond faster response time time compute entire result identical case application program submitting query beneficial provide result data sooner stream opposed dumping entire result join computation step computation application overlapped data processing backend machine questions arise allocate memory right-deep query trees rdhs join algorithm correctness bucket building relations resident memory requirement relations distributed number buckets relation large relation small bucket relation additional buckets relations intermediate relation staged disk form exist solely stream tuples level query tree rdhs alternative dynamic bottom-up scheduling algorithm earlier dynamic bottom-up scheduling algorithm assumed memory hold relation individually relations simultaneously rdhs algorithm potentially reduces memory requirements retaining dataflow entire query tree rdhs single bucket relation algorithms remains open question scheduling strategy outperform case right-deep query trees shown previously right-deep query trees provide potential exploiting parallelism concurrent scans hash table build operations case results intermediate join computations stored disk inserted memory resident hash tables intermediate join results exist stream tuples flowing query tree size building relations accurately predicted cardinality estimates based predicates applied base relation opposed estimates size intermediate join computations bushy trees potentially re-arrange joins minimize size intermediate relations best-case right-deep tree store larger intermediate relations disk extra cpu network costs incurred larger intermediates strategies proposed deal limited memory situations offer range interesting tradeoffs breaking query tree represents static approach dynamic bottom-up scheduling algorithm reacts amount memory run-time rdhs strategy deliver tuples sooner constant stream user application similar left-deep query tree right-deep trees generally assumed memory intensive query tree format case join relations shown figure left-deep right-deep query tree format assume size relations pages assume size pages size pages point execution left-deep query tree results simultaneously reside memory pages memory required order execute query efficient manner right-deep query tree relations reside memory optimal query processing relations consume pages memory left-deep tree requires memory right-deep tree size intermediate relations grow left-deep trees case attributes added result additional join intermediates stored memory hash tables memory requirements increase note width tuples intermediate relations increase right-deep trees tuples probe hash tables don consume memory duration join bushy query trees recall section scheduling non-critical-path joins affect amount parallelism adapt limited memory situations 
processors disks speedup system constant memory overflow kbyte disk pages tuple relations query joinabprime join attrs partitioning attrs figure figure speedup curves project gamma performance additional processors employed response time obtained single processor basis give artificially low expected performance estimates larger configurations similar argument made allnodes joins degree short-circuiting approximately half local joins remote joins basically unaffected change point processor configuration short-circuits half tuples speedup results underestimate scalability gamma speedup processors non-hash partitioned joins locally approximately experiments tested gamma source relations hash partitioned joins performed non-partitioning attributes figures performance joins equivalent size relations partitioned round-robin fashion additionally recall joins hash-partitioned attributes performed faster remotely locally shows join operators off-loaded remote processors large relations substantiates results obtained dewi smaller relations join overflow set experiments configuration size query processors disk page size kbytes constant varied total amount memory memory initially set sufficient hold total number tuples required building phase tuple join queries sufficient build tuples processors total amount memory incrementally lowered evenly reducing memory processors shape curves figure obvious performance deteriorates rapidly memory limited due distributed version simple hash join algorithm resolve hashpartition overflow predicted analytically dewi viewing graphs mind number overflows represents number overflows detected joining sites total number occurrences partition overflow labeled number times interesting points discovered careful examination curves figure response times local remote join curvers crossover recall previous subsection joins partitioning attributes faster locally remotely opposite true round-robin partitioning default strategy relations created result query figure overflows overflow overflows overflows overflows local joins remote joins memory smaller relation response time seconds system query joinabprime join attrs partitioning attrs tuple relations constant configuration nodes joins non-partitioning attributes crossover explained initial overflow gamma switches hash functions effect changing joining attributes non-partitioning attributes change hash functions order ensure joining processors case subset sites overflow function distribute overflow tuples original tuples sets tuples continuously re-map processors processors experience overflow subsequent overflow processing relative flatness response time curves overflows simple hash-join effective small number overflows occur result important means optimizer factor estimating amount memory selectivity factor operator significantly affecting response time query effect disk page size join performance set experiments wanted explore effect alternative disk page sizes join execution time constant gamma configuration consisting query processors disks scheduling processor memory constant large hash-table overflows occur figure shows results joinaselb query disk page size varied kbytes increasing disk page size significantly reduces join response time performance improvement levels kbyte pages speedup curves presented figure speedup curves level observed manner recall gamma joins bounded time select tuples joining relations figure presents results obtained joinaselb query selections performed source relations results obtained similar presented non-indexed selection figure result explain satisfaction performance allnodes configuration intuitively expect allnodes fall remote local shares benefits drawbacks explanation increased cost scheduling allnodes joins relations joined large fully exploit additional processing power gamma requires messages schedule query operator node join logically composed operators build join allnodes require additional scheduling messages assuming milliseconds small inter-node message half additional scheduling overhead incurred explanation appears possibility allnodes joins fall local remote joins performing constant configuration nodes constant configuration nodes disk page size kbytes disk page size kbytes response time seconds allnodes joins remote joins local joins system constant memory overflow tuple relations query joinaselb join attrs partitioning attrs speedup allnodes joins remote joins local joins system constant memory overflow tuple relations query joinaselb join attrs partitioning attrs figure figure joinabprime queries aggregate queries aggregate tests included mix scalar aggregate aggregate function queries query computes minimum non-indexed attribute queries compute sum minimum attribute partitioning relation subsets results tests contained table query produces single result tuple result tuples bothered display query times adjusted time store result relation treating scalar aggregate query aggregate function query single partition teradata machine algorithm handle types queries amp computes piece result calculating partitions amps redistribute partial results hashing partitioning attribute result step collect partial results partition single site final result computed gamma implements scalar aggregates similar manner hashed redistribution step discussed skipped disk-based processor computes piece result sends process scheduler processor combines partial results final answer aggregate functions implemented teradata machine scalar aggregates disk-based processors compute piece result partial results redistributed hashing partitioning attribute table aggregate queries execution times seconds number tuples source relation query description teradata gamma teradata gamma teradata gamma min scalar aggregate min aggregate function partitions sum aggregate function partitions update queries set tests included mix append delete modify queries teradata machine executing full concurrency control recovery gamma full concurrency control partial recovery operators performance results machines directly comparable results tests presented table query appends single tuple relation indices exist appends tuple relation index exists query deletes single tuple relation index locate tuple deleted case teradata hash-based index case gamma clustered b-tree index queries query indices exist indices updated queries index updated fourth sixth queries test cost modifying tuple ways tests non-clustered index exists unique attribute machines addition case gamma table update queries execution times seconds number tuples source relation teradata gamma teradata gamma teradata gamma append tuple indices exist append tuple index exists delete tuple key attribute modify tuple key attribute modify tuple modified attribute odd non-indexed attribute key attribute locate tuple modified modify tuple non-key attribute non-clustered index clustered index exists unique attribute case modified attribute key attribute requiring tuple relocated tuple relocated secondary index updated set queries modify non-key nonindexed attribute final set queries modify attribute non-clustered index constructed index locate tuple modified table fourth sixth queries machines index locate tuple modified modifying indexed attribute tuple move position index systems avoid index locate tuple modified file scan handle case carefully file scan reasonable solution gamma deferred update files indices handle problem solution teradata machine problem gamma provide logging provide deferred update files updates index structures deferred update file corresponds index structure data file overhead maintaining functionality shown difference response times rows table conclusions future directions report presented results initial evaluation gamma database machine comparing performance teradata dbc database machine similar size examining performance gamma relative number processors comparison draw number conclusions machines regard gamma glaring deficiencies lack full recovery features extremely poor performance distributed simple hash-join 
algorithm large number overflow operations processed illustrated high response times million tuple joins table in-depth investigation join overflow section solution process adopting replace current algorithm parallel version hybrid hash-join algorithm dewi dewi algorithm outperforms simple hash-join algorithm recognizes memory limitations repartitions source relations partition smaller relation exceed memory join broken collection smaller joins gamma computes regular distributed join simple hash-join algorithm retained overflow resolution method problem halloween problem folklore performs degree partition overflow small expected case hybrid algorithm intend implementing recovery server collect log records processor based experiments varied disk page size gamma conclude increase default page size kbytes increasing page size kbytes slight improvement queries impact queries indices non-clustered indices negative results generally applicable adopting track-size pages number experimental systems talking wise decision finally clear network interfaces gamma present bottleneck completed implementation co-processor board vax transfer packets memory megabits token ring rate megabits board eliminate network interface bottleneck based results number conclusions drawn teradata database machine significantly superior performance gamma clustered indices search structure implemented teradata incorporate hash-based join algorithm software current sort-merge join algorithms provide predictable response times results situations overflows hash-join algorithms provide significantly superior performance planning number projects based gamma prototype year intend compare performance parallel sort-merge hash join algorithms context gamma results presented paper sort results expect evaluation database machine provide sounder basis comparison gamma alternative ways partitioning relations processors disks intend explore effect partitioning strategies performance selection join queries multiuser environment query preferred partitioning relations referenced interested determining tradeoff response time throughput multiuser environment function partitioning strategies acknowledgements large systems projects large number people listed authors made paper bob gerber deserves special recognition work design gamma leadership implementation effort query optimizer implemented muralikrishna rajiv jauhari implemented read-ahead mechanism improve performance sequential scans anoop sharma implemented aggregate algorithms embedded query interface goetz graefe joanna chen implemented predicate compiler deserve special credit debug machine code produced compiler finally microelectronics computer technology corporation support funding study teradata machine dewi astr astrahan system relational approach database management acm transactions database systems vol june babb babb implementing relational database means specialized hardware acm transactions database systems vol march bitt bitton dewitt turbyfill benchmarking database systems systematic approach proceedings large database conference october brat bratbergsengen kjell hashing methods relational algebra operations proceedings large database conference august chou chou h-t dewitt katz klug design implementation wisconsin storage system wiss software practices experience vol october dewi dewitt katz olken shapiro stonebraker wood implementation techniques main memory database systems proceedings sigmod conference boston june dewi dewitt gerber multiprocessor hash-based join algorithms proceedings vldb conference stockholm sweden august dewi dewitt gerber graefe heytens kumar muralikrishna gamma high performance dataflow database machine proceedings vldb conference japan august dewi dewitt smith boral single-user performance evaluation teradata database machine mcc technical report number db- march gerb gerber dataflow query processing multiprocessor hash-partitioned algorithms phd thesis computer sciences technical report wisconsin-madison october gerb gerber dewitt impact hardware software alternatives performance gamma database machine submitted computer sciences technical report wisconsin-madison july jark jarke koch query optimization database system acm computing surveys vol june kits kitsuregawa tanaka moto-oka application hash data base machine architecture generation computing vol measurement concepts corp teradata study technical report radc-tr- rome air development center griffiss air force base rome march nech neches patent october prot proteon associates operation maintenance manual pronet model waltham mass ries ries epstein evaluation distribution criteria distributed database systems ucb erl technical report berkeley seli selinger access path selection relational database management system proceedings sigmod conference boston ston stonebraker michael eugene wong peter kreps design implementation ingres acm transactions database systems vol september tane tanenbaum computer networks prentice-hall tera teradata corp dbc data base computer concepts facilities teradata corp document tera teradata corp dbc data base computer system manual rel teradata corp document november tera teradata corp dbc data base computer manual rel teradata corp document november vald valduriez gardarin join semi-join algorithms multiprocessor database machine acm transactions database systems vol march 
indexreads sreads rjoinreads initrreads indexreads sreads rjoinreads meaning rnl mapsreads number ios smap pages rmapreads number ios mapping tuples nal destination processors calculate read quantities decide priority pool pages assume mapping joining phases algorithm sequential join begin sites nished mapping tuples nal destination sites contention maps pages index pages model assume maps stored b-tree index entries rec pairs leaf pages leaf pages index memory resident mapsreads calculated index reads calculated rnl assuming map lookup hits pool probability ratio currentnumber maps pages pool total size maps rmapreads calculated rst ning pages jrj procs memory mapspagesresident charging read write owpage quantities initrreads indexreads sreads rjoinreads calculated rnl number tuples processor krk fanout procs krk andthenumberofrpages processor jrj fanout procs jrj network cost subsetting nested loops expression snl net distribute mapping jrj fanout procs msg receive mapping jrj fanout procs msg distribute joining jrj fanout procs msg receive joining jrj fanout procs msg finally cpu cost subsetting nested loops snl cpu cost index probes krk procs cpuindex factor arises index lookup maps lookup index lookup actual join subsetting nested loops sorting snl-s rnl presence clustered index number ios dramatically reduced sorting joining technique reduce number ios mapping phase maps clustered maps subsection case cost snl-s snl-s scan initial fragment jrj procs two-pass sort map site jrj procs reads mapping jrj procs maps reads numsmapreads two-pass sort join site jrj fanout procs reads join jrj fanout procs index reads numsindexreads reads join numsreads numsmapreads calculated analogous fashion waynumsindexreads calculated replicating nested loops sorting algorithm quantities numsindexreads numspagereads calculated replicating nested loops sorting algorithm nowthe number tuples processor krk fanout procs krk network cost identical snl finally cpu cost sort mapping processor krk procs log krk procs keyswap move cpu cost sort join processor krk procs fanout log krk procs fanout keyswap move analytic model experiments section present results experiments analytical model cases xedksk pages tuples tuples xed number tuples page varied number pages noted assumed fanout average number tuples tuple joins hardware parameters weusedwere comp msec compare keys keyswap msec swapapairofkeys hash msec hash key tuplemove msec move tuple mem swap msec swap twotuples msec sequential msg msec send message costs approximate costs wehave measured gamma noted wehaveassumed processor system memory size memory size critical parameter performance algorithms section compare algorithms memory sizes small index ormaps memory medium indexes maps memory memory large index andmaps memory case basic experimentisto xthesizeofs vary size plotting performance algorithms function size figure shows analytic model performance algorithms small memory case memory pages processor graph illustrates memory scarce algorithms snl-s reasonable alternatives rnl snl terrible performance multiple tuple rnl-s poor performance primarily due cost writing reading processor cost broadcasting processor system time sec pages pages memory numprocs snl-s rnl rnl-s snl figure analytic model performance algorithms small memory case table rough breakdown running timesof algorithmsintocpu network costs numbers table ranges minimum maximum fractions data points graphs figure cases model predicts cpu costs small fraction total cost sorting versions algorithms considerably higher cpu costs non-sorting counterparts algorithm frac cpu frac network frac rnl rnl-s snl snl-s table breakdown execution times small memory case network costs signi cantly higher fraction hhthan ofthe algorithms ispartiallybecause redistribute partially costs cpu lowwhen compared costs algorithms figure shows performance algorithms fromfigure interesting region comparison snl-s roughly comparable figure makes point consistent experiments snl-s beats small portion total problem space region snl-s faster knee graph occurs longer memory fromthis point additionalr page jsj jrj handling jrj grows quantity shrinks slope curve diminishes curvefor snl-s figure begins steep slope small relations number tuples number ofpages essentially additional tuple results additional page number tuples approximately equal number pages additional tuples additional increase time due additional fractional reading tuples pages point slope curve snl-s diminishes figure shows performance algorithms medium memory con guration pages processor rnlandsnl performbetter ect memory rnl-s snl-s pronounced rnl snl directly impacted fraction smap index memory figure shows snl-s medium memory case graph shows snl-s ectively make additional memory memory avoid spool tuples disk beats snl-s wider margin figure analytic model performance algorithms memory large pages time sec pages pages memory numprocs snl-s figure analytic model performance snl-s small memory case time sec pages pages memory numprocs snl-s rnl rnl-s snl figure analytic model performance algorithms medium memory case processor note sorting variants nested loops algorithmsactually perform worse non-sorting variants memoryis large hold index andsmap memory non-sorting variants algorithms fault relations indices memory page read sorting variants algorithms case sorting overhead wasted figure focuses snl-s snl algorithmsinthe largememorycase whilethe nested loops algorithms beat small instances faster time sec pages pages memory numprocs snl-s figure analytic model performance snl-s medium memory case time sec pages pages memory numprocs snl-s rnlrnl-s snl figure analytic model performance algorithms large memory case optimization snl-s sorting variants algorithms section improved sorting optimization two-pass sort begins ends relation ondisk rtuples sorted runs network written sorted runs sorted runs merged writing result merge back disk tuples produced merge joined maps onthe sorted incurring anyoverhead required spool disk re-read join figure shows snl-s osnl-s optimized snl-s medium memory con guration optimization improves performance snl-s change result nested loops algorithms time sec pages pages memory numprocs snl-s snl figure analytic model performance snl snl-s large memory case small case time sec pages pages memory numprocs snl-s osnl-s figure optimized versus basic snl-s implementation experiments section describe implementation experiments nested loop join algorithms gamma goal explore performance algorithms implementation investigate naturally nested loops algorithms implementedin system indices hash-join algorithms implementation gamma falls class shared-nothing sto architectures hardware consists processor intel ipsc hypercube processor con gured cpu megabytes memory megabyte maxtor disk drive disk drive embedded scsi controller kbyte ram acts disk cache sequential read operations nodes hypercube interconnected form hypercube customvlsi routing modules module supports full-duplex serial reliable communication channels operating megabytes sec gamma built top operating system designed speci cally supporting database management systems nose multiple lightweightprocesses shared memory non-preemptivescheduling policy preventconvoys bgmp occurring nose communications nose processes reliable message passing hardwareoftheintel ipsc hypercube file services nose based wisconsin storage system wiss cdkk services 
providedbywissinclude sequential les byte-stream les unix tree indices long data items external sort utility scan mechanism sequential sequence records mayvary length page inserted deleted arbitrary locations optionally mayhave indices map key values record identi ers records matching indexed attribute designated clustering attribute basic code needed added gamma included code perform local indexed nested loops join code broadcast tuples multiple sites code smap lookup redistribution snl snl-s algorithms item straightforward item twowas tuple redistribution mechanismsused bythe parallel hybrid-hash algorithm assume tuple destination fortunately added code broadcast subset redistributions work skew-handling join algorithms dnss code needed written items twowere implement rnl rnl-s algorithms item straightforward cultyis althoughsmap conceptually lot likean index avery erent manner ofusingvalues associatively access tuples join attribute values determine set target processors implementsmap section required rewrite signi portion system code implements indices toavoid rewrite making smap access method index made relation detail smap isabinary relation tuple tuple ins recall partitioning attribute store smap hash partitioned smap noticed optimizer rewrites binary join range range retrieve relation join range range smap range retrieve result join result relation join recall nition isakey importantly minor modi cations gammascheduler evaluating wayjoin gammadoes almostexactly snl join algorithm execution works tuple shipped processor smap tuples ateach processor fragmentofr received step joined local fragmentofsmap tuples produced include attributes tuple produced join step processor tuples processor tuples senttoproc step joined maindi erence algorithmthis produces snl algorithm section join smap step lookup smap join accomplished local nested loop index join algorithm created clustered index smap make cient implement rnl-s snl-s existing system sorting code code assumes input relation sorted disk beginning end sort implemented algorithms optimization subsection experiments con gured system pool pages processor eachof kbytes processors byte network packets cases tuple size bytes performed sets experiments implementation roughly mediummemory large memory cases analytic model figure results experimentins contained tuples atapproximately tuples page approximately pages spread processors roughly pages processor page pool index smap wevaried size tuples relative performance algorithms closely matches predicted bythe analytic model figure time sec pages pages processors rnl-s rnl snl snl-s figure experimental data gamma medium memory case figure shows gamma performance snl-s medium memory case graph roughly analogous figure figure free memory havetouse multiplepartitions itsperformance degrade figure large memorycase wewere limitedby availabilityofphysical memory growing pool shrank relations setting tuples pages entire relation occupies pages spread processors time sec pages tuples processors snl-s figure medium memory case roughly pages processor page pool cient free space hold index pages smap pages wevaried size tuples figure shows results experiment graph corresponds graph figure generated analytic model time sec rpages pages processors rnl rnl-s snl snl-s figure experimental data gamma large memory case finally figure shows performance snl snl-s large memory case predicted analytic model figure snl beats snl-s region snl snl-s beat small relations time sec pages pages processors snl snl-s figure experimental data fromgamma large memory case snl snl-s conclusion analytic experimental investigation parallel hybrid hashing parallel nested loops index con rms intuition hybrid hashing performs nested loops combinations input relation sizes relation sizes erent nested loops index signi cantly performance hybrid hashing nested loops algorithmswe considered snl snl-s rnl rnl-s snl-s provided acceptable performance general memory larger indexed relation snl algorithm choice joins relations disparate sizes uncommon select-join selectivity high parallel database systems pro implementing algorithms nested loops index algorithm cient nested loops algorithms perform index exists join input relation sizes ciently erent simple cost formulas analytic model optimizer determine algorithm blasgen eswaran storage access relational databases ibm systems journal bgmp blasgen gray mitoma price convoy phenomenon operating system review cdkk h-t chou dewitt katz klug design implementation wisconsin storage system software practice experience october copeland khosha adecomposition storage model proc acm sigmod conference pages austin texas dewitt gerber multiprocessor hash-based join algorithms proc twelfth vldb pages stockholm sweden dgs dewitt ghandeharizadeh schneider bricker hsiao rasmussen gamma database machine project ieee tkde march dko dewitt katz olken shapiro stonebraker wood implementation techniques main memory database systems proc acm sigmod conference pages june dnss dewitt naughton schneider seshadri practical skew handling parallel joins proc nineteenth vldb vancouver british columbia august egks englert gray kocher shah benchmark nonstop sql release demonstrating near-linear speedup scaleup large database proc sigmetrics conference pages esw epstein stonebraker wong distributed query processing relational database system proc acmsigmod conference ktmo kitsuregawa tanaka motooka application hash data base machine architecture generation computing omiecinski lin hash-based index-based join algorithms cube ring connected multicomputers ieee tkde september shekita carey performance evaluation pointer-based joins proc acm-sigmod conference pages atlantic city jersey schneider dewitt performance evaluation parallel join algorithms shared-nothing multiprocessor environment proc acmsigmod conference pages portland oregon june stg salzberg tsukerman gray uern vaughan fastsort distributed single-input single-output external sort proc acm-sigmod conference pages atlantic city jersey sto stonebraker case shared database engineering stamos young symmetric fragment replicate algorithm distributed joins ibm research division almaden research center san jose california december val valduriez join indices acm tods june valduriez gardarin join semijoin algorithms multiprocessor database machine acm tods march wdy wolf dias ective algorithm parallelizing sort merge joins presence data skew proc isdpds pages dublin ireland july wdyt wolf dias turek ective algorithm parallelizing hash joins presence data skew ibm watsonresearchcenter techreport 
dynamic memory allocation multiple-query workloads manish mehta david dewitt computer science department wisconsin-madison mmehta dewitt wisc abstract paper studies problem memory allocation scheduling multiple query workload widely varying resource requirements memory allocation scheduling schemes presented performance compared detailed simulation study results demonstrate inadequacies static schemes fixed scheduling memory allocation policies dynamic adaptive scheme integrates scheduling memory allocation developed shown perform effectively widely varying workloads introduction important reason popularity relational database systems ability process ad-hoc queries posed users past research query processing dealt issues query optimization scheduling resource allocation work area concentrated processing single queries multi-user issues important issue largely memory allocation multiple-query workloads past majority memory allocation policies proposed concentrated allocating proper amount memory single operator query presence concurrently executing queries localized allocation techniques ignore global system behavior lead poor performance reduced throughput memory allocation query determined isolation drawback memory allocation policy largely independent query scheduling policy knowledge schemes schedules queries first-come first-served manner delaying actual execution sufficient memory dbmin chou demonstrate decoupling query scheduling memory allocation disastrous effects performance system problem processing multiple-query workloads complex workload consists types queries widely varying memory requirements demonstrate research supported ibm corporation research initiation grant donation ncr abridged version paper proceedings vldb conference dublin ireland type query sensitivity memory allocated effective memory allocation policy carefully differences performance system maximized paper study relative performance query scheduling memory allocation policies compare schemes perform scheduling memory allocation independently dynamic algorithm integrates decisions performance policies compared detailed simulation model rest paper organized section discusses related work workloads studied paper presented section discussion metric compare policies section sections describe scheduling memory allocation policies section presents simulation model performance policies workloads presented section conclusions future work section related work subject memory allocation database systems studied extensively significant portion work related allocating buffers queries order minimize number disk accesses hot set model sacc defines notion hot set nested-loop join operations pre-allocate join hotset prior execution dbmin algorithm chou extends idea hot-set estimating buffer allocation file based expected pattern usage dbmin algorithm extended marginal gains allocation employed perform predictive load control based disk utilization falo schemes exception falo ignore effects concurrently executing queries make localized decisions query addition algorithms handle allocation memory hash joins work knowledge directly handles memory allocation concurrently executing hash-join queries corn authors introduce concepts memory consumption return consumption study reduction response times due additional memory allocation heuristic algorithm based ideas proposed memory allocation algorithm performance determined runtime parameters problem heuristic performance algorithm sensitive parameters authors discuss set parameter values performance based average response times discussed section metric multiple class workloads schemes first-come first-served policy service arriving queries shown lead bad performance multi-query workload query scheduling algorithms proposed chen schn handle scheduling single complex join queries multiple queries batch scheduling algorithms studied meht directly applied batch scheduling algorithms attempt maximize throughput impact query response times adaptive hash join algorithms adapt changing memory requirements proposed zell implications adapting memory investigated context multiple query workload evident taking memory executing query giving query benefits performance system drawback lies schemes dynamically change query plans run-time grae workload description study queries involving single join selections simple workload allowed study effects memory allocation load control complex query scheduling issues pipelining intra-query parallelism execution strategies complex queries left-deep right-deep bushy scheduling schn relative performance multiuser environment including queries multiple joins made impossible separate effects memory allocation query scheduling issues addition database systems exception gamma dewi volcano grae execute multiple-query joins series binary joins pipeline tuples adjacent joins query tree simplified workloads previously falo simplification workload selections executed scanning data file indices join selectivity query number output tuples produced join half number tuples outer relation inclusion indices varying join selectivity response time query memory requirements queries result ignoring simplifications affect results qualitatively joins executed hybrid-hash join algorithm dewi shap algorithm operates phases phase called build phase relation partitioned buckets tuples hash bucket in-memory hash table tuples hash remaining buckets written back disk separate file bucket number buckets conclusions discuss application techniques join algorithms selected minimum bucket fit memory space allocated run time phase called probe phase outer relation partitioned buckets tuples hash bucket joined immediately tuples tuples written bucket file disk algorithm terminates algorithms proceeds join tuples bucket read in-memory hash table constructed scanned tuples probe hash table constructed matching join attribute values results tuples written back disk size relation pages amount memory join rnrn proportional rnrn multiquery environment composed join queries number users join operations complex query composed multiple joins memory requirements query vary widely facilitate study decided classify join types small medium large idea simple small queries operands fit memory workloads medium queries run pass system large queries execution require multiple buckets workloads studied paper consist mixes queries classes show order maximize throughput system executing workload carefully control allocation memory queries classes queries sections describe classes detail small query class query class represents join queries minimal memory requirements class queries expected execute pass hybrid hash algorithm disk buckets created build phase algorithm experiments set average memory requirement class size main memory actual requirement varying memory medium query class class represents join queries operands size main memory experiments assumed medium queries range memory average queries fit memory simultaneously memory requirements class queries order magnitude larger small class memory requirements queries substantial compared total amount main memory presence concurrently executing queries medium queries frequently require multiple join passes depending actual scheduling memory allocation policy employed large query class class represents queries operands larger amount physical memory require multiple buckets execution large query sizes varied size memory upto times memory size performance objective metric section describes performance metric compare memory allocation scheduling policies examined paper metric presented order simplify presentation algorithms section spent significant amount time effort find reasonable goal multi-class workload performance goals typically single class workloads adequate biased class combining query types single class maximizing throughput biases metric smaller queries higher throughput algorithms maximize throughput smaller queries expense classes fare similarly minimizing average response time inadequate metric determined large queries long execution time high response times absence universally accepted relative importance workload classes defined organization 
tpc council wanted performance goal weights relative priority classes equally performance goal chosen study fairness step measuring fairness obtain class ratio observed average response time average response time class instances class executed system normalizes effect metric actual values response times query types differ orders magnitude fairness defined standard deviation ratios obtained classes step higher standard deviation means larger difference response time implies performance class disproportionately worse compared classes system system unfair class addition measured percentage change response time classes lower implies classes performance observed response times closer normalization expected response times ferg optimizer estimate query response time invent arbitrary expected response times queries choose approach absence real optimizer prevented stand-alone response times response times individual class shown fairness metric memory allocation policies begin section describing ways allocating memory hash join operation minimum maximum discuss alternatives applied query classes small medium large resulting combinations provide wide range alternatives controlling allocation memory queries multiuser environment join memory allocation amount memory allocated hybrid hash join range square root size relation actual size relation dewi multi-query environment allocating memory join reduces execution time operation disk cpu contention query performs fewer operations drawback allocating memory queries wait longer memory allocating memory opposite effect increases execution time disk contention reduce waiting time queries multi-programming level system higher memory requirement individual query reduced executed parallel studied effect allocation schemes query performance minimum scheme join allocated minimum memory required process join square root size relation partitioning phase joining phase required effect buckets relations read written scheme memory intensive disk cpu contention maximum maximum scheme works small medium queries join allocated memory relation temporary relation resulting selection fit memory tuples outer relations written back bucket files disk join processed reading relation allocation scheme minimizes response time query memory intensive memory query enters system wait longer begin execution large queries scheme size relations greater amount main memory previous schemes ignore memory run-time scheme determines query allocation run-time examining memory query ready execution query memory subject constraint amount memory allocated minimum required query square root size relation maximum allocation extremes interesting increases number tuples bucket reduces number tuples read disk written back impact memory allocation class combining schemes ways query classes allocation schemes small schemes medium schemes large schemes studying combinations feasible number combinations reduced removing schemes small large queries redundant expected perform badly queries small class require small amounts memory execute preliminary experiments observed cases queries maximum memory required memory needed queries small average size physical memory queries wait long memory result maximum allocation scheme superior schemes class queries elected scheme small queries similarly queries large class bad idea queries consume memory blocking queries minimum queries scheduling policies response time single query determined execution time query queries scheduled execution scheduling decision gains added significance response times queries vary significantly considered schedule policies fcfs responsible adaptive fcfs simple scheduling policy illustrated figure queries classes directly memory queue arrive system memory queue served first-come first-served fcfs order queries execute sufficient memory present results scheduling policy combination medium-query memory allocation schemes maximum minimum fcfs-maximum combination bad small queries wait large queries higher response times medium queries suffer policy restrict multiprogramming level mpl medium queries hand fcfs-minimum combination high system contention lot queries fit system minimum memory allocated schemes inherently biased larger queries larger queries memory block smaller queries addition larger queries longer execute present system longer means average mpl larger queries disproportionately higher compared smaller queries time progresses larger queries tend consume increasing fraction system resources responsible term scheduling policy responsible biased favor smaller queries shown figure small queries directly memory queue fcfs scheduling policy medium large queries hand queued separate queues prevent blocking small queries scheduler calculates average amount memory consumed small queries leave amount memory small queries leftover memory divided medium large queries memory allocation policy minimum large queries medium queries order prevent starvation class minimum mpl amount memory small queries calculated multiplying average mpl small queries average memory requirement responsible biased small queries small queries directly memory queue medium large queries wait separate queues execution small medium large memory queue small medium large memory queue figure fcfs scheduling figure responsible scheduling adaptive fcfs scheduling lets scheduling decision determined memory availability biased larger queries responsible biased favor small queries demonstrate schemes exhibit poor performance adaptive scheduling scheme hand allocate resources goal fairness achieved maximum extent basic mechanism adaptive control mpl class queries class mpl queue maintained incoming queries wait current mpl class dynamically determined level level fluctuate time control fairness metric mpl queue serviced independently fifo order query belonging class completes waiting query queue moved class mpl queue memory queue figure illustrates queues managed adaptive scheduling algorithm mentioned small queries execute maximum memory large queries execute minimum properties algorithm calculates average amount memory consumed queries classes remainder distributed medium queries assume memory maximum mpl small class small queries consume average memory similarly assume large query mpl require average memory medium queries current maximum medium mpl medium query receives memory dividing memory manner ensures smaller queries blocked medium large queries note memory allocated query related directly mpl class adaptive algorithm integrates query scheduling memory allocation small medium large memory queue mpl queues figure adaptive scheduling adaptiveness algorithm arises fact mpls query classes determined dynamically based system parameters periodically algorithm checks average response times query classes evaluates fairness metric section variance high implying class algorithm takes compensating action offending class throttled back decision increasing mpl class worst receives resources decreasing mpl offending class reduce resource consumption actual algorithm presented detail figure general principles deciding action response state system increase decrease mpls constraints mpl class memory class exceed total memory size algorithm decide class maximum mpl adjusted algorithm change activate calculate average response times class calculate fairness metric dev response time change mrt calculate difference percentage change difference percentage change small class difference percentage change medium class difference percentage change large class dev devthreshold sort higher means class poorer performance switch increase small mpl decrease large mpl decrease medium mpl increase medium mpl decrease large mpl decrease small mpl decrease medium mpl increase large 
mpl decrease small mpl decrease small mpl increase large mpl decrease medium mpl increase small mpl decrease medium mpl decrease large mpl decrease small mpl increase medium mpl decrease large mpl figure pseudo code adaptive algorithm mpl smaller query class smaller queries shorter response times changing mpl makes system respond change faster figure parameters control adaptive algorithm adjusts query workload algorithm invoked time variable activate set true invoked frequently algorithm susceptible transients workload hand infrequent activation makes algorithm slow respond workload purposes paper activate set true completion medium query parameter devthreshold controls deviation algorithm tolerates making compensating action low threshold means system respond low deviation react quickly transient change high threshold means algorithm change runtime parameters deviation high class performing worse threshold set purposes performance study sensitivity analysis algorithm parameters found section execution adaptive algorithm compute average observed response times query classes order calculate percentage change ideal case requires algorithm provided response time representative query class run mpl set activation frequency algorithm activation occur single query class completed execution algorithm calculating expected response time class solution study require input numbers class queries run multiuser mode response time observed disk read response time system bound response time cases proportional disk response time compare current disk read response time number estimate expected response time technique replaced estimation technique changing algorithm estimate inaccurate penalty severe estimate longer needed single query class completed simulation model simulator work derived simulation model gamma parallel database machine validated actual gamma implementation simulator written csim process-oriented simulation language schw simulator models centralized database system shown figure system consists single processing node composed cpu memory disk drives set external terminals queries submitted queries arrive system routed special scheduler task controls scheduling execution transactions present system database modeled set relations declustered ries livn disk drives simulator models database system closed queueing system reis terminals terminals model external workload source system terminal sequentially submits stream queries class query formulated terminal sends scheduler task execution waits response submitting query processing node processing node system modeled single cpu disk drives buffer pool cpu round-robin process scheduling policy buffer pool models set main memory page frames page replacement buffer pool controlled lru policy extended love hate hints starburst buffer manager haas hints provided relational operators fixed pages unpinned love hints index scan operator index pages memory hate hints sequential scan operator prevent buffer pool flooding addition memory reservation system control scheduler task memory reserved buffer pool operator memory reservation mechanism join operators ensure memory prevent hash table frames stolen operators memory cpu disks terminals scheduler processing node query scheduling memory allocation figure simulator architecture simulated disk models fujitsu model disk drive disk cache divided cache contexts prefetching pages sequential scans disk model slightly simplifies actual operation disk cache managed request required page number specifies prefetching desired context worth disk pages blocks read cache context part transferring page originally requested disk memory subsequent requests prefetched blocks satisfied incurring operation simple round-robin replacement policy allocate cache contexts number concurrent prefetch requests exceeds number cache contexts disk queue managed elevator algorithm key parameters processing nodes configuration parameters listed table system memory small chosen simulation time low crucial factor performance actual size memory relative size queries system memory scaled software parameters based actual instruction counts gamma prototype disk characteristics approximate fujitsu model disk drive earlier scheduler scheduler task accepts queries terminals implements scheduling memory allocation algorithms discussed sections query wait mpl queue mpl high memory memory queue scheduling policy determines order queues serviced query scheduled operation scheduler coordinates startup termination operators query configuration node parameter cpu cost parameter instructions number disks disks initiate join cpu speed mips terminate join memory varied terminate select page size apply predicate disk seek factor read tuple disk rotation time msec write tuple output buffer disk settle time msec probe hash table disk transfer rate sec insert tuple hash table disk cache context size pages start disk cache size contexts copy byte memory disk cylinder size pages tuple size bytes table simulator parameters values operators queries work reported basic relational operators select join results tuples stored back database queries complete select process spawns additional scan process reads pages disk passes select process select process applies filtering predicate scanned pages passes qualifying tuples join process simulator models actual execution detail accurate modelling tuple-level operations performance results introduction section presents results performance evaluation scheduling memory allocation policies describe characteristics base workload results obtained variety workloads examined base workload workload parameters experiments shown table times query classes chosen arbitrarily larger classes larger times mpl low number terminals class varied system moved lightly loaded state heavily loaded state addition results presented ratio terminals classes varied change mix workload terminal ratio experiment set small medium large represent ratio mpls due differences times execution times actual ratio closer mpl class varies algorithms figures show response times classes number small terminals varied medium class terminals change large class terminals range discussed section fcfs scheme solid lines biased larger queries small queries show high response times blocked larger queries load increases fcfsululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululul number small query terminals time sec number medium query terminals time sec number large query terminals time sec table experimental parameters system load response times fcfs-maximum fcfs-available fcfs-minimum adaptive responsible-maximum responsible-available responsible-minimum system load response times fcfs-maximum fcfs-available fcfs-minimum adaptive responsible-maximum responsible-available responsible-minimum figure small query class figure medium query class system load response times fcfs-maximum fcfs-available fcfs-minimum adaptive responsible-maximum responsible-available responsible-minimum system load fairness metric fcfs-maximum fcfs-available fcfs-minimum adaptive responsible-maximum responsible-available responsible-minimum figure large query class figure fairness maximum memory medium queries blocks small queries performs worst fcfs-minimum memory medium queries blocks small queries performs fcfs-available performs schemes medium queries fare similarly fcfs policies response times increase load increases case effect large queries fcfs-maximum minimizes disk contention limiting number small medium queries system response time fcfs schemes fcfsavailable fcfs-minimum responsible schemes dashed lines good job handling small queries making medium queries suffer reason schemes leave memory smaller queries leaves memory medium queries queued large queries queued response times increase correspondingly reasons firstly fewer large queries system low medium 
query mpl reduces disk contention significantly large queries low execution times leading smaller response times adaptive scheme behaves responsibly small queries prevents excessive blocking larger queries unlike responsible schemes algorithm medium queries penalized carefully controlling class mpls adaptive leads highest response times large queries large queries higher base response times compared small medium queries high response time large queries desirable fairness performance schemes regard fairness metric shown figure fcfs schemes poorly unfair small query class responsible schemes bad unfairness queries medium query class adaptive algorithm fairest schemes entire load range prevents smaller queries blocked time penalize larger classes present series workloads compare performance algorithms doubling terminals section examine performance algorithms workloads number terminals query class doubled compared base case workloads vary ratio queries workload test algorithms adapt workloads fairness metric numbers presented workloads response time numbers qualitatively similar base case differences explicitly mentioned discussion workload doubling small terminals workload increased ratio small medium terminals reader mind due difference times classes actual mpls range figures shows performance schemes workload fcfs schemes unfair smaller queries perform worse workload compared base case workload small queries penalty blocking smaller queries higher responsible schemes biased small queries workload makes unfair medium queries performance worsens adaptive algorithm fair job distributing memory classes shows performance doubling medium terminals workload doubled number terminals medium class performance schemes shown figure previous workloads compared adaptive algorithm fcfs responsible schemes perform worse fcfs schemes block small queries workload larger number medium queries responsible schemes exhibited poor performance medium queries base case worse number medium queries increases adaptive algorithm adapts increased medium workload job reducing variance query classes doubling large terminals figure shows performance schemes workload number large terminals doubled numbers show fcfs responsible schemes worse adaptive scheme fcfs schemes explicitly control mpl large query class large queries execute waiting memory responsible schemes perform badly medium queries large queries number large terminals doubled large queries queued leading higher response times adaptive fairest algorithm system load fairness metric fcfs-maximum fcfs-available fcfs-minimum adaptive responsible-maximum responsible-available responsible-minimum system load fairness metric fcfs-maximum fcfs-available fcfs-minimum adaptive responsible-maximum responsible-available responsible-minimum figure fairness metric small terminals doubled figure fairness metric medium terminals doubled restricts larger queries dominating system prevents excessive queueing time system load fairness metric fcfs-maximum fcfs-available fcfs-minimum adaptive responsible-maximum responsible-available responsible-minimum figure fairness metric large terminals doubled reduced number query types previous experiments varied ratio terminals query classes workload contained queries classes workloads classes present performance algorithms workloads presented responsible schemes shown perform badly previous workloads omitted differences algorithms shown discussed detail small medium queries workload consists small medium queries figures show response times small medium classes performance algorithms small class adaptive algorithm shows response time fcfs-minimum fcfs-available fcfsmaximum performance schemes queries medium class fcfsmaximum response times medium queries surprising fcfs-maximum makes medium queries wait longest memory response time class reason making medium queries wait memory lets queries execute pass reducing disk contention significantly reduction disk contention compensates time spent waiting memory fcfs-available fcfs-minimum induce fewer memory waits queries medium query class medium queries execute multiple join passes system loaded small queries added disk contention schemes perform worse adaptive performs similar fcfs-minimum high loads penalizes medium queries order achieve lower response times small queries fairness metric algorithms shown figure addition present percentage change obtained classes queries figure adaptive scheme achieve system load response times fcfs-maximum fcfs-available fcfs-minimum adaptive system load response times fcfs-maximum fcfs-available fcfs-minimum adaptive figure small query class figure medium query class system load fairness metric fcfs-maximum fcfs-available fcfs-minimum adaptive system load percentage change fcfs-maximum fcfs-available fcfs-minimum adaptive figure fairness figure percentage change fairness percentage change compared fcfs algorithms medium large queries response times adaptive fcfs schemes workload shown figure figure presents fairness achieved algorithms percentage change shown figure graphs demonstrate fcfs-maximum performs medium queries low loads execution times queueing times small due low number queries system high loads queueing times increase substantially queries wait memory leading high response times fcfs-minimum hand worst scheme medium queries low loads due high execution times load increases fcfs-minimum performs queueing times remain low queries executed concurrently compared schemes fcfs-available performs similar fcfs-maximum low loads fcfs-minimum higher loads adaptive algorithm shows good performance range behaves fcfs-maximum low loads fcfs-minimum high loads fcfs-maximum algorithm large queries low disk contention due low medium mpls leads low response times large queries fcfs-minimum disk contention worst scheme large queries fcfs-available performs response times large queries adaptive algorithm increase rapidly load increases algorithm performs worst high loads reason degradation drawback manner memory allocated medium queries system load response times fcfs-maximum fcfs-available fcfs-minimum adaptive system load response times fcfs-maximum fcfs-available fcfs-minimum adaptive figure medium query class figure large query class system load fairness metric fcfs-maximum fcfs-available fcfs-minimum adaptive system load percentage change fcfs-maximum fcfs-available fcfs-minimum adaptive figure fairness figure percentage change adaptive adaptive makes large queries wait order improve performance medium queries due manner medium queries allocated memory extra memory utilized fully performance medium queries improve medium query memory divided equally concurrent medium queries cases improvement allocating memory minimum maximum needed query plan investigate performance heuristic proposed query maximum minimum memory required future leads high percentage high loads fig adaptive algorithm fairness fcfs-minimum fcfs-available fcfs-maximum shown fig small large queries medium queries fcfs policies schemes differ medium queries handled compare performance adaptive fcfsavailable algorithms figures performance fcfs-available similar adaptive algorithm workload medium queries minimum memory allocation large queries small queries block fcfs scheme perform small class difference performance algorithms system load response times fcfs-available adaptive system load response times fcfs-available adaptive figure small query class figure large query class system load fairness metric fcfs-available adaptive system load percentage change fcfs-available adaptive figure fairness figure percentage change sensitivity analysis performance adaptive algorithm controlled values parameters devthreshold activate activate determines frequency adaptive algorithm executed devthreshold determines variance response times tolerated adaptive algorithm algorithm makes change mpls current fairness devthreshold sensitivity algorithm values parameters investigated experiments performance algorithm studied workloads queries classes workload small medium large terminal represents lightly loaded system workload small medium large terminal represents heavily loaded system sensitivity activate figure shows sensitivity adaptive algorithm 
practical skew handling parallel joins david dewitt rey naughton donovan schneider seshadri july abstract present approach dealing skew parallel joins database systems approach easily implementable current parallel dbms performs skewed data degrading performance system non-skewed data mainidea multiplealgorithms specialized erent degree skew smallsample relations joined determine algorithmis wedeveloped implemented experimented skew-handling parallel join algorithms whichwecallvirtual processor range partitioning clear winner high skew cases traditional hybrid hash join clear winner lower skew skew cases present experimental results implementation algorithms gamma parallel database machine knowledge rst reported skew-handling numbers actual implementation introduction multiprocessor database system technology progressed point number companies shipping products parallelism provide dramatic speedup scaleup performance clear success systems parallelism ective means meeting performance requirements large database applications basic technique systems exploiting intra-query parallelism hash-based redistribution relations joining attribute vulnerable presence skew underlying data simply put underlying data ciently skewed load imbalances resulting parallel join execution swamp gains due parallelism unacceptable performance result response problem large growing number skew-handling algorithms proposed general terms algorithms signi amount preprocessing order compute execution plan designed minimize load imbalances algorithms succeed minimizing skew invariably perform muchworse basic parallel hash join algorithm data skewed previously proposed skew handling algorithms require relations joined completely department computer sciences wisconsin-madison hp-labs palo alto scanned join begins wdyt time perform parallel hash join small multiple time required scan relations joined represent substantial overhead unacceptable extremely skewed data empirical evidence extreme degrees skew occur commonly practice sub-optimal penalize normal case order bene extreme case reason soughttodevelop approach join processing normal case approaches performance fastest parallel join algorithms non-skewed data avoids disastrous performance degradation standard hash-based join processing ers skewed data basic idea algorithms optimized ering degrees skew found experiments algorithms cient usual parallel hybrid hash join algorithm algorithm call virtual processor range partitioning performs moderately skewed data cost slightly higher parallel hybrid hash join settling algorithms implemented skew handling algorithms range partitioning weighted range partitioning scheduling version virtual processor range partitioning performed tests implementation wepresent detailed data performance implementation paper knowledge skew-handling algorithms rst implemented research prototype commercial parallel database system product fundamental step underlying approach initial pass sampling relations joined resulting set samples twoways predict level skew data select join algorithm employ skew handling algorithms determine proper mapping work processors initial sampling implementation extremely fast approximately percent time takehybrid hash perform join relations assuming non-skewed data desirable property approach easily implemented framework existing parallel database systems modi cations required existing system minimal person-month add skew-handling scheme gamma prototype remainder paper organized section describes algorithms techniques avoid skew section describes implementation algorithms gamma parallel database machine section present results series experiments implementation algorithms section describes related work handling skew parallel join operations including comparison earlier techniques present conclusions section algorithms section composed parts description basic parallel hash join vulnerable skew basic techniques employ handle skew resulting algorithms built basic techniques techniques context parallel hash joins applicable wide range parallel database algorithms fact fundamental problem skew joins skew occur hashing parallelize task techniques describe section applied traditional join algorithm suchas sort merge processor review basic parallel hash join highest level working parallel hash join algorithms shared-nothing multiprocessor database system simple concreteness suppose joining join condition initially relations distributed system processors sizes tuples jrj jsj approximately jrj tuples reside disk processor similarly processor jsj tuples disk perform join processor executes steps processor parallel reads partition relation disk applying hash function join attribute tuple turn hash function range numbers tuple hashes thenitissent processor number set tuples processor step denoted processor parallel builds memory resident hash table tuples step hash table erent hash function repartition tuples step processor parallel reads partition disk applying hash function step tuple turn step hash function map tuples processors set tuples senttoprocessori step denoted processor receives incoming tuple processor probes hash table built step joins tuple answer tuple generated mentioned simpli description tuples received step memory someover handling scheme employed commonly processing handled partitioning smaller subparts called buckets bucket small memory critical factor determining performance algorithm number buckets needed eachof larger number buckets tuples buckets spooled disk re-read perform join preceding description clear good parallelization number tuples mapped processor approximately equal load imbalances result form imbalance walton wdj terms redistribution skew load imbalances result poorly designed hash function load imbalance due poor hash function removed bychoosing hash function theoretical literature hashing number techniques designed hash function high probability performs fundamental problem arises repeated values join attribute nition hash function map tuples equal join attribute values processor wayaclever hash function avoid load imbalances result repeated values subtle load imbalance occurs number matching tuples varies processor processor form load imbalance results join selectivityfor ers join selectivityforr type load imbalance called join product skew bywalton wdj skew avoidance fundamentals subsections describe techniques apply resolving types skew range partitioning basic approachtoavoiding redistribution skew replace hash partitioning range partitioning idea allocating processor bin hash function processor allocated subrange join attribute values delineate boundaries ranges equally spaced join attribute domain values chosen equalize number tuples mapped subrange join attribute values appearing relation processors choose splitting sending tuples values processor tuples join attribute values processor general processors splitting values delineating boundaries contiguous ranges call splitting values partitioning vector partitioning vector exact partitions tuples relation equal sized pieces computing exactpartitioning vectoris cult attractiveaspect range partitioning easy determine approximate partitioning vector sampling examining entire relation technique sampling approximate splitting vectors previously dbms algorithms evaluating nonequijoins dns parallel external sorting dns theoretical investigation table relations performance sampling-based range splitting appears relation join question arises algorithm attempt balance number tuples node number tuples node sum tuples node answer clear general observation imbalance number building tuples muchworse imbalance number probing tuples imbalance number building tuples site rise extra buckets local subjoins driving number signi cantly observation validated results reported experimental results section subset-replicate complication arises join processing range partitioning presence highly skewed data equal sized partitions map single data multiple partitions join attribute values equal-sized partitioning map processor processor range partitioning assigns single values partition care ensure answer tuples produced simple solution send tuples repeated join attribute processors mapped results multiple 
exodus optimizer generator goetz graefe david dewitt computer sciences department wisconsin research partially supported defense advanced research projects agency contract -kby national science foundation grant dcrand grant microelectronic computer technology corporation abstract paper presents design initial performance evaluation query optimizer generator designed exodus extensible database system algebraic transformation rules translated executable query optimizer transforms query trees selects methods executing operations cost functions methods search strategy avoids exhaustive search modifies advantage past experience computational results show optimizer generated relational system produces access plans good produced exhaustive search search time cut small fraction introduction recent years number data models proposed including daplex ship abe klug gem zani gemstone cope iris lyng probe daya mano postgres ston ldl tsur implementing database system data model difficult laborious task goal exodus project ease burden database implementor dbi exodus designed assist dbi creating system data model augmenting existing system exodus construct database system data model extend system adding access method algorithm existing operator query language achieve exodus design consists powerful highly efficient storage system database implementation language language constructs specifically designed assist database implementation type manager maintains state location information types procedures defined system optimizer generator future plan investigating generators user interfaces overview architecture exodus found care design storage manager file system presented care programming language rich paper describe optimizer generator recently query optimizers seli wong kooi designed implemented specific data model database system mind operators algorithms access methods cost model database system implemented optimization process tailored target data model implementation postgres optimizer ston incorporation access methods optimization process exodus support single conceptual data model impossible provide single optimizer target applications solution hypothesized care query optimizer organized rule-based system operators access methods added database system optimizer informed properties adding rules rule base began investigate concept optimizer clear feasibility designed hinged separate cleanly data model specific parts optimizer common components common components consist primarily search mechanism supporting software pieces specific data model include special types box operators algorithms implementing operators cost functions algorithms catalog management software making easy pieces critical making optimizer generator successful sections demonstrate rule based approach makes components straightforward preliminary performance results demonstrate access plans obtained competitive produced exhaustive search techniques taking fraction time produce find optimal access plan query simply generate access plans estimate respective processing costs output expensive system optimizer seli basic strategy augmented pruning technique deletes cheapest set equivalent subplans step optimization process pruning optimizer unacceptably slow system rule-based optimizer employ laws musts join operator cartesian product selection heuristics move selections joins search strategy order reduce number access plans considered remainder paper organized section present design rule based optimizer generator describe operation optimizer produced generator search strategy employed generated optimizer improves learning presented section section computational results obtained optimizer generated restricted relational model section compare contrast work related research future directions outlined section conclusions found section pointscale default design optimizer generator overview order sufficiently general optimizer generator based abstraction optimization suitable data models decided queries access plans expressed trees operator trees general set oriented data models complex queries composed nesting finite set procedures nodes query trees labeled operator arguments selection predicate alternative ways transferring data operators temporary files pipelines precluding simply refer subsequently inputs streams query optimized initial operator tree constructed exodus user interface parser output optimizer access plan interpreted recursive procedure transformed approaches successfully existing database systems gamma dewi operators access plan interpreted predicates compiled machine language system seli access plan compiled machine language freytag frey frey suggests applying rule-based techniques step database systems frequently alternative algorithms logical operation relational join operator implemented alternative join methods model distinguishes operators primitives provided data model methods specific implementations operators access plans produced optimizer trees method argument node model queries access plans query optimization consists query tree reordering method selection optimization scheme centered algebra data model refer algebraic optimization query tree access plan shown figure notice producing access plan query tree left types rules applied tree operators rearranged pushing selection join operator replaced method implements file fig grn figure proposed care initially intended implement rule-based optimizer language prolog warr cloc ops forg loops bobr languages provide pattern word examples paper examples based relational data model chosen easily understood firmly ideas presented apply data models larger examples ended matching search engine unification elegantly build query trees addition languages augmentation rule base run-time capability desirable reasons database system permits addition abstract data types access methods inform optimizer optimizer finds sequences transformations occur frequently optimizer augment rule set adding single rule combines sequence transformations successive optimizations sequence transformations single step implemented experimented prototype prolog abandoned prototype problems prolog fixed search strategy depth search found needed augment search strategy dynamically optimizer running fairly cumbersome task implementation c-prolog interpreter slower accept abandoned prototype decided pursue idea implementing rule-based optimizer generator building optimizer generator required work initially left freedom implement desired functionality search strategy tuned process optimizing algebraic queries experiment alternative designs straightforward manner principal disadvantage generator approach optimizer changed running feature researchers found ston input exodus optimizer generator consists set operators set methods algebraic rules transforming query trees rules describing correspondence operators methods information contained model description file figure overview optimizer generator database system constructed generator produces data model specific optimizer description run time query transformed operator tree user interface optimized generated optimizer interpreted transformed program generated optimizer transforms initial query tree step step maintaining information alternatives explored data structure called mesh mesh hold access plans query tree pruned data structure time optimization process large set transformations collected data structure called open maintained file fig grn figure priority queue open initialized set transformations applied initial query tree open standard set moves search algorithms barr general optimization algorithm open empty select transformation open apply correct node mesh method selection cost analysis nodes add newly enabled transformations open rules governing query tree transformations method selection specific data model defined model description file input optimizer generator implement query optimizer data model dbi writes model description file set procedures model resembles optimizer generated convenient augment existing model description file generator program transforms description file program compiled linked set procedures written dbi form 
processors work producing answer tuples multiple sites cient send tuples repeated attribute relation sites mapped send tuple repeated attribute relation sites repeated values call technique subset-replicate subset-replicate similar fragment-replicate technique proposed distributed relational query processing epstein esw suppose joining join predicate suppose relations tuples shown table suppose join processors splitting vectorinthiscaseis single processors subset-replicate partitioning processors send tuples processor tuples toprocessor subset part ofthe partitioning tuples subsetted correctness tuples join attribute replicated processors means tuples senttop tuples senttop question arises replicate building relation subset probing outer relation vice-versa situations perform reasonable heuristic subset building relation replicate probing relation motivation heuristic critical portion building relation mapped processor small minimize number buckets join weighting complication arises range partitioning case join attribute appears erentnumber times erent partitions suppose join attribute values tuple relation partition processors andp partitioning vector meaning tuples join attribute mapped processors total tuples join attribute balance load evenly processors tuples join attribute directed processor join attribute values processor processor join attribute refer technique distributing replicated values subsetted relation weightedrange partitioning virtual processor partitioning subsection deal problem join product skew concreteness suppose thatwe arejoining tuple relations thatin relation join attribute appears times join attribute appears assume wehave processors equal sized range partitioning tuples join attribute relations mapped processor meaning processor asked generate result tuples remedy problem bychoosing set splitting values mapped processor case solution problem choose partitions processors idea appeared times skew join literature respect hash bucket partitioning rst technique ktmo refer technique multiple range partitions node virtual processor partitioning previous wechose buckets processor total buckets wewould granularity resolve problem spread buckets subranges mapped erent processor leaves open question virtual processor partitions mapped actual processors considered techniques subsection load scheduling basic techniques mapping virtual processor partitions actual processors round robin simplest scheme processors ith virtual processor partition mapped actual processor mod processor scheduling scheme virtual processor partition compute estimate cost joining tuples formula estimating cost join wechose simple technique estimating est est est est estimate number tuples mapped partition est estimate number tuples mapped partition est estimate number tuples computed estimate size assuming join attribute values eachofr uniformly distributed endpoints range virtual processor partition estimate cost joining virtual processor partitions computed task scheduling algorithm equalize times required virtual processor partitions allocated physical processors heuristic scheduling algorithm lpt gra approach similar bywolf wdyt inscheduling hash partitions paper statistics schedule partitions gained complete scan relations sampling hash partitioning range partitioning algorithm description algorithms implemented terms skew handling techniques ned rst discuss approximate splitting vectors computed algorithm hybrid hash rst sampling compute statistical pro join attribute values relations joined obtained sample strati sampling coc stratum consisting set tuples initially residing processor processor sampling performed page-level extent map sampling extent map sampling section issues involving strati sampling page level sampling discussed wenow describe skew handling algorithms hybrid hash basic parallel hybrid hash algorithm modi cations skew handling description algorithm alternatives appears simple range partitioning top level algorithm works sample building relation samples compute approximate partitioning vector number partitions ned partitioning vector equal number processors redistribute building relation approximate partitioning vector determine processor tuples build in-memory hash table building relation tuples tuples partitioned buckets sized bucket main memory redistribute probing outer relation approximate partitioning vector step tuple probing relation probe in-memory hash table outputting join result tuple eachmatch occurred step probing tuples buckets building relation written directly disk probing tuples received owbuckets building probing relations processed weighted range partitioning algorithm range partitioning simple range partitioning tuples redistributed weighted range partitioning virtual processor partitioning round robin algorithm range partitioning number partitions equal number processors number partitions multiple number processors exact number partitions parameter algorithm partitions allocated processors round robin allocation virtual processor partitioning processor scheduling algorithm virtual processor partitioning round robin round robin allocation partitions processors processor scheduling lpt implementation details section describe details implementation skew handling algorithms gamma begin explaining howwe sampled relations modi cations gamma remainder algorithms sampling implementation mentioned section strati sampling obtain sample relations distributed multiprocessor strati sampling node multiprocessor samples processor takes samples local partition database simple random sample entire relation strati sample cient purposes strati sampling requires processor speci number samples partition database number techniques proposed problem notably sampling trees sampling hash tables orx dense index primary key dns section describe technique wecall extent map sampling extent-based sampling requires index dense primary key index attribute scheme hinges fact systems allocate pages contiguous units called extents record information pages stored linking extents pages information maintained small memory-resident data structure address page extent found adding set address rst page extent information select random page tuple generate random number number pages relation find address rth page bychaining linked list extents random page desired page brought random tuple desired wefollow randomly choosing tuples page correctly chooses random page pages relation number tuples acceptance rejection sampling accept reject randomly chosen page inclusion probabilities tuple relation identical pages number tuples require fetch random tuple average number required fetching random tuple inverse ll-factor ll-factor wewould average fetch random tuple previous index-based methods assuming previous methods havenowasted due acceptance rejectance sampling reason wehave adopted extent-map sampling implementation page-level sampling implementation means random page selected read memory extent map sampling add tuple page sample ect boosts number samples factor equal averagenumber tuples page technique moste cient correlation join attribute page low implementation gamma order investigate performance skew handling algorithms implemented algorithms gamma dgs experimental vehicle gamma falls class shared-nothing sto architectures hardware consists processor intel ipsc hypercube processor con gured cpu megabytes memory megabyte maxtor disk drive disk drive embedded scsi controller kbyte ram acts disk cache sequential read operations nodes hypercube interconnected form hypercube custom vlsi routing modules module supports full-duplex serial reliable communication channels operating megabytes sec gamma built top operating system designed speci cally supporting database management systems nose multiple lightweight processes shared memory non-preemptivescheduling policy preventconvoys bgmp occurring nose communications nose processes reliable message passing hardware intel ipsc hypercube file services nose based wisconsin storage system wiss cdkk services provided wiss include sequential les byte-stream les unix tree indices long data items external sort utility scan 
data model specific optimizer model description file dbi lists set operators data model set methods considered building comparing access plans rules defining legal transformations query trees termed transformation rules rules defining correspondence operators methods termed implementation rules model description file required parts optional part required part declare operators methods data model include code preprocessor declarations generated code part consists transformation rules implementation rules optional part code appended generated code parts discussed detail addition illustrate pieces fit series examples part model description file called declaration part operators methods data model declared keywords operator method number arity list operators methods arity operator join method hash join loops join cartesian product operator join methods hash join loops join cartesian-product declared signal generator join operator methods require input streams operator method declarations part description file include code written output file optimizer generated code capability provide data model specific definitions types optimizer generator oper argument meth argument oper property meth property types structure definition nodes query trees access plans mesh store arguments operators methods predicates properties dbi associate node mesh node proper operator arguments method arguments inserted calling procedures provided dbi stored memory locations type oper argument operator type meth argument method dbi wishes store information subtree root node relation cardinality tuple width node mesh fields provided information oper property type oper property meth property type meth property contents field depends operator depends method chosen node relational prototypes store schema intermediate relation oper property sort order meth property part description file called rule part transformation rules implementation rules rule consists expressions optional condition expressions keyword implementation rules arrow transformation rules arrow legal directions transformation arrow point left double-sided one-sided arrow exclamation mark transformation applied query tree generated transformation optimizer performance feature correctness typical situation improve optimizer performance commutativity rule commutativity results original query tree query tree generated generated earlier duplication detected query tree removed allowing commutativity applied performance correctness issue expression transformation rule expression left side implementation rule consists operator parameter list parameter expression number number input stream subquery expression side implementation rule consists method list inputs join join join hash join line join commutativity rule applying results original form once-only arrow exclamation mark line hash join suitable implementation method join operator appears expression associativity rule case identify operators arguments join predicates transferred correctly transformation applied identification operators expression number number appears operator side arrow arguments copied operators dbi wishes default action simple copying function copy arg declared preprocessor replacing default action simply copying arguments initial query mesh mesh final access plan needed dbi define functions copy copy argument passing scheme sufficient procedure transformation implementation rule default mechanism procedure called transfer possibly modify arguments project hash join hash join proj combine hjp rule special form hash join called hash join proj hash join project operator hash-join-proj chosen optimizer call dbi supplied procedure combine hjp combine projection list join predicate form argument hash join proj transformation rules implementation rules condition conditions written procedures executed optimizer determined subquery matches pattern rule subquery operators positions rule condition met special action reject provided reject action executed transformation added open condition code access arguments properties operators inputs expression pseudo variables defined generator variables called operator operator input input numbers variables identify operators inputs variable structure record includes fields oper property oper argument meth property meth argument case transformation rule directions condition code inserted optimizer code distinguish cases compile time preprocessor names forward backward defined condition code join join join join ifdef forward cover predicate operator oper argument input oper property input oper property reject endif ifdef backward cover predicate operator oper argument input oper property input oper property reject endif illustrates join associativity rule conditions control application transformation join operator appears expression numbers appended distinguish instances operator optimizer transfer correctly join predicates operators transformation rule applied condition code lines copied optimizer code statement condition code executed direction removed preprocessor boolean function cover predicate assumed determine attributes occurring predicate argument function attributes relations arguments rule set formal properties sound complete sound means legal transformations condition code correct generator generated optimizer work properly complete means rule set cover cases equivalent query trees derived initial query tree transformation rules rule set complete optimizer find optimal access plans queries hand rule set redundant fact dbi foresees combination rules frequently recommended required combination single rule speed optimization process affect results search parameters section set restrictively model description file dbi provide set procedures property procedures cost functions support functions property cost function concatenation word property cost operator method names support functions fixed operator property function required method property function cost function required support functions include argument comparison memory allocation deallocation formatting procedures property argument fields memory functions intermediate data structures access plans formatting procedures built-in debugging facilities including interactive graphics program property functions operators dbi cache information individual nodes intermediate query trees speed condition argument processing relational prototype schema intermediate relation cached property functions methods dbi derive cache information depends selected method physical sort order cost functions determine processing cost method depending operator argument input streams scheme dbi functions complement automatically generated optimizer desirable side effect dbi basically forced write code structured modular dbi routines written independently meaning written stages development project true transformation implementation rules rule independently rules generator builds connections control structures incremental development enhancement database system optimizer component supported imagine dbi explore newly proposed index structure optimizer index structure future optimizations dbi write implementation rules property function cost function generator produces source code optimizer single pass description file reading declaration part builds symbol table operators methods copies source lines output file rule part maintains temporary files procedures match apply analyze match takes subquery adds applicable transformations open apply performs transformation selected open analyze determines cheapest method root subquery matching implementation rules calling cost functions bidirectional transformation rules code generation procedure invoked match apply direction bidirectional rules appears rules generated optimizer transformation rule tests inserted procedure match subquery transformed rule rule once-only rule subquery generated rule rule admittedly tools debugging optimizer generator code implementing search strategy proved invaluable debugging dbi code prototype implementation graphics 
mechanism sequential sequence records mayvary length page inserted deleted arbitrary locations optionally mayhave indices map key values record identi ers records matching indexed attribute designated clustering attribute beginning work gammaalready contained code needed perform parallel hybrid hash join critical code thatneeded tobe added tothe system order toincorporate skew handling join algorithms code parallel strati page level extent map sampling code sort resulting samples build required approximate splitting vectors code redistributes tuples distribution types subset-replicate required algorithms items abovewere straightforward wenow discuss redistribution code detail basic parallel hybrid hashing gamma makes data structure called split table dgs data structure entries hash bucket processor number pairs processors execute relational operation split tables entries semantics suchthatany tuple hashes hash bucket processor number split table entry hash bucket processor executing operation copy split table processor split table outgoing pages processor tuple maps hash bucket added page page lls message page target processor add basic range partitioning added type split table called range split table simple modi cation change entries split table correspond ranges join attribute values hash buckets deciding send tuple hashing join attribute entry range split table searched range join attribute tuple maps range repeated values split table redistribution building relation duplicate ranges selected random processor redistribution probing outer relation processors subranges add weighted range partitioning augmented basic range split table weights upper lower boundary values range table weights computed sorted set samples time partitioning values computed redistribution building relation sending tuple randomly selected subrange subrange selected probability ects weights weighted-range split table obvious add virtual processor range partitioning expand basic range splitting tables add entries processors culty lower level gamma code assumes outgoing page entry split table large numbers virtual processors space required scheme prohibitive processors virtual processor ranges processor require output ers megabytes byte network packets node total amount memory node sytem solve problem two-level split table upper level table numberofentries number virtual processor partitions lower level table entry processor eachentry upper table consists range lower split table entry number pair tuple processed decide processor rst lookup performed upper table determine set virtual processor ranges join attribute tuple appears entries ranges examined determine whichlower level entries tuple belongs set entries lower level table system determine processors tuple page destination processor experiments results test data purposes experimentwewanted set test data simple intuitively easy understand stress skew handling algorithms option generate relations attributes drawn standard statistical distributions zipf normal decided found relations attributes make experiments harder understand control suppose perform set joins pair relations varying level skew relations keeping answer size approximately constant cult sets zip distributions remedy problem generated relations number integer attributes amounts scalar skew tuple relation attribute constant appears xed number tuples remaining tuples values uniformly distributed distribution major bene makes easy understand experiment performed easy answer size constantover varying amounts skew finally captures essence zip distribution small number highly skewed values bulk values appearing infrequently ering drawbacks term scalar skew due walton wdj model skew omiecinski omi exact description attributes case assuming relation tuples attributes relevant experiments number case number tuples appears join attribute tuples chosen random remainder tuples join attribute chosen randomly number tuples relation attribute semantics appears ten randomly chosen tuples remaining tuples values uniformly chosen random rationale choosing attributes apparent set experiments addition attributes listed tuple contained string attribute pad length tuple bytes experiments belowwe relations tuples relation occupies approximately megabytes disk space experiments conducted processors disks speedup scaleup experiments performed wewere interested focusing relative performance erent algorithms previous join dgg dgs dgs dns sorting dns tests demonstrated gamma linear speedup scaleup wide range erent hardware software con gurations single skew experiments rst set experiments ran building relation skewed probing relation uniform models common sort join practice joins key relation foreign key data point average experiments range weighted range virtual processor range partition round robin number samples building relation xed probing relation sampled algorithms virtual range partition processor scheduling algorithm samples building probing relations virtual processor range partitioning algorithms virtual processors processor results experiment table alg dnf dnf dnf range dnf dnf dnf range vp-rr vp-ps table ect skewed building relation table entries marked dnf means algorithm nish reason tests nish cases marked dnf algorithms mapped tuples join attribute single processor simultaneously memory processor current gamma implementation per-node hybrid hash code handle extreme case hybrid hash algorithm choice skew case compared skew handling algorithms hybrid hash incur overhead collecting samples sorting samples computing approximate splitting vector hybrid hash determine destination processor redistribution compute hash function algorithms search sorted list range entry erence performance range partitioning range weighted range partitioning range skew artifact implementation weighted range partitioning implemented cient table search repartitioning expect range partitioning reimplemented code slightly faster skew doesn check weights choosing destination subset phase range partitioning weighted range partitioning ect partitioning sending tuples join attribute tuples processor range partitioning sends tuples processor weighted range partitioning sends tuples processor tuples tuples processor weighted range partitioning performs worse number tuples distributed processor cases case join hash table processor bucket tuples bucket mapped situation worse bucket case virtual processor range partitioning round robin allocation vp-rr starts skew slightly higher overhead weighted range redistribution determine destination processor searchamuch bigger range table bigger bya factor virtual processor range partitioning processor scheduling vp-ps overhead sample sort probing relation run lpt scheduling algorithm skewed cases algorithms outperform range range map tuples processors avoiding large hash table entry ect wewanted test ect skewed probing relation algorithms note rst algorithms sample probing relation algorithms splitting vector independent skew probing relation reason performance deteriorates rapidly sowe note hybrid hash vp-ps samples probing relation estimates virtual processor execution times inaccurate provide good performance algorithm range range vp-rr vp-ps table ect skewed probing relation alternative approach handling single relation skew sample probing relation samples compute splitting vector building probing relations pursue approach reason probing relation highly skewed distribute building relation splitting vector evenly distributes probing relation greatly varying numbers building tuples processor turn processor manymore buckets building relation evenly distributed performance join product skew subsection present experiments relations participate join skewed general sort skew harder deal 
capabilities implemented demonstration quick understanding debugging including debugging tools optimizer command line switch generator program remains non-trivial problem coding operations index structure exodus eases task database implementation language rich bidirectional subquery generated opposite direction rule applied subquery patterns match patterns match operators positions rule subquery rule applied condition condition met apply transformation nodes generated operators operator arguments inputs filled node procedure called finds existing equivalent node invokes property caching method selection node process detail implementation rule code added procedure analyze subquery rule pattern match code calls cost function method compares result expensive implementation found subquery parser finds end rule part procedures library support routines appended output file support routines implement control structure maintain open data structure finally part model description file appended optimizer source code operation generated optimizer cost model optimizer supports simple powerful cost query tree sum costs methods access plan criticize model naive incorporation buffering effects potentially reduce cost intermediate files effects exist incorporated cost functions reasons information passed arguments cost functions written dbi mentioned earlier information query trees access plans explored stored data structure called mesh mesh network nodes represents alternative query trees access plans size node bytes query trees important mesh designed avoid unnecessary redundancy avoid redundant processing natural share nodes query trees achieve optimizer allocates nodes transformation sharing copies feasible implementation typically nodes required transformation independent size query minimal size actual size depends size data structures defined dbi maximal arity operators methods data model current implementations node bytes long tree file fig grn figure figure bold arrows denote transformations solid lines show input streams flow upward dotted lines point subtrees reused transformation pushes selection query tree transformation applies join commutativity precisely node created operator appears transformation rule side optimizer traverses nodes bottom-up replace existing equivalent node nodes equivalent operator operator argument input hashing scheme employed make search equivalent nodes extremely fast scheme detect equivalent nodes initial query tree copied mesh common subexpressions query recognized early node replaced existing duplicate matched implementation rules order find optimal access plan subquery rooted node matched transformation rules applicable transformations added open parent nodes subquery point subquery equivalent subquery input streams matched implementation rules propagate cost improvement obtained transformation performed term reanalyzing finally parent nodes matched transformation rules possibilities transformations called rematching file fig grn figure file fig grn figure figure transformations push selection query tree reusing nodes apply join associativity node labeled rematched node labeled input resulting entry open eventually lead transformation shown figure search strategy learning number transformations open large complex query queries optimized reasonable amount time critical optimizer avoid applying transformations find optimal access plan quickly search directed barr transformation selected open step optimization process ideal situation select transformations transform initial query query tree optimal access plan feasible optimal access plan shortest sequence transformations optimizer selects transformation promises largest cost improvement promise calculated current cost transformation information transformation rule involved measure promise transformation rule expected cost factor transformation rule bidirectional transformation rules expected cost factors direction interpretation factor cost transformation expected cost factor transformation rule cost transformation rule good heuristic pushing selections tree expected cost factor rule rule neutral average join commutativity concept expected cost factors raises important issues factor valid associate rule independent database queries optimized factors determined address question decided difficult error prone dbi set expected cost factors hand data model rules future dbi implement set cost functions determined automatically optimizer learning past experience adequate method average observed cost quotients rule recall expected cost factor estimate quotient costs applying transformation rule suitable approximate factor observed quotients rule simplest averaging method arithmetic average applications rule optimizer generated query pattern database average observed quotients rigid alternative average applications suitable fairly cumbersome implement values stored rule alternative calculate sliding average rule sliding average weighted average current expected cost factor newly observed quotient easy implement efficiently finally average quotients geometric average arithmetic average tests evaluated averaging formulae delim box center geometric sliding average geometric arithmetic sliding average arithmetic formulae expected cost factor rule consideration current observed quotient cost cost count times rule applied sliding average constant discussed averaging formulas lead statistically valid constructs performance differences fairly small cases find beneficial rule negatively beneficial rule applied reflect search strategy optimizer adjusts expected cost factor rules advantageous transformation recalculates factor rule applied techniques adjusts factor preceding rule applied formula half weight rule frequently enables subsequent beneficial transformations expected cost factor lower neutral preferred neutral rules indirect benefit call indirect adjustment finally cost advantage realized reanalyzing parent nodes transformation rule expected cost factor adjusted half normal weight call propagation adjustment ordering transformations open expected cost decrease negative effect situations open equivalent subqueries costs transformed rule expected cost factor transformation expensive query tree selected counterintuitive good search strategy offset effect optimizer subtracts constant expected cost factor estimating cost transformation part access plan lowered expected cost factor increases expected cost improvement subquery transformed equivalent subquery expected cost factors direct search optimizer finds optimal access plan quickly optimal access plan found optimizer ignore remaining transformations open output plan impossible plan optimal solution optimizer searching limit set transformations applied cost improvement expected applying transformation compared cost equivalent subquery found improvement multiple current cost transformation applied removed open analogy finding lowest point terrain uphill reach lower valley technique termed hill climbing multiple mentioned hill climbing factor typical values neutral rules applied explore complete search space hand experiments show relational model hill climbing factors close work finally reanalyzing factor recall importance reanalyzing figures cost newly generated subquery significantly higher equivalent subquery reanalyzing wasted effort cost newly generated subquery multiple equivalent subquery parent nodes subquery inputs matched transformation implementation rules subquery replaced values hill climbing reanalyzing factors depend data model expected cost factors learned optimizer implemented feature computational results relational prototype section report preliminary results obtained optimizer generated subset relational model model restricted select join operators implemented model producing optimal join tree reportedly major problem relational query optimization seli wong kooi leaves query trees introduced artificial operator called reads file disk transfers operator introduced convenience write cost functions operators methods regard input streams disk operators makes easy express fact 
skew single relation intuitively problem join product skew small number repeats tremendous blowup number tuples generated join join relations join clause result tuples generated due matches tuples join attributes result bytes addition exceeding capacity disk drives don queries makeany sense decided experiment modest skews rst set experiments shows performance algorithms con guration numberofsamples number virtual processors node table algorithm range vp-rr vp-ps table performance data join product skew joins table designed result size roughly comparable tables case result tuples due joining tuples join attribute clear virtual processor algorithms signi success dealing sort skew intuitively reason range weighted range algorithms skew relation tuples join attribute processor exception join virtual processor algorithms virtual buckets mapped processors distribute work join round robin algorithm fails distribute building relation virtual processor range partitioning processor scheduling algorithm fails distribute multiple buckets estimates work required virtual processor inaccurate clear performance virtual processor range partition algorithms critically dependent number virtual processors processor table explores performance round robin variant join numbers processor node experiments processor scheduling variantwasuniformly worse round robin variant omit data points algorithm table shows clear trend virtual processors performance reason tuples distributed actual processors achieving load balancing virt procs exec sec table dependence number virtual processors virtual processor range partitioning finally wewanted illustrate dependence virtual processor range partitioning number samples table lists average time function number samples virtual processor range partition round robin algorithm function number samples join virtual processor range partitioning round robin allocation uniformly skew handling algorithm present data note performance stable independent number samples general trend taking samples results poor load balancing taking samples results muchoverhead due sampling notice table running times dip samples begin rise number samples execution time sec table dependence number samples virtual processor range partitioning finally wewould emphasize virtual processor range partition round robin exceedingly successful balancing load processors execution table maximum minimum times processors complete building phase redistributing building relation building in-memory hash table entire join samples virtual processors processor note total time seconds ers time reported join table times presented table averages runs times table single run erence maximum minimum times building phase erence total execution time phase min seconds max seconds building complete join table maximum minimum times processors virtual processor range partitioning related work wealth research area parallel join algorithms originally join attribute values assumed uniformly distributed skew problem bfks bra dgs ktmo parallel join algorithms matured uniformity assumption challenged section examine number previously proposed algorithms dealing data skew compare algorithms walton dale jenevein walton wdj present taxonomyofskew parallel databases distinguish attribute skew avs whichisskew inherent dataset partition skew occurs parallel machines load balanced nodes avs typically leads partition skew factors involved include tuple placementskew tps initial distribution tuples mayvary nodes selectivityskew selectivity selection predicates mayvary nodes case range selection range-partitioned attribute redistribution skew nodes receive erentnumbers tuples redistributed preparation actual join join product skew jps join selectivity individual nodes leading imbalance number output tuples produced walton analytical model order compare scheduling hash-join algorithm wdyt hybrid hash-join algorithm gamma dgs main result scheduling hash ectively handles hybrid hash degrades eventually worse scheduling hash increases join signi cantly skewed absolute performance hybrid hash signi cantly scheduling hash schneider dewitt explored ect skewed data distributions parallel join algorithms processor version gamma database machine experiments designed tps absent tested avs distributed values hash function redistribution phase ective balancing load low likewise jps low results parallel hash-based join algorithms hybrid grace simple sensitive resulting avs building relation due hash table insensitive probing relation experiments double-skew lead jps run extrapolated problems worse case superset building relation kitsuregawaandogawa kitsuregawa ogawa describe algorithms bucket-converging parallel hash-join bucket-spreading parallel hash join bucket-converging hash join basic parallelization grace join algorithm ktmo relation read disk parallel partitioned buckets larger number nodes bucket statically assigned node redistributed phase algorithm size bucket examined buckets redistributed sum sizes buckets processor balanced relation processed similarly phase respective buckets node joined locally point rst phase algorithm initial repartitioning susceptible alternative propose bucket-spreading hash join algorithm algorithm relations partitioned buckets bucket horizontally partitioned processors initial repartitioning phase phase algorithm sophisticated network omega network redistribute buckets nodes local join operation omega network logic balance load bucket redistribution simulation results arepresented forthe twoalgorithms avsis modeled azip distribution data uniformly distributed algorithms identical bucket-spreading algorithm shown ectively reduce presence increasing avs bucket-converging algorithm ers compared weighted-range virtual processor algorithms algorithms higher response times algorithms redistribute joining relations bucket-spreading algorithm redistributes relations addition relations memory extra write read relations disk required repartitioning phases bucketconverging algorithm hand incurs extra redistribution costs buckets redistributed order balance load processors point algorithm susceptible hua lee hua lee proposed algorithms processing parallel joins presence avs rst algorithm tuple interleaving parallel hash join based bucket-spreading hash join algorithm kitsuregawa ogawa major erence relying specially designed intelligent network mapping buckets nodes decision handled software coordinator node algorithm adaptive load balancing parallel hash join avoid muchof massive data redistribution incurred tuple interleaving algorithm case mild skew amoreselective redistribution perform algorithm relations partitioned buckets bucket statically assigned single node immediately performing local joins partition tuning phase executed bestt decreasing heuristic determine buckets retain locally versus redistribute algorithm basically identical kitsuregawa ogawa bucket-converging algorithm nal algorithm extendedadaptive load balancing parallel hash join designed case severe skew relations partitioned buckets bucket stored locally nodes report size local bucket coordinator decides allocation buckets nodes allocation decision broadcast nodes buckets redistributed network local joins respectivebuckets performed node basic form algorithm identical wolf wdyt algorithms computation allocation strategy algorithms compared analytical model basic results tuple interleaved extended adaptive load balancing algorithm una ected byskew size partitions performance adaptive load balancing algorithm bucket-converging algorithm eventually cross muchworse skew increases rst algorithms basically identical kitsuregawa relative performance algorithms algorithms extended adaptive load balancing parallel hash join algorithm repartitions relation relations memory extra read write relations occurs initial bucket forming phase cost step higher cost incur sampling relations implementation wolf dias wolf wdyt propose algorithm parallelizing hash joins presence severe data skew scheduling hash algorithm relations read local selections projections applied results written back locally set coarse hash buckets additionally statistics based 
input methods based indices stored relation test queries experiments generated randomly generate query tree top operator selected priori probabilities assigned join select test join select chosen input query trees built recursively procedure predefined limit join operators query reached join operators generated query join argument equality constraint randomly picked attributes inputs selection argument comparison attribute constant attribute comparison operator constant picked random database consists relations tuples relation attributes schema cached main memory optimizer test run schema intermediate relation cached query tree node mesh operator property method property considered system sort order transformation rules included join commutativity associativity commutativity cascaded selects select-join rule rule pushing selects query tree left branch selection clause applied branch join commutativity applied left-branch form select-join rule forces optimizer perform rematching indirect adjustment rule optimizer push joins tree bidirectional rule joins considered methods nested loops merge join hash join index join merge join requires inputs sorted respective join attribute index join requires input permanent relation index join attribute selection filter method input stream output stream scan considered file scans index scans scan implement conjunctive clause cascade selects operator bottom cost calculation estimates elapsed seconds mips computer data passed operators buffer addresses algebra description realized shortcomings generator corrected section future work tests ensure generated optimizer transforms query correctly produces optimal near-optimal query plan test duplicate existing optimizer compare query plans produced required imitating cost functions easily accessible information importantly restricted set operators methods leaving room modification experimentation decided compare optimization results exhaustive search access plans modified optimizer undirected exhaustive search avoid thrashing time-shared computer experiments aborted optimization query mesh contained nodes implied open contained elements heap area grown megabytes tables summarize typical results sequence randomly generated queries queries sequence join operators select operators reanalyzing factor set equal hill climbing factor report results values hill climbing reanalyzing factors demonstrate effects search effort quality resulting access plans hill climbing factor undirected exhaustive search comparison restricted search strategies unrestricted search remaining runs directed limited search column labeled total nodes generated amount main memory mesh average size mesh numbers column sum mesh sizes times access plans found fourth column shows sum estimated execution costs generated access plans column states cpu time seconds spent optimizing entire sequence queries center box cccc nnnn hill total nodes nodes sum estimatedcpu climbing generated plan execution costs time table summary queries increasing search effort larger hill climbing reanalyzing factors cpu time increases cost access plans decreases notice sum costs exhaustive search higher restricted search due fact optimizations aborted memory requirement exhaustive search turned excessively high exhaustive search completed suboptimal plan produced interesting restrict attention queries aborted undirected exhaustive search restricted queries exhaustive search succeeded table center box cccc nnnn hill total nodes nodes sum estimatedcpu climbing generated plan execution costs time table summary queries aborted exhaustive search table notice substantial differences resource consumption cpu time memory queries search strategies produce access plans cost optimal plan table detailed picture cost differences associating plan number nodes mesh time plan generated times seconds user mode gould running utx version times measured getrusage system call machine cpu rated mips optimizer ran uninterruptedly cpu center box cssc cssc cccc cccc cost difference number queries relative hill climbing factor exhaustive search difference table frequencies differences queries queries cost access plans differ worst case query double cost results undirected exhaustive search inferior search strategy presented paper search strategy employed rule based optimizer generally earlier associate expected cost factor rule direct search promising direction considered test expected cost factor valid construct factor rule independent queries optimized test hypothesis sequences queries optimized independent runs optimizer expected cost factors rule end run compared sequences selected combination select join probabilities generate random queries limit set number joins allowed single query expected cost factors show variance fall rule normal distribution statistical testing sets test queries equality hypothesis true confidence attempted determine averaging methods suited optimizer results conclusive averaging techniques worked equally query sequences tested discouraging means differences adjustment formulae insignificant differences directed search undirected search remain related work techniques employeed optimizer generator based variety earlier efforts query optimization area pioneering work system project astr seli ingres project ston wong yous smith chang smit optimization algebraic identities compilers programming languages database optimization microbe relational distributed database system nguy freytag assumes work code generation frey frey access plans query plans set-oriented data models expressed trees search strategies areas deduction theorem proving learning improve programs performance game playing programs barr query optimization research date surveyed jarke koch jark deals relational systems extensions designers previous query optimization programs data model fact reordering join trees seli kooi assume order joins executed makes semantic difference exodus optimizer generator hand operators semantics left open allowing dbi design experiment data models algebraic transformation laws design implementation optimizer distributed relational database system microbe nguy goal microbe rule based optimization step minimize number operators amount data shipped operators set transformation rules formulated proven guarantee deterministic result independent actual sequence transformations microbe optimizer takes log steps number operators query transformation rules hand-coded pascal implementation language project approach differs microbe approach important ways assume fixed data model assume soundness completeness rule set requiring properties proving deterministic results set rules significantly harder data models algebras dbi procedures transform query generated approach allowing dbi concentrate correctness approaches similar formal properties algebra query optimization theory data model standpoint search program dedicated search algorithm adaptive learning capabilities promise function search strategy stronger theoretical properties optimizer generator aware target data model unable search algorithms hart guaranteed optimal access plan queries special case relational model find calculate promise transformation guarantee properties needed direct search effective manner future work interesting design issue remains provide general support predicates form predicates data models writing dbi code predicates operator arguments general hardest part developing optimizer prototypes current design dbi design data structures provide operations rule conditions argument transfer functions difficult invent all-around satisfying definition support predicates significant improvement optimizer generator fact predicates special case arguments poses additional challenge design argument data structure remain dbi hill climbing reanalyzing factors significant effect amount cpu time spent optimizing query values surely model algebra dependent set 
frequency algorithm executed graphs show performance algorithm execution interval varied seconds simulated execution time workloads increasing activation period implies adaptive executed reacts slowly workload algorithm fare badly lightly loaded system system load low performance deteriorate adaptive scheme activated hand heavily loaded system performance sensitive activation period activation period low algorithm over-reactive system state performance degrades activation period increases performance reactive performance improves increase algorithm degrade algorithm under-reactive region good performance corresponds completion time medium query activating algorithm medium query completion good heuristic activation period fairness metric light heavy dev threshold fairness metric light heavy figure sensitivity activate figure sensitivity devthreshold sensitivity devthreshold figure shows performance adaptive devthreshold varied devthreshold increases adaptive mpls classes frequently performance degrades lightly loaded case fairness decreases devthreshold increased devthreshold increased adaptive perform worse fairness stablizes expected adaptive performs worse heavily loaded system threshold values algorithm takes actions frequently fairness deteriorates algorithm unstable threshold increased performance improves lowest achieved algorithm degrades fast threshold increased shows adaptive sensitive devthreshold reasonable performance achieved workload sensitivity workloads previous experiments contained queries classes small medium large large queries easily defined queries system memory division small medium queries obvious queries needing system memory defined small queries needing memory termed medium queries experiment designed test sensitivity adaptive boundary small medium queries performance adaptive fcfs algorithms presented boundary small medium queries varied system memory reminder boundary means queries requiring memory classified small queries allocated maximum memory queries memory requirement memory medium queries memory allocated scheduling algorithm queries require system memory termed large allocated minimum memory figure show response times class figure presents fairness achieved algorithms experiment boundary small medium queries low performance algorithms similar previous experiments adaptive performs small class fcfs-minimum fcfs-available fcfs-maximum order reversed large class adaptive highest response time medium class fcfs schemes similar performance order terms fairness adaptive fcfs-minimum fcfs-available fcfs-maximum boundary increased queries classified small queries fcfs schemes differ medium queries allocated memory performance schemes small med boundary response times small med boundary response times figure small query class figure medium query class small med boundary response times dev threshold fairness metric figure sensitivity activate figure sensitivity devthreshold similar fact performance schemes identical boundary difference fcfs-minimum performs worse medium query compared schemes lots medium queries system allocating minimum memory helps increase mpl reduces queueing time boundary small medium query high medium queries queries classified small advantage allocating minimum memory medium queries fcfs-minimum performs worse fairness achieved algorithms pattern schemes converge higher boundaries performance adaptive worsens increase boundary restriction mpl class reduced small medium boundary high medium large queries system mpl adaptive reserves memory medium large query reserved memory improves performance medium large queries memory underutilized underutilization performance small class degrade queued unnecessarily worsening small class performance improved response times small medium classes algorithm unfair figure shows adaptive unfair boundary increased algorithm performs fcfs schemes long boundary small medium queries experiment shows boundary increases restriction mpl greater performance degrade results show queries termed small memory requirement high small queries maximum memory allocated requirement high queries queued leading high response times boundary desirable reasonable performance conclusions future work paper investigated problem memory allocation multiple query workload consisting queries belonging classes resource requirements results obtained demonstrate performance memory allocation policy closely linked scheduling policy service arriving queries memory allocation policies scheduling policies memory allocation scheduling policies combined produce schemes makes separate allocation scheduling decisions performance compared adaptive algorithm combines decisions simulation study demonstrated adaptive algorithm excellent performance wide variety workloads cases performs schemes demonstrated intelligent combination allocation scheduling decisions give substantial gains performance extensions adaptive algorithm presented paper cases fairness criteria executing multi-class workload workloads consist queries types type fixed response time throughput goal investigate present scheme extended handle performance objectives queries workloads hash join queries adaptive algorithm applied queries join methods adaptive algorithm observed response time estimates control mpl classes join methods nested-loop sort-merge division queries classes valid sort-merge nested loop join case sort-merge joins queries divided small medium large classes based size memory needed sorting relations size relation make division nested-loop join queries investigate policies developed adapted processing mixes transactions queries finally important future objective implement adaptive scheme paper measure performance real database workloads acknowledgements authors acknowledge kurt brown idea fairness metric paper reviewing paper jim gray suggesting idea varying system load study performance chen chen ming-syan segmented right-deep trees execution pipelined hash joins proc vldb conf vancouver canada august chou chou dewitt evaluation buffer management strategies relational database systems proc int vldb conf stockholm sweden aug corn cornell integration buffer management query optimization relational database environment proc int vldb conf amsterdam netherlands aug dewi dewitt implementation techniques main memory database systems proc acm sigmod conf boston june dewi dewitt gamma database machine project ieee transactions knowledge data engineering march ferg ferguson nikolaou geargiadis goal oriented adaptive transaction routing high performance transaction processing systems proc int conf parallel distributed systems san diego jan falo faloutsos sellis predictive load control flexible buffer allocation proc int vldb conf barcelona spain sept grae graefe dynamic query evaluation plans proc acm sigmod conf portland oregon grae gray volcano extensible parallel dataflow query processing system computer science technical report oregon graduate center beavorton june haas haas starburst mid-flight dust clears ieee trans knowledge data eng march livn livny khoshafian boral multi-disk management algorithms proc acm sigmetrics conf alberta canada meht mehta soloviev dewitt batch scheduling parallel database systems int conf data engineering vienna april faloutsos sellis flexible buffer allocation based marginal gains proc acm sigmod conf denver reis reiser lavenberg analysis closed multichain queueing networks jacm april ries ries epstein evaluation distribution criteria distributed database systems ucberl technical report berkeley sacc sacco schkolnick buffer management relational database systems acm tods december schn schneider dewitt tradeoffs processing complex join queries hashing multiprocessor database machines proc vldb conf melbourne australia aug schw schwetman csim users guide mcc technical report act- microelectronics computer technology corp austin march shap shapiro join processing database systems large main memories acm tods sept cornell buffer management based return consumption multi-query environment vldb journal january zell zeller gray adaptive hash join algorithm multiuser 
environments proc int vldb conf melbourne australia aug 
performance evaluation parallel join algorithms shared-nothing multiprocessor environment donovan schneider david dewitt computer sciences department wisconsin research partially supported defense advanced research projects agency contract -cby national science foundation grants dcrmcs mcs digital equipment corporation external research grant abstract join operator cornerstone relational database systems inception time effort making joins efficient obvious trend multiprocessors attention focused efficiently parallelizing join operation paper analyze compare parallel join algorithms grace hybrid hash represent class hash-based join methods simple hash represents looping algorithm hashing algorithm traditional sort-merge gamma database machine serves host performance comparison gamma shared-nothing architecture commercially components increasingly common research industry introduction years significant amount effort focused developing efficient join algorithms initially nested loops sort-merge algorithms choice work kits brat dewi demonstrated potential hash-based join methods faster conditions hash-based join algorithms property easy parallelize trend multiprocessor database machines algorithms received lot attention fact researchers including baru brat dewi dewi kits presented performance timings variety distributed join algorithms popular parallel join algorithms compared common hardware software environment paper present performance evaluation parallel versions sort-merge grace kits simple dewi hybrid dewi join algorithms context gamma database machine dewi dewi gerb algorithms cover spectrum hashing looping hashing finally sorting feel gamma good choice experimental vehicle incorporates shared-nothing architecture commercially components basic design increasingly popular research bubba mcc cope bora commercial arena products teradata tera tandem tand experiments designed test performance join algorithms conditions compare algorithms join attributes attributes distribute relations loading circumstances exploit situation drastically reduce inter-processor communications performance join algorithms analyzed size relations joined exceeds amount memory goal show performance algorithm affected amount memory reduced join algorithms analyzed presence non-uniform join attribute values considered effectively join algorithms utilize processors disks finally bit vector filtering techniques babb vald evaluated parallel join algorithms set experiments viewed predicting relative performance algorithms size memory constant algorithms required process relations larger size memory remainder paper organized section overview gamma database machine presented parallel join algorithms tested section section results experiments conducted conclusions section overview gamma database machine section present overview gamma database machine complete description gamma dewi gerb performance analysis gamma found dewi hardware configuration gamma consists vax processors megabytes memory megabit token ring prot connects processors vax running berkeley unix processor acts host machine gamma megabyte fujitsu disk drives provide database storage processors diskless processor reserved query scheduling global deadlock detection remaining diskless processors execute join projection aggregate operations selection update operations execute processors attached disk drives software overview physical database design gamma relations horizontally partitioned ries disk drives system alternative ways distributing tuples relation provided round-robin hashed range partitioned user-specified placement key range partitioned uniform distribution implied strategy tuples loaded relation distributed round-robin fashion disk drives hashed strategy selected randomizing function applied key attribute tuple select storage unit strategy user specifies range key values site partitioning strategy user specifies partitioning attribute system distributes tuples uniformly sites process porting gamma software intel ipsc-ii hypercube processors disk drives july query execution gamma traditional relational techniques query parsing optimization seli jark code generation queries compiled tree operators predicates compiled machine language parsed optimized compiled query host software idle scheduler process dispatcher process scheduler process turn starts operator processes processor selected execute operator task assigning operators processors performed part optimizer part scheduler assigned control execution query operators leaves query tree permanent relations query schema information optimizer determine assigning operators processors gamma algorithms operators written run single processor input operator process stream tuples output stream tuples demultiplexed structure term split table process begins execution continuously reads tuples input stream operates tuple split table route resulting tuple process split table case selection operation producing tuples subsequent join operation join executed processes split table selection process entries tuple satisfying selection predicate selection process apply hash function join attribute produce index split table obtain address machine port join process receive tuple process detects end input stream closes output streams sends control message scheduler indicating completed execution closing output streams side effect sending end stream messages destination processes exception control messages execution operator completely self-scheduling data flows processes executing query tree dataflow fashion result query relation operators root query tree distribute result tuples round-robin basis store operators disk site enhance performance operations array bit vector filters babb vald inserted split table case join operation join process builds bit vector filter hashing join attribute values building hash table relation brat dewi dewi vald hash table relation completed process sends filter scheduler scheduler received filters sends processes responsible producing outer relation july join processes set filters eliminate tuples produce tuples join operation operating storage system operating system gamma constructed lightweight processes shared memory reliable datagram communication services multiple bit sliding window protocol tane messages processes processor short-circuited communications software file services gamma based wisconsin storage system wiss chou services include structured sequential files indices byte-stream files unix long data items sort utility scan mechanism parallel join algorithms implemented parallel versions join algorithms sort-merge grace kits simple hash dewi hybrid hash-join dewi algorithms share data partitioning stage tuples joining relations distributed processors joining actual join computation depends algorithm hashing grace simple hybrid algorithms sorting merging sort-merge algorithm additionally grace hybrid join algorithms partition relations joined additional fragments relation larger amount main memory referred bucket-forming phase kits degree interaction bucket-forming phase joining phase differs grace hybrid algorithms details algorithm presented sections discussion refer relations joined smaller relations joining relation sort-merge parallel version sort-merge join algorithm straightforward adaptation traditional single processor version algorithm essentially identical algorithm employed teradata machine tera dewi smaller joining relations partitioned split table entry processor attached disk hash function applied join attribute tuple determine disk site tuples arrive site stored temporary file july entire relation redistributed local files sorted parallel figure depicts partitioned disk nodes relation notice relation fragment disk passed split table redistribution relation processed manner hash function redistribute relations tuples fragments site possibility joining kits local merge performed parallel disk sites fully compute join required present sorted relation user final merge locally merged relation fragments send tuples remote diskless processors merging felt difficulties involved relation tuples duplicate attribute values required backup outweighed potential benefits offloading 
ner hash function maintained eachbucket scheduling phase occurs coordinator collects coarse bucket statistics computes allocation buckets nodes allocation strategy broadcast nodes relations redistributed network hash-joins performed locally bucket heuristics proposed computing allocation strategy scheduling phase including longest processing time rst rst decreasing skew analytical model brie compare strategies avs modeled zip distribution tpsor skewoccurs double-skew skewin join relations stylejoin speci cally modeled load-balancing heuristics shown highly ective balancing load number processors large comparison made performance join algorithms skew handling non-skew handling hua extended adaptive load balancing parallel hash join algorithm algorithm incurs extra read write relations initial bucket forming phase cost step higher cost sampling relations case increased accuracy skew information obtained tuple ciently improve variance response time processors cost extra read write pass worthwhile implementing algorithms hardware software base impossible determine precisely algorithm performance omiecinski omiecinski omi proposed load balancing hash-join algorithm shared memory multiprocessor algorithm based bucket-spreading algorithm kitsuregawaand ogawa ers doesn rely special-purpose hardware assigns buckets processor rstt decreasing heuristic optimizations shared-memory environment analytical limited experimental results processor sequent machine show algorithm ective limiting ects avs double-skew joins avs modeled byhaving single account relation values uniformly distributed conclusion algorithms skew handling proposed paper represent simple augment existing parallel database systems make performance robust presence skewed joins modi cations needed install existing system simple needed add extent-map sampling equivalent support subset-replicate virtual processor split tables nally small amount code analyze samples build split tables experiments performed suggest joins pilot sample relations involved join inspect resulting set samples determine relation highly skewed bycounting number repeated samples relations appears skewed revert simple hybrid hash relations appears skewed virtual processor range partition round robin join algorithm skewed relation building relation scheme incorporates number heuristics optimizer heuristics tricked choosing sub-optimal plan situations simple implementable general runs non-skewed joins time comparable standard hybrid hash overhead outlined abovetakes seconds implementation runs skewed joins ering terrible worst-case performance result running hybrid hash highly skewed data anumberofinteresting open questions remain addressed future work experiments illustrate virtual processor range partitioning algorithm depends critically number virtual processors chosen optimal number parameter depends system con guration importantly number processors skew tolerate values experiments virtual processors processor reasonable performed test data claim globally optimal work address question handle joins operands greatly erent size experience experiments suggest critical pointistokeep number buckets building relation minimum twoways large number buckets result large building relation skewed building relation reasonable heuristic relations roughly comparable size skewed relation building relation erent size smaller relation building relation skew handled building split table based samples probing relation weintend experiment heuristic future work finally number processors system grows thousands overhead sorting analyzing samples grow cost obtaining samples constantnumber samples processor system scales clear overhead grow fast cost performing join processors join big join room reducing overhead processing parallel central coordinating processor rst step processor sort local set samples sending coordinator simple merge sort acknowledgments researchwas supported donations dec ibm ibm research initiation grant ncr tandem generous support researchwould havebeen bfks baru frieder kandlur segal join cube analysis simulation implementation kitsuregawa tanaka editors database machines knowledge base machines kluwer academic publishers bgmp blasgen gray mitoma price convoy phenomenon operating system review bra kjell bratbergsengen algebra operations parallel computer performance evaluation kitsuregawa tanaka editors database machines knowledge base machines kluwer academic publishers cdkk h-t chou david dewitt randy katz anthony klug design implementation wisconsin storage system software practice experience october coc william cochran sampling techniques john wiley sons york york edition lawrence carter mark wegman universal classes hash functions journal computer system sciences david dewitt robert gerber multiprocessor hash-based join algorithms proceedings twelfth international conferenceonvery large databases pages stockholm sweden dewitt gray parallel database systems future high performance database processing communications acm dgg david dewitt robert gerber goetz graefe michael heytens krishna kumar muralikrishna gamma high performance data database machine proceedings twelfth international conferenceonvery large databases pages kyoto japan august dgs david dewitt shahram ghandeharizadeh donovan schneider performance analysis gamma database machine proceedings sigmod international conference management data pages chicago illinois dgs dewitt ghandeharizadeh schneider bricker hsiao rasmussen gamma database machine project ieee transactions knowledge data engineering march dns david dewitt rey naughton donovan schneider comparison non-equijoin algorithms proceedings eighteenth international conference large databases barcelona spain august dns david dewitt rey naughton donovan schneider parallel external sorting probabilistic splitting pdis miami beach florida december esw robert epstein michael stonebraker eugene wong distributed query processing relational database system proceedings acm-sigmod international conference management data gra graham bounds multiprocessing timing anomalies siam journal computing kien hua chiang lee handling data skew multiprocessor database computers partition tuning proceedings international conference large databases pages barcelona spain august masaru kitsuregawa yasushi ogawa bucket spreading parallel hash robust parallel hash join method data skew super database computer sdc proceedings sixteenth international conferenceonvery large data bases brisbane england august ktmo kitsuregawa tanaka moto-oka application hash data base machine architecture generation computing seetha lakshmi philip ectiveness parallel joins ieee transactions knowledge data engineering december omi edward omiecinski performance analysis load balancing hash-join algorithm forashared memorymultiprocessor inproceedingsof seventeenthinternational conferenceonvery large data bases barcelona spain september frank olken doron rotem random sampling -trees proceedings fifteenth international conferenceonvery large databases pages amsterdam netherlands august orx frank olken doron rotem ping random sampling hash les proceedings acm sigmod conference management data pages atlantic city jersey donovan schneider david dewitt performance evaluation parallel join algorithms shared-nothing multiprocessor environment proceedings acm-sigmod international conference management data pages portland oregon june seshadri rey naughton sampling issues parallel database systems proceedings edbt conference vienna austria march sto stonebraker case shared database engineering wdj christopher walton alfred dale roym jenevein taxonomyand performance model data skew ects parallel joins proceedings seventeenth international conferenceonvery large data bases barcelona spain september wdyt joel wolf daniel dias philip john turek ective algorithm parallelizing hash joins presence data skew ibm watson researchcenter tech report 
benchmark michael carey david dewitt rey naughton computer sciences department wisconsin-madison version january abstract benchmark represents comprehensive test oodbms performance report describe benchmark present performance results implementation oodb systems hope benchmark provide insight end-users evaluating performance oodb systems hope research community database schema instance workload evaluating techniques algorithms oodbms implementation note version january reportis amodi version oftheoriginal technical report theoriginal reportwaswritten spring importantchange reportis introduction ofversantnumbers whichwere run december version report subsequentversions eliminated explanations system performance spring report techreport anonymous ftp ftp wisc anticipation future releases numbers revising explanations release numbers time consuming prevent timely distribution numbers introduction builders object-oriented database management systems oodbms faced wide range design implementation decisions decisions profound ect performance resulting system recently anumber oodbmss publically developers systems havemadevery erentchoices fundamental dec provided funding began research bulk work funded bydarpa contract number daab -c-q monitored army research laboratory sun donated hardware server experiments aspects systems technology clear precisely systems performance characteristics fact clear performance metrics give pro oodbms performance designed benchmark rst step towardproviding comprehensive oodbms performance pro performance characteristics tested speed erent kinds pointer traversals including traversals cached data traversals disk-resident data sparse traversals dense traversals ciency erent kinds updates including updates indexed unindexed object elds repeated updates sparse updates updates cached data creation deletion objects performance query processor cases query language ciently expressive query programmer erenttypes queries design benchmark produces set numbers single number single number benchmark advantage catchy easy abuse system comparisons benchmark returns set numbers great deal informationabout asystemthandoesone thatreturns asingle number asingle numberbenchmark benchmark precisely mirrors application system point consensus constitutes canonical oodbms application fact growing evidence canonical oodbms application mistake point build single number benchmark paper describe benchmark give preliminary performance results implementation public-domain research system exodus commercially oodb systems objectivity whichisalsoavailable dec object ontos versant lastly mentioned expected include results commercial system objectstore system object design odi lawyers send notice dissatis run benchmarking process drop objectstore results paper face legal action readme directory ftp wisc details unfortunate chose withdraw odi approach persistence provided interesting contrasts systems timings presented paper presentinteresting information performance systems tested whichwas unavailable comparison addition providing insightinto performance existing oodbmss hope future provide arich source testworkloads forthe oodbms research community nishing benchmark commercial system early signs context managed uncover correctness performance problems version system wehave run benchmark fact companies participated benchmark plans benchmark part performance correctness tests system validation suite future releases product remainder paper organized section compares benchmark previous orts oodbms benchmarking section describes structure benchmark database section describes hardware testbed con guration run benchmark overview systems tested section describes benchmark operations discusses experimental results operation presented finally section conclusions plans future work related work benchmark benchmark commonly referred sun benchmark rst standard benchmark attempted predict dbms performance engineering design applications intentwas measure performance navigation simple updates suchit primarily intended capture cost database interactions presence ectiveness client caching speci cation based designers experience initial simple database operations benchmark rkc implemented sun operations initial benchmark found highly correlated small range queries added insightbeyond obtained exact-match lookups eliminated combined general operations relationship operations initial benchmark subsumed general traversal operation early visibility simplicity facto standard oodb benchmarking run current oodb products database benchmark based consists part objects connections part vedata elds apartid atype coordinate pair build date part out-going connections parts variable number incoming connections connection type length provide notion locality object graph parts logically ordered part connections part chosen connection chance referencing nearby part nition nearby part part space database sizes benchmark operations run parts model applications working sets memory ten times larger parts model applications data sets exceed physical memory optional huge database parts object operations version benchmark consists operations rst part lookup operation random parts part ids object graph traversal operation accesses connected parts selecting random part performing aseven-level depthrst traversal multiple visits allowed parts reachable benchmark operation insertoperation thatadds parts tothe database benchmark speci cation calls elapsed time measures cold warm operation operation repeated ten times cold time time required rst iteration ecting elapsed time starting empty cache warm time measures case cache fully initialized hypermodel benchmark benchmark directly related hypermodel benchmark developed tektronix starting initial sun simple database operations benchmark developers hypermodel set develop comprehensive engineering dbms performance test suite based hypertext application model compared hypermodel includes richer schema wider range operations hypermodel database graphof interconnected nodes unlike relationship nodes connections nodes hypermodel participate relationships hypermodel nodes participate hierarchical relationship relationships unlike type node hypermodel databases include types nodes viewed relationship forms tree ve-way fanout hypermodel database includes levels non-leaf nodes level leaf nodes non-leaf node holds integer values leaf nodes small byte text string bitmap moderate size database parameterized number levels set running benchmark operations ratio text leaf nodes bitmap leaf nodes relationships created randomly interconnecting nodes adjacent levels hierarchy intended model hypertext links randomly interconnects nodes hierarchy hypermodel benchmark consists erent groups operations including exactmatch lookups byinteger attribute oid range queries group lookups eachfollow relationship random node directly related nodes lookups inverse sequential scan set closure operations editing operations hypermodel closure operations added response fact unlikeoo initial sun benchmark traversals felt important engineering applications hypermodel closure operations performs reachability traversal starting randomly chosen node level hierarchy relationships areverse traversal part benchmark emphasized terms evaluating oodb system performance gather lists oids encountered compute aggregate values sum count applies predicate avoid traversals small subset objects modi eld visited objects editing operations update text string eld bitmap eld leaf nodes hypermodel requests cold warm times operation oodb benchmarking work oodb studies related work engineers ontologic initial sun benchmark study performance vbase rst oodb product ering ections work provided summary benchmark shortcomings including lack opportunity semantic object clustering discussed simple schema lack complex operations suchastraversals area researchers altair designed complex object benchmark acob studying alternative client server process architectures dfmv unlike previous oodb benchmarks notion complex objects included design small numberoftraversal update operations involved cient expose tradeo software architectures interest finally winslett churecently studied oodb relational system performance porting actual vlsi layout editor magiceditor berkeley systems portions magic modi work focused systems save restore performance 
proceedings nasa conference mass storage systems college park maryland september processing satellite images tertiary storage study impact tile size performance jiebing david dewitt computer sciences department wisconsin-madison jiebing dewitt wisc introduction july nasa begin launch series satellites part mission planet earth popularly eosdis earth observing system data information system fully deployed satellites aggregate data rate megabytes rate impressive adds couple terabytes day petabytes year lifetime satellites today mass storage technology data stored tape latest tape technology offers media dense reliable drives transfer rates range magnetic disk drives quantum dltdrive transfer rate sec compressed cartridges drive capacity compressed shelf life years rated passes qua tertiary storage systems suited sequential access primary medium database storage limited efficiently processing data tape presents number challenges chl cost capacity gap gra tapes disks narrowed factor density commodity tape technology gigabytes uncompressed commodity disk technology gigabytes uncompressed factor total cost disk tape library raw data satellite termed level data data scientist undergo number processing steps including basic processing turning electrical voltage measured pixel image digital typically bits cleansing geo-registration satellites tend drift slightly passes area end result level data product consisting series georegistrated images earth scientist research processing expands volume data collected factor original data received satellite deleted processing storage requirements exceed terabytes day figure cited part eosdis project nasa contracted hughes build system work supported nasa contracts usra- nagwand nagwarpa arpa order number monitored army research laboratory contract daab -c-q ibm intel sun microsystems microsoft legato processed data ready analysis earth scientist analysis involves applying series algorithms typically developed earth scientists large number images data set frequently scientist interested type images region earth surface extended period time focus research handle images stored tape random access environment tile size tape block size depends largely transfer speed access latency seek speed current dlt technology tile size tape block size expected range order achieve good average performance tile size big size beneficial kind applications purposes paper make assumptions images interest scientist stored tape images accessed processed order stored tape analysis requires access portion image entire image term portion image clip region typically analysis clip portion image regard assumption images single sensor undoubtedly span multiple tapes makes sense mix images sensors tape analysis requiring access multiple tapes data sensors techniques sun minimize tape switches combination techniques assumption requires pattern images advance sorted tape order cases order determined examining meta data data set companion paper show tape processing technique call query pre-execution automatically accurately determine pattern assumption based fact satellite images large size avhrr image megabytes scientists frequently interested small region large number images image entirety eosdis test bed ekd put strong emphasis providing real-time dynamic subsetting avhrr images alternative approaches handling tape-based data sets hierarchical storage manager hsm marketed emass ema systems operate granularity file file unit migration tertiary storage tape secondary storage disk memory system store satellite images typically image stored separate file image processed transferred entirety tape disk memory approach work applications portion image needed wastes tape bandwidth staging disk capacity transferring entire images alternative hsm add tertiary storage additional storage level database system approach pursued sequoia dfg paradise dkl projects integrated approach extends tertiary storage normal role archive mechanism integrated approach database query optimizer optimize accesses tape complicated ad-hoc requests data tertiary storage executed efficiently addition task applying complicated analysis region interest large number satellite images performed single query sfg integrating tertiary storage database system requires block-based scheme move data layers storage hierarchy process executing query kbytes typical block size moving data memory disk small unit transfer tape memory disk dealing large raster images approach postgres sun paradise dkl partition satellite image set tiles tiles unit transfer tape memory disk smaller disk block bytes transfer data disk memory database system buffer pool query portion image residing tape meta data image determine minimum number tiles satisfy request tiles moved tape disk tile-sized units disk memory units bytes page size database system paper examines impact tile size time required retrieve series partial clipped images residing tape evaluation includes simplified analytical model simple simulation study verify analytical model performance evaluation paradise database system extended include support tertiary storage results careful selection tile size reduce time required clip series images residing single tape show state art tape drives quantum dlta smaller tile size range reasonable performance gain larger tiles sizes variety image clip region sizes remainder paper organized section describes problem derivation analytical model section describes simulation experiments analyzes results section examines impact tile size variety experiments paradise test vehicle section conclusions discusses future work analytical model section describe simplified analytical model compute time clip single raster image rectangular region assume tape head positioned beginning image model study effect tile size time clip raster image problem description discussed section tiling partitions image smaller rectangular pieces preserve spatial locality adjacent pixels figure depicts alternative partitioning strategies single image linear layout tape top left rectangle represents un-tiled image middle rectangles top row show image partitioned tiles tiles image data moved directly mechanical devices tape disk passing main memory tile read tape controller memory written tape block cache disk read tiles directly database buffer pool approach flood buffer pool large amounts information forcing valuable information tiled written tape tile bottom portion figure depicts tiling alternatives laid tape assuming tiles tape row-major fashion choice row-major layout affect performance demonstrate tile size dominating factor tiles laid tape row-major column-major order viv iiii figure single image tiles linear layout dashed rectangle figure corresponds portion image analysis wishes examine term clip region shaded area tiles retrieved tertiary storage order satisfy clip request impact tiling illustrated comparison untiled image top-left rectangle figure -tile image top-right rectangle figure un-tiled image entire image read tape order process clip request hand image partitioned tiles ths image tiles read number seek operations increases assuming tape head initially positioned start image general tiling reduce amount data transferred clipping partial images hand introduce additional seek operations consecutive tile accesses total time spent migrating parts image memory disk depends tape seek speed tape transfer speed seek startup cost seek startup cost fixed overhead tape head 
cpu cycles sites disks join processors correspond processors disks increase intra-query parallelism partition sort relations concurrently performance problems due disk head network interface contention problem bit filters created complete relation applied outer relation chose partition relations serially bububu bububu hash split table disk disk disk partitioning relation disk drives sort-merge figure july simple hash centralized version simple hash-join dewi operates smaller joining relation read disk staged in-memory hash table formed hashing join attribute tuple larger joining relation read disk tuples probe hash table matches number tuples exceeds size hash table memory overflow occurs figure depicts steps order handle overflow step relation build hash table hash table space exceeded join operator creates file streams tuples file based hash function tuples distributed hash table step query scheduler passes function operator producing tuples outer relation relation step tuples tuples overflow partition spooled directly temporary file tuples probe hash table affect join left task joining overflow partitions exceed capacity hash table process continues overflow partitions created time join fully computed overflow step step step table hash simple hash-join overflow processing figure july parallelize algorithm inserted split table step route tuples joining site hash table overflow join sites overflow processing step centralized algorithm fact join site overflows locally defined overflow file overflow file stored single disk horizontally partitioned overflow files assigned disks horizontally partition overflow file nodes disks assumes tuples uniformly distributed acress join nodes nodes overflow approximately degree final result aggregate overflow partition horizontally partitioned disk sites step figure split table step route tuples joining sites augmented functions relation passed split table tuples routed joining sites joining directly overflow files temporary storage centralized algorithm overflow partitions recursively joined overflow occurs joining sites finally noted processors executing join operation constrained disks case sort-merge algorithm recently simple hash join algorithm employed gamma overflow resolution method parallel implementations grace hybrid algorithms grace hash-join centralized grace join algorithm kits works phases phase algorithm partitions relation disk buckets hashing join attribute tuple phase relation partitioned buckets hash function final phase algorithm joins respective matching buckets relations number buckets chosen large reduces chance bucket exceed memory capacity processors effect join buckets event buckets smaller main memory combined phase form optimal size join buckets referred bucket tuning kits grace algorithm differs fundamentally sort-merge simple-hash join algorithms data partitioning occurs stages bucket-forming bucket-joining parallelizing algorithm address data partitioning stages insure maximum utilization july bandwidth bucket-joining stage bucket partitioned disk drives partitioning split table shown figure task time join ith bucket ith bucket tuples ith bucket distributed joining processors joining split table entry processor effect join tuples arrive site stored in-memory hash tables tuples bucket relation distributed joining split table tuples arrive processor probe hash table matches bucket-forming phase completely separated joining phase grace join algorithm separation phases forces grace algorithm write joining relations tuples back disk beginning join stage algorithm parallel implementation grace join algorithm bucket tuning number buckets determined query optimizer order ensure size bucket aggregate amount main-memory joining processors disk kdisk bubububububububububu bububu table split partitioning entries bububububu bubu bubu bucket bucket bucket disk grace partitioning buckets figure july hybrid hash-join centralized hybrid hash-join algorithm dewi operates phases phase algorithm hash function partition relation buckets tuples bucket build in-memory hash table remaining buckets stored temporary files good hash function produces buckets ensure bucket tuples small fit main memory phase relation partitioned hash function step buckets stored temporary files tuples bucket immediately probe in-memory hash table built phase phase algorithm joins remaining buckets relation respective buckets relation join broken series smaller joins computed experiencing join overflow notice size smaller relation determines number buckets calculation independent size larger relation grace join algorithm additional memory bucket-forming phase order produce extra buckets hybrid exploits additional memory immediately begin joining buckets parallel version hybrid hash join algorithm similar centralized algorithm partitioning split table separates joining relations buckets buckets intended temporary storage disk partitioned disk sites grace algorithm likewise joining split table route tuples respective joining processor processors necessarily attached disks parallelizing joining phase partitioning relation buckets overlapped insertion tuples bucket memory-resident hash tables join nodes addition partitioning outer relation buckets overlapped joining bucket bucket requires partitioning split table enhanced joining split table tuples bucket processors effect join remaining buckets joined joining split table needed figure depicts relation partitioned buckets disk sites bucket joined diskless processors july bububup bububu bucket bucket bucket partitioning split table bububu bububu bubububububububu disk disk diskless processors entries entries entries partitioning buckets hybrid hash-join figure experimental results tested parallel algorithms conditions performance algorithms studied attributes partition relations joined joining attributes wanted compare effects bit vector filtering algorithms diskless processors hash-based algorithms explored finally impact non-uniformily distributed join attribute values performance algorithms studied benchmark relations based standard wisconsin benchmark bitt relation consists thirteen -byte integer values -byte string attributes tuple bytes long noted hashing unique attribute determine tuple destination site loading database benchmark join query joinabprime joins tuple relation approximately megabytes size tuple relation approximately megabytes size produces tuple result relation megabytes size ran experiments benchmark join queries joinaselb joincselaselb trends results presented kilobyte disk pages experiments default hardware environment consists processors disks single diskless processor reserved query scheduling global deadlock detection refer configuration local joins performed sites attached disks section explore july performance simple grace hybrid algorithms diskless processors configuration termed remote join performance parallel join algorithms sensitive amount memory relative size joining relations designing set experiments decisions make capture aspect performance algorithms approach amount memory constant varying size relations joined choice size joining relations constant artificially varying amount memory rejected choice accepted alternative increasing size joining relations side-effect increasing number needed execute query experiments analyze join performance wide range memory availability results graphed x-axis representing ratio memory size smaller relation note memory sum memory joining processors effect join case hash-based join algorithms memory construct in-memory hash table sortmerge join algorithm memory sorting merging case sort-merge join algorithm simply reduced amount sort merge space simple-hash join algorithm reduced amount hash table space grace hybrid algorithms data point relative memory availability instance equates two-bucket join likewise data point computed buckets grace hybrid 
movement tape seek speed fast tape head advanced read writing data parameters determine random access latency single tape parameters number factors affect query performance image figure partitioned tiles clip request shown figure partition strategy advantage respect number seeks performed amount data transferred compared un-tiled image clip requests results clip region contained inside tile tile image case un-tiled image incur seeks transfer entire image image tiled pieces incur seek start tile transfer image image tiled pieces incur seeks transfer tiles transfer tiles transfer image size location clip region affect performance tiling alternatives order understand problem developed analytical formula model average-case behavior model assumptions order reduce complexity problem analytical model makes assumptions tile stored single tape block tape block unit migration tape memory tape head initially positioned beginning image images square tiles tiles shape clipping region proportional image shape clipping region contained inside image boundary order clipped tiles returned tape order stored tape assumption eliminates indirect effect tape block size multiple tiles potentially packed single tape block section examine effect assumption assumption concentrate single image residual impact previous tape head position fourth assumptions reduce number parameters considered variation tile clipping region shape change tape access behavior discussed section final assumption minimize randomness seeks clipping operation analytical formula derivation model response time migrate tiles clipped region tape memory sum time spent operations initial seek intermediate seeks tile transfer total seek startup table describes symbols analytical model figure exhibits symbols graphical view note figure tile unit length integer fraction modeled obvious figure number tiles covered partially covered clip region varies depending position clip region sections start figuring probabilities clip region locations analyzing times spent operations clip cases finally give final average case formula description symbol comments image size kbytes single tile size kbytes image dimension clip dimension clip size clip area image area acb tape seek rate kbytes sec startup seek cost sec tape transfer rate kbytes sec table parameters figure target clipping region clipping cases figure illustrates cases clip region put image case overlapping tiles case overlapping tiles elongated horizontally case overlapping tiles elongated vertically case overlapping tiles find probability case uniform distribution upper left corner point clip region reside tiles tile areas reside cases illustrated figure total area regions possibly stay image probability case happen derived number tiles move area stay tile case probability case case case case figure cases clipping case case case case figure areas cases probabilities case case area case area case area case area initial seek time initial seek time time move tape head beginning image tile touched clip region figure analysis upper left corner clip region reside restricted area depending cases suppose area upper left corner image equal probability tiles region assume tile defined row column number tiles skipped reach beginning image average jia tiles skipped reach tile covered clip applying cases figure case case mab nab case mab nab case finally initial tile seek time intermediate seek time intermediate seek time total time spent seeking transfers contiguous sets tiles contained clip region figure transferring set tiles region perform seek transfer tiles transferring tiles perform seek transferring tiles transfer set contiguous tiles tape head moved group tiles affected clipping region assuming tiles touched clip region form region number tiles skipped initial seek movements applying cases figure reach case case case case final version intermediate seek time pbti pbti pbti pbti transfer time tile transfer time total time spent transferring tiles clipped region memory figure based assumption made previous calculation intermediate seek time tiles transferred leads analyzing cases figure formula case case case case version transfer time pbtr pbtr pbtr pbtr seek startup time tape seek fixed startup overhead model seek startup time overhead depends number seeks performed size seek operation region totally seeks needed clip breaking cases figure case case case case version seek startup time pbts pbts pbts total response time total response time sum times due complexity formula number items involved simplification write entire formula list parameters function rely plotting figures analyze behavior formula components derived ttftitrtsfabsri make plot graph easier understand substitute acb image size tile size clip selectivity tfmtcsri analysis purposes fix image size clipping area image show plotting graphs formula reveals interesting property tile size increases seek time including decreases transfer time increases combination opposite effects makes response time complex function tile size analytical model analysis understand implications response time formula derived evaluate variety parameters plot response time curve function tile size values parameters listed table image size varied clip selectivity relative image size tape-related parameters selected based quantum dlttape drive qua compression turned parameter values evaluated kbytes iii kbytes sec kbytes sec sec table selected values parameters figure show response times variety image size clip size combination relative gain image fetching response time curves exhibit kind diminishing return left region curves head upwards steadily relative gain curves demonstrates smaller tile sizes tend perform bigger tile sizes image sizes closer happening pick curves break response time curve parts seek transfer seek overhead tile image response clip clip clip clip tile image clip clip clip clip figure response time performance gain image fetching images iii dlt serpentine tapes seek time linear function seek distance seeking tracks observed maximum seconds seek time seconds technical specification random blocks single track seek time close linear function accurate modeling seek time dlt drive found tile size image response clip clip clip clip tile size image clip clip clip clip figure response time performance gain image fetching images tile size image response clip clip clip clip tile size image clip clip clip clip figure response time performance gain image fetching images figure shows breakdown response time seek transfer seek overhead components clipping image seek time seek overhead decrease tile size increases transfer time increases faster rate dominates response time effect tape seeks illustrated region left tile size figure reduction seek time resulting fewer shorter seeks offsets increase transfer time tile size increases based figures dlt drive tile size region choices sized images yield reduction total clip time image fetching tile size image clip response seek transfer overhead total 
performance applications operating database objects benchmark hypermodel represent signi orts area oodb benchmarking feel benchmark area basically mentioned brie introduction existing benchmarks ciently comprehensive test wide range oodb features performance issues tested order methodically evaluate suite oodb products excellent test oodb performance simple navigational update tasks intended number application systemcharacteristics thatit measure forexample complex objects important oodb applications real notion complex objects models inter-object locality nearby objects database generation problems large database local object neighbors erentthansemantically based complex objects group objects aggregate object providing natural unit clustering examine densityoftraversals fraction objects accessed page traverals involve updates object queries potentially important application oodb system features hypermodel attempted correct number sun indirectly benchmark shortcomings designers succeeded developing complex benchmark respect set operations tested clear howmuch added complexity worthwhile terms insights provided benchmark complex schema semantic notion complex objects hypermodel design hypermodel includes erent read-only traversal operations havebeendesigned erent opposed probing design performance space oodb systems fact performance results presented appendix attempt made draw insights conclusions results tests included hypermodel object queries updates indexed non-indexed object attributes repeated objectupdates impact oftransaction boundaries otherperformance-related oodb features designed test finally hypermodel cult implement consistently published speci cations section methodical broad completely overboard area complexity designing guide design process began surveying features functional performance-oriented found current oodb products made list features techniques signi impact relative performance proceeded develop series tests cover features distinguish techniques erentvendors implement wewere uenced signi cantly philosophy underlying wisconsin benchmark relational database systems bdt wewanted broad stress test oodb systems terms function system performance database description benchmark designed test erent aspects system performance database structure operations nontrivial precise descriptions benchmark implementations benchmark implementations anonymous ftp directory ftp wisc informal description benchmark understanding basic results planning implement benchmark obtain copy implementations anybenchmark opportunities cheating implementing hacks follow letter benchmark speci cation intentions benchmark designers opportunities discovered companies begin tuning implementations benchmark pointbenchmark designers typically steps disallowthe cheating benchmark speci cation pointwehave write fair completely complex benchmark cult task mentioned approachtoovercoming culty consists making implementations readily bullet-proof speci cation prevents cheating expect future gain experience watching implement benchmark speci cation evolve benchmark intended suggestiveofmany erent cad cam case applications details model speci application recall goal benchmark test aspects system performance model speci application wedraw analogies applications wedosoto provide intuition benchmark justify motivate benchmark sizes benchmark database small medium large table summarizes parameters benchmark database parameter small medium large numatomicpercomp numconnperatomic documentsize bytes manual size bytes numcomppermodule numassmperassm numassmlevels numcompperassm nummodules table benchmark database parameters appendix ddl description benchmark database diagram interested reader consult appendix reading description database design library akey component benchmark database set composite parts composite part corresponds design primitivesuch register cell vlsi cad application procedure case application set composite parts forms refer design library database design library number composite parts module controlled parameter numcomppermodule whichiscurrently set composite part number attributes including integer attributes builddate small character array type composite part document object models small amount documentation composite part document integer attribute small character attribute title andacharacter string attribute text length string attribute controlled parameter documentsize composite part object document object connected bi-directional association addition scalar attributes association document object composite part graph atomic parts intuitively atomic parts composite part units composite part constructed small benchmark composite part graph atomic parts medium large benchmarks composite part graph atomic parts number controlled parameter numatomicpercomp composite part corresponds procedure case application atomic parts graph correspond variable statement expression procedure atomic part composite part graph designated root part atomic part integer attributes builddate anddocid small character array type reason including attributes apparent benchmark operations sections builddate values atomic parts randomly chosen range minatomicdate maxatomicdate addition attributes atomic part connected bi-directional association atomic parts controlled parameter numconnperatomic initial idea connect atomic parts composite part random fashion random connections ensure complete connectivity ensure complete connectivity connection initially added atomic part connect parts ring connections added random addition initial plans interconnection variation variation included ensure satisfactory coverage oodbms performance space preliminary tests systems sensitive benchmark parameter connections atomic parts implemented byinterposing connection object pair connected atomic parts intuition connections data connection object repository data connection object integer eld length short character array type figure depicts composite part document object graph atomic parts view union atomic parts corresponds object graph benchmark object graph broken semantic units localityby composite parts composite parts provide opportunityto test ectivevarious oodbms products supporting complex objects assembling complex designs design library whichcontains composite parts atomic parts including connection objects documents accounts bulk database set composite parts ciently structured support operations wished include benchmark added assembly hierarchy database intuitively assembly objects correspond higher-level design constructs application modeled database vlsi cad application assembly type typenumber builddate title widget docs text widget doesn put spec docid documentation figure composite part document object correspond design register alu assembly made composite parts case base assembly made assembly objects case complex assembly rst level assembly hierarchy consists ofbase assembly objects base assembly objects integer attributes builddate short character array type eachbase assembly bi-directional association shared composite parts unshared composite parts number shared unshared composite parts base assembly controlled parameter numcompperassm benchmark database designed support multiuser workloads single user tests distinction shared unshared composite parts added provide control sharing con ict patterns multiuser workload sharing module basis composite part referenced private composite part base assembly module referenced private composite part base assembly module module paper deals single user tests unshared composite part associations single user benchmark unshared composite parts base assembly chosen random set composite parts relationship build dates composite parts base assemblies important queries benchmark query nds base assemblies composite part recent builddate build date base assembly control relationship base assemblies builddate chosen randomly range minassmdate maxassmdate composite parts divided categories young composite parts build dates chosen randomly range minyoungcompdate maxyoungcompdate composite parts build dates comp parts build dates range assembly objects build dates range young comp parts build dates range figure build dates benchmark objects chosen randomly range minoldcompdate maxoldcompdate percentage young versus composite parts controlled paramenter youngcompfrac interpretation youngcompfrac composite parts young composite parts youngcompfrac set figure timeline showing relationship 
figure breakdown response time simulation experiments analytical model section trade-off decreasing seek time increasing transfer time tile size increased analytical model based number simplifying assumptions easy derive analyze conditions results obtained valid verify accuracy developed simulation model explore broader range test conditions analytical model simulation configuration analytical model simulation model focuses response time transferring data tape memory simulator consists components work load generator generating clip requests sizes shapes locations image clipper generating sequence tile accesses required satisfy clip operation simulated block-based tertiary storage manager request tile tertiary storage manager simulator converts tile number tape-block address simulates moving tape head current position desired tape block transferring block tape memory tape parameters table model quantum dlttape drive result data point represents average response time clip requests locations major differences analytical simulation models assumptions section relaxed images longer square clip shape proportional image shape addition tape block size tile size multiple tiles packed single tape block simulation model general capture cases covered analytical model analytical model verification verify analytical model repeated experiments tile tape block size clipping shape area analytical model analysis comparison analytical result plot relative difference data response times simulation analytical results figure difference margin sized image clips response time generated simulation model slightly lower analytical model cases negative number difference due randomness clip region selection error margin acceptable amount runs simulation study based numbers clear analytical model captured exact behavior clipping assumptions turn confirmed finding made analytical model tile size image rel fference clip clip clip clip figure relative difference analytical simulation result image tile size image rel fference clip clip clip clip figure relative difference analytical simulation result image tile size image rel fference clip clip clip clip figure relative difference analytical simulation result image tape block size tile size mentioned section simulation model examine impact varying tile size tape block size independently tape block smaller tile affect performance tile stored set contiguous tape blocks hand size tape block larger size tile multiple tiles packed single tape block affect response time fetching tile result reading tiles covered clip operation figure curves tape block size tile size ratios tape block size larger tile size performance degrade general packing multiple tiles single tape block similar effect increasing tile size packing tiles bigger tape block row-major order tiles packed tape block over-all shape tiles tape block rectangular irregular shape degrade clipping performance results tile tape block size results presented paper size tile tape block tile size image clip response ratio ratio ratio tape block tile figure effect tape block size tile size varying clipping shapes assumptions made analytical model shape clipping region proportional image shape clipping regions area shapes affect performance investigate effect experimented clipping region shapes long wide square long thin rectangular shape height times width wide long shape rotated degrees square proportional image shape previous experiments figure shows result experiment illustrates shapes response times interesting notice wide curve consistently long curve tile size increases caused row-major linear ordering tiles tape layout helps wide clips reduce number tiles seeked drop long curve due fact image partitioned tiles x-axis average half tile skipped tile size half tiles skipped tile size addition tile layout forces wide shape clips read entire image favors long clips column-major nature square clips close average behavior matter response times differ clipping shapes observe trend curve response time observed tile tape block size range tile size image clip response square wide long average clip shape figure varying clip shape simulation implementation results verify previous results realistic environments chose repeat experiments configurations direct application user application program accesses raster images directly tapes paradise dbms extended handle data tapes application program stand-alone program capable accessing tiled raster image data tapes typical scientific applications access tape resident data set paradise dkl object-relational database system developed wisconsin madison capable handling spatial data vector-based images raster-based efficiently raster images paradise combines tiling compression high performance disk based system separate project extended paradise include tertiary storage manager accesses data quantum dlttape drive implementations share block-based tape device driver raster image clipping code time involved tape access raster image clipping memory comparable application program directly transfers data tape user space staging disk main memory buffer pool give realistic measurement tape access time experiments paradise represents end-to-end performance clipping raster images tertiary database system experiments configurations conducted dec celebris pentium mhz memory tertiary device quantum dlt tape drive tape driver experiment breaks large block multiple internal physical chunks operating actual tape ioctl scheme simplify physical tape record address mapping ensuring single chunk write call generate single physical record tape drive single logical tape block mapped multiple contiguous physical tape records tape results paradise queries executed cold buffer pools main memory disk cache due high cost experiments realistic environments cut number randomly generated clip shapes simulation result figure shows result application program clip shape experiment figure figures close general trend curves absolute numbers application program tile sizes consistently higher simulation numbers sec difference smaller tile sizes sec difference lager tile sizes caused factors captured simulation model included include posttape processing time clipping time memory smaller population random samples overhead breaking logical tape block transfer multiple physical chunk transfer difference demonstrates importance application experiments providing realistic performance numbers tile size clip image response square wide long average clip shape figure varying tile shape application figure shows response times obtained clipping images configurations analytical simulation application paradise curves demonstrate trend tile size increases response time increases amount growth bigger larger tile sizes cases case tile size explained difference simulation application results caused extra overhead transferring big chunk versus transferring multiple contiguous smaller records tape driver extra fixed startup cost didn model analytical simulation experiments difference paradise result application result interesting major source difference extra hop staging disk general dbms engine paradise assume exclusive access tape blocks maximum buffer size allowed single read write request translated multiple kernel level calls tapes individual write call considered separate tape record tape seek operation based physical record number logical record number query transfer tape blocks staging disk purpose sharing multiple queries re-current accesses reading 
build dates composite parts assembly objects young composite parts higher levels assembly hierarchy made complex assemblies complex assembly usual integer attributes builddate short character array type additionally bi-directional association subassemblies controlled parameter numassmperassm base assemblies complex assembly level assembly hierarchy complex assemblies complex assembly higher hierarchy levels assembly hierarchy controlled parameter numassmlevels eachassembly hierarchyiscalledamodule modules intended model largest subunits database application extensively multiuser workloads explicitly small medium databases consists single module modules scalar attributes integers builddate short character array type module manual object larger version document manuals included testing handling large simple objects figure depicts full structure single user benchmark database note picture misleading terms shape scale actual assembly fanout assemblies small medium databases compared atomic parts small database atomic parts medium database testbed con guration hardware test vehicle pair sun workstations isolated piece ethernet sun ipx workstation con gured megabytes memory megabyte disk drives model sun gigabyte disk drive model sun server sun hold system software swap space sun drivewas hold database actual data database systems tested sun drivewas design library composite parts base assemblies complex assemblies manual text type builddate manual design root module figure structure module hold recovery information transaction log journal system data recovery disks con gured unix systems raw disks depending capabilities oodbms objectivity nfs read write non-local les disks formatted unix les system exodus hand prefers raw disks hold database log volumes clientwe sun sparc elc workstation mips con gured megabytes memory megabyte disk drive model sun disk drivewas hold system software swap device release sunos wasrunonboth workstations software exodus exodus consists main components exodus storage manager esm programming language esm les untyped objects arbitrary size b-trees linear hashing currentversion esm version exo page-server architecture dfmv client processes request pages server tcp server satisfy request pool disk initiated byinvoking disk process perform actual operation disk process read page server process returns requesting client process keepsacopy pool esm concurrency control recovery services locking provided page levels normal modes special nonpl protocol index pages recovery based logging changed portions objects fzt pages client pool cached transaction boundaries locks reacquired server cached pages rst subsequent transactions programming language extends adding persistence basic storage class collections persistent objects b-tree indices services provided primitive compared commercial counterparts support associations iterators selection predicates queries versions currentversion based gnu compiler esm storing persistent objects operations persistent objects compiled instructions virtual machine interpreted runtime scd currentversion interpreter epvm epvm stores memory-resident persistent objects pool esm client process pointers memory-resident objects swizzled tested software traversed epvm esm decides replace page pointers unswizzled page dirty log records updated objects generated sentto server page experiments disk page size kbytes unit transfer client server client server pools set mbytes pages mbytes raw devices forboth log data volumes objectivity version unlike exodus objectivity dec object employs server architecture dfmv architecture server process handling data client processes access database pages nfs nfs provide locking separate lock server process lockserver sun ipx run server process con gurations current release objectivity coarse grain locking level container current b-tree implementation index objects distributed multiple containers recovery implemented shadows gra transaction updates written shadow database commit time updates applied carefully actual database journal recover event commit fails transaction aborts shadow database simply deleted objectivity likeontos employs library-based approach task adding persistence modifying compiler approachtaken persistent objects ned inheritance persistent root class addition persistence objectivity sets relationships iterators access persistent objects mechanism handle overloading operator handles permit manipulation persistent objects transparent fashion benchmark tests client pool set byte pages objectivityarchitecture employ server architecture set pool size sunos memory pages actual memory ering pages roughly systems mentioned database shadow les stored unix les ontos version exodus ontos employs client-server architecture ontos unique approach persistence objects inherit ontos ned root object class created context erent storage managers in-memory storage manager manages transient objects heap standard implementation standard storage manager implements object-server architecture dfmv unit locking unit transfer client server processes individual object storage manager called group storage manager implements page-server architecture granularity locking client server data transfers mode disk page mechanisms single application storage manager object created operator overloaded appropriately benchmark composite parts atomic parts connection objects created group manager standard object manager remaining classes objects features provided byontos slightly richer systems ontos forms bulk types sets lists associations associations arrays dictionaries b-tree hash indices iterators provided bulk types including nice objectsql interface system lacks query optimizer object-sql object-sql express benchmark queries performance acceptable support provided nested transactions optimistic concurrency control mechanism notify locks databases spanning multiple servers recovery redo logging transaction updates ered virtual memory transaction commits updates written journal les server journal les successfully ushed disk updates applied actual database approach ering client side erentinontos systems maintaining client pool persistent objects virtual memory control clientcache approach limits set objects client access scope single transaction size swap space processor application running relies operating system application programmer explicit deallocate object calls good job managing physical memory ontos transaction commits application choice keeping cache intact ushing objects virtual memory experiments tested ability system cache objects multiple transactions cache option mode insure cached data consistent respect transactions running solution time investigate notify locks benchmark default disk page size kbytes unit transfer client server group object manager unix systems hold database journal les ontos raw system versant beta exodus versant odbms employs client-server architecture likeontos versantusesan object-server architecture unit locking transfer unit client server processes individual object versant object manager implicitly caches un-caches objects touched transaction needed server storage manager performs page granularity storage manager exception administrative clustering utilities insulates rest object-server notion pages versant approachto managing access groups objects dynamic client issuing group read request versant locking logical logging object-level granularity versant interface library-based approach adding persistence modifying compiler results section presents results running oodbmss order ensure implementations equivalent faithful speci cations benchmark exodus objectivity ontos implementations written authors paper versant implementation written contractor hired byversant carefully audited authors paper interesting result exercise lack standard oodbms data model programming language found features provided systems similar implementations system ported fairly easily pains con gure systems identically running benchmark 
interest fairness contacted companies concerned comments implementations ensure wewere inadvertantly misusing systems objectivity ontos numbers wegave companies march deadline time send bug xes application-level comments results quoted objecitivty ontos representnumbers weachieved systems received march emphasize vendors chance react added feature varying atomic part fanouts versantnumbers ensure results ect performance tested system capable wechose achieved december results presented small medium single user benchmark databases times seconds database sizes size databases systems intepreting results small databases measured sizes fanout exodus objy dec odb ontos versant medium databases measured sizes fanout exodus objy dec odb ontos versant traversals traversal operations implemented methods objects database traversal navigates procedurally object object invoking method objectasit visited someofthe traversalsupdate objectsas theyareencountered othertraversals simply invokea null method object ran eachtraversal small medium benchmark databases small benchmark read-only traversals traversals run twoways cold hot cold run traversal traversal begins database cache empty client server caches system supports great pains ush cache runs architectural implementation erences actual technique varied system system cases mechanisms tested con ectiveness hot run traversal consists rst running cold traversal running exact query times reporting average middle runs omitted run average overhead commit processing included hot times twoways running cold hot traversal single transaction separate transactions vendors provide pre-released versions systems versions problems product releases xed required eachvendor certify accepted internally release estimate date release record sizes versant databases considered requiring class traversal warm cache warmed rst running traversal similar identical warm traversal warm performance function cold hot performance cold warm traversal misses cache hot decided cold hot succinctly provided mostimportantinformation twoapproachesproduced erent results systemstested ability cache objects transactions ect examined traversal subsubsection traversals interest space include times running twotraversals single transaction medium single user benchmark database ran cold traversals medium database size traversal touched signi cantly data cached cold hot times similar traversal touched small subset database data cached case hot time provided information present small con guration hot time similarly update traversals small medium databases ran cold traversals running multiple update traversals caused logging tra transaction time hot traversals provided information cold ect updating cached data investigated traversal present descriptions results traversals gaps numbering traversals correspond traversals tested eliminated benchmark contributed signi information benchmark implementations directory ftp wisc implementations traversals including deleted report traversals presented numeric order felt order make exposition clearer traversal raw traversal speed traverse assembly hierarchy base assembly visited visit referenced unsharedcomposite parts composite part visited perform depth rst search graph atomic parts return count number atomic parts visitedwhendone traversal test raw pointer traversal speed similar performance metric frequently cited benchmark note due high degree localityin benchmark non-trivial number cache hits cold case left graph figure shows results traversal small database cold case results hot traversal small database cold hot traversal run single transaction graph figure table compares performance systems hot traversal cold hot traversals run single transaction multiple transactions traversals run small database fanout connections atomicpart response time seconds small cold times objy dec odb ontos versant connections atomicpart response time seconds small hot times objy dec odb ontos versant figure traversal small database exodus objy dec odb ontos versant herewe seethe bene ofclientcaching caching ectis duplicated operation benchmark discussing subsequent results read-only queries report cold hot times run single transaction figure shows cold times systems medium database traversal sparse traversal speed traverse assembly hierarchy base assembly visited visit referenced unsharedcomposite parts composite part visited visit root atomic part return count number atomic parts visited note dfs atomic parts composite part visits root part test coupled traversal interesting insightinto costs bene full swizzling approachtoproviding persistent virtual memory odi withdrew benchmark test interesting left graph figure performance measured small database cold times graph figure hot times finally figure performance medium database connections atomicpart response time seconds objy dec odb ontos versant figure cold traversal medium database connections atomicpart response time seconds small cold objy dec ontos versant connections atomicpart response time seconds small hot objy dec ontos versant figure traversal small database connections atomicpart response time seconds medium objy dec ontos versant figure cold traversal medium database traversal traversal updates repeat traversal update objects traversal therearethreetypes update patterns traversal single update atomic part consists swapping attributes threetypes updates aupdate atomic part composite part bupdate atomic partasitisencountered cupdate atomic part composite part times return number update operations wereactuallyperformed figure results small database sense comparison abc completely characterize update story systems exodus ontos leave dirty data pages server pool commit time pages eventually written disk objectivity hand forces dirty pages back disk subsequent transactions tend rereference pages server pool exodus ontos approach superior hand pages referenced subsequent transactions incur cost writing dirty data pages disk order make room pages exodus queries measured erence time required simply commit transaction time required connections atomicpart response time seconds small objy dec ontos versant connections atomicpart response time seconds small objy dec ontos versant connections atomicpart response time seconds small objy dec ontos versant figure traversal small database connections atomicpart response time seconds medium objy dec ontos versant connections atomicpart response time seconds medium objy dec ontos versant connections atomicpart response time seconds medium objy dec ontos versant figure traversal medium database commit transaction ush server pool disk seconds total seconds lowoverhead partially due fact running traversal server ush dirty pages disk background concurrently traversal running client adding update traversal test aspect system performance keeping dirty pages server cache commit figure results medium database traversal traversal indexed eld updates repeat traversal update date eld indexed speci update increment date odd decrement date goal check overhead updating indexed eld variants traversal number updates returned connections atomicpart response time seconds small objy dec ontos versant connections atomicpart response time seconds small objy dec ontos versant connections atomicpart response time seconds small objy dec ontos versant figure traversal small database end figure results small database implementations objectivity automatic index maintenance automatic index maintenance means index updated update exodus ontos numbers ect overhead explicit index maintenance coded byhand systems ontos provide implicit index maintenance feature tests presented paper figure results medium database traversals operations manual traversal scans manual object counting number 
parallel sorting shared-nothing architecture probabilistic splitting david dewitt rey naughton donovan schneider abstract problem external sorting shared-nothing multiprocessor critical step algorithms determine range sort keys handled byeach processor twotechniques determining ranges sort keys exact splitting parallel version algorithm proposed byiyer ricard varman probabilistic splitting sampling estimate quantiles present analytic results showing probabilistic splitting performs exact splitting finally present experimental results implementation sorting probabilistic splitting gamma parallel database machine introduction paper problem external sorting shared-nothing parallel database system shared-nothing means database system implemented top multiprocessor whicheach processor local memory disk communication processors place interconnection network speci sorting problem address multiple-input multiple-output sorting sorting problem initially data sorted disk distributed multiprocessor unsorted termination sorting algorithm disk partitioned approximately equal sized non-overlapping sorted runs processor top level algorithm problem determine splitting vector nal sorted order records processor sort key records processor havesortkey greater records processor sort key greater based splitting vector redistribute records record processor redistribution locally sort records processor produce nal result computer sciences department wisconsin madison hewlett packard labs palo alto performance sorting algorithm critically dependent step paper fundamentally erent approaches determining splitting vector rst approachwe due iyer earlier paper due yamane proposes similar algorithm asymptotic running time algorithm iyer description yamane ciently detailed estimate rough asymptotic running times wechose algorithm due iyer study call method exact splitting deterministically computes exact splitting vector processor allocated number records minus approachwe whichwe call probabilistic splitting computes approximate splitting vector sampling unsorted discuss probabilistic splitting similar techniques apparently discovered rediscovered times sorting literature knowledge carefully studied context external parallel sorting show analytical model shared-nothing parallel systems probabilistic splitting beats exact splitting present scaleup speedup sizeup experimental data implementation sorting probabilistic splitting gamma database machine related work parallel external sorting salzberg stg present algorithm single-input single-output sorting demonstrate carefully engineered parallel version sort-merge internal sort merge phases made fast single input single output sites bottleneck parallel sort-merge bene compute splitting vector sort-merge multiple-input multiple-output sort nal merge accomplished faster sequential pass entire beck bbw describes similar sort earlier algorithms nal sequential merge phase include bitton bbdw valduriez gardarin graefe gra presents description implementation evaluation amultiple-input multiple-output sorting algorithm shared-memory multiprocessor algorithm splitting vector graefe suggests thatthis splitting vectormight computable sampling investigate alternative experimental results assume splitting vector algorithm run huge body literature dealing parallel internal sorting abstract computational models pram work directly relevanttoourwork unrealistic abstract computational model unrealistic assumption number processors proportional number records sorted noted previously idea sorting approximate splitting vector obtained sampling invented re-invented times sorting literature frazer mckellar proposed uniprocessor internal sort based sampling showed asymptotically restrictions distribution data sorted algorithm runs linear time distributive sorting recursive bucket sort based sampling similarities sorting probabilistic splitting dobosiewicz dob originally proposed algorithm proved data uniformly distributed runs time janus lamagna proposed distributive sorting attempts provide performance non-uniform data distributions sampling compute approximate cumulative distribution function data experimentally evaluated algorithm performance partitions results showed distribution smooth algorithm performed investigate parallel implementation algorithm quinn qui suggested implementing parallel quicksort sort processors choose pivot elements random run recursive quicksorts parallel experiments showed speedup processors skew sizes arguments recursive quicksorts huang chow parallel external sorting approximate partitioning based sampling algorithm samples purposes rst compute approximate splitting vector local quicksort partitioning samples pivot elements combinatorial analysis present analytic formulas showing good asymptotic performance implement approach compare baugst greipsland parallel external sorting approximate partitioning based synchronized sampling sorted les detail algorithm implement sampling rst processor sorts local fragment processor samples fraction fragmentby kth record predetermined resulting set samples sorted partitioning vector formed baugst greipsland discuss analyze quality resulting partitioning vector determine fraction sampled lorie young describe algorithm multiple-input single-output sorting feature algorithm nal output phase heavily overlapped internal sorting phase reduces time initiation algorithm rst sorted tuple appears output algorithm splitting vector suggest computable statistical technique technique virtually identical baugst greipsland technique analytic data presented lorie young assume splitting vector algorithm begins mostrecently inworkdone concurrently independently fromthe work presented paper blelloch etal blm investigated internal sorting algorithms fora processor cmthey concluded experimental analytic comparisons probabilistic splitting local radix sorts provided highest performance beating parallel bitonic sort parallel radix sort remainder paper organized sections describes probabilistic exact partitioning algorithms cost model section cost models compare performance section describes implementation probabilistic splitting gamma parallel database machine section presents results experiments implementation probabilistic splitting algorithm description probabilistic splitting based simple idea approximate splitting vector compute arandomsubset exactsplitting vectorforthe randomsubset nally exact splitting vector subset approximate splitting vector idea simple care evaluating quality approximate splitting vector interesting tradeo added cost taking larger sample produces approximation improved performance results approximation error approximate splitting vector translates directly skew number records processors parallel database system derive number samples guarantee skew number processors forskew denote ratioof maximum number recordsat anysite tothe average number records site wehave processors records sorted average number records processor isn nition maximum number records anysiteissn theorem seshadri naughton total samples probability processor keys solving number samples required guarantee skew probability trading samples skew tocomplete thedescription ofprobabilistic splitting weneed todescribe howto ndthe optimal skew setting small result poor performance due cost samples sampling phase setting large result poor performance due uneven sizes subproblems processors phases algorithm function relating skew number samples depends number processors equation eachvalue erent optimal section includes experiments illustrating tradeo implementation probabilistic splitting finding optimal optimization problem set solve optimization problem cost estimates phases algorithm cost model developed extremely simple interpreted attempt predict absolute numbers running times algorithm intent model ciently precise yield accurate absolute running times good predict whichchoice set alternatives expected give performance analogous situation query optimizers optimizers successful choosing good evaluation plan cost estimates accurate absolute sense main simplifying assumptions wemake overlap operations cpu operations network tra contention network work individual nodes machine including cpu network completely parallel nodes machine assumptions allowus time single node perform segment computation total time multiprocessor perform full computation comp compare keys exchange twokeys move move record sequential random msg send receive message sample random sample table parameters cost model set parameters table cost model parameters based measurements gamma parallel database machine times higher 
occurrences character traversal checks rst character manual object medium database byte manual obtained cold times results independent atomic part fanout small database times traversals manual provide insight provided medium database times exodus objy dec odb ontos versant traversal cached update perform traversal followedbyt inasingletransaction report total time minus hot time minus cold time goal traversal investigate performance updates cached data original traversal warms cache traversal updates objects touched connections atomicpart response time seconds medium objy dec ontos versant figure medium database time report ned suchaway isolate time updates log writes recall updates atomic parts figure times obtained small databases traversals omitted experimented traversals changed size document objects traversals scanned documents traversing atomic part subgraphs reverse-traversals atomic part root assembly hierarchy tests deleted nal benchmark experimentation discovered provide additional insightbeyond provided traversals queries queries operations ideally expressed queries declarative query language queries expressed declaratively systems query expressed declaratively system implemented free procedure essentially represents hand coded version query execution engine order evaluate query traversals queries run cold hot case tests coupling query facility application programming language requiring connections atomicpart response time seconds cached update objy dec ontos versant figure cached update small databases function called eld values qualifying object queries read-only gaps numbering correspond queries tested eliminated paper due space constraints lack additional insights query exact match lookup generate random atomic part part generated lookup atomic part return number atomic parts processed note lookup query benchmark left graph figure results measured small database graph figure results measured small database hot times finally figure results measured medium database cold queries case systems index avoid scaling response time database relative ordering systems performance consistent small results queries queries interesting considered query choosearange dates dates found database atomic parts retrieve atomic parts satisfy range predicate connections atomicpart response time seconds small cold objy dec ontos versant connections atomicpart response time seconds small hot objy dec ontos versant figure small database connections atomicpart response time seconds medium objy dec ontos versant figure cold query medium database connections atomicpart response time seconds small cold objy dec ontos versant connections atomicpart response time seconds small hot objy dec ontos versant figure small database query choose range dates dates found database atomic parts retrieve atomic parts satisfy range predicate query scan atomic parts note queries candidates tree lookup medium fanout database obtained cold numbers similar results obtained fanouts omit fanout exodus objy dec odb ontos versant query path lookup generate random document titles title generated base assemblies composite part document count total number base assemblies qualify note system supports path indices query run faulting documents composite parts system support path indices objects selected paths brought odi systemwetested thatsupportspath indices sothis anotheroperation thatbecame interesting odi withdrew benchmarking ort left graph figure shows small database cold times graph figure small database hot times finally figure medium cold times connections atomicpart response time seconds medium objy dec ontos versant figure cold query medium database query single-level make find base assemblies composite part build date build date base assembly report number qualifying base assemblies found query mimics processing unix make command determine base assemblies rendered date modifying composite parts left graph figure shows small database cold times graph figure small database hot times figure medium cold times query ad-hoc join find pairs documents atomic parts wherethedocument atomic part matches document return count number pairs encountered left graph figure shows small database cold times graph figure small database hot times finally figure medium cold times structural modi cation operations report present results insert operation insert composite parts delete operation delete composite parts timed build operation connections atomicpart response time seconds small cold objy dec ontos versant connections atomicpart response time seconds small hot objy dec ontos versant figure small database connections atomicpart response time seconds medium objy dec ontos versant figure cold query medium database connections atomicpart response time seconds small cold objy dec ontos versant connections atomicpart response time seconds small hot objy dec ontos versant figure small database connections atomicpart response time seconds medium objy dec ontos versant figure cold query medium database connections atomicpart response time seconds insert small cold objy dec ontos versant connections atomicpart response time seconds delete small cold objy dec ontos versant figure insert delete small database database build programs erent erent systems exodus ontos weusedmultiple transactions objectivity build single large transaction felt comparison build times meaningful structural modi cation insert create composite parts includes creating number atomic parts small con guration large document objects insert database installing composite parts randomly chosen base assembly objects left graph figure shows results insert operation small databases left graph figure results medium databases structural modi cation delete delete newly createdcomposite parts atomic parts document objects graph figure shows results delete operation small databases graph figure results medium databases connections atomicpart response time seconds insert medium cold objy dec ontos versant connections atomicpart response time seconds delete medium cold objy dec ontos versant figure insert delete medium database conclusion benchmark designed provide comprehensive pro performance oodbms complex benchmark comprehensive hypermodel benchmarks results tests added complexity coverage provided signi bene test results reported paper observed tests reported space legal reasons exhibit system performance characteristics observed hypermodel designed start support multiuser operations operations implemented database structure paper framework construct multiuser benchmark speci cally modules assembly structure shared private composite parts precisely vary degrees sharing con ict multiuser workloads future work wewill ning experimenting multiuser workloads investigate performance oodb systems concurrency versioning facilities plan add structural modi cations test abilityofan oodbms maintain clustering face updates acknowledgment designing running systems tested huge task completed lot wewould jim gray mike kilian ellen lary pat brien mark palmer jim rye dec initial discussions led project feedback progressed rick cattell shared thoughts early change successor gave feedback design rosanne park rickspickelmier objectivity gerard keating mark noyes ontos jack orenstein dan weinreb odi extremely helpful teaching systems debugging orts joseph burger krishna kunchithapadam bart miller helped trackdown strange interaction systems environment law foley hoag eliot machine humming mailboxes full finally wewould give special sta members wisconsin joseph burger 
dan schuh tan mike zwilling testbed running anderson hypermodel benchmark proceedings edbt conference venice italy march bdt dina bitton david dewitt carolyn turby benchmarking database systems systematic approach proceedings ninth international conferenceonvery large data bases pages cattell skeen object operations benchmark acm transactions database systems march duhl damon performance comparison object relational databases sun benchmark proceedings acm oopsla conference san diego california september dfmv david dewitt philippe futtersack david maier fernando velez study architectures object-oreinted database systems proceedings vldb conference brisbane australia august exo exodus group exodus storage manager technical documentation january fzt michael franklin michael zwilling tan michael carey david dewitt crash recovery client-server exodus proceedings acm-sigmod conference management data pages june gra jim grayetal recovery manager system database manager acm computing surveys june joel richardson michael carey persistence language issues implementation softwarepractice experience december rkc rubenstein kubicar cattell benchmarking simple database operations proceedings acm sigmod conference sanfrancisco california scd schuh carey dewitt persistence revisited implementation experiences proceedings fourth international workshop persistent object systems morgan kaufmann winslett chu database management systems ecad applications architecture performance proceedings nsf conference design manufacturing systems atlanta georgia january white dewitt performance study alternative object faulting pointer swizzling strategies proceedings vldb conference vancouver british columbia august benchmark database schema description schema notation hybrid based data nition languages ddls systems tested inter-object denoted pointer notation partof eld atomic part object composite part object atomic part part type compositepart expressions set bag denote sets bags multisets objects type eld atomic part object set totheconnection objectsthathold dataabout outgoing connections theatomic part atomic parts addition inverse relationships denoted schema pronounced inverse fact atomic part inverse relationship connection objects connected captured ddl description atomic part class set connection connection eld eld atomic part inversely related eld connections finally noted schema includes instances relationships modeled inverse relationships pair elds eld set bags addition type information ddl description notes top-level collections expressed type extents needed benchmark operations extent annotation end class nitions listed extent clauses attributes data members ofeach class indexed order provide acceptable performance benchmark operations noted mandatory type extents implemented waymust provided materialize relevant collections set atomic parts support benchmark operations similarly indices suggested mandatory omitting lead inferior performance results finally avoid dictating data clustering strategy implementors free cluster objects database order achievegood performance subject constraint database instance clustering strategy entire series operations including tests small medium large databases designobj root class hierarchy objects class designobj int char type int builddate atomicpart objects primitives building designs class atomicpart designobj int int docid set connection connection set connection connection compositepart partof compositepart parts extent indexed builddate indexed connection objects wire atomicparts class connection char type int length atomicpart atomicpart atomicpart atomicpart compositeparts parts constructed atomicparts class compositepart designobj document documentation document part bag baseassembly usedinpriv baseassembly componentspriv bag baseassembly usedinshar baseassembly componentsshar set atomicpart parts atomicpart partof atomicpart rootpart extent indexed document objects describe compositepart objects class document char title int string text compositepart part compositepart documentation extent title indexed indexed manual objects describe module class manual char title int string text int textlen module mod module man assembly objects build hierarchical designs class assembly designobj complexassembly superassembly complexassembly subassemblies module module module assemblies class complexassembly assembly set assembly subassemblies assembly superassembly class baseassembly assembly bag compositepart componentspriv compositepart usedinpriv bag compositepart componentsshar compositepart usedinshar extent indexed modules designs resulting assembly composition class module designobj manual man manual mod set assembly assemblies assembly module complexassembly designroot extent indexed finally figure extended entity-relationship diagram schema database readers prefer terms e-r modeling concepts designobj type builddate isa module designroot assembiles subassemblies complexassembly assembly isa baseassembly componentsshared compositepart rootpart parts connection type length atomicpart docid documentation document title text componentspriv title text manual textlen man figure entity-relationship diagram benchmark 
tiles staging disk main memory buffer pool final processing adds overhead test finally extra processing overhead paradise storage engine managing large objects tiles tile size impact obvious experiments tile size clip image response analytical simulation application paradise figure comparison configurations kind effect clip queries large number images conducted experiment clipping images fixed region area image boundary figure show results application program paradise system figures show advantage smaller tile size tile worst cases gain relative small cases upper-bound determined difference transfer speed seek speed shows smaller tiles post performance penalty query processing account resource occupied larger tiles case paradise staging disk space buffer tape block smaller tile size save resource leads efficient processing tile size response figure clipping images application tile size response figure clipping images paradise conclusions future work analytical model study impact tile size performance efficient retrieval partial images tapes demonstrated detail simulation performance evaluation direct application program end-to-end system tile size complex effect response time image clipping queries interesting observations implications analyzed find tile size direct impact retrieving partial images tertiary image store tile size range observed optimal dlt tape drive experiments conducted application program paradise system gave convincing evidence support optimal tile tape block size range efficient processing raster images environment partial image access frequent access order images original loading order encouraging block size small range tremendously provide flexible resource management in-memory transfer buffer cache disk space constraint access order tape storage order hard conform ad-hoc query environment companion study developed set techniques utilize order constraint schedule query execution tertiary database management system concentrated image clipping study applying analysis images higher dimensional arrays lead interesting findings result scaled n-dimensional arrays expansion dimension sizes number seeks seek distance explode exponentially bigger impact tile size selection expected higher dimensions interesting direction study impact ordering tiles apply techniques clustering spatial objects spatial filling curves curve hilbert curve techniques hierarchical subchunking tiles levels optimizing tape accesses dfg davis farrel gray eosdis alternative architecture study report september ekd emery kelley dozier rotar on-line access weather satellite imagery image manipulation software bulletin american meteorological society january gra gray mox gox scans measure archive eosdis experience june hillyer avi silbertschatz modeling performance characteristics serpentine tape drive bell lab technical report august qua quantum corporation dltproduct manual sfg stonebraker frew gardels meredith sequoia storage benchmark sigmod record sun sarawagi efficient processing multi-dimensional arrays proceedings ieee data engineering conference february dewitt query pre-execution batching two-pronged approach efficient processing tape-resident data sets submitted february 
intelligently scheduling operators maximum memory requirements query reduced schedule executing -join bushy tree section execution step hash tables resident memory step completes memory reclaimed hash tables join operators hash tables join operators constructed execution step memory requirements reduced hash tables reduce memory consumption query constructing schedule execution schedule noted hash table space reclaimed step scan -build step scan -probe -build -release scan -build step scan -probe -probe -build -release step scan -build step scan -probe -build -release scan -build step scan -probe -probe -probe -release execution plan requires steps maximum memory requirements reduced execution query maximum hash tables maximum hash tables types execution plan modifications insufficient reducing memory demands techniques subsections left-deep right-deep query trees employed initial performance evaluation left-deep right-deep query trees preceding discussion multi-way join query represented right-deep query tree potentially offer significant performance advantages query represented left-deep tree section focus quantitatively measuring extent performance advantage reader note goal performance evaluation determine range performance tradeoffs left-deep right-deep query trees purport encompass situations analysis serve show feasibility strategies proposed processing multi-way join queries experimental vehicle analysis chose shared-nothing database machine gamma dewi dewi gamma runs processor ipsc intel hypercube inte megabyte maxtor disk directly attached intel processor deficiency ipsc system provide dma support disk transfers disk blocks transferred disk controller fifo buffer cpu copy block memory high-speed hypercube connected network topology specially designed hardware routers communication processors implementing scheduling algorithms directly gamma measuring performance chose build simulation model gamma reasons decision felt simpler faster construct scheduling algorithms simulator actual system simulation model study algorithms hardware configurations larger gamma rest section describe simulation model validation simulation model experimental results model comparing performance tradeoffs scheduling left-deep right-deep query trees simulation model simulation model gamma constructed node multiprocessor system consists disk module cpu module query scheduler module multiple instances operator module additionally stand-alone modules provided network module file manager module terminal module denet simulation language livn construct simulator disk module schedules disk requests elevator algorithm order accurately reflect hardware gamma disk module interrupts cpu bytes transferred channel fifo buffer memory vice versa cpu module enforces fcfs nonpreemptive scheduling paradigm requests exception byte transfers disk fifo buffer operator modules responsible modeling relational operators select join modules repeatedly make requests cpu disk network modules order perform operation instance module required select join operator query tree query scheduler module implements algorithms process left-deep right-deep query trees simply assigns operators query tree operator managers relevant processing nodes depending scheduling algorithm intel forced design system added system completed empty socket board dma access memory network module models fully connected network terminal module entry point queries system finally file manager track files defined disks file declustered number pages file disk assignment page file physical disk address maintained assumed pages file contiguous physical assignment file pages accurate modeling sequential random disk accesses simulation model validation order provide faith results multiprocessor database machine simulator validated simulator results produced gamma validation procedure system configured kbyte disk pages kbyte network pages costs basic operations machine relevant system parameters summarized table validate simulation model present performance selection query join query system processors disks expanded versions wisconsin benchmark relations bitt serve test database selection query retrieves tuples tuple relation stores resulting tuples back database shown figure simulation model matches observed gamma performance closely query actual error greater implied figululululululululululululululululululululululululululululululululululululululululululululululululululululululululul disk parameters average seek time msec average settle time msec average latency msec uniform transfer rate mbytes sec track size kbytes disk page size kbytes xfer disk page scsi memory instructions network parameters maximum packet size kbytes send bytes msec send bytes msec cpu parameters instructions read disk page instructions write disk page instructions miscellaneous tuples network packet tuples disk page number sites number cpus site number disks site simulation parameters model validation table ure gamma page readahead mechanism reading pages file sequentially performance implications mechanism discussed detail order validate join performance model joined tuple relation megabytes tuple relation megabytes produce tuple result relation megabytes illustrated figure simulation model overestimates response time query constant factor range processors disk attribute modeling inaccuracy related gamma page readahead mechanism scanning file sequentially join queries cpu intensive operations gamma effectively overlap cpu costs constructing probing hash table disk reading joining relations imply model overpredicting performance selection query presented figure cpu requirements query lower join query extent overlap cpu disk processing limited claim supported fact simulation model accurately predicts execution times selection queries non-clustered b-tree access queries generate series random disk requests readahead employed processors disk model gamma selection response time secs processors disk response time secs gamma model joinabprime join result validation selection join performance figure experimental design stated beginning section experiments designed present range performance differences left-deep right-deep query trees experiments conducted query suite consisted join queries composed joins order simplify analysis queries highly constrained queries designed size result relation constant number joins query query tree representation accomplished making relations size setting join probe-ability factor join query tree probing tuple joins building tuple parallel version simple hash-join algorithm dewi schn join method stated assumed main memory exists hash table overflow occurs number concurrent join operations database composed tuple relations relation selection predicate applied reduces output cardinality tuples input tuples bytes wide attributes added successive join result cardinality joins tuples bytes wide result relations written back database order accurately predict performance typical database machines buffer pool hit ratio order model disk prefetch mechanism system parameters identical table response time queries measured time query plan submitted database machine query fully computed major experiments reported experiment considers performance differences environment declustering joining relations forces high level resource contention experiment environment changed ensure low level resource contention fourth experiments experiments repeated environment memory joining unlimited high resource contention environment database machine small number processors large relations declustered nodes executing multiple scan join operators concurrently result high degree resource contention experiments system configured relation declustered nodes join query tree processed nodes results full declustering experiments shown figure join query performance right-deep query tree approximately faster analogous left-deep query tree left-deep right-deep query trees identical single join queries performance improvement occurs disks fully utilized 
executing scans parallel right-deep trees performance improvement scan declustered relation fully utilizes number joins deep left deep response time secs scan selectivity number joins deep left deep response time secs scan selectivity full declustering nodes figure disks right-deep query tree demonstrate performance advantage experimental conditions note maximal memory requirements left-deep right-deep query trees identical join queries high right-deep queries joins times high joins relations joined declustered set nodes benefits provided right-deep query trees maintained relative amount memory consumed number joins increases low resource contention environment set experiments wanted demonstrate performance tradeoffs query representation strategies configuration processors machine relations declustered subset nodes gerb cope resource contention reduced executing operators concurrently system configured manner tuple relations declustered distinct non-overlapping nodes join processed nodes processors execute join operator assigned identical processors building relation declustered conditions number processors actively participating query scanning relations building probing hash tables increased number joins query increased -join query nodes -join query nodes number joins query result relation declustered nodes illustrated figure left-deep query trees unable advantage hardware resources additional joins added query expected relations scanned time left-deep query tree employed right-deep query trees constant response time maintained number joins increased startling easily explained experimental parameters step executing query scanning building relations constructing hash tables relations size selectivity factor applied relations declustered distinct nodes join nodes correspond base relation declustering nodes scan executed completely parallel interference cost operation constant number joins disregarding small overhead initiating operators phase probing phase scale number joins due effect pipelining tuples produced lower join immediately network participate level join processing tuples upper lower levels tree overlapped viewed throughput pipeline constant depth join tree difference response time number join levels increases due increased latency initiate terminate number joins deep left deep response time secs partial declustering nodes figure pipeline results contained figure represent best-case performance improvements right-deep versus left-deep query trees experimental parameters set parallelism potential right-deep strategy exploited fullest realistic conditions performance improvements right-deep query trees fall extremes presented figures noted rightdeep query joins required times memory left-deep join queries results demonstrate extremely high performance benefits obtained right-deep query representation strategy limited memory experiments set experiments relaxed assumption unlimited amount memory exists joining query model parameters identical reported previous section exception analysis concentrated query consisting joins high resource low resource contention full declustering disjoint declustering experiments conducted static right-deep scheduling strategy section processing right-deep query trees order model limited memory environment modified aggregate amount memory joining relative memory required stage building relations memory simultaneously response time plotted left-deep right-deep strategies x-axis values ranging building relations co-reside memory building relations fit memory simultaneously x-axis values required resolution memory overflow left-deep query trees reported static right-deep strategy assumed optimizer perfectly predict scan selectivities choose optimal places break query tree limited memory high resource contention figure performance left-deep static right-deep scheduling algorithms shown amount memory varied environment base relations declustered sites observations noted figure obvious left-deep scheduling algorithm advantage memory added contrast static right-deep scheduling algorithm demonstrate significant performance advantages additional memory crossover point graphs demonstrates fact breaking query tree pieces detrimental performance right-deep scheduling algorithms x-axis tree broken pieces ensure right-deep strategy experience memory overflow requiring writing subsequent reading temporary join computations disk points query avail mem mem joins static deep left deep response time secs avail mem mem joins static deep left deep response time secs limited memory full disjoint declustering figures execution point note flatness right-deep scheduling graph range query tree broken pieces joins queries tested produced intermediate relations constant size number joins query placement break effect performance number tuples temporarily staged disk conditions growing diminishing temporary join size results selection break points query effect execution time query explored future performance analysis limited memory low resource contention figure present execution time left-deep right-deep scheduling strategies join query relations joined declustered mutually disjoint processors disks simulation parameters identical reported section results similar shown figure shape curves identical obvious partial declustering environment offers additional performance advantages right-deep scheduling strategies memory unlimited encouraging stated earlier relations partially declustered database machines large numbers processors disks conclusions paper problems tradeoffs task processing queries composed joins multiprocessor database machine focused strategy chosen represent query tree affects degree parallelism applied query effects performance resource consumption query extent dataflow processing techniques applied cost query optimization hash based join methods assumed analysis sort-merge join method discussed briefly results obtained analysis right-deep query representation strategy suited exploit parallelism found large multiprocessor database machine configurations added benefit importance accurately estimating join selectivities potentially reduced right-deep query trees order quantitatively measure performance benefits right-deep query trees provide left-deep query trees constructed simulation model parallel database machine implemented scheduling algorithms processing queries represented formats experimental results analysis algorithms confirmed right-deep query trees offer significant performance advantages large database machines extent performance improvement strongly dictated physical placement base relations cost increased resource consumption memory limited performance difference scheduling algorithms diminishes future work includes analyzing performance tradeoffs query tree representation strategies proposed scheduling algorithms multiuser workloads skewed data distributions multiuser performance comparisons scope paper memory requirements query serve good indicator potential throughput memory crucial high performance query processing hash-join algorithms hope apply technique adaptive sampling lipt lipt tackle problem skew acknowledgments jeff naughton helpful discussions work baru baru frieder kandlur segal join cube analysis simulation implementation database machines knowledge base machines kitsuregawa tanaka eds kluwer academic publishers bitt bitton dewitt turbyfill benchmarking database systems systematic approach proceedings large database conference october brat bratbergsengen kjell algebra operations parallel computer performance evaluation database machines knowledge base machines kitsuregawa tanaka eds kluwer academic publishers cope copeland alexander boughter keller data placement bubba proceedings sigmod conference chicago june dewi dewitt katz olken shapiro stonebraker wood implementation techniques main memory database systems proceedings sigmod conference boston june dewi dewitt gerber multiprocessor hash-based join algorithms proceedings vldb conference stockholm sweden august dewi dewitt gerber graefe heytens kumar muralikrishna gamma high performance dataflow database machine proceedings vldb conference japan august dewi dewitt ghandeharizadeh schneider performance analysis gamma database machine proceedings sigmod conference chicago june dewi dewitt ghandeharizadeh schneider bricker hsiao rasmussen gamma database machine project ieee 
transactions knowledge data engineering march gerb gerber dataflow query processing multiprocessor hash-partitioned algorithms phd thesis computer sciences technical report wisconsin-madison october gerb gerber dewitt impact hardware software alternatives performance gamma database machine computer sciences technical report wisconsinmadison july ghan ghandeharizadeh dewitt multiuser performance analysis alternative declustering strategies proceedings international conference data engineering grae graefe rule-based query optimization extensible database systems thesis computer sciences technical report wisconsin-madison november grae graefe volcano compact extensible dynamic parallel dataflow query evaluation system working paper oregon graduate center portland february grae graefe ward dynamic query evaluation plans proceedings sigmod conference portland haas haas freytag lohman pirahesh extensible query processing starburst proceedings sigmod conference portland inte intel corporation ipsc user guide intel corporation order march kits kitsuregawa nakano takagi query execution large relations functional disk system proceedings international conference data engineering lipt lipton naughton schneider practical selectivity estimation adaptive sampling proceedings sigmod conference atlantic city jersey livn livny denet user guide version computer sciences department wisconsin madison carey experimental results distributed join algorithms local network proceedings vldb conference stockholm sweden august schn schneider dewitt performance evaluation parallel join algorithms shared-nothing multiprocessor environment proceedings sigmod conference portland june schn schneider dewitt design tradeoffs alternative query tree representations multiprocessor database machines computer sciences technical report wisconsinmadison august shap shapiro join processing database systems large main memories acm transactions database systems vol september ston stonebraker aoki seltzer parallelism xprs memorandum ucb erl february 
dbi determined automatically feel alternative requires level sophistication time experimentation expected dbi order provide dbi dba control optimization process intend leave control tradeoff quality resulting access plan cost optimization experiments independent hill climbing factor reanalyzing factor averaging method half nodes typically generated plan found additional stopping criterion avoid large part wasted effort plan found commercial ingres comparison optimization time expected query execution time introduced optimization consumed fraction time estimated executing plan found optimization abandoned plan executed intend explore criteria involves gradient improvements imagine graph time spent optimization horizontal axis estimated execution time plan vertical axis curve flattens optimization process end stop flat length time termination condition plan evaluating number nodes generated single query optimization preempted experiments set fixed limit queries intend calculate reasonable limit query individually limit exponential number operators query plan making generated optimizers recognize common subexpressions final access plan extracted mesh common subexpressions detected mesh optimized procedure extracts access plan mesh exploit feature implement nested method expressions definition method classes operator exact-match index look-up implementation rules requiring index look-up index join index selection adding access method system current design implementation rule added model description file rule access method method class access method added class intend exploring idea improving search strategy introduction phases search process phase proven heuristics rules low expected cost factors limited amount hill climbing reanalyzing search ended query tree improved significantly cost establishes upper bound phase phase broader search basically search starting result phase initial query tree finally phase work analogous peep hole optimization compiler technology predicate clause reordering hana assignments tasks phases designed idea phases similar generalization idea pilot pass rose real test optimizer generator real system exodus project team intends implement relational database system real system relational relational technology sufficiently systems exist performance comparison purposes data models work experiment exodus model simultaneously good idea assess realistically general design significant shortcomings real test set design optimizer recently proposed data models abe klug daplex ship probe daya mano ldl tsur finally realize optimizer generator works largely syntactic level algebra semantics data model left dbi code advantage allowing dbi maximal freedom kind data model implement disadvantage leaving significant amount coding dbi incorporate semantic knowledge data model description file long term goal attention conclusions important result demonstrated work rule-based optimizer generators separate search strategy optimizer data model implement generic optimizer search algorithm suitable data models model optimization chosen algebraic optimization expected fit modern set-oriented data models architecture exodus optimizer generator enforces modular extensible design dbi query optimizer code transformation implementation rules independent property cost functions defined limited programming tasks dbi consequence incremental design evaluation data model optimizer encouraged generator inputs fairly easy design code pieces tricky depending design arguments writing rule conditions argument transfer functions fairly burdensome work needed achieve adequate support dbi area preliminary performance evaluation optimizer generated subset relational data model demonstrates exhaustive search query optimization process experiments cover data model generalization justified dbi tune search strategy good part tuning automatically system terms optimization speed quality access plans produced generated optimizer appears competitive hand-coded optimizer exception cases found access plans found prototype relational model good produced exhaustive search designing set queries compare systematically generated optimizer complete relational model existing commercial relational query optimizer acknowledgements authors encouragement helpful suggestions exodus project members michael carey daniel frank joel richardson eugene shekita muralikrishna astr astrahan system relational approach database management acm transactions database systems vol june barr barr feigenbaum handbook artificial intelligence william kaufman los altos bobr bobrow stefik loops manual loops release notes xerox palo alto care carey dewitt extensible database systems proceedings islamorada workshop feb care carey dewitt richardson shekita object file management exodus extensible database system proceedings vldb conference aug care carey dewitt frank graefe richardson shekita muralikrishna architecture exodus extensible dbms preliminary report proceedings international workshop object-oriented database systems sep cloc clocksin mellish programming prolog springer-verlag york cope copeland maier making smalltalk database system proceedings acm sigmod conference june daya dayal smith probe knowledge-oriented database management system proceedings islamorada workshop feb dewi dewitt gerber graefe heytens kumar muralikrishna gamma high performance dataflow database machine proceedings vldb conference aug forg forgy ops manual computer science technical report carnegie-mellon frey freytag translating relational queries iterative programs thesis harvard sep frey freytag goodman translating relational queries iterative programs program transformation approach proceedings acm sigmod conference june hana hanani optimal evaluation boolean expressions online query system communications acm vol hart hart nilsson raphael formal basis heuristic determination minimum path cost ieee transactions ssc vol jark jarke koch query optimization database systems acm computing surveys vol june klug klug access paths abe statistical query facility proceedings acm sigmod conference june klug klug equivalence relational algebra relational calculus query languages aggregate functions journal acm vol july kooi kooi optimization queries relational databases thesis case western reserve sept lyng lyngback kent data modeling methodology design implementation information systems proceedings international workshop object-oriented database systems sep mano manola dayal pdm object-oriented data model proceedings international workshop object-oriented database systems sep nguy nguyen ferrat galy high-level user interface local network database system proceedings ieee infocom rich richardson carey programming constructs database system implementation exodus submitted rose rosenthal dayal reiner fast query optimization large strategy space pilot pass approach unpublished manuscript seli griffiths selinger astrahan chamberlin lorie price access path selection relational database management system proceedings acm sigmod conference june ship shipman functional data model data language daplex acm transactions database systems vol mar smit smith chang optimizing performance relational algebra database interface communications acm vol ston stonebraker wong kreps held design implementation ingres acm transactions database systems vol sept ston stonebraker rowe design postgres proceedings sigmod conference tsur tsur zaniolo ldl logic-based data-language mcc technical report db- mcc feb warr warren pereira pereira prolog language implementation compared lisp proceedings acm sigart-sigplan symp programming languages wong wong youssefi decomposition strategy query processing acm transactions database systems vol sept yous youssefi wong query processing relational database management system proceedings vldb conference oct zani zaniolo database language gem proceedings acm sigmod conference 
joins experienced hash table overflow end section analyze performance grace hybrid join algorithms data points integral number buckets partitioning non-partitioning attribute joins local configuration gamma teradata relation created database administrator required partitioning key attribute case gamma partitioning strategy round-robin hashed range section details relations joined hash-partititioned joining attributes partitioning phase parallel algorithms previous section longer eliminated special-case system handle join operation partitioning attribute gamma relies operating system short-circuit packets processes machine design july partitioning split table maximize extent tuples mapped hash-join buckets processor figures display execution times joinabprime query function amount memory relative size relation join attributes partitioning attributes figure figure tests conducted local configuration processors joins executed processors disks points made graphs smaller relation fits memory hybrid simple algorithms expected identical execution times expect memory data point simple hash equal hybrid hash respective behavior identical algorithms write approximately one-half joining relations disk simple hash slower sends tuples joins sites processing turn tuples belong overflow partition section hybrid algorithm writes tuples belonging bucket directly disk expected grace joins insensitive decreasing amount memory hybrid sensitive percentage memory relative size joining processors disks figure processors disks partitioning attributes join attributes figure simple nonkey grace nonkey hybrid nonkey sort-merge nonkey memory smaller relation simple key grace key hybrid key sort-merge key memory smaller relation partitioning attributes join attributes july relations large occurs grace algorithm extra memory joining decreasing memory simply increases number buckets incurs small scheduling overhead hybrid decreasing amount memory ratio forces algorithm stage half joining relation back disk note response time hybrid algorithm approaches grace algorithm memory reduced hybrid derives benefits exploiting extra memory memory reduced relative performance algorithm degrades extra rise curves occurs memory scarce partitioning split table exceeds network packet size pieces figures hybrid algorithm dominates entire memory range memory ratios simple hash outperforms grace sort-merge decreasing fraction larger joining relation written back disk memory availability decreases simple hash degrades rapidly repeatedly reads writes data performance sort-merge algorithm stable dominated hybrid grace algorithms entire memory range upward steps response time curves sort-merge result cost additional merging passes required sort larger source relation interesting feature sort-merge curves drop response time memory ratio decreased phenomenon occurs hypothesize number merge passes required sorting larger joining relation constant memory range adding additional sort buffers adds processing overhead important point trends observed graphs general shape similar analytical results reported dewi experimental results dewi single-processor versions algorithms reasons find similarity encouraging demonstrates algorithms parallelizes serves verify parallel implementation algorithm fair consistent fashion interesting note curves figures differ constant factor memory availabilities tested response time difference turns difference shortcircuiting entire distribution partitioning attribute joins opposed shortcircuiting tuples non-partitioning attribute joins algorithms time store final join result identical round-robin tuple distribution strategy store result tuples query algorithm shortcircuit result tuples july sort-merge attribute values identical partitioning attributes time sort merge constant relations partitioned joining sites partitioning attribute joins shortcircuit tuples non-partitioning attribute joins shortcircuit tuples shortcircuiting accounts constant response time difference noted sort-merge times unnecessarily high smaller relation fits memory current implementation doesn recognize fact smaller relation written back disk measured time write read relation approximately seconds simple hash experience effects joining phase set joining processors sort-merge expected partitioning attribute joins increasingly reap benefits shortcircuiting processing join overflows savings materialize hash function changed overflow converting partitioning attribute joins non-partitioning attribute joins hash function modification order efficiently process non-uniform data distributions case subset joining sites overflow joining hash function tuples overflow partition read disk re-split overflow tuples re-map overflowing processors leave non-overflowing processors idle importantly local memories unused explanation grace joins slightly complicated independent amount memory partitioning buckets completely shortcircuited partitioning attribute joins tuples shortcircuited non-partitioning attribute joins accounts total response time difference partitioning non-partitioning attribute joins implies joining phases partitioning non-partitioning attribute joins identical joining tuples shortcircuit network case argue intuitively case good implementation important feature hashing execute join operations join broken buckets tuples bucket outer relation possibly join tuples bucket relation grace joins tuples bucket compared tuples bucket technique applied finer level buckets figure bucket composed number individual fragments fragments created hashing partitioning split table required join tuples fragment bucket tuples july fragment bucket ranges number disk sites ranges fragments buckets reside disk partitioning split table redistribute tuples join processors disks perform join operation non-partitioning attribute joins perform partitioning attribute joins initial bucket-forming partitioning phase completed performance difference partitioning non-partitioning attribute hybrid joins easy explain similarity grace joins local configuration n-bucket hybrid join partitioning split table identical n-bucket grace join exception tuples bucket joined immediately stored temporary files joining split table identical algorithms tuples shortcircuit network processing buckets case grace joins difference execution times due cost partitioning buckets join attributes partitioning attributes grace hybrid performance intermediate points stated introduction section chose plot response times hybrid grace algorithms memory ratio corresponded integral number buckets straight lines connecting plotted points figures curves step functions alternatively chosen algorithms overflow non-integral memory availabilities simple hash-join algorithm process overflow basically decision represents tradeoff pessimistic electing run additional bucket optimistic hoping overflow mechanism cheaper extra bucket grace algorithm pessimistic choice choice extra buckets inexpensive tradeoffs obvious hybrid algorithm figure presents detailed examination performance hybrid join algorithm memory ratios performance optimal memory ratios memory fully utilized unnecessary disk performed line connecting points represents optimal achievable performance perfect partitioning joining relations horizontal line reflects results partitioning attributes equal joining attributes presented trends identical non-partitioning attributes snapshot performance show expected behavior plotted points graphs july pessimistic option executing extra bucket explaining performance hybrid algorithm overflow requires details simple algorithm process overflows tuples relation arrive join site inserted hash table based application hash function histogram based application hash function tuple join attribute updated histogram records number tuples ranges hash values capacity hash table exceeded procedure invoked clear number tuples hash table write overflow file function section clear hash table memory space overflow detected accomplished examining histogram hash values histogram show writing tuples hash values overflow file free memory knowledge tuples hash table examined qualifying tuples written overflow file subsequent tuples arrive join site compared present cutoff hash values cutoff mark written directly overflow file inserted hash 
table notice hash table overflow memory smaller relation ovfl key constant key optimal key figure processors disks july heuristic clearing memory turns insufficient case additional tuples removed hash table heuristic overly optimistic notice successive application heuristic increases percentage incoming tuples written overflow file invocation heuristic incoming tuples chance directed hash table immediately overflow file tuples examined free memory filled required previous invocation heuristic shape response time curves hybrid algorithm figure illustrates heuristics impact performance overflow curve worse hybrid buckets cpu overhead required repeatedly search hash table heuristic forces tuples written overflow file incurring additional disk finally network protocol costs sending tuples join site returning tuples fit overflow files local joins transmission overflow tuples shortcircuited protocol cost step-like function occurs points number passes hash table identical results demonstrate tradeoff exists pessimistic increasing number buckets optimistic counting simple hash-join resolve memory overflow multiprocessor bit vector filtering set experiments ran joinabprime tests bit filters babb vald parallel join algorithms bit filtering tuples applied joining phase sort-merge joins bit filter built disk site smaller relation partitioned network stored temporary files hash-based algorithms bit filter built join sites tuples relation inserted hash tables simple hash-join algorithm means number overflows increases opportunities filtering non-joining tuples increases overflow treated separate join grace hybrid joins bucket treated separate join separate bit filters built part processing bucket join size bit filter increasing number buckets overflows increases effective size aggregate bit filter entire join operation figures show results partitioning non-partitioning attribute joins bit filtering applied tests conducted cpus disks notice relative july sort-merge key-filtered hybrid key-filtered grace key-filtered simple key-filtered memory smaller relation sort-merge nonkey-filtered hybrid nonkey-filtered grace nonkey-filtered simple nonkey-filtered figure partitioning attributes join attributes processors disks figure partitioning attributes join attributes processors disks positions algorithms changed execution times dropped comparison results shown figures performance improvements bit filtering individual algorithm shown figures interesting effect note shape curves grace join algorithm memory reduced execution time falls memory ratio reaches buckets begins rise explained implementation bit filtering memory tuples approximately site attempt set bit filter gamma single kbyte packet filter shared joining sites yielding bits site overhead bits set effectiveness filter low small percentage probing tuples eliminated filter memory decreased number buckets increases separate filter join bucket buckets gains eliminating additional probing tuples exceeds cost scheduling extra bucket response time drops effect occurring buckets non-joining tuples eliminated filtering hybrid join algorithm experiences bit filtering effects result obvious memory reduced amount disk increases harder isolate effects bit filtering july processors disks figure processors disks figure hybrid nonkey-filtered hybrid key-filtered hybrid nonkey hybrid key memory smaller relation processors disks figure processors disks figure simple nonkey-filtered simple key-filtered simple nonkey simple key memory smaller relation sort-merge nonkey-filtered sort-merge key-filtered sort-merge non-key sort-merge key memory smaller relation memory smaller relation grace key grace non-key grace key-filtered grace nonkey-filtered grace algorithm july similar effect occurs simple hash-join memory reduced overflows occur frequently tuples eliminated bit filters large bit filters low response times simple hash-join eliminating non-joining tuples early avoid writing tuples disk reading multiple times performance sort-merge join algorithm benefits significantly bit filters single filter tuple outer relation case eliminated filter written disk sorted read merging larger bit filter improve performance join algorithms remote joins partitioning non-partitioning attributes gamma diskless processors performing join aggregate operations goal tests section explore effect diskless processors performance join algorithms sort-merge algorithm excluded section current implementation algorithm utilize diskless processors gamma capable executing join operation mix processors disks earlier tests simple hash-join algorithm dewi performance configuration local remote configurations experiments processors disks storing relations diskless processors performed actual join computation hybrid simple grace algorithms tested remote configuration results joinabprime query displayed figure grace algorithm difference execution time join attribute partitioning attribute attribute constant entire range memory availability occurs execution time bucket-forming phase constant number buckets source relations completely written back disk response time difference partitioning non-partitioning attribute cases reflects savings gained shortcircuiting network bucketforming phases partitioning attribute joins shortcircuiting explains spreading difference shown hybrid joins memory tuples shipped remotely processing join types joins half required memory partitioning attribute joins write half building probing tuples disk locally partitioning phase algorithm july simple nonkey simple key grace nonkey grace key hybrid nonkey hybrid key memory smaller relation figure joins executed diskless processors shortcircuiting network non-partitioning attribute joins write tuples locally table presents difference percentage local writes partitioning non-partitioning attribute joins analyzing table shows number buckets increases memory reduced relative savings local writes partitioning attribute joins increases non-partitioning attribute joins fact non-partitioning attribute joins perform partitioning attribute joins simple number buckets join type partitioning attr non-partitioning attr difference percentage local writes redistribution partitioning non-partitioning attribute joins table july hash-join puzzling memory ratio identical reasons hybrid recall hybrid simple identical point memory reduced curves spread hybrid hash function changed overflow turning joins nonpartitioning attribute joins local remote joins partitioning attributes comparison performance local remote joins partitioning attributes shown figure grace joins cost partitioning constant join processing performed partitioning attribute joins partitioning shortcircuit tuples joining phase tuples distributed join processors building probing joins locally tuples shortcircuit network addition result tuples remote-join processing shortcircuiting benefits realized joining phase explanation describes observed hybrid join performance crossover response time graphs simple hash-join algorithm memory ratio decreased result switching hash functions overflow recall hybrid simple join algorithms equivalent memory hold smaller relation discussed previous section hybrid joins faster locally remotely join attributes partitioning attributes section show opposite true joins non-partitioning attributes memory crossover occurs overflows occur simple hash-join non-partitioning attribute join performance degrades results support reported dewi gamma kbyte disk pages local remote joins non-partitioning attributes non-partitioning attribute joins joining attribute results presented previous sub-section longer hold figure shows performance hash-join algorithms non-partitioning attributes local remote configurations grace joins figure demonstrates local joins superior performance remote joins constant margin entire range section motivation change hash functions july partitioning attributes join attributes simple nonkey remote grace nonkey remote simple nonkey local grace nonkey local hybrid nonkey remote hybrid nonkey local memory smaller relation hybrid key remote hybrid key local grace key remote grace key local simple key remote simple key local 
guessed measuring system comp time high comparisons general purpose gamma compare key routine works keys arbitrary type arbitrary positions tuple move times measurements moving tuple slotted page slotted page incurs additional overhead compared simple unix bcopy times byte pages finally general sample involved random ios index page locate data page randomly selected tuple data page notation number records page number bytes page memory disk number pages main memory number records number processors interesting case case multiprocessor sort passes requires processor space exceeds square root number pages allocated whichallows large les processor pages sorting processor sort page processors byte pages multiprocessor sort twogigabyte number memory pages processor increased megabytes -node multiprocessor sort gigabyte passes numbers large sorted passes table page stg case two-pass case top level algorithm works parallel processors sample fragment disk-resident parallel processors sort samples send samples single processor sorted sets samples merged approximate splitting vector computed total sorted set samples splitting vector broadcasted processors parallel processors read fragment splitting vector redistribute records processor processor memory lled incoming records processor sorts records writes sorted run disk continues reading incoming records parallel processors merge sorted runs disk backonto disk wenow cost step turn concreteness set expected number samples processor guarantee skew certainty sampling takes time sample sorting local set sampled keys assuming in-memory heapsort takes log comp cpu time local sets sampled keys gathered single node sorted simplest haveeach processor send message designated processor processor total sort cientwayisto embed binary tree hypercube initially leaves send sorted samples parents sets samples merged parents send sets samples parents root tree complete sorted set samples total time initiation sort leaves completion nal merge root tree nlog comp sort initial sets samples processor comp move merges tree time merges computed parents leaves merge les size cost comp move grandparents leaves merge lesofsize root merges les size log sum quantities comp move network cost gather samples log msg seconds network cost broadcast resulting splitting vector processors log msg seconds partitioning source assume record processor binary search splitting vector determine processor belongs copies page tuples bound processor cost step log comp move finally ship data time msg sort incoming records note processor hold records memory sort records kbm times extra factor skew assuming sort heapsorting key ptr pairs copying records nal position cost kbm log comp sort keys kbm move move records output ers write disk nal merge processor heaviest load kbm runs records time spent kbm read runs kbm log kmb comp compares merge nally kbm move copy records output pages write disk gathering terms depend skew equation cost function skew expression involves terms log determine optimal skew optimal number samples numeric method roots derivative equation simpler compute reasonable range skews increments return gave smallest determine number samples implemented approach searching found wide range numbers processors wide range problem sizes taking samples processor close optimal result supported experiments implementation reported section note equation bykeeping number samples processor constant letting skew grow slowly processors added makes intuitive sense number processors grows keeping size source constant amountofwork exclusive sampling processor decreases keeping number samples constant implies sampling takes larger larger fraction execution time number processors increases increase number samples processor number processors grow increase fraction total running time due sampling quickly swamps gains obtained reducing skew goal predict absolute performance numbers comparison predicted numbers measured numbers implementation show fairly good agreement table compares predicted measured numbers varying numbers processors case sorting million byte tuples samples processor num processors predicted time sec measured time sec ratio table analytic model predictions measured performance exact splitting section algorithm proposed byiyer nding exact splitting vector complete algorithm complex iyer irv fordetails wehave adapted steps shared-nothing multiprocessor original algorithm designed shared memory mind goal section present algorithm give intuition justify model cost probabilistic splitting section assume wehave processors records rst step exact splitting algorithm processor fully sorts fragment producing sorted runs processor recall goal compute -element splitting vector divides entire equally sized segments algorithm explained terms computes single splitting element suppose sort-key partitions entire segments initial records entire sorted records entire sorted assume thatf case symmetric algorithm proceeds processor selects equally spaced elements sorted run note randomly chosen elements chosen equal intervals sorted run processors sends elements single processor merges elements computes exactf splitting elements exactf splitting broadcasted processors processor determines pair elements elements chosen step bracket broadcasted splitting processors form coordinated binary search records intervals bracketing elements determine exact splitting detail suppose previous iteration splitting determined processor determined records sorted order bracket current iteration processor reads element sorted order sends element coordinating processor determines splitting process continues atwhichpoint current guaranteed exact splitting entire step description greatly simpli guaranteed time algorithm true nal splitting bracketed current general algorithm searchforward backward interval wehave case exact splitting bracketed case results fewest number records read terms description iyer irv assuming cases pages occur recall describes single element splitting vector compute full vector previous algorithm repeated iterations make work processor exact splitting proportional number processors system wenow develop simple analytic model performance sorting algorithm exact splitting case model probabilistic splitting goal predict absolute numbers wewanttomake relative comparison probabilistic exact splitting identify key parameters determine algorithms relate case probabilistic splitting assume sorted passes case algorithm top level processor sorts local segment processors cooperate determine exact splitting vector processors redistribute data write sorted incoming runs disk processor merges runs disk wenow cost step turn initial sort takes time read local segment order form initial sorted runs write runs disk cpu form initial sorted runs log move run bkm runs merge runs reads sequential writes random cpu merge log bkm move analyzing cost determining splitting vector complicated divide cost parts initialization iterations recall process determine splitting elements rst cost nding single splitting element quantile set consists quantiles basis initially weneedtoread pages disk cost processor send initial keys processor sorted probabilistic splitting assume keys gathered passed binary tree processors sorting initial sort log comp merges tree total comp network cost log msg gather keys log msg distribute splitting constant cost sum basis operations quantiles sum preceding quantities tok iterations cost 
iterations quantile explained number iterations log iteration consists reading midpoint consecutiveelements cost sending designated processor log msg assuming pass elements binary tree processors sorting elements log comp nally sending message backtoeach processor log msg total cost sum quantity tok completes cost quantile determination quantiles computed computation proceeds case probabilistic splitting redistribute data assume record processor binary search splitting vector determine processor belongs copies page tuples bound processor cpu cost step log comp move cost network cost redistribute data msg processor write incoming tuples disk cost finally processor merge runs whichwillentail cost cpu cost log move note skew analytic results comparison clear probabilistic splitting exact splitting terms add ideal unrealistic situation perfect splitting vector priori cost probabilistic splitting adds explicit cost sampling implicit cost due skew phases algorithm exact splitting adds explicit costs processor sorting original segment iterative algorithm compute exact splitting vector broad terms analytic model predicts shared-nothing multiprocessor sample tolerate skew compute exact splitting vector relative erence performance algorithms increases number processors applied sort grows figure shows performance predicted algorithms sorting million byte tuples processor allocated pages bytes total bytes sounds small number pages discuss section found long memory sort passes performance sorting algorithm insensitive amount memory allocated pages tuples page processor sort tuples passes processors smallest number processors plot figure multiprocessor sort million tuple relation passes probabilistic exact number processors execution time seconds figure analytic model predictions sorting tuples complete range processors considered probabilistic splitting faster exact splitting large numbers processors execution time exact partitioning begins increase processors added due fact processors system algorithm individual partitioning elementmust repeated times mentioned sections developed models regard relative positions curves shapes important absolute numbers reason remainder section present graphs ratios execution times algorithms execution times speci cally show ratio time exact splitting time probabilistic splitting line graph corresponds probabilistic splitting fast exact splitting factor weinvestigated dependence performance algorithms record size sampling general expensive tuple sizes decrease random sample pull complete page means tuple sizes decrease random sample represents larger percentage time scan figure shows erence relative performance algorithms sorting million byte tuples million byte tuples million byte tuples graph relative performance twoalgorithms remains approximately constantfor tuple sizes reason exact splitting adversely impacted small record sizes binary search phase algorithm probe relation pull complete page order examine single tuple curve byte tuples stops processors million byte tuples memory pages bytes processor processors entire relation aggregate memory multiprocessor entire relation memory cost model assumed two-passes invalid byte tuples byte tuples byte tuples number processors ratio exact probabilistic figure analytic model predictions sorting byte tuples wealsowanted investigate dependence algorithms problem size figure shows predicted relative performances algorithm les byte tuples shape curves explained noting roughly number page reads processor sampling portion probabilistic splitting precise number depends hit ratio index pages pool sampling number page reads processor percentile determination phase tuples tuples tuples number processors ratio exact probabilistic figure analytic predictions ratios algorithms tuple les exact splitting number processors grows signi factor running time exact splitting ratio running time exact splitting probabilistic splitting grows grows fraction total running time represented bythesek hidden running time sorting portion algorithm essence means grow ratio running times grow compare curves erentvalues larger ect delayed takes processors probabilistic dominates produce curves gure scaled memory processor problem size pages tuples pages tuples nally pages tuples started processors ensured data point sort completed twopasses finally weanticipated size grows probabilistic splitting attractive absolute sense comparison exact splitting figure shows speedups probabilistic partitioning sizes gure basis point processors speedups ratios respect processor time implies perfect speedup processors basis single processor les sorted passes figure implies larger size processors probabilistic splitting apply ectively sorting problem intuitively reason add processors amountof sorting work processor decreases amount sampling work processor remains constant large sizes processors sampling time tiny fraction total execution time seconds seconds tuples smaller les sampling time processors signi portion fraction total execution time seconds seconds tuples tuples tuples tuples number processors speedup figure analytic model predictions speedup tuple les description implementation order investigate performance parallel sorting algorithm based probabilistic splitting implemented algorithm gamma database machine dgs experimental vehicle gamma falls class shared-nothing sto architectures hardware consists processor intel ipsc hypercube processor con gured cpu megabytes memory megabyte maxtor disk drive disk drive embedded scsi controller whichprovides kbyte ram acts disk cache sequential read operations nodes hypercube interconnected toform hypercube custom vlsi routing modules module supports full-duplex serial reliable communication channels operating megabytes sec gamma built top operating system designed speci cally supporting database management systems nose multiple lightweight processes shared memory non-preemptivescheduling policy preventconvoys bgmp occurring nose communications nose processes reliable message passing hardware intel ipsc hypercube file services nose based wisconsin storage system wiss cdkk services provided wiss include sequential les byte-stream les unix tree indices long data items external sort utility scan mechanism sequential sequence records mayvary length page inserted deleted arbitrary locations optionally mayhave indices map key values record identi ers records matching indexed attribute designated clustering attribute ingamma relations arehorizontally partitioned alsoknownasdeclustering lkb disk drives order increase aggregate bandwidth provided hardware query language gamma user alternative declustering methods experiments user determined tuples reside site based range predicate applied partitioning attribute tuple relation collection tuples stored processor referred fragment relation parallel sorting algorithm based probabilistic splitting operates processor randomly samples local fragment relation sorted sends sort attribute values sampled tuples central coordinator coordinator sorts sampled values determines partitioning elements relation divided partitions processors coordinator sends vector partitioning elements processor disk fragment relation phase algorithm relation redistributed elements splitting vector phase begins initiating scan sort processes processor initiated scan process reads local fragment relation re-distributes network elements partitioning vector gamma terminology split table determine processor tuple routed tuples redistributed byte network packets packet tuples arrives processor sort process adds packet memory resident sort incurring copy time sort lls array pointers tuples sorted wiss quicksort algorithm finally sorted run process materializes sorted run copying tuple network packet output page writes disk nal phase algorithm sort processes merges sorted runs single run written back disk implemented algorithm terminates sorted relation partitioned disks system con 
objects databases decade turmoil michael carey ibm almaden researchcenter harry road san jose carey almaden ibm david dewitt computer sciences department wisconsin-madison madison dewitt wisc abstract decade ago connection objects databases explored number erentways community driven perception managing traditional business data largely solved problem projects investigating ideas adding abstract data types relational databases building extensible database systems objectoriented database systems toolkits constructing special-purpose database systems addition work underway computer science research community extending programming languages database-inspired features suchaspersistence transactions paper wetake eld decade ago terms database support objects vice versa research projects commercial database products share vision biases future objects databases identify anumber researchchallenges remain addressed order ultimately achieve vision permission copy fee part material grantedprovided copies made distributedfor direct commercial advantage vldb copyright noticeand title date noticeis copying permission large data base endowment tocopy republish requires fee special permission endowment proceedings vldb conference mumbai bombay india introduction ten years ago database eld onthe verge ofan interesting confusing era era objects databases rest computer science term object meant erent things people database community addition multiple ways object-oriented technology impact database systems internally externally explorations newly underway time work grouped rough areas extended relational database systems persistent programming languages object-oriented database systems database system toolkits components research extended relational database systems progress years beginning bear signi fruit ston althoughworkonpersistent programminglanguageshad underway time programming languagescommunity atki work applyingthose ideas object-oriented languages taking object-oriented database systems brand idea born cope finally work database systemtoolkitsand componentarchitectures including exodus project care begun wishing gain deeper perspectiveinto eld time ditt interesting accurate snapshot objects databases decade things clearer view areas panned produced interesting stream research results outlast speci page areas fact weanticipate not-too-distantfuture real survivor remaining list survivor bene ted successes mistakes goal paper informal wehave wearenow headed unbiased opinion caution reader intended scholarly work spotty incomplete refer interested readers resources zdon ston kim aswell proceedings conference series vldb sigmod information topics results touch remainder paper organized section reviews state objects databases decade ago examining ways technologies combined section today erent combinationshave panned terms research accomplishments commercial database systems standards section present views objects databases heading howwe researchers eld fromhere finally section concludes paper objects databases wehave explained world objects databases exciting confusing place traditional database researchers extending favorite data model relational incorporate complex types data programming language researchers busily adding persistence permanent data storage object-oriented languages rapidly gaining favor researchers proposing radical approaches accommodating data management applications camp believed combining key features objectoriented programming languages database management systems yield generation onesize- ts-all database systems camp felt answer toolkit aid system developers building domain-speci database management systems camp objects important contributing technology toolkit extended relational database systems rst approach proposed moving databases applicationswas evolutionary approach open type system relational database system addition user-de ned abstract data types adts adt user required implementthetype ning representation writing functions external programming language type registered database system making system aware size functions included functions provided functions input output instances adt registered system adt built-in type ning type attribute relation adt functions queries dynamically loaded needed runtime approachwas pioneered adt-ingres effort uc-berkeley early ong mids postgres project began follow-on ingres initially laying approach providing query optimizers information properties adts functions ston goal postgres provide support storing querying complex objects postgres project advocated radical procedure data type approach ston rejected codasyl-like pointer spaghetti felt characterized systems supported inter-object object-oriented database systems precomputation query rewriting techniques held approaches avoiding overheads problems procedure-centered proposal persistent programming languages erent approach addressing complex data-intensive applications advocated programming language community takethe type system programming model objectoriented programming language smalltalk clos clu trellis owl aclu descendent orc add features make data persistent programexecutions atomic argument approachwas someapplicationsjust manage permanent data happy imperative programming model language type system constructing complex persistent data structures applications bene signi cantly fromlosingthe impedance mismatch arises boundary programming language type system meets relational database type system good survey state area decade ago objects entering persistent language scene found atki respects recent manifesto darwen date darw combinationof rediscovery elaboration approach page workinthis area involvedaddressing alternativesolutions number problems orthogonality anytype made persistent persistence models persistence reachabilityversus persistence allocation binding namespace management persistentroots type systems type safety alternative implementation techniques supporting transparentnavigation maintenance garbage collection persistent data structures object-oriented database systems radical approach addressing perceived non-traditional database applications engineering applications emerged time database community combine features modern database system object-oriented programminglanguage yielding object-oriented database oodb system early oodb projects laidthe foundationinthis area gemstone cope maie whichwas based smalltalk vbase andr whichwas based clu-likelanguage orion bane whichwas based clos major motivation reduce eliminate impedance mismatch cited discussion persistent programming language work distinguished work object-oriented databases work persistent languages focus support queries indexing navigation afocus addressing versionmanagementneeds engineering applications decade earlier early days relational database systems single ned data model relations whichwere sets tuples simple attributes similarly competing relational query languages emerged early quel sql early days oodb systems erent agreement details data model underlying language type system query model language version management features provided systems general agreement oodb communitythat direction support engineering applications bit commonality approaches viewed altitude emerging oodb revolution spawned work manyaspects systems including data model details query languages indexing techniques query optimization processing techniques system architectures user interfaces prettymuchevery aspect database systems readily imagine database system toolkits components major approach proposed time based belief type dbms meet functionality performance requirements broad range next-generation applications camp advocated erent approach provide dbms extended anylevel extensible dbms based set kernel facilities tools aid developers rapidly building domain-appropriate dbms members camp envisioned database systems specialized application domains documents managed document-oriented database systems geographic data managed geographic information systems domain-appropriate dbmss haveanumberoffundamental erences erent query languages erent access methods erent storage organiguration processors rst kth approximately relation stored disk attached processor kth processor modifying implementation entire relation materialized sorted order host processor application program straightforward order minimize number random seeks performed pages sorted runs read written blocks composed kbyte pages random seeks occur phases algorithm rst phase algorithm scan process node reading blocks unsorted relation redistribution process node concurrently writing sorted runs disk processes read write erent regions disk operation involves random seek problem occurs merge phase sort page read input run written output run incurs random seek performing operations blocks pages provide improvement system ipschypercube support ibm-style channel programs improvement dramatic process issued request operating system determines process runnable context switchis performed process selected run immediately performs operation time rst process allowed run disk heads moved negating bene provided blocking operations initial implementation byte pages con guration provide adequate performance added multi-block feature change improve performance muchaswe expected pages time improved performance single page hand switching toa single byte page improved performance general database system operations sorting large pages decrease performance forexample index operations insteadoflong pages amuchbetterlong-term solution modify gamma operating system accept vector operations executed order interesting thing observed running preliminary experiments maximum space generally minimize execution time sort memory scarce resource obtaining long runs important order minimize number passes long amount memory square root data size size entire data sorted passes cpu cost sort independent size run producing longer runs reduce cost making sort cpu bound graefe made similar observation gra tests required passes experimentation found size pages balanced cpu time tended minimize execution time sort operation implemented version algorithm sorted runs produced tournament sort fact runs produced long produced quicksort version ran slower problem overcome parallel algorithm correctly ciently sample relation parallel order determine partitioning elements correctness relation sampled stored single processor tuple processor stored equally sampled statistical terms simple random sample note samples acceptable haveeach processor samples result random sample note processor takes samples set samples tuples single processor portion database totake random sample making parallelism implementation processor attempts sample tuples local fragment relation processor random number generator seed ciency processor checks local catalog information determine tuple sample stored local disk tuple retrieved disk sort attribute sampled tuple stored locally sample terms disk ect central processor generated random keys senttoeach processor keys tuples partition stored b-tree index ciently retrieve tuple sample note optimization require sort attribute relation identical attribute partition relation relation creation requires attribute fetch random tuple attribute partition relation relation creation attribute algorithm works correctly performance degradation due unsuccessful searches index tuples stored processors results scaleup speedup metrics evaluating performance parallel algorithm amultiprocessor database machine scaleup interesting metric multiprocessor database machines constant response time maintained workload increased adding proportional number processors disks speedup interesting metric additional processors disks result decrease response time query similar set experiments reported egks equi-join queries release tandem nonstop sql system dgs forequi-join queries gamma dns fornon-equijoin queries gamma scaleup speedup results parallel sorting algorithms contained gra stg interesting metric algorithm performance call sizeup number processors held constant size problem instance varied sizeup tests growth rate execution time function problem size salzberg reported sizeup numbers sorting stg con guration results reported section relation sorted evenly distributed relation creation processors applying range predicate unique attribute values range relation cardinality minus sort performed unique attribute relation values attribute range relational cardinality minus values unique unique attributes tuple correlated sorting relation unique attribute processors results kth tuples relation redistributed repartitioning phase algorithm randomness sample size return scaleup speedup sizeup section initially present results illustrating dependence execution time sample size brie uptoacertain point taking samples signi cantly reduces skew total execution time point time spent sampling outweighs savings due reducing skew aspect dependence execution time number samples probabilistic nature probabilistic splitting taketwo erent sets samples size quality splitting vector generated samples general random samples representative actual population means run sorting algorithm erent random samples size running time sort sets samples samples lower variance running time erent sets samples sampling avg avg-s avg number samples execution time seconds figure sorting time function sample size figure illustrate twoaspects relationship number samples execution time graphs represent set experiments sort million byte tuples processors varying sample sizes sample size ran trials initializing random number generator erent seed eachtime graph figure lines point lowest line labeled sampling average elapsed time thirty trials samples forapoint middle upper lines average total execution time sort thirty trials samples point uppermost upper lines average total execution time sort standard deviation samples standard deviation computed thirty trials similarly point lowest upper lines average total execution time sort minus standard deviation samples standard deviation computed thirty trials graph figure expands scale top lines graph figure additional lines added showing maximum execution time observed trials number samples showing minimum nal pointwe emphasize performance probabilistic splitting depend distribution data sort attribute demonstrate experimentally generated instance relation sorted sort attribute drawn highly skewed normal distribution million values drawn normal distribution variance table shows performance sorting algorithm skewed uniformly distributed sort attribute lines table refer sorting million byte tuples processors samples average min max variance reported trials trial erent random seed avg avg-s avg min max number samples execution time seconds figure variance sorting time function sample size distribution average time sec max sec min sec std deviation sec uniform skewed table performance sorting skew uniform distribution scaleup scaleup experiments wevaried number processors disks steps sorting average byte tuples processor processors million byte tuple relation sorted processors size relation sorted million tuples section implementation processors total samples means processors samples processors timings presented averages trials trial erent random seed table presents scaleup results obtained ideally algorithm exhibit constant response time relation size hardware con guration scaled factors contribute slight increase response times additional processors added skew sizes portions allocated processor grows task initiating processes site sampling operator relation scan sort operator store operator performed single processor finally number processors increase ects short-circuiting dgs messages execution query diminishes processor con guration approximately tuples input relation end sort process processor short-circuiting communications network number processors increased number short-circuited packets decreases point 
zations erent transaction mechanisms key projects representing approachwere exodus project care genesis project bato dasdbs project depp exodus provided storage manager objects care provided persistent programming language based writing access methods query operators provided query optimizer generator generating optimizer domain-appropriate query language rule-based language speci cation genesis provided set composable storage indexing primitives database system compiler assembling storage manager 
speci cation dasdbs provided complex object storage manager witha multi-layeredtransaction facilityasakernel domain-appropriate data model query layer built layering modeled rss rds separation system importantproject started time ibm starburst project schw starburst classi partly component-based dbms support storage indexing components major goal classi extended relational dbms centered relational model terms query language sql models query optimization execution key goals starburst develop clean architectural model facilitate storage indexing related extensions explored rule-based approachtoproviding extensible query processing subsystem page summary clear turmoil database research community competing approaches leveraging objectoriented ideas database world eachwithits believers commercial world part ten years relational database system technology nally maturing terms commercial products relational systems nally starting adopted enterprise-scale applications extended relational persistent programming language database toolkitproducts twotinyoodb companies servio logic gemstone fame ontologic vbase fame nowontos attempting market rst product offerings years panels database research conferences debated virtues evils objects argued utilized packaged database world objects databases wenow fast-forward today roughly ten years initial object explosion database eld erent approaches considered back whichhavedied wounded cropped meantime approaches healthy growing view nutshell approaches database system toolkits persistent programminglanguages generated anumberofinteresting results bothapproaches essentially proven dead-ends practical commercial sense approaches object-oriented database systems led research results academic community product offerings small startup companies approach failed live original commercial expectations approach based generating languagespeci object wrappers relational databases emerged commercial database scene approach appears important building object-oriented client-side applications approaches extended relational database systems renamed object-relational database systems called likelytoemergeastheultimate winner terms providing objects mainstream enterprise database applications section closely eachof points brie touch related developments corba ole java middleware appeared scene past years casualties mentioned casualties past decade ironically reason paper database toolkit approach toolkits suchasexodus genesis dasdbs essentially fallen bythewayside aware ongoing work area reason expertise ended required ended bit exible awkward incomplete dimensions database system design space reason object-oriented objectrelational database systems managed provide extensibility proven worthwhile formostbuilders ofdomain-orienteddata management facilities simply start scratch toolkit simplify process illustrate problems brie exodus experiences exodus provided fullfunction client server storage manager handling object storage persistentvariant simplify management objects construction access methods query operations rule-based query optimizer generator simplify development cient query processors number research projects startup companythatweknow made exodus storage manager common problem wanted exodus implement object servers exodus storage manager client server architecture tended introducing unwanted level indirection systems care someprojects alsomadeuse programming language database implementors preferred control low-level details ering concurrency recovery application-oriented programmers found abittoolow-level collections queries exodus query optimizer generator general ine cient hard left predicates logical query rewrites implementorwhen appliedto full-functionlanguage sql put exodus test nowbecharacterized object-relational page data model extra query language excess designed mid-way exodus project care tomake long story short found waytoomuchtodoin building system declare exodus succeeded regard luckily good news exodus project nonetheless managed produce number interesting researchby-products including system design implementation performance studies direct relevance object-oriented object-relational database systems steady stream rst-rate graduate students wehave characterized persistent programming language area casualties decade-long object wars unlike toolkits area research active academia characterization stems fact weareaware commercial implementation properly characterized apure persistent programming language bad news balanced good news aswork persistent languages signi impact navigational programming interfaces manyoftoday object-oriented database products addition results area topics persistence models pointer swizzling schemes garbage collection schemes persistent data directly transferable objectoriented databases bad news subsection paper discuss transfer target object-oriented database eld expanded commercially rate founders contributors expected object-oriented database systems tremendous amount happened objectoriented database area past decade early milestone helped focus researchanddevelopment general prescription developed collection leading database system language researchers constitutes object-oriented database system atki agreed systems support complex objects object identity encapsulation inheritance substitutability late binding computationally complete methods extensible type system persistence secondary storage management concurrency control recovery hoc queries optionally choose support multiple versus single inheritance static versus dynamic type checking distribution long transactions version management open individual choice programming paradigm language choice exact details type system degree fanciness type system templates degree uniformity purity object model research energy expended object-oriented database area manyinteresting results produced variety data model issues examined including basic object models support composite objects schema evolution object-oriented query language proposals appeared haveanumber papers query processing issues languages handling path expressions nesting manyschemes designed indexing object-oriented databases addressing issues efcient andupdates paths queries portions class hierarchy pointer-based joinmethodsand complexobject assembly schemes studied queries large object bases alternative client server architectures proposed studied including schemes transactional data caching client server crash recovery algorithms designed data-shipping environments common objectoriented database systems series oodb benchmarks published characterize performance systems finally anumber version con guration managementmodels proposed implemented systems side signi cantsystems ground-breaking prototypes important systems included objectstore ode whichhave signi degrees oodb research impact numerous commercial oodb products market today currentplayers oodb marketplace include gemstone objectivity objectstore ontos poet versant addition consortium oodb product vendors banded leadership rick cattell sunsoft early formed object database management group odmg group worked draft oodb standards object data language odl object query language oql programming interface manipulating querying object databases latest version speci cation called odmgrelease published earlier year catt research companies draft standard possibly wrong things decade hard work impossible gain complete agreementonanything object-oriented database systems today erences oodb products terms details programming interfaces implementation twists query support odmg standard form approximately page years vendors support standard divided pieces chapters standard manyvendors choosing support piece piece aware vendor supports object query portion standard oql object-oriented database products bit relational database products respects view facility fact prerequisite research area nished opinion schema evolution painful oodb world oodb products rely codasyl-like schema application compilation cycle coupling oodb application programming language tight single-language commonly systems intents purposes addition robustness scalability fault-tolerance oodb products match relational database products problems application development tools client server computing environments haveevolved tools area fewer end-user tools application objectoriented database world tools widely today application development relational world pc-based applications talking odbc relationalservers haveemergedasacommon architecture database applications dramaticallyreduced number programmers writing lower-level database code embedded sql turn diminished impact impedance mismatch led dominant computing environment thin clients fat servers opposite design point objectoriented database systems response oodb systemvendors havedeveloped odbc 
connectivitysolutions solutions exploit objectoriented features underlying database systems partly result aforementioned problems commercial oodb market grown bit slowly expected expected consumers oodb technology cad system vendors slower expected moveaway relying les store data commercial database world large enterprises barely nished embracing relational technology wholeheartedly anxious undertakeyet major paradigm shift object-relational database systems parallel explosion work objectoriented database system area extended relational database systems matured products today fromseveral vendors ca-ingres ibm illustra unisql fact timethese systems adopted attractive data model query language features oodb world trend doubt continue path object-relational database systems extended relational database systems ston foretold document drafted erent set leading database researchers comm response oodb manifesto cited earlier atki documentgave main tenets so-called third-generation database systems provide support richer object structures rules subsume generation relational dbmss open subsystems tools multidatabase middleware products laid set detailed propositions third-generation database systems provide richtype system inheritance functions encapsulation optional unique ids rules triggers highlevel query-based interface stored virtual collections updatable views separation data model performance features accessibility multiple languages layered persistence-oriented language bindings sql support query-shipping client server interface object-relational systems objectoriented database systems aboveways start relationalmodeland query language sql build terms object features current early products provide support twotypes objects adts section row types composite types adts user-de ned base types discussed earlier role enable set built-in types dbms extended data types text image audio video time series point line polygon enable dbms manage kinds facts entities enterprise database intended model employee resume photograph addition salary rowtypes direct natural extension type system tuples make rows intables toenjoy object-like properties named types functions methods addition base type attributes row objects permitted reference-valued attributes model-wise typed row ref dept treated ananotherpaperthatwewouldrecommendtointerestedread- ers kim explains object-oriented relational database technologies combined perspective unisql founder page avor base type supported multivalued attributes attributes values sets bags arrays lists base type elements lastly inheritance supported enable natural variations rowtypes captured schema persons students employees workstudystudents havemuch common topmost level object-relational database schema collection named relations objects relations nowbeasrich supported oodb systems sql extensions object queries include features path expressions method-like function invocation syntax support nested sets from-clause oodb systems past decade research results workonprototypes ofobjectrelational database systems build relationaldatabase technology basic foundationalready existed required system extensions explored contexts postgres project berkeley extra excess ort exodus project wisconsin starburst project ibm almaden currentparadise project wisconsin dimensions object query support object-relational systems bene directly work oodb area mentioned vendors ering products degrees objectrelational functionality ibm system supports user-de ned base types functions rules andlargeobjects asdoes ca-ingres system rst commercial system features unisql support user-de ned base types provide support row objects inheritance including view support fact illustra complete product functionalitywise object relational market supports features form addition server products vendors starting market readymade adt-based type extension packages managing data types image text illustra datablades ibm database extenders predict add-on packages willbe primary early driver acceptance object-relational database technology object-relational database systems today extent problem plagues oodb systems erences notice object-relational database systems ended adopting pointer spaghetti approachthatpostgres workedto avoid thatwere advocatedand studiedelsewhere zani care interesting note foundation manyof rowtype extensionspredatesthe initial object revolutionby years laid part orts daplex ship gem zani vendor vendor sql standards effort working hard standardize features included adt concept time amended recently include support row objects unlikethe oodb marketplace major database vendors pushing direction concerned standards major vendors ibm signi object-relational features working implementing extensions informix recently purchased illustra promisingcustomers amerged universalserver product late oracle promising version substantial object support similar timeframe object-oriented clientwrappers addition approaches actively studied decade ago approach recently gaining favor commercial world object wrappers relational databases support development object-oriented client-side applications working legacy databases number vendors products today including persistence software ontologic products language-speci generate smalltalk classes act proxies data underlying database permitting programmers interact data natural programming tools tools aid developers ning constructing objects underlying database rely key-to-oid mappings maintain correspondences programming objects database data attractiveness wrapper approach itenables object-oriented applicationstobe written today enterprise data makingan object-oriented design methodology implementing business objects disadvantages products tend weak query side requiring hoc queries posed sql underlying relational schema creates paradigmmismatchfor application programming querying force design paradigm choices representing business logic utilize underlying database system triggers procedures constraints enforce data integrity code business rules procedures dbms smalltalkon client side makesuch decision unfortunate reality page related developments moving lies ahead wemust mention number related developments object area havesome impact database world technologies corba ole javahave attracting industry attention recent trend growing importance database middleware wewill discuss technologies brie corba standards developed object management group omg confused odmg focused solving problems arise developinglarge distributed object-oriented applications biggest success ning standards interoperable object rpc mechanism addition havedeveloped standards services registering locating named resources distributed environment expect corba continue important respects addition omg attempted number factorable object services including persistence service collection service indexing service transaction service predict omg fail years database research separate majority services indexing transactions collections andqueries inamannercapable ofprovidinganything approaching reasonable performance advocate corba ne-grain access database data making database object acorba object weexpectsuch approaches willperform poorly ultimately fail corba stick coarse-grained object rpc related support services opinion set facto object standards microsoft interfaces ole underlying object model distributed microsoft answer corba source standards ole key technology build manage desktop data wintel world major vendors working integrate ole support database engines tools clear support ole adts important future looming horizon microsoft ole work blak ers approach separating query optimization execution world data lives addition databases wewill comment ole section discussion object trends complete touching java furor recently sweeping computer industry past year javaisessentially safe subset standard machineindependent pcode-like representation executable java programs javawas designed enable safety checks guaranteesthatmake shipping javacode applets internet reasonable reason currentjava furor howwilljava impactdatabase systems willmention java section potential impacts clear javawould ideal language writing adts executed server side client side database world trend importance growing market database middlewareproducts products provide uniform interface multiple backend database systems client side todayis undoubtedly microsoft access product relational query access anybackend dbms speaks odbc permits queries draw data multiple backends server side 
memory smaller relation figure figure partitioning attributes join attributes memory bucket-forming phase grace algorithm involves processors disks execution time phase constant processors actual join operation memory ratio expect join phase grace algorithm behave one-bucket hybrid join hybrid executes joins diskless processors faster memory ratio inconsistency recall section grace algorithm non-partitioning attribute joins effectively partitioning attribute joins bucket-forming phase results obtained partitioning attribute joins previous section displayed figure directly applied case difference local remote response time exists non-partitioning attribute join times slower partitioning attribute join times increased costs bucket-forming discussion contained section explains performance hybrid algorithm memory availability bucket-forming joining phases completely overlapped experiments involve non-partitioning attribute joins tuples distributed joining processors resulting subjuly stantial network traffic remote processing wins case joining relations tuples distributed processors cpu cycles building probing hash tables successfully offloaded diskless processors memory reduced local joins partitioning phenomena discussed hybrid joins section explains shift performance memory availability half tuples joined written disk disk bucket subsequently joined effectively partitioning attribute join memory reduced larger fraction join partitioning attribute join illustrated figure partitioning attribute joins executed faster locally remotely explains curves crossover difference widens memory reduced performance simple hash-join algorithm easy explain fastest remote processors memory availability reasons hybrid doesn crossover hybrid writing subsequent reading overflow files benefits shortcircuiting modification hash function hash table overflow eliminates possibility achieving performance observed partitioning attribute joins non-uniform data distributions set experiments wanted analyze performance parallel join algorithms presence non-uniformly distributed join attribute values order isolate effects non-uniform data distributions varied distribution join attribute values independently figure shows combinations comprised experimental design space key figure represents attribute distribution building probing relation uniform distribution non-uniform distribution response time joinabprime query performance metric set experiments recall query joins tuple relation megabytes tuple relation megabytes tuple relation building relation tuple relation outer probing relation non-uniform distribution chose normal distribution standard deviation parameters resulted highly skewed distribution values fact tuple relation attribute duplicated tuples tuples join attribute values range tuple relation created randomly selecting tuples july uniform non-uniform uniform non-uniform outer relation relation figure tuple relation tuple relation primary key values uniformly distributed normal attribute characteristics distribution tuple relation tuple relation attempt make initial scan relations joined balanced distributed relations join attribute range partitioning strategy provided gamma resulted equal number tuples disks previous experiments amount memory relative size smaller joining relation basis comparing join algorithms remember amount memory sufficient join tuples distributed evenly joining processors processors disks experiments table presents results parallel join algorithms cases memory availability joins produced result relation tuples joins joins produced result tuples results joins presented result cardinality query tuples find normalizing results meaningfully compare results join types analyze performance join algorithms addition bit vector filters subsection july algorithm memory memory hybrid filter grace filter sort-merge filter simple filter join results non-uniform join attribute distributions response times seconds table begin analyzing effects distributed join attribute values building relation comparing results results hash-join algorithms major factors result building non-uniformly distributed attribute tuples generally distributed equally buckets chains tuples form hash tables due duplicate attribute values factor significant aggregate memory allocated join sufficient hold building relations tuples tuples uniformly spread joining processors distributed join attribute values experiments hash function distribute relation uniformly memory overflow resulted hash function perform poorly pass overflow mechanism resolve overflow join bucket factor chains tuples forming hash tables materialized distributed join attribute values fact chains tuples found average maximum hash chain length table shows slower hash-based join algorithms philosophy grace join algorithm small buckets prevent buckets overflowing executed algorithm additional bucket memory overflow occur memory availability hybrid algorithm processes overflow fairly efficiently memory reduced recall simple hybrid hash-join algorithms identical memory availability july bucket-join hybrid algorithm experiences overflow shown memory availability results cost overflow resolution significant sort-merge join algorithm run faster hashing function distribute tuples unevenly joining processors hash-join algorithms requiring subset sites store disk sort subsequently read tuples expect negative impact performance explanation recognizing merge phase join works join attribute relation skewed maximum join attribute merge phase read outer relation case semantic knowledge inherent sort-order attributes allowed merge process determine join fully computed joining tuples read similar effect occurs significant part relation skipped reading outer relation read effects outer probing relation join attribute non-uniformly distributed determined comparing results results non-uniform data distribution outer join attribute result unequal numbers tuples distributed joining processors memory availability noticeable effects shown sort-merge discussed memory reduced small differences hybrid grace join algorithms occurs memory reduced joining relations divided disjoint buckets outer join attribute non-uniformly distributed outer relation uniformly divided buckets result disk sites requiring additional disk bucket forming bucket joining number buckets increases significant effects non-uniformly distributed join attribute values feel results encouraging hybrid join algorithm argue joins re-establish relationships relationships generally one-to-many join attribute key relation side smaller building relation hashjoin algorithm case result type join shown efficiently processed july bit vector filtering expected table shows application bit vector filters improves performance parallel join algorithms table presents percentage improvement gained bit filters join algorithms shown sort-merge simple join algorithms experience greatest improvement bit filtering occurs filtering tuples eliminates large number disk grace join algorithm experiences worst speedups filtering applied joining phase bucket-forming phase disk eliminated bit filters algorithm stated section bit filtering techniques extended bucket-forming phase join algorithm join type experienced greatest improvements filtering distributed attribute values resulted collisions setting bits bit filter fewer bits set filter effect screening outer probing tuples sort-merge filtering improvement filtering allowed sorting pass outer relation grace join algorithm memory availability exception joins experiencing significant performance improvement reduced speedup traced addition extra bucket join recall section increasing buckets buckets caused extra overhead incurred network packet size exceeded extra scheduling overhead send query packets offsets bit filter benefits gained non-uniform join attribute values algorithm memory memory hybrid grace sort-merge simple percentage improvement bit vector filters table july conclusions future work conclusions drawn experiments uniformly distributed join attribute values parallel hybrid algorithm appears algorithm choice dominates algorithms degrees memory availability bit filtering cheap significantly reduce response times non-uniformly distributed join attribute values provide twist relative performance join algorithms performance hybrid join 
algorithm degrades join attribute values relation non-uniformly distributed case optimizer choose run hybrid algorithm extra buckets ensure bucket exceed memory capacity switch grace join algorithm sort-merge join algorithm conservative algorithm stable performance regard non-uniform join attribute distributions find encouraging hybrid join algorithm performs joining attribute outer relation non-uniformly distributed expect type join common case re-establishing one-to-many relationships results presented tempted conclude remote processors executing join operators good idea hybrid algorithm sufficient memory join non-partitioning attributes restrictive relation partitioning attribute non-partitioning attribute joins fairly addition gamma processes joins locally processors cpu utilization remote configuration cpu utilization processors disk drops approximately multiuser environment offloading joins remote processors permit higher throughput reducing load processors disks intend studying multiuser tradeoffs future opportunities exist expanding work instance single join process operates processor time increasing amount intra-query parallelism important point immediately optimizer bucket analyzer detects potential distribution problem increasing number buckets potentially expensive hybrid joins increasing number join processes dynamically adjusting number join processes depending load information interesting opportunity intra-query parallelism send buckets remote disks large systems buckets joined parallel july babb babb implementing relational database means specialized hardware acm transactions database systems vol march baru baru frieder kandlur segal join cube analysis simulation implementation database machines knowledge base machines kitsuregawa tanaka eds kluwer academic publishers bitt bitton dewitt turbyfill benchmarking database systems systematic approach proceedings large database conference october bora boral parallelism bubba proceddings international symposium databases parallel distributed systems austin texas december brat bratbergsengen kjell hashing methods relational algebra operations proceedings large database conference august brat bratbergsengen kjell algebra operations parallel computer performance evaluation database machines knowledge base machines kitsuregawa tanaka eds kluwer academic publishers chou chou h-t dewitt katz klug design implementation wisconsin storage system wiss software practices experience vol october cope copeland alexander boughter keller data placement bubba proceedings sigmod conference chicago june dewi dewitt katz olken shapiro stonebraker wood implementation techniques main memory database systems proceedings sigmod conference boston june dewi dewitt gerber multiprocessor hash-based join algorithms proceedings vldb conference stockholm sweden august dewi dewitt gerber graefe heytens kumar muralikrishna gamma high performance dataflow database machine proceedings vldb conference japan august dewi dewitt smith boral single-user performance evaluation teradata database machine mcc technical report number db- march dewi dewitt ghandeharizadeh schneider performance analysis gamma database machine proceedings sigmod conference chicago june gerb gerber dataflow query processing multiprocessor hash-partitioned algorithms phd thesis computer sciences technical report wisconsin-madison october jark jarke koch query optimization database system acm computing surveys vol june kits kitsuregawa query execution large relation functional disk system data engineering conference kits kitsuregawa tanaka moto-oka apllication hash data basae machine architecture generation computing vol july prot proteon associates operation maintenance manual pronet model waltham mass ries ries epstein evaluation distribution criteria distributed database systems ucb erl technical report berkeley seli selinger access path selection relational database management system proceedings sigmod conference boston tane tanenbaum computer networks prentice-hall tand tandem performance group benchmark non-stop sql debit credit transaction proceedings sigmod conference chicago june tera teradata corp dbc data base computer concepts facilities teradata corp document vald valduriez gardarin join semi-join algorithms multiprocessor database machine acm transactions database systems vol march july 
ibm datajoiner product full-function relational dbms engine facilities accessing varietyofbackend database products cost-based distributed query optimizer early object-relational ering area called unisql availableas middleware version unisql system middleware query products number relational products lie inwhat expected tobe fastest growing segments database market objects databases began past nowwehave present future hold objects databases section share vision regard predicting future cult cheat describing commercial database products latency fromresearch prototypes robust products order years makes job easier describing vision decade database products discuss challenges researchers face helping eld database solution year weenvision large enterprises reaping bene families products afully integrated solution predict object-relational database systems mature end delivering scalably robustly object-oriented database systems promisingto deliver object-relational servers provide full support object-oriented page adts including inheritance adts ability implement anyofanumber programming languages provide full object-oriented support rowtypes extended sql features area integrated sql important features including object-oriented views authorization triggers constraints sql standard day sql sql support middle-tier desktop applications servers work high-function object-oriented caching client front-ends provide developmentenvironment object model describe database levels querying navigational programming methods run cached data client server depending whichischeaper likewise queries fragments thereof true triggers referential integrity constraints types constraints business rules year speci implemented sql methods written sql imperative object-oriented language choice simplyrun makes sense run leave object-oriented databases love today remain niche solutions embedded prepackaged solution packages problems areas engineering design telecommunications on-line trading web page management serving applications demand level seamlessness highperformance moderate databases heavyweight object-relational solution address ectively niche shrink time object-relational vendors lite versions products object-oriented client wrappers leave rst step client-side direction wehavesketched server object-relational data model havemuch object-mapping work job map object-relational concepts java smalltalk object-oriented language choice tightly integrated engine sense assist early client-side enforcement business rules execution business logic cache data updates sophisticated order cooperatively process queries research challenges believes view world wecertainly number problems remain solved order year fromhere areas needing work include server functionality algorithm improvements integrated clients parallelization provisions legacy data access addition world database standards holes order realize full potential vision brie explain open problems eachof areas server functionality performance object-relational servers continue evolvefrom today sql-based relational servers early objectrelational servers research needed object query processing work draw fully large body work sql query processing fromthe order yield industrial-strength solutions year wedid marking work consulting client year ago anditwas clear work room improvement today systems applied research needed complete task object-ifying sql someofthis drawn fromwork oql similar languages work properly extending sql support views updates constraints triggers remains object-relational servers future drawuponwork object-oriented database world topics suchas path indices object clustering adt side important open problem support extensible access methods talked early days object revolution ideal solution sight industrial-strength support data types demand solutions problem clientintegration mentioned solution year include highly integrated client component atthe surface component good mappings programming interfaces needed serveobjectrelational objects programs smalltalk java languages fully integrated object query support addition navigation open problems area include querying cache database intelligentway ushing cache shipping objects client systems today cached objects base tables views caching programming interface work correctly face updates updates benchmarking work performed rst author employedat wisconsin-madison hoping publish benchmark design not-toodistant future page client side trigger triggers timely consistent manner client server boundary performance boundary notawall separating disjointworlds true enforcement constraints types methods execute properly side client server java solutions problems obvious interfaces servers provide today potential solution servers provide cooperation hooks exploited high-function client tools parallelization place research needed parallelism parallel database systems today successfully parallelize query execution relational queries object-relational queries area large enterprises parallel database systems important ultimatesuccess object-relational database systems extent relational query processing technology extended object queries true parallel execution techniques potentially sticky issues await arising fact important adts suchaslargemultimedia image video audio gis data types involve expensive operations parallelized load imbalances large execution times queries types plague large enterprises parallelizing adt operations interesting data types cpu perspectives open problem providing framework make easier issues explored image gis data types context ofthe paradise project atwisconsin dewi legacy data sources fond hope databases somedayachieveworld domination recognize solutions requiring world data moved database system universally accepted result important area research providing access legacy data sources older database systems relational pre-relational kinds systems document image management systems weenvision middlewaresolution webelievethat apromisingapproach tosolvingthisproblem place distributed object-relational query engine initial thoughts culties parallelizing object-relational dbms http wisc dewitt dewitt html vldbsum end users disparate data sources goal make data stored centralized object-relational database system approachwould make data common query interface makeavailableall nice client-side tools expect object-relational database systems support result three-layer architecture clients top wide variety data sources bottom including object-relational dbmss relational dbmss pre-relational dbmss ims non-database data sources middle providing glue object-relational middleware query engine research issues related approach legacy data access include distributed query optimization mix object-relational relational dumber data sources ective handling semistructured data structured documents web pages query semantics query processing data sources yield relevance-ranked results approach legacy data explored garlic project ibm almaden research center care semi-structured data focus tsimmis project stanford garc microsoft ole work blak addressing problem space ning protocol query processor talking non-database data sources standards area standards sql moving direction wehave outlined drawing oql inspiration areas weare concerned important areas standards addressed expect work area key area adts adts ned external programming languages process queries involving adts object-relational query processor aware information properties type operations selectivity estimates function costs ston object-relational database systems bring opportunity third-partyvendors provide libraries adts rowtypes address problem domains providing special-purpose data managers future domainspecialists make business providing extensions object-relational systems situation todayisthateachvendor supports user-de ned data types interface ning registering types fortunately sql addressing eachsuchvendor erpage ent provisions additional information needed query optimization sql addressing aspect adt registration process ultimate success third-party data type market depend emergence suitable standards area related area wewould eventual standard access method interface vendors providers index structures data types specialize areas standards bene cial year area client server interfaces nice cooperative client server interface alludedtoabove ned standard enabling multiple providers competition area requiring database vendor provide full top-tobottom solutions mentioned previous 
subsection standardizing interface query tools accessing non-database sources bene cial finally success wouldn nice somedayhave fresh query language standard legacy design quirks sql simply left supported forever conclusions paper wehavetaken albeit biased transpired area objects databases period wehave explained whywe approaches fared wehave predict future commercially believethat verge era object-relational database systems willbegin taking enterprise ultimate success willbe due work past present future communityhas areas including extensibility object data models query languages persistent languages object mapping approaches survive believethatmany results provetohave lasting impact shape highly integrated client server object-relational database solutions year encourage work goal wehave attempted identify key researchanddevelopmentchallenges lie ahead takeover successful ten years future objects databases appears bright left acknowledgements joel richardson eugene shekita co-authors vldb paper care led invited write paper superb wisconsin students sta faculty colleagues vehad pleasure working projects related topic paper wewould industrial colleagues ibm almaden ibm santa teresa manyinteresting discussions related issues finally wewould nelson mattos ibm reading providing helpful feedback earlier draft paper andr andrews harris combining language database advances objectoriented developmentenvironment proc acm oopsla conference orlando oct atki atkinson buneman types persistence database programming languages acm computing surveys june atki atkinson object-oriented database system manifesto proc dood conf kyoto japan bane banerjee data model issues object-oriented applications acm trans ofce info sys jan bato batory genesis project develop extensible database managementsystem ditt blak blakeley data access masses throughole proc acm sigmod conference montreal canada june care carey dewitt richardson shekita object file managementinthe exodus extensible database system proc vldb conf kyoto japan aug care carey thearchitecture exodus extensible dbms ditt care carey dewitt vandenberg data model query language exodus proc acm sigmod conference chicago june care carey shoring persistentapplications proc acm sigmod conf minneapolis care carey heterogeneous multimedia information systems garlic approach proc ieee ride workshop taipei taiwan march catt cattell object database standard odmgrelease morgan kaufman publishers page comm committee advanced dbms function third-generation database system manifesto sigmod record july cope copeland maier making smalltalk database system proc acm sigmod conference boston june darw darwen date manifesto sigmod record march depp deppisch paul schek storage system complex objects ditt dewi dewitt kabra luo patel client-server paradise proc vldb conference santiago chile sept ditt dittrich dayal eds proc int workshop object-oriented database systems paci grove sept garc garcia-molina tsimmis approach mediation data models languages proc int workshop generation info technologies systems naharia israel june kim kim object-oriented database systems promises reality andfuture proc vldb conference dublin ireland august kim kim modern database systems object model interoperability acm press maie maier development objectoriented dbms proc acm oopsla conference portland oct ong ong fogg stonebraker implementation data abstraction relational database system ingres sigmod record march schw schwarz extensibility starburst database system ditt ship shipman functional data model data language daplex acm trans database sys march ston stonebraker inclusion types relational data base systems proc ieee data eng conf los angeles feb ston stonebraker object managementin postgres procedures ditt ston stonebraker readings database systems edition morgan kaufmann publishers ston stonebraker object-relational dbmss great wave morgan kaufmann publishers zani carlo zaniolo database language gem proc acm sigmod conference san jose zdon zdonik maier readings objectorienteddatabase systems morgan kaufmann publishers page 
building scalable geo-spatial dbms technology implementation evaluation jignesh patel jiebing navin kabra kristin tufte biswadeep nag josef burger nancy hall karthikeyan ramasamy roger lueder curt ellmann jim kupsch shelly guo johan larson david dewitt jeffrey naughton computer sciences department wisconsin-madison abstract paper presents number techniques parallelizing geo-spatial database systems discusses implementation paradise object-relational database system effectiveness techniques demonstrated variety complex geo-spatial queries global geo-spatial data set introduction motivation past ten years great deal research devoted extending relational database systems handle geo-spatial workloads fact handling workloads driving forces object-relational database technology researchers acknowledged existence large data sets geo-spatial domain vast majority research date focused language issues uniprocessor query evaluation indexing techniques unfortunate large data set problems lurking beneath surface surface vengeance paper describe techniques building parallel geospatial dbms discuss implementation techniques paradise parallel object-relational database system present results variety queries global geo-spatial data set verge dramatic change quantity complexity geo-spatial data sets best-known large geo-spatial data set petabyte data set generated nasa eosdis project data generated application primarily huge collection raster images arriving rate mbytes years typical queries data set involve selecting set images interest scientist images portions images scalar attributes date instrument interestingly portions images retrieved clipping rasters polygon political geographical spatial feature class queries data set select images portions images based content images northern wisconsin lakes covered ice sequoia benchmark ston captures types queries expected eosdis project applications match eosdis terms sheer data size applications large data sets today standards significantly applications data sets complex eosdis data set factor recent decision government relax restrictions level resolution allowable publicly satellite image illegal distribute satellite image resolution meters satellite images meter resolution legal rise number commercial ventures launch satellites download images meter resolution images support commercially viable applications meter resolution images key piece applications identifying storing objects polygons polylines derived images running queries based combination objects images one-meter resolution image city pre-processing application identify store objects structure building roads trees walkways cars larger meter diameter applications enabled data set invented clear involve complex queries spatial relationships objects moving meter resolution profound implications geo-spatial applications number applications storing processing querying geo-spatial data grow tremendously size raster data grow factor number polygons polylines data grow orders magnitude database developer researcher challenge implicit clear techniques needed provide scalable performance complex queries geo-spatial data sets needed parallel relational database systems successful applying parallelism complex queries large data sets techniques parallel relational database systems geo-spatial workloads generalization parallel select operator applies complex function image large set images natural speed large class geo-spatial queries informix universal server includes capability parallel function apply traditional parallel database techniques sufficient fully support scalable geo-spatial query processing important differences geo-spatial database systems spatial objects attributes applying parallelism queries objects requires spatial partitioning interesting queries spatial types involve proximity exact matching query processing time operations rarely localized single spatial partition data queries evaluated combination replication data operations introduce tradeoffs exist typical parallel relational applications large objects raster images make reasonable applying parallelism individual objects megabyte object large satellite imge make sense decluster object multiple nodes turn means query time decide query satisfied fragment object assemble object order execute query raises set issues present relational systems dramatically assembling large objects naturally pulling fragments multiple nodes pushing data node requires communication paradigm pulling generally parallel relational database systems operations closest answered pair objects objects closest object verify objects circle radius distance implies operators similar spirit traditional aggregates operate sets tuples important difference single object member multiple groups find closest toxic waste dump city dump considered respect multiple cities turn necessitates multi-step operators complex parallel relational systems designed implemented techniques handle aspects parallel geo-spatial databases resulting system paradise runs single processor multiprocessor systems paper describe results running paradise multiprocessor built commodity pentium processors linked high-speed interconnect order validate techniques sought large geospatial database experiment answer acquire years world-wide avhrr satellite images dma dcw polygonal map-data entire globe size data set times larger regional sequoia benchmark produced versions data set test system scaleability data sets ran set queries closely patterned sequoia benchmark state art advanced considerably sequoia benchmark defined included number complex queries stress optimizer query evaluation subsystems dbms sequoia benchmark results show techniques designed implemented paradise object-relational database system provide good speedup scale-up performance geospatial workloads techniques geo-spatial scaleability section describe basic software techniques paradise begin overview data model spatial image adts section describes basic software architecture system describing basic parallelization query processing mechanisms paradise sections final sections describe mechanisms extended achieve geo-spatial scalability storage processing spatial image data types substantial growing body work related performance geo-spatial workloads section discuss relevant related work applicable general terms system stated goal similar monet system bonc explicitly names parallelism project goal paradise data model query language paradise loosely interpreted object relational data model addition standard attribute types integers floats strings time paradise set spatial data types including point polygon polyline swiss-cheese polygon circle spatial data types provide rich set spatial operators accessed extended version sql paradise additional data types designed facilitate storage retrieval image data including sensor data satellite images types raster images supported bit bit bit dimensional array data type provided dimensions varied dimensional data form latitude longitude measured precipitation function time stored array finally paradise support mpeg-encoded video objects extended set types arbitrary combinations defining table types table mix terrain map data area latest reconnaissance photo geo-spatial metaphor simplifies task fusing disparate forms data multiple data sources including text sensor image map video data sets types including base types implemented abstract data types adts types defined paradise architectural overview process structure paradise shown figure types clients exist graphical front-ends browsing querying updating spatial data sets exist windows unix application development class library addition providing support dynamic sql library includes paradise abstract data types allowing applications manipulate instances types returned interface application process query result tuples query coordinator schema cache scheduler data server data server data server data server figure paradise process structure paradise database system consists query coordinator process data server processes processes communicate communication infrastructure automatically selects efficient transport mechanism message processes share common memory 
processors packets short-circuited intra-node packets expensive inter-node packets smaller con gurations bene short-circuiting proc relation size tuples execution time sec actual ideal table scaleup results speedup speedup experiments xed size relation sorted million tuples varying number processors held constant samples processor number samples todetermine partitioning elements unique attribute sort attribute timings presented averages trials trial erent random seed processors execution time sec speedup parallel ciency table speedup results theresponse time speedup forthe onemillion tuple relation sortareshownin table obviousthatadding additional processorssigni cantly reduces theexecution time ofthequery factors prevent system achieving perfectly linear speedups importantto note base case processors perfect speedup factor processors case scaleup experiments performance limited overhead scheduling operators query tree ects short-circuiting ects skew size sort tasks allocated processor demonstrate ect errors approximate splitting vector measured number tuples distributed eachnode maximum values measured ered optimal assuming perfectly uniform distribution processor con guration maximum skew approximately processor con guration maximum skew found optimal multiprocessor performance limited slowest site increase skew processors added results sublinear speedups sizeup sizeup experiments xed number processors sorted relations sizes ranging tuples tuples cases number samples xed processor times presented averages trials problem size tuples execution time sec ratio running times table sizeup results table shows surprising result implementation achieved sublinear sizeup sorting tuples times long sorting tuples reason occurs portion running time due sampling takes amount time independent size problem smaller problem sizes sampling overhead signi component running time larger problem sizes table presents data table sampling overhead subtracted running times table shows ignore sampling component speedup approximately linear highlights importantpoint larger problem size ective probabilistic splitting problem size tuples execution time sample time sec ratio running times table sizeup results exclusive sampling time conclusion partitioning sorted critical step multiple-input multiple-output external sorting analytic results suggest problem probabilistic splitting dominates previously proposed deterministic method experimental results prove thirty processors maximum test probabilistic splitting achieves good speedup scaleup performance speedup scaleup continue inde nitely order maintain constant expected skew sizes les produced probabilistic splitting number samples grow number processors means number processors scales eventually choose large skews large numbers samples give good performance general important note speedup achieved probabilistic splitting improves size sorted grows recall figure sorting million record les systems tens processors implementation proves probabilistic splitting highly ective technique unable proveitonourcurrent hardware expect les billion records probabilistic splitting ectiveeven systems hundreds processors acknowledgements researchwas supported donations dec ibm ncr tandem wewould rick rasmussen assistance dealing gamma hardware software bbdw dina bitton haran boral david dewitt kevin wilkinson parallel algorithms execution relational database operations acm transactions database systems september bbw micah beck dina bitton kevin wilkinson sorting large les backend multiprocessor ieee transactions computers arild baugst jarle fredrik greipsland parallel sorting methods large data hypercube database computer proceedings sixth international workshop database machines pages deauville france june springer-verlag bgmp blasgen gray mitoma price convoy phenomenon operating system review blm blelloch leiserson maggs plaxton smith zagha comparison sorting algorithms connection machine cmin proceedings rdannual acm symposium parallel algorithms architectures hilton head north carolina july cdkk h-t chou david dewitt randy katz anthony klug design implementation wisconsin storage system software practice experience october dewitt gray parallel database systems future database processing passing fad acm sigmod record december dgs dewitt ghandeharizadeh schneider bricker hsiao rasmussen gamma database machine project ieee transactions knowledge data engineering march dns david dewitt rey naughton donovan schneider comparison non-equijoin algorithms proceedings eighteenth international conference large databases barcelona spain august dob dobosiewicz sorting distributive partitioning information processing letters egks englert gray kocher shah abenchmark ofnonstopsql release demonstrating near-linear speedup scaleup large database technical report tandem part tandem computers frazer mckellar samplesort sampling approach minimal storage tree sorting journal acm gra goetz graefe parallel external sorting volcano technical report cu-cs- colorado boulder march huang chow parallel sorting data partitioning sampling proceedings seventh international computer software applications conference pages chicago illinois november irv balakrishna iyer gary ricard peter varman percentile nding algorithm multiple sorted runs proceedings fifteenth international conferenceonvery large databases pages amsterdam netherlands august philip janus edmund lamagna adaptive method unknown distributions distributive partitioned sorting ieee transactions computers april lkb livny khosha boral multi-disk management algorithms proceedings sigmetrics conf raymond lorie honestyc young lowcommunication sort algorithm parallel database machine proceedings fifteenth international conferenceonvery large databases pages amsterdam netherlands august qui quinn parallel sorting algorithms tightly coupled multiprocessors parallel computing ries epstein evaluation distribution criteria distributed database systems technical report ucb erl tech rep uc-berkeley seshadri rey naughton sampling issues parallel database systems submitted june stg betty salzberg alex tsukerman jim gray susan uern bonnie vaughan fastsort distributed single-input single-output external sort proceedings acm-sigmod international conference management data pages atlantic city jersey sto stonebraker case shared database engineering patricvalduriez andgeorgesgardarin join semijoin algorithmsforamultiprocessor database machine acm transactions database systems march yamane parallel partition sort database machines masaru kitsuregawa hidehikotanaka editors database machines knowledge base machines pages kluwer academic publishers 
system transport protocol tcp mpi communication processors smp memory transport vehicle clients applications guis connect process parsing optimization controls parallel execution query processes results sets collected delivery back client special attention efficient delivery result tuples large objects images attributes returned application program typically invoking method attribute addition portion object needed client retrieved relevant attribute large multidimensional array client small subarray middle array subarray fetched client large portion entire attribute establishes data pipeline application data transferred efficiently minimal delay implemented multithreaded processes top shore storage manager care shore storage manager storage volumes files untyped objects -trees -trees beck gutm objects arbitrarily large size storage volume allocation space inside storage volume performed terms fixed-size extents aries moha shore recovery mechanism locking multiple granularities object page file optional lock escalation unix blocking shore separate process mounted storage volume processes main shore server process share shore buffer pool shared memory describes extension shore paradise handle tape-based storage volumes basic parallelism mechanisms paradise basic parallelism mechanisms developed part gamma project dewi dewi tables fully partitioned disks system round-robin hash spatial declustering discussed scan selection query executed separate thread started fragment table paradise push model parallelism implement partitioned execution dewi tuples pushed leaves operator tree upward paradise operator join sort select takes input input stream places result tuples output stream streams similar concept volcano exchange operator grae active entities streams objects specialized form file streams network streams file streams read write tuples disk network streams move data operators shared-memory communications network transport protocol tcp mpi addition providing transparent communication operators processors network streams provide flow-control mechanism regulate execution rates operators pipeline network streams specialized split streams demultiplex output stream multiple output streams based function applied tuple split streams key mechanisms parallelize queries dewi types streams derived base stream class interfaces identical implementation operator totally isolated type stream reads writes runtime scheduler thread running process control parallel execution query instantiates correct type stream objects connect operators relational algorithms part paradise standard algorithms basic relational operators indexed selections provided non-spatial spatial selections join operations optimizer choose nested loops indexed nested loops dynamic memory grace hash join kits paradise query optimizer written opt kabr replicating small outer tables index exists join column table parallel database systems shat phase approach parallel execution aggregate operations query involving average operator group clause phase participating thread processes fragment input table producing running sum count group phase single processor typically combines results phase produce average group standard sql defined set aggregate operators operator functions performed phases system built hard coded system case object-relational system supports type extensibility set aggregate operators advance type added system introduce operators point adt closest method finds spatially closest polyline min aggregate closest examine number large polylines finding correct result solution problem define aggregate operators terms local global functions local function executed phase global function phase function signature terms input output types system extended adding adts aggregate operators aggregate local global functions registered system catalogs permits aggregates added modifying scheduler execution engine similar approach illustra informix paradise algorithms executing spatial join operations r-tree exists join attribute relations joined indexed nested loops algorithm generally pbsm algorithm pate dealing large satellite images key focus paradise dbms project development techniques dealing large satellite images arrays scientific data section describe techniques developed storing processing instances attribute types unlike systems paradise stores attributes inside database system files file system storage issues paradise array adt support n-dimensional arrays dimensions optionally unlimited size array adt type geo-located raster adt derived store satellite images array adt automatically handles small large arrays efficiently small arrays inlined directly inside tuple normal attribute arrays larger fraction shore page set made separate objects case metadata array number dimensions size dimension left inlined oid object actual array approach number advantages shore object array automatically migrated secondary tertiary storage tuples relation remain physically clustered significantly reducing cost sequential scan queries requiring access array pay cost reading array disk buffer pool large arrays array adt code chunks suni array subarrays called tiles size tile approximately kbytes tile stored separate shore object mapping table track objects store subarrays subarray dimensionality original array size dimension proportional size dimension original array proposed suni figure illustrates process array decomposition array paradise fetch portions required execute operation clipping satellite image polygons relevant tiles read disk tape final performance enhancement tile written disk compressed lossless compression algorithm lzw wel handle unpredictability compression algorithm array adt examines size reduction achieved compression compression reduce size tile significantly tile stored uncompressed form flag mapping table tile compressed tiles array compressed original raster compress tiles break tiles add map table figure temporary tables large objects arrays large attributes present special challenges processing queries object-relational dbms challenges involve insertion attributes intermediate relations produced process executing query creation instances attributes executing query relational dbms intermediate relation produced process executing query copies attributes underlying base table made process repeated multiple times executing complex query attributes satellite image approach good performance paradise tuples temporary tables produced executing query share original copy large attributes copies large attributes made tuple inserted permanent relation copy avoided sql sql notion attribute copy ensures raster data located node rest tuple advantage preventing unnecessary network traffic execution subsequent queries large attributes created part intermediate result query clip array attribute projection list predicate evaluation query clip array attribute clause paradise mechanisms dealing storage large attributes large attributes belonging tuples base table stored shore file deleted base table deleted large attributes intermediate table stored shore file temporary intermediate table deleted intermediate table deleted finally large attributes produced part predicate evaluation stored shore file operator performing predicate evaluation deleted operator completed execution copy insert mechanism copy large attributes created query execution permanent tables pull discussed section paradise push model parallelism push model parallelism breaks dealing large attributes satellite images process executing query involving redistribution intermediate tuples processors unnecessarily copy large attributes paradise tactics deal problem optimizer avoids declustering tuples large attributes paradise turns pull model parallelism query involving clip set raster images set polygons selected areas interest wetlands assume relations spatially partitioned grid tuples relations redeclustered order process 
query assume optimizer decides expensive redecluster tuples raster images approach push tuples images approach produce correct result data needed process query moved processors paradise pull model situation clip method invoked instance array adt array stored node node clip performed array adt starts operator node array stored fetch tiles portions array covered clip pull redistributed tuple inserted permanent result relation discussed previous section copy large attributes made case pull insures required data moved processors general pull expensive operation pull requires separate operator started remote node addition pull operator results extra random disk seeks aware costs architect good solution totally avoided pull end concluded overhead pull acceptable relative size objects pulled declustering arrays good bad fundamental question respect parallelization operations paradise tiles single large image declustered multiple disks easy paradise paradise array adt decomposes large arrays multiple tiles discussed previous section array adt pull pieces array residing disk attached processor partitioning tuples table facilitates parallelization relational operations partitioning large image multiple disks facilitates parallel application function entire image searching image scud missile launchers clipping image set polygons partitioning table beneficial small tables true arrays clipping images polygons searching large collection photos red sunsets benefit long number images processed larger number processors computing pixel-bypixel average arrays benefit declustering arrays answer store tiles image disks processor repartition fly query involves computationally intensive operation images approach added benefit simplifying task migrating images secondary tertiary storage section experimentally explore tradeoffs partitioning images spatial query parallelization spatial declustering addition hash round-robin partitioning paradise spatially decluster tuples table basic idea spatial declustering divide spatial domain multiple partitions turn mapped storage units hashing round-robin fashion spatially declustered table loaded spatial attribute tuple determine partition tuple belongs spatial partitioning scheme multiple tables order maximize amount local processing queries involving spatial join operations tables addition point polyline polygon data spatially decluster geo-located image data satellite images oil field seismic data spatial declustering attractive performance viewpoint factors complicate illustrated figure spatial partitioning non-point data polylines polygons impossible map polyline polygon single partition partition polylines polygons spanning multiple partitions replicated order insure queries spatial attribute produce correct result replicate entire tuple complicates updates simply replicate bounding box spatial feature complicates query processing partition partition partition partition figure problem spatial partitioning skew divides spatial domain small number partitions equal number storage partitions skew major problem relation road data state wisconsin spatially divides state partitions partitions data madison milwaukee green bay tuples partition area rhinelander north-central wisconsin likewise partitions large areas lake michigan lake superior tuples mapped proposed hua dewi reduce effects partition skew walt significantly increase number partitions increasing number partitions increases number tuples spanning multiple partitions percentage tuples replicated preliminary tests showed thousands partitions smooth skew significant extent alternative approach dealing skew decluster based distribution data set koudas koud describe interesting approach based declustering leaves r-tree difficulty approach makes parallelization queries multiple data sets efficient multiple data sets declustered boundaries parallel spatial join processing normal join operation execution spatial join query parallel phase process phase tuples relations joined redeclustered join attributes order bring candidate tuples nonspatial attributes hashing join attribute values map attribute processor phase participating processors joins partitions tuples receives phase single processor spatial join algorithm pbsm pate phase input tables declustered joining attributes phase algorithm eliminated table joins spatial attributes process slightly complicated partitioning function spatial partitioning function mapping tuples partitions space section order minimize effects spatial skew phase algorithm partitions processors spatial attributes tuples span multiple spatial partitions replication repartitioning phase insure correct result produced finally replicating tuples introduces possibility duplicate tuples produced tables river road data wisconsin query determine wisconsin river cross wisconsin river span multiple spatial partitions turns cross places process redeclustering river road data phase objects replicated partition overlap partitions cross mapped processors result query identical result tuples designed implemented parallel spatial join algorithms involving replication bounding box information full tuples description analysis performance algorithms found pate spatial aggregation processing geo-spatial database system opens entire spectrum operations handled efficiently normal relational query processing techniques query find river closest point process operation iteratively expand circle point circle overlaps polyline river expansion step find candidate river closest eliminated type operation form spatial aggregate query totally dissimilar task executing sql min operation type operation extended include term spatial join aggregation query query find closest river cities populations greater million selection predicate applied cities table filter cities populations million remaining cities joined rivers table notion join case overlap spatial aggregate function defines join satisfiability spatially closest figure illustrates problems encountered parallelize spatial join aggregate queries grids figure correspond boundaries spatial partitions madison note closest river madison map spatial partition processor expands circle madison overlapping river eventually encounter northern boundary spatial partition madison found river closest river tile north paradise sends copy madison tuple processors river data surrounding tiles assume processor finds candidate river implementation works correctly case solution complex explain confines paper processors spatial-based split table forward matches operator combines results find closest river evaluation type query contained section madison figure benchmark description performance evaluation benchmark description generating meaningful test suite parallel geo-spatial database system turned non-trivial project sequoia benchmark ston wanted problems paper alludes national size benchmark data set state level benchmark approximately small testing scaleup speedup spatial queries benchmark simple original sequoia benchmark provided mechanism scaling database address issues turn global sequoia data set sequoia lead real data benchmark years resolution avhrr satellite images obtained nasa raster images raster composite image covering entire world polygon data dcw dcw global data set variety information things roads cities land drainage properties data sets geo-registered coordinate system definition tables raster date date channel integer recording channel data raster raster image populatedplaces string unique feature identifier face string feature-id polygon type integer category populated place values location point spatial coordinates place string place landcover string unique feature identifier type integer type water-body categories shape polygon boundary water body roads string unique feature identifier type integer type road categories shape polyline shape road drainage string unique feature identifier type integer drainage feature type categories shape polyline shape drainage feature query descriptions benchmark fourteen queries 
bucky object-relational benchmark michael carey david dewitt rey naughton mohammad asgarian paul brown johannes gehrke dhaval shah abstract trade journals corporate marketing machines verge revolution object-relational database revolution webelieve face revolution armaments paper presents bucky benchmark object-relational database systems bucky queryoriented benchmark tests key features offered object-relational systems including rowtypes inheritance path expressions sets atomic values methods late binding user-de ned abstract data types methods test maturity object-relational technology relativeto relational technology provide object-relational version bucky relational equivalent thereof relational bucky simulation finally brie discuss initial performance results lessons resulted applying bucky early object-relational database system products introduction addition object-relational features relational database systems dominate database marketplace arguably striking advance rdbms functionality relational database systems rst introduced approximately years ago sto major players rdbms industry begun shipping released products early beta releases degree object-relational functionality rest hinting addition companies including startups established work supported informix ncr byarpa order monitored army research laboratory contract daa nasa contracts usra- nagnagw- nsf award irimichael carey current address ibm almaden research center dhaval shah current address cisco systems computer sciences department wisconsinmadison fcarey dewitt naughton johannes dhavalg wisc informix corporation brown illustra database vendors begun ering full object-relational database systems universal servers rdbms trade journal advertising-speak clear observers database industry functionality ered object-relational database systems considerable bene users surprisingly performance implications features step rectifying situation wehave ned implemented bucky benchmark bucky objectives designing bucky objective test key features add object object-relational database systems areas object-relational query performance tested bucky queries involving rowtypes inheritance queries involving inter-object queries involving set-valued attributes queries involving methods row objects queries involving adt attributes methods discuss rationale choosing features detail section brie philosophy focus essential primitive erences objectrelational relational database systems avoid testing functionality shared object-relational traditional relational systems functionality tested existing relational benchmarks wisconsin benchmark tpc bucky benchmark consists object-relational schema data generation program set queries schema paper describe bucky benchmark discuss sorts insights provide object-relational dbms performance wehave fact run bucky existing systems still-fresh memories benchmarking experience cdn cdkn curbed appetite publish benchmark results commercial systems addition opinion industry verge ood object-relational functionality early publish meaningful comparative results interesting implications object-relational database systems compared relational systems benchmark universal complex kwery ynterfaces object-relational technology greatly expands space alternatives schema designer inheritance hierarchy set independenttables inter-object key foreign-key pairs set-valued attributes store elements logically embedded sets separate table foreign key linking parent tuple relational object-relational design space expansion applies methods adts row objects cases logically method row object directly expressed relevant sql queries separate method similarly logically adt set methods expressed de-encapsulating adt internal structure attributes sql rowtypes converting adt methods expressions sql queries simple adts put erently application developer choice object-relational make database application code terms utilizing features ered systems goals bucky benchmark examine performance tradeo erent design alternatives ered brave world object-relational databases addition object-relational bucky schema load program query set wehavealso ned relational bucky schema semantically equivalent notesection totheobject-relational schema implemented load program ned set relational queries semantically equivalentto bucky object-relational queries implementing versions benchmark system nition object-relational database system supports full relational ddl dml compare contrast approaches common software framework comparison important reason results comparison provide insight relative maturity object-relational versus relational query optimizers runtime systems preview paper remainder paper explain rationale design bucky benchmark describe schema present object-relational relational versions bucky query suite wego wewilldiscuss sorts lessons learned running bucky pertaining system tested pertaining general state objectrelational dbms technology today present preliminary results obtained running bucky illustra dbms hope bucky benchmark serve tool driving measuring improvements needed make object-relational technology commercial success bucky design rationale features tested bucky match growing consensus database eld constitutes objectrelational system well-known exposition consensus appears stonebraker book sto stonebraker lists features added relational dbms order considered object-relational dbms inheritance complex object support extensible type system adts triggers list features tested bucky stonebraker list inheritance rst item fourth items bucky feature list object methods set-valued attributes map items stonebraker list mapping one-to-one detail object methods set-valued attributes considered part complexobject support set-valuedattributes contribute extensible type system item bucky list tested features adt support maps item stonebraker list finally item list bucky benchmarkincludes trigger tests agree advanced trigger support isavery important feature dbms orthogonal system object-relational weleave trigger benchmarking question ning benchmark tests object extensions object-relational systems aspects application performance query performance object extensions part story agree goal bucky provide benchmark speci captures essence missed existing benchmarks object-relational systems provide superset relational functionality existing relational benchmarks wisconsin tpc-a tpc-d set query benchmarks gra test relational subset object-relational dbms important feature scope bucky focus oodb systems client-side pointer traversal performance application tools provide kind functionality top object-relational systems inspired wrapper tools relational systems persistence ontos architecture typical object-relational system performance suchtoolswould function caching layer top dbms dbms functionality well-tested existing oodbms benchmarks cdn bucky attempt test navigational program performance finally noted due extensible nature object-relational database systems customized provide specialized solutions designed speci application domains data types embodied illustra informix data blade architecture buy sequence data blade gis data blade text data blade ibm family database extenders oracle family application cartridges similar purpose regard data type-speci extensions targets benchmarks sequoia benchmark suchabenchmark gis data management systems domain-speci testing scope bucky benchmark results bucky provide insightinto base performance dbms shedding light resulting abilitytodowell domain-speci benchmark domain-speci performance depend heavily quality data structures algorithms employed prepackaged solution enrolled courses department staff instructor professor person employeestudent coursesoffered dept coursesection sections worksin teaches teacher major employees advisor student section hastaken students advisees majors chair figure schema structure bucky benchmark bucky database description database bucky benchmark modeled database application figure graphical sketchoftheschema lines gure person student person employee studenttota employee sta employeeto instructor instructorto instructor professor represent inheritance types remaining lines represent relationships instances types labeled end relationship end bucky designed run object-relational system mentioned earlier run relational system appropriately mapping object features relational features section discuss key features versions bucky schema order make designs clear details eachversion found appendices inheritance object-relational ddl natural model information bucky people byhaving inheritance hierarchy rooted person type object-relational bucky root 
correspond directly queries original sequoia benchmark queries test geo-spatial functionality covered sequoia benchmark query load benchmark database build indices query select raster images satellite channel clip image fixed polygon sort results date polygon rectangular region roughly continental united states approximately raster image select raster date raster data clip polygon raster raster channel order date query select raster images date clipping image constant polygon average pixel values clipped images produce single result image constant polygon future queries refers polygon select average raster data clip polygon raster raster date date query select raster image date satellite channel clip image fixed polygon perform lower resolution clipped portion insert result permanent relation select raster date raster channel raster data clip closedpolygon polygon lower res raster raster channel raster date date query select city based city select populatedplaces phoenix query locate polygons overlap geographical region insert result permanent relation query requires spatial selection select landcover shape overlaps polygon query select polygons lie fixed radius point maximum area query requires combination spatial non-spatial selection select shape area lcpytype landcover shape circle point radius shape area constant query find polygons nearby city named louisville polygon nearby city square centered city location query requires spatial join select landcover shape landcover lcpytype landcover populatedplaces populatedplaces louisville landcover shape overlaps populatedplaces location makebox length query select raster data date channel lies oil field query involves join raster set polygons select landcover shape raster data clip landcover shape landcover raster landcover lcpytype oil field raster channel raster date date query select rasters average pixel geographical region polygon greater fixed constant query interesting requires creation large attribute clipped raster predicate evaluation selects rasters based calculated property raster data select raster date raster channel raster data clip polygon raster raster data clip polygon average constant query find closest road type point query requires evaluation spatial aggregate closest geo-spatial systems handle spatial aggregates traditional relation aggregates select closest shape point type roads group type query find closest drainage feature lake river large city query requires evaluation spatial aggregate cross product relations make query work efficiently parallel system spatial declustering support spatial semi-join select closest drainage shape populatedplaces location populatedplaces location drainage populatedplaces populatedplaces location overlaps drainage shape populatedplaces type large city group populatedplaces location query demonstrates techniques paradise handling geo-spatial data approach digress moment describe approach query executed declustering drainage relation spatial region drainage features lie universe shape attribute broken tiles tiles numbered row-major order starting upperleft corner tile mapped nodes hashing tile number drainage relation spatially declustered sending tuple node tile shape attribute located drainage features span tiles mapped multiple nodes replicated nodes declustering points relation points spatially declustered declustering policy previous step spatial index shape attribute declustered drainage relation built fly index local node built fragment drainage relation node finally operator tree figure executed select scan city spatial semi-join index scan drainage join aggregate index scan drainage global aggregate tuples cross node boundary tuples transferred operators node figure spatial semi-join city tuple forms largest circle completely contained tile node circle probe index drainage feature tuple falls circle closest drainage feature features universe relation spatial attribute rectangular box completely encloses spatial attribute tuple relation case city tuple join aggregate operator node index probe return tuples closest feature node system city tuple replicated nodes system operator pipeline join aggregate operator takes incoming city tuple probes index drainage small circle system starts circle area roughly millionth area entire universe index probe returns tuples operator finds feature closest point sends tuple operator global aggregate operator pipeline index probe return tuples join aggregate operator forms circle area previous circle probes index expansion probing circle continues circle expands boundary universe index scan changed file scan drainage relation final operator pipeline global aggregate operator collects closest drainage feature point nodes produces final result global aggregate operator entire system operator represents sequential portion query execution hurts speedup scaleup approach problem modifications r-tree search algorithms suggested kim rous explore approach query find drainage features lakes rivers cross road query joins large spatial relations tests efficiency system spatial join algorithms select drainage roads drainage shape overlaps roads shape query select rasters year channel clip rasters oil fields query requires join large number rasters large number polygons select landcover shape raster data clip landcover shape landcover raster landcover lcpytype oil field raster channel raster date date raster date date spatial data set scaleup fundamental goal paradise project test scalability geo-spatial query processing techniques requires data set instantiated sizes finding scale benchmark data set difficult partially data spatial partially data real world fundamentally scale data set attempting model larger instance data set orthogonal ways spatial data set grow larger domain spatial data set expanded double data set size northern hemisphere base data set hemispheres scaled data set call kind scaleup boundary expansion scaleup scale geo-spatial data set region consideration constant view higher resolution call kind scaleup resolution scaleup boundary expansion resolution scaleup data set grow interest experiments chose resolution scaleup considered number approaches simulating resolution scaleup fixedresolution real-world data set settled primary idea user moves data set higher resolution existing spatial features detailed time number smaller satellite features hover existing feature visible scaling river higher resolution shape river detail time number small tributaries initially visible visible figure diagrams resolution scaleup scheme details scheme polygon scaleup polyline scaleup polyline point added existing object original polyline polygon original polygon figure polygons polygon points scaled factor increase number points polygon generate satellite polygon points satellite regularly shaped polygon inscribed bounding box sides tenth size sides original polygon bounding box satellite randomly original polygon increasing number points original polygon randomly picking edges original polygon breaking edges note process doubles number polygons doubles total number points data set general scale polygon times increase number points polygon add satellites points figure shows -point polygon scaled times points added original polygon satellite polygons points created polylines polylines scaled similarly polygons figure shows -point polyline scaled factor points scaling point data times achieved adding points randomly distributed original point raster scale raster data resolution image increased times images added increase resolution pixel 
raster over-sampled times perturb pixel values over-sampled pixels slightly prevent artificially high compression ratios testbed description dbms configuration tests conducted paper cluster intel express pcs configured dual mhz pentium processors mbytes memory dual fast wide scsiadapters adaptec seagate barracuda gbyte disk drives solaris operating system processors connected mbit ethernet cisco catalyst switch internal bandwidth gbits disks configured raw disk drives unix file system holding database holding log sixth disk initialized unix file system disk holding system software swap space disk drives hold database distributed scsi chains paradise configured mbyte buffer pool small buffer pool relative mbyte physical memory paradise query processing buffer pool dynamically allocated memory maximum process size observed benchmark execution mbyte swapping occurred test configurations relations partitioned disk drives database storage buffer pool flushed queries command query insure query sees cold buffer pool scaleup experiments set scaleup experiments conducted nodes disks table specifies data set sizes scaleup configuration results obtained query contained table nodes raster pop places roads tuples size tuples size tuples size nodes drainage landcover tuples size tuples size tuples size table scaleup data set sizes nodes nodes nodes query query query query query query query query query query query query query table scaleup execution times seconds discussion scaleup results query substantial portion work load process paradise system present load numbers paper query query touches data rasters rasters uniformly distributed configuration result close perfect scaleup small fluctuations numbers paradise compression raster tiles tuples uniformly distributed node end slowest operator content tiles node compression decompression expensive query queries data raster images node configuration operators nodes work node case time double costs moving disk arm tile raster examined remain query queries perform index lookups query nested index join shows linear scaleup spatial index landcover packed satellite features smaller easier pack bulk loading index dewi benefits query scans substantial portion index query query selects oil field polygons sends nodes polygons joined raster double size database node selected raster work newer satellite polygons added scaleup smaller original polygons result clip increases rate slower scaleup accounts fact query execution time double query query scales perfectly cost evaluating clause remains node query query successful scaling bad nodes exact behavior speculate due method scaling data set cpu time accounts large portion execution time query order check distances shapes points database scaled shapes points makes distance computation shape expensive query number nodes increase number points find local drainage feature spatial semi-join increase points replicated sub-linear scaleup query scaleup super linear size result double double database size scaled database add small polylines smaller probability joining query comments query apply query shows scaleup involves rasters speedup experiments speedup experiments conducted nodes disks database size table speedup results contained table speedup data size tuples size raster populated places roads drainage landcover table nodes nodes nodes query query query query query query query query query query query query query table speedup execution times seconds discussion speedup results query query shows super-linear speedup disks results fewer tiles disk turn results shorter disk seeks reading raster tiles query queries data raster images individual raster images reside single disks queries exhibit speedup query queries involve index lookups query index nested loops spatial join data spread nodes indices smaller node speedup linear index size decreases logarithmic rate query parallelism query involves single raster processing query node holds selected raster query work involved query lies evaluating predicate clause work evenly distributed good speedup query local aggregation node benefits increasing degree parallelism discussed scaleup section global aggregate evaluation remains sequential reducing speedup slightly linear query pbsm spatial join algorithm relational hash join algorithms forms partitions joined increasing nodes partitions fit memory resulting super-linear speedup query performance query similar query speedup rasters selected decluster rasters experiments mentioned section interesting design issue decluster tiles individual raster images shed light issue ran series tests raster images tiles declustered multiple nodes chose queries tests query selects clips large number rasters touches rasters advantage declustering individual rasters order benefit parallelism query hand examines rasters good candidate illustrating potential benefits declustering understand query good candidate execution declustering query computes average clipped region rasters average operator started node operator contacts processors rasters reside order pull tiles image overlap clipped region relevant tiles pulled average computed process sequential suppose tiles raster image spatially declustered case processor compute average tiles image stored locally note clipped region small effective processors tiles clipped region reason experimented variant query query identical query clipped region entire raster image results table query response time increases declustering query slightly performance query larger clip region benefits significantly declustering confirms intuition declustering rasters worth added complexity entails speed computations large portions rasters declustering declustering query query query table seconds conclusions paper design parallel version paradise database system paradise employs parallel database techniques developed part gamma project incorporates number techniques parallelizing geo-spatial database queries evaluates effectiveness comprehensive set queries geo-spatial data set examine performance results critical eye appears successful achieving scaleup speedup geo-spatial workloads closer reveals encouraging story queries sub-optimal speedup scaleup performance precisely ran efficiently small number nodes ran slowly nodes uniformly showed good speedup scaleup queries running times seconds nodes exhibited good speedup scaleup sixteen nodes suggests addition features paper historical success parallel database systems traditional relational environment duplicated challenging world large complex geo-spatial workloads acknowledgments intel ibm generous hardware donations paradise project funding paradise project provided nasa contracts usra- nagwand nagwand arpa arpa order number monitored army research laboratory contract daab -c-q lola olsen nasa goddard assistance helping acquire avhrr data sets benchmark beck beckmann -tree efficient robust access method points rectangles proceedings acm-sigmod conference june bonc peter boncz wilko quak martin kersten monet geographic extensions approach high performance gis processing edbt care shoring persistent applications carey dewitt naughton solomon proceedings sigmod conference minneapolis dcw vpfview users manual digital chart world defense mapping agency july dew dewitt gamma database machine project ieee transactions knowledge data engineering march dewi dewitt gray parallel database systems future database processing passing fad communications acm june dewi dewitt naughton schneider seshadri practical skew handling parallel joins proceedings large data base conference vancouver august dewi 
row type called person attributes common universitya liated people person thastwo subtypes student employee add studentand employee-speci information employee subtypes sta instructor add information speci non-instructional sta instructors finally subtypes instructor professor tisalso subtype student providing test case multiple inheritance bucky database instances non-leaf super types abstract classes parlance leaf types instances means instructor teaching assistant professor addition types table hold instances person thas person table employee employee table student studenttable andthese tables contained table sub-table hierarchy mirrors type hierarchy complete sql -style description object-relational bucky schema full paper http wisc naughton bucky html direct model inheritance relational ddl created separate table nonabstract type hierarchy employee instructor student repeating common elds table nition felt natural mapping complete ddl description version bucky schema full paper alternative single table union attributes hierarchyplusatype tag null values attributes apply row wewere worried approachwould end wasting space depending hownull attributes represented system alternativewould vertically decomposed schema subtype table key speci supertype table person employee attributes unique type employee table scheme havejust attributes person datehired status worksin concerned approachwould require joins reassemble objects interesting experiment mapping alternatives future salient feature object-relational ddl direct support inter-object attributes student ttype denotes student major rowoftype department create row type student major ref department person departmentrowtype inverse set students majoring department create row type department majors set ref student noted presence suchinverse sets strictly required student major relationship fully captured bythereference contained student type included set bucky spirit object-relational data modeling encourages representation binary relationships bi-directional manner unlike oodb systems whichallow users system inverse nature relationships sort aware current o-r product ddl support making assertions sql support fact support collection-valued attributes recently moved sql retain bucky current o-r products provide support expect reappear sql object extension not-too-distant future relational ddl relationship modeled key foreign key pair create table student majordept integer department create table department deptno integer null primary key relational model doesn support set-valued attributes analogy relational case majors set object-relational schema department type relationship directional relational case reconstructing query involves writing join clause majordept deptno inherentdirectionality sets erence object-relational bucky schema relational version availabilityofsetvalued attributes storing sets instances base data types object-relational bucky type nition person includes attribute kidnames type set varchar set strings person children relational model nested sets modeled adding additional kids table attribute foreign key referencing person table kidname attribute string referenced person children abstract data types key features o-r paradigm abstract data type adt facility enables users data types columns tables user-de ned types sql commands built-in system-de ned types users functions operate adt instances test facility bucky schema includes data type called locationadt whichisequivalent class nition class locationadt private int lat int lon public int extract latitude return lat int extract longitude return lon float distance locationadt loc return sqrt thislat loclat thislon loclon erent object-relational database systems erent approaches supporting adts provide sql -style adts structural content adt ned sql row-de nition-like syntax declaring internal structure dbms provide blackbox adts dbms total size information adt relational bucky schema adt support assumed simply un-encapsulate locationadt type eachofitstwo data elementsbecomesa eldineach relational tables locationadt eld object-relational table department sta professor student methods object-relational systems functions written sql simple functions external language complicated functions test avors bucky includes functions written person row object type subtypes salary function functions written sql locationadt functions written external language acceptable salary function bucky demands late binding employees professors function called compute salary based -monthacademic year salary degree summer support create function salary professor returns numeric return aysalary monthsummer nitions bucky sql functions givenin thefull paper thesqlfunctionsignatures methods locationadt sql-based relational dbmss provide equivalentofadtsor parameter description table cardinalities parameter table cardin numstudents student numdepts department tasperdept sta perdept sta profsperdept professor kidsperperson kids coursesperdept sectionspercourse coursesection semesterspersection enrolled studentspersection coursesperstudent figure parameter setting populating bucky database adt functions relational version bucky benchmark stores location data columns ected tables performs salary computations directly relational versions bucky adt test queries obvious disadvantage de-encapsulating details salary computations experimental setup section explain target system set order run bucky obtain meaningful numbers queries benchmark run cold pool empty enviroments database pages cached operating system ers system cache cold ush database pool queries huge table benchmark queries scanned ush unix pool ahuge part database scanned found experimentation wewere generate repeatable query running times strategy ective veri running queries times ushing time match rst signi cantdatacaching occurring queries self-explanatory parameter settings shown figure populating bucky database show parameter values resulting table sizes terms number rows small data set wehave found cient generating interesting ordbms performance results tradeo current state technology attribute distributions important bucky queries mention kids person generated person generating number adding kids girlnamex boynamex probability generating kid girlnamey randomly chosen probability choosing girlname means boy girl boy girl share numeric names people additional girl havetwo additional girls birth dates uniformly distributed salaries complex subclass employee represents salary erentway sta haveanannualsalary tas haveamonthly salary percent time professors -month salary number summer months generated numbers query asks employees making returns employees database indices created data order speed queries muchas strategy creating indices benchmark query query determine query indices potentially improve performance legal create indices data bulk-loaded slowdown bulk-loading report bulk-loading time separately index creation time bucky queries preliminary results section describes bucky benchmark query set earlier presenttwo sets queries run system set exercises object-relational o-r capabilities set relational subset system describe bucky query explain role benchmark single-exact exact-match table find address sta member simple exact-match lookup relational o-r versions query select street city state zipcode staff rst test serves provide performance baseline thatcan helpful interpreting results queries hier-exact exact-match table hierarchy find address employee o-r sql query search employee table subtables simply select street city state zipcode employee relational sql searching types requires schema sseparate tables yielding select street city state zipcode staff union select street city state zipcode professor union select street city state zipcode tests ciency o-r system handling queries subtable hierarchies measuring impact system approach scanning indexing hierarchies single-meth method query table find professors make year o-r sql query involves invoking salary method body 
written sql select street city state zipcode professor salary relational sql salary method query select street city state zipcode professor aysalary monthsumer test establishes ciency o-r system approach indexing function results compared indexing stored relational attributes hier-meth method query table hierarchy find employees make morethan year query returns sta professor objects tuples salaries professors uniformly distributed salary tas uniformly distributed sigh o-r sql query clean-looking call salary function recall implementation function erent employee subtypes select street city state zipcode employee salary relational sql method computation embedded query involves explicit union select street city state zipcode staff annualsalary union select street city state zipcode professor aysalary monthsummer union select street city state zipcode apptfraction semestersalary tests theo-rsystem handling indexingon function results presence table hierarchy single-join relational join query find sta birthdate live area zipcode fairly traditional relational join o-r sql oid predicate prevents satisfying sta member pair appearing select city city staff staff birthdate birthdate zipcode zipcode oid oid relational sql query identical ids oids select city city staff staff birthdate birthdate zipcode zipcode baseline test join processing verifying o-r query cient relational query regular joins hier-join relational join table hierarchy find persons birthdate live zipcode aera query hierarchy o-r sql select city city person person birthdate birthdate oid oid zipcode zipcode relational sql query hier-join ten-way union query ten arms union consists join pair tables hold subtypes person professors students tas sta relational database due length query statement shown test investigates ciency o-r system handling joins table hierarchies set-element set membership find sta child named girl kidname values database query returns percent sta objects people o-r sql query simple tests membership girl nested kidname set select street city state zipcode staff girl kidnames relational sql query involves join table needed normalize data relational case distinct clause relational version needed force semantics o-r query sta tuple output select distinct street city state zipcode staff kids kidname girl query tests o-r system handling nested sets wehavementioned nested sets recently eliminated sql leaving query benchmark vendors support users wantit select join required relational case o-r system supports indexing set-valued attributes opportunity win set-and set membership find sta children named girl boy query returns percent sta objects o-r sql query straightforward select street city state zipcode staff girl kidnames boy kidnames relational sql query involves joins select distinct street city state zipcode staff kids kids kidname girl kidname boy slightly complex test o-r system handling queries involving nested set attributes hop-none single-hop path selection find student major pairs rst bucky path expression test queries itreturnsall studentsandteaching assistants persons o-r sql query easily written select state majordno majorname majorbuilding student relational sql union joins select state dno building department student majordept deptno union select state dno building department majordept deptno tests ciency o-r system processing queries involve path expressions awell-implemented o-r system handle o-r relational cases equal ciency point strictly speaking o-r path expressions equivalent relational systems left outer joins joins explicitly chose regular joins relational case reason decision mentionedin section weknow bucky database dangling relationships knowledge database wehave simply written query convenient natural form case natural o-r relational formulations important notice relational version query explicitly encodes information object-relational version relational version names source target tables relationships involved query object-relational case information tables target objects encoded schema scope information mentioned section fact sql committeerecently votedto removeunscoped standard reason weexamine performance results obtained running bucky object-relational product pre-dates decision hop-one single hop path one-side selection find majors students named studentname query pairs students department selection student relational sql query select deptno student department majordept deptno studentname union select deptno department majordept deptno studentname note union studentmay regular student o-r sql ways express rst variant starts query students path major department select state majordno majorname majorbuilding student studentname variant starts departments sets pointers department majors selection target set-valued bit obtuse due sql clause table view world select state dno building department table majors majorsname studentname variant tests o-r system handling short path expressions predicates originating table variant tests o-r system ciency handling queries involving nested sets case inverse relationships supported exploited ectively due nature selection predicate hop-many one-hop path many-side selection find students majoring department relational sql version select deptno student department majordept deptno deptname union select deptno department majordept deptno deptname twoways express o-r sql rst variant starts departments thepathtostudents selection source set-valued select state dno building department table majors deptname variant starts students path major departments selection target scalar o-r sql select state majordno majorname majorbuilding student majorname deptname variant tests o-r system handling queries path expressions target table restricted bya predicate selection predicate path target table originating table o-r system handles path queries naively failing make scope information failing reorder path expressions joins likelydo poorly thistest aswith previous test inverse relationship exploitation advantageous test hop-one two-hop path one-side selection find semester enrollment limit department number department sections courses taught room o-r sql manyways express query query hop-none involves join tables start follow sections courses departments wechose start courses awkward user express query varianta start sections path department selection source two-hop chain scalar valued variantaisthus simple-looking select semester nostudents coursedept- dno coursedept- coursesection roomno o-r variant starts departments path sections selection target two-hop chain set-valued variantblookslike select semester nostudents dno department table coursesoffered table sections roomno relational sql variant select semester roomno deptno coursesection department deptno deptno courseno courseno deptno deptno roomno tests theo-rsystem shandling path queries longer paths adt-simple simple adt function find latitudes sta members turn attention testing adt support starting simple case query function invocation select list object relational sql query select extract latitude place staff relational sql adt unencapsulated wehave select latitude staff tests ciency o-r system function dispatchmechanism versus ciency retrieving stored data adt-complex complex adt function sta member distancebetween sta member query applies complex adt function object relational sql select distance place place staff staff relational sql computation spelled completely sql select sqrt latitude latitude latitude latitude longitude longitude longitude longitude staff staff tests o-r system function dispatch mechanism time versus case relational case expression complex adt-simple-exact exact-match adt 
find ids sta live latitude longitude query point exact match object relational sql query select staff place locationadt relational sql select staff latitude longitude tests o-r system ciency handling exact match query involving adt requires adt indexing support adt-complex-range range complex adt function find ids names sta ids distance units wenow complex adt query whichino-r sql select staff staff distance place place relational sql select staff staff sqrt latitude latitude latitude latitude longitude longitude longitude longitude tests o-rsystem ciency handling range query involving adt queries considered addition queries considered including number test queries queries eliminated running bucky actual o-r system found results simply reinforced presented queries tested include single-range rangequeryoversingle table andhier-range range query table hierarchy results similar exact-match queries set-or set membership results whichwere similar set queries hop-both single-hop path double-ended selection results essentially predictable based pair single-ended selections hopnone two-hop path selection hop-many twohop path many-side selection hop-both twohoppath double-endedselection whichlargely reinforced thecorresponding single-hop queryresults nally adtsimple-range range simple adt function produced results similar adt-simple-exact initial bucky results lessons section brie describe preliminary experience applying bucky benchmark actual system early object-relational products system tested illustra nowowned informix loading bucky database big erence implementing bucky relational object-relational models arose generating bulk-loading input les database harder object-relational data due presence basically o-r systems make querying simpler preconnecting objects relationships declared schema queries concise cases quickly discovered loading complex time-consuming result approach loading rst generate external data les loaded database system bulk-loading facility portability uniformity reasons load les generated stand-alone program byanyone ensuring exact input data set les bulk-loaded dbms minor syntactic tweaking match eld tuple delimiters dbms bulk-loading facility approachtoloadingwas straightforward relational bucky database proved cult object-relational case generating load students table student things major relational systems data student simply includes department student major department result generating department load don department majors information captured student table recovered join queries contrast generating load les tables student department object-relational case holding key major department student data include oid object identi student major department major department object created oid eventually current o-r systems address problem allowing surrogate department object load time surrogate temporary external oid system replaces actual oid loading process providing support surrogate oids makes bulk-loading problem generating managing surrogate oids preparing data bulkloading trivial illustrate joys loading o-r database suppose generating department data department object include student departmentasamajor surrogate oids student objects set surrogates department surrogates students means remember association students departments time generate students time generate departments working large database number associations huge making data structure needed store associations larger memory paging data structure make data generation impossibly slow worst size exceed swap space program won nish running note interchanging generation order department student tables won cyclic dependency solve problem program generates relational load les series smaller programs awk programs calls unix sort join utilities munge output object-relational load mentioned relational load les include information rows related whichotherrows key-foreign key pairs examquery o-r single-exact hier-exact single-meth hier-meth single-join hier-join set-element set-and hop-none hop-one hop-many hop-one adt-simple adt-complex adt-simple-exact adt-complex-range figure measured times seconds bucky queries path expression results shown unscoped scoped pairs times ple relationship studentrow major department represented storing department key student tuple load munging programs replace representation putting student tuple majors set departmentrow department tuple studentrow accomplished joining department student class lling surrogate oids writing joined tuples process implemented sort-merge join unix sort join utilities similar approach bucky schema worth noting muchofthis ort unnecessary object-relational database systems sql supported notion bi-directional relationships declared students major departments majors attributes inversely related explicitly linking data direction relational case leaving system reverse direction finally amount loading work cpu time system greater o-r case o-r system assign object real oid replace object surrogate oid newly assigned real oid extra work dramatically visible loading times wesaw preparing bucky database loading times longer object-relational case munging time required prepare o-r input les excluded running bucky queries describing bucky queries section brie intended test present preliminary results obtained running bucky version illustra rst-generation o-r database system product results reported measured informix initial illustra implementation bucky produced wisconsin improved ways improvements made initial version addition faster hardware platform create proper function indexes load adtfunctions statically dynamically intothe engine priorto runningthebenchmark queries table lists relational objectrelational o-r bucky results queries single-exact single-join relational queries table o-r times essentially identical expect o-r times queries hier-exact hier-join worse relational times erences due o-r query optimizer bug optimizer fails correctly choose indexbased plan inthe presence table hierarchy theversion illustra whichwe ran tests wenow turn method queries single-meth hier-meth comparing o-r times query single-meth shows large gains o-r support indices functions provide o-r system execute query index lookup employee salary function complexity query predicate relational case predicate essentially includes in-query expansion o-r function body forces query plan involves sequential scan performance advantage o-r hier-meth isn o-r time worse case due optimizer bug mentioned plan based functional index missed set queries set-element set-and cases relational version involves join signi cantly faster o-r version showing o-r system handling nested sets improved wenow path queries o-r times shown hop-none rst o-r time seconds worse relational time seconds resulted writing o-r query path expression reason lower o-r performance system support scoped system built notion scoped added sql system schema eld major points object type departmentobj knowing target object department table ithasto revert amounts nested-loops join scanning student table major pointer student tuple questionable fairness compare performance explicitly scoped relational join unscoped pointer join include o-r time seconds table time obtained simulating o-r system support scoped explicitly rewriting path query explicit oid-join join student department tables relational query join predicate major oid led o-r time beat relational time due query plan selected optimizer o-r case relational case alternatively implemented unscoped join relational system replace major attribute pair attributes tablename majordept decode thispair attributes client application impossibly slow supports unscoped strictly powerful costly terms performance cases wewillseehere didn test wehave notion client application benchmark path query hop-one recall select-join queries welooked twoways expressing queryino-rsql givenour schemathereare directions follow relationship variants source pair numbers figure mentioned previously thetwonumbers 
gure due scoped unscoped option case hop-one o-r times shown variant query written path expression studentsto departments o-rtimesand relational time identical due fact cases selective student predicate applied rst case lackofscope information problem variant traverses relationship opposite direction department set majors shown illustra times slower case nested sets unscoped point including times included tests systems support scoped nested sets note join-based rewrite variantbwould variant lastly note inverse relationship information allowasystem choose forward-traversal plans settraversal plans current o-r systems sql provide anysuch support query hop-many results shown variantb traversal variant query hop-one omit times variantthattraverses set unscoped plan including benchmarkwhen systems provide scoped relational time path variantof -hop-many o-r times unscoped case lack scope information forces system apply selection unscoped path query cost high oid-join version performs relational version case path query hop-one weshow forward path traversal results omitting traversal reverse set direction query involves unscoped o-r performance good due highly selective predicate roomno case relational version slower o-r versions query group queries involves adts functions adt-simple results show slightoverhead function invocation o-r case function body extremely simple results adt-complex show adt function performance beats relational expression evalution complexfunctions o-rand times essentially identical query adt-simpleexact finally o-r time query adtcomplex-range clear o-r system advantage adt case reporting bottom line previous benchmarks avoided idea boiling entire benchmark single number fun compress results full set results performance pro system challenge implementors o-r systems ning bottom-line metrics bucky benchmark bucky o-r ciency index number measures relative performance system o-r relational functionality ned geometric object-relational test times geometric relational test times bucky o-r power rating measures absolute performance system o-r functionality simply o-r power rating comparing object-relational systems ifsystemahasa higherpower rating system system sense faster o-r ciency index contrast interesting single system illustra omit set-valued attribute set-of-reference queries recently dropped sql oid-join encoding scoped queries o-r ciency index anxiously await rst o-r system o-r ciency rating based reporting times queries rewrites indicating successfully ran full o-r version bucky queries faster relational version loading programs queries freely database area departmentweb site http wisc naughton bucky html conclusions paper presented bucky benchmark object-relational database systems bucky query benchmark tests object features ered objectrelational systems including rowtypes inheritance path expressions sets atomic values methods late binding user-de ned abstract data types methods evaluate current state o-r art presented objectrelational bucky relationally mapped simulation thereof strongly advocate running versions o-r engine discussed lessons learned running bucky early o-r product results highlighted number issues related current products object-relational technology sql general expect bucky benchmark continue evolve initial bucky experience nutshell object-relational technology double-edged sword today part queries naturally concisely expressible power object-relational model sql extensions today greater expressive power free found loading objectrelational database challenging loading information-equivalent relational database inverse relationship support helped addition sql language features o-r systems sets inheritance methods andadts providenew implementation challenges implementors dbms engines wesawthatanumber bucky queries run faster relational version bucky involving sets reasons sql advocates exclusive scoped stonebraker refers object-relational technology great wave sto clear activityin industry wave starting wash today hope bucky yearsasthiswave continues customers technology o-r systems ready deployment applications developers provide forcing function improving current state art end wehave ered bucky performance metrics o-r ciency index comparing o-r relational implementations bucky o-r power rating comparing o-r systems cdkn michael carey david dewitt chander kant rey naughton status report oodbms benchmarking ort proceedings acm oopsla conference pages portland october cdn michael carey david dewitt jeffrey naughton benchmark proceedings acm-sigmod conference management data washington cattell skeen object operations benchmark acm transactions database systems march gra jim gray benchmark handbook morgan kaufmann san mateo sto michael stonebraker object-relational database systems wave morgan kaufmann janet wiener rey naughton bulk loading oodb performance study proceedings international conference large data bases pages santiago chile august janet wiener rey naughton bulk loading revisited proceedings international conference large data bases zurich switzerland august 
dewitt kabra luo patel client-server paradise proceedings vldb conference september eos http eos nasa gov grae graefe encapsulation parallelism volcano query processing system proceedings acm-sigmod international conference management data gutm gutman r-trees dynamic index structure spatial searching proceedings acm-sigmod conference boston mass june hua hua lee handling data skew multiprocessor database computers partition tuning proceedings vldb conference barcelon spain september info http informix illu http illustra moha mohan aries transaction recovery methods supporting fine-granularity locking partial rollbacks write-ahead logging acm tods march kabr kabra dewitt opt object oriented implementation extensible database query optimization submitted http wisc navin research opt kits kitsuregawa nakayama takagi effect bucket size tuning dynamic hybrid grace hash join method proceedings vldb conference amsterdam august koud nick koudas christos faloutsos ibrahim kamell declustering spatial databases multi-computer architecture edbt kim min-soo kim ki-joune spatial query processing method nearest object search -trees paper submitted pate patel dewitt partition based spatialmerge join proceedings acm-sigmod conference june pate patel dewitt study alternative parallel spatial join algorithms submitted vldb conference august prep preparata shamos editors computation geometry springer rous nick rossopoulos steve kelly vincent nearest neighbor queries proc acm-sigmod pages shat shatdal naughton aggregate processing parallel rdbms proceedings acm sigmod conference san jose california shat shatdal interaction software hardware architecture parallel relational database query processing phd thesis computer science department uwmadison ston stonebraker frew gardels meredith sequoia storage benchmark proceedings sigmod conference washington sql iso iec sql revision iso-ansi working draft database language sql sql jim melton editor document iso iecjct american national standards institute july suni sarawagi efficient processing multidimensional arrays proceedings ieee data engineering conference february tera teradata dbc database computer system manual release document teradata corp nov dewitt query pre-execution batching two-pronged approach efficient processing tape-resident data sets submitted september walt walton dale jenevein taxonomy performance model data skew effects parallel joins proceedings seventeenthvldb conference barcelon spain september welc welch technique high performance data compression ieee computer vol 
query pre-execution batching paradise two-pronged approach efficient processing queries tape-resident raster images jiebing david dewitt department computer sciences wisconsin madison jiebing dewitt wisc work supported nasa contracts usra- nagwand nagwarpa arpa order number monitored army research laboratory contract daab -c-q ibm intel sun microsystems microsoft legato abstract focus paradise project design implement scalable database system capable storing processing massive data sets produced nasa eosdis project paper describes extensions paradise handle execution queries involving collections satellite images stored tertiary storage modifications made paradise order make execution queries transparent user efficient paradise storage engine shore storage manager extended support tertiary storage log-structured organization tape volumes paradise query processing engine modified incorporate number mechanisms including query pre-execution object abstraction cache-conscious tape scheduling query batching performance evaluation working prototype demonstrates techniques provide dramatic improvement traditional approaches management data stored tape introduction july nasa begin launch series satellites part mission planet earth popularly eosdis earth observing system data information system fully deployed satellites aggregate data rate megabytes rate impressive adds couple terabytes day petabytes year lifetime satellites today mass storage technology data stored tape latest tape technology offers media dense reliable drives reasonable transfer rates quantum dltdrive transfer rate approximately sec compressed cartridges drive capacity compressed shelf life years rated passes tertiary storage systems suited sequential access primary medium database storage limited efficiently processing data tape presents number challenges cost capacity gap tapes disks narrowed factor density commodity tape technology uncompressed commodity disk technology uncompressed factor total cost disk tape library addition storage systems removable media easier manage expandable disk based-systems large volume data management approaches handling tapebased data sets database systems hierarchical storage manager hsm marketed emass store large objects externally systems operate granularity file file unit migration tertiary storage tape secondary storage disk memory system store satellite images image typically stored separate file image processed transferred entirety tape disk memory approach work applications portion image needed wastes tape bandwidth staging disk capacity transferring entire images alternative hsm incorporate tertiary storage directly database system approach pursued postgres paradise projects extend tertiary storage normal role archive mechanism integrated approach database query optimizer execution engine optimize accesses tape complicated ad-hoc requests data tertiary storage served efficiently addition increasingly powerful object-relational features systems illustra postgres paradise complicated tasks analyzing clipped portions interest large number satellite images performed single query paper describe extensions made paradise handle query processing image data sets stored magnetic tape simple adding support tape-based storage volumes modern tape technology quantum dlt digital linear tape dense fast typical tape seek takes minute solution pronged employ query execution paradigm term query preexecution idea pre-execution grew experimental observation queries accessed data tape slow afford execute query describe detail section pre-execution phase paradise executes query made block data residing tape occurs paradise simply collects fetching data proceeds execution query entire query pre-executed paradise accurate string tape blocks query cache-conscious tape scheduling algorithm reorders tape minimize number seeks performed query executed idea query preexecution sounds impractical demonstrate version paradise tertiary storage manager employ query pre-execution works effectively dealing large raster images tape paradise query batching make query processing tape efficient query batching variant traditional tape-based batch processing gray terms data pump idea query batching simple dynamically collect set queries users group batches batch set tapes pre-execute query batch obtain string merge strings execute queries batch concurrently processing batch essentially multiple instruction stream single data stream misd mode ultimate goal scan tape sequentially pumping tape blocks queries constitute batch blocks read tape illustrate issues accessing tertiary-resident data set system paradise process year worth weekly satellite imagery data figure shows data set stored paradise entire data set appears user single relation week channel integer attributes image attribute type raster adt bodies images stored sequentially tape volume time order disk -resident portion raster adt metadata includes oids linking metadata actual images query find image pairs week week bear similarities region channel image layout tape meta data disk week channel image query find image pairs weeks channel bear similarities region interest evaluate similar similar similar expected tape requests figure motivating assume tape readers mount tapes needed batch simultaneously executing query requires evaluating similar function image pairs channel channel channel channel weeks clear figure evaluating function naively excessive tape head movement sets images eliminate random tape accesses relevant portions images week cached disk image week accessed techniques executing pointer joins assembling complex objects reorder object accesses reduce number random accesses multi-user environment query executed plan aggregate effect result large number random tape accesses limited size disk cache make matters worse sufficient rely solely query optimizer generate optimal plans tertiary query processing remainder paper organized section summarize research related problem adding tertiary storage support database systems mechanisms extend paradise handle tertiary storage volumes section section describes design implementation query pre-execution query batching inside paradise section performance evaluation techniques conclusions future research directions contained section related work tertiary storage management focus highlight lts projects application log-structured file system techniques management tertiary storage highlight integrates lfs tertiary storage allowing automatic migration lfs file segments user data index nodes directory files secondary tertiary storage partial-file migration mechanisms highlight attempt provide alternative whole-file migration techniques widely employed hsm hierarchical storage management systems highlight approach closely integrated lfs treats tertiary storage primarily backing store lts flexible design objective provide general-purpose block-oriented tertiary storage manager extensions postgres manage data optical juke box design paradise tertiary storage volume manager borrows number techniques lts focuses tape devices optical devices multi-layered caching migration architecture manage persistent objects tertiary storage proposed preliminary results demonstrate sequential access tape segments benefits multi-level caching random accesses excessive overhead tape scheduling high access latency magnetic tape devices prompted number researchers explore alternative ways minimizing number random tape extend disk scheduling algorithms problem tape scheduling models access behaviors helical scan tapes tapes investigates tape scheduling cache replacement policies results demonstrate important position tape head attempting obtain optimal schedule batch tape accesses models behavior accesses serpentine tapes dlt tapes compares scheduling algorithms designed optimize random dlt drive studies show careful scheduling tape accesses significant impact performance data placement tapes investigate optimal 
placement data tape order minimize random tape algorithms assume fixed access pattern tertiary tape blocks effective applications fixed access patterns effective general-purpose database systems ad-hoc queries make predetermining access patterns essentially impossible addition collecting access patterns reorganizing data tapes time difficult task accomplish on-line system tertiary storage query processing propose special techniques optimize execution single join operations relations stored tape careful selection processing block size ordering block accesses demonstrated reduce execution time factor exploits parallelism disk tape devices joins identifies number system factors direct impact query processing focus single relational operations user-managed tertiary storage attempt integrate tertiary storage database system appeared three-level storage hierarchy proposed direct control database management system tertiary storage bottom layer data elevated tertiary storage secondary storage user-level commands user-level approach concept user-defined abstract proposed reduce number accesses made tertiary storage idea carefully abstracting important contents data aggregate summary information form abstract stored disk majority queries satisfied abstracts integrated approach comprehensive system-level approach integrating tertiary storage general database management system proposed technique breaking relations tertiary storage smaller segments units migration tertiary secondary storage migration segments scheduled optimally query involving relations tertiary storage decomposed multiple mini-queries operate terms segments mini-queries scheduled run-time availability involved segments disk memory set priority-based algorithms fetch desired segments tertiary storage demand replace segments cache disk follow-up work details framework dynamically reordering query execution modifying query plans based availability data segments difference approach emphasis optimizing tape accesses bottom layer execution engine leaving original query plan unchanged strategy simpler opportunities optimizing executions multiuser environment appears fruitful combining approaches query pre-execution mechanism resolve accesses satellite images schedule nodes query plans handle data dependencies operators query tree system architecture paradise object-relational database system primary focus efficient management processing large spatial multimedia data sets structure paradise server process shown figure shore storage manager underlying persistent object manager support tertiary storage paradise began extending shore extensions section shore storage manager extensions tertiary storage shore storage manager persistent object manager built-in support multi-threading concurrency control recovery indexes transactions structured set logical modules implemented classes access permanent data involves modules disk read write process buffer manager manager disk volume manager basic shore storage manager added components block-oriented tape driver tertiary storage volume manager disk-cache buffer manager cache volume manager minor modifications higher layer modules addition components enables shore directly access volumes tertiary storage details components paradise adts catalog manager extent mgr tuple mgr query optimizer scheduler shore storage manager paradise sql queries result paradise tuples paradise client figure paradise process architecture block-oriented tape driver low-level physical driver accessing data tape volumes module adds block-oriented access interface top standard unix tape routines driver formats tape set fixed-sized tape blocks request physical tape block arrives driver directs tape head disk read write process obtain asynchronous environments lack non-blocking mechanism physical address performs read write operation block-oriented fashion driver implemented class tape head state information instance variables addition set service utilities loading maintaining tape metadata information provided facilitate tape mounts dismounts metadata includes information tape format tape block size current tape end block number tape label standard unix tape routines driver independent underlying tertiary storage device platform tertiary storage volume manager tertiary storage volume manager responsible space management tape volumes functionality normal shore disk volume manager allocating de-allocating pages extents pages addition responsible mapping individual pages tape blocks keeping track mapping logical physical tape block addresses basic unit access inside shore storage manager page simplify implementation tertiary storage volume manager designed provide interface regular disk volume manager advantage making access tertiary data totally transparent higher layers shore preserving interface critical block size disk tape media performance characteristics seek operations tape orders magnitude slower seeks disk larger block size required implementation makes configure tape block size tape volume formatted separate study examine effect tape block sizes variety operations raster satellite images stored quantum dlt tape drive set tests determined optimal tape block size kbytes tapes append-only media logstructured organization handle updates tape blocks dirty tape blocks appended current tail tape mapping table maintain correspondence logical physical tape blocks shore storage manager organizes disk volumes physically terms extents basic units space allocation de-allocation extent set contiguous pages logically disk volume organized terms stores logical units storage file unix file system store consist extents figure depicts regular shore disk volume organization rectangle left denotes page tiles inside page slotted entries figure set pages beginning volume reserved metadata storage includes volume header slotted array extent map slotted array store map extent map maintains page allocation extent extents belonging single store maintained linked list extents head list stored store map figure illustrates extensions made support shore volumes tertiary-storage extended volume header cover tape-related meta information addition tape block mapping table design allowed implement tertiary storage volume manager class derived disk volume manager significant amount code reuse addition storing needed tape volume information header blocks makes tape volume completely self-descriptive header blocks cached mounting tape volume disk cache manager read tape blocks cached secondary storage subsequent reuse disk cache managed disk cache manager tertiary storage volume manager consults disk cache manager information cached tape blocks acquiring cache block space disk cache manager resource manager utilized in-memory buffer manager cache management unit management tape block page cached entry tape block mapping table logical tape block address physical address page disk cache information address cached page easily calculated addition dirty bit record block updated resource manager incorporate kinds cache-replacement policies lru simplicity cache volume manager cache volume manager simplified version regular shore disk volume manager takes care mounting dismounting disk cache volumes routines reading writing pages tape blocks transferring tape blocks cache volume tape volume header pages extent map store map data pages page bitmap extent link owner store number extent link head fill factor volume volume size extent size page size figure disk volume organization store map data pages page bitmap extent link owner store number extent link head fill factor pages tape block mapping table tape volume header extent map current physical end tape block number tape block size disk volume header physical tape block number figure tape volume organization 
examples tertiary storage accesses figure illustrates operation shore page miss occurs main memory buffer pool processes present figure shore server process disk read write process regular disk volume disk process cache volume tape process tape volume shared-memory region normal buffer pool buffer tape blocks transferred tape cache volume shaded components represent components memory move blocks data scsi devices passing memory modified permit access tape data illustrate type access performed walk types accesses explain actions involved figure disk volume access access pages normal disk volume involves steps page miss main memory buffer pool results series actions buffer manager selects buffer pool frame incoming page identifies volume manager examining volumeid component pageid buffer manager invokes method volume manager fetch page step disk volume manager translates page number pageid physical address disk device passes manager step manager turn sends read request disk process step request physical address page disk buffer pool frame disk driver schedules read moves page directly place buffer pool step page writes follow similar sequence steps tape vol mgr disk disk tape disk vol mgr mgr buffer mgr buffer pool tape transfer buffer shared memory cache vol mgr legend page request request data movement process logical module shore disk volume cache volume tape volume figure tertiary storage access structure tape volume access access pages tape blocks complicated desired page reside cache volume tape buffer manager sends request tape volume manager step queue maintained shared-memory volume manager communicate requests disk tape process queue maintained shared-memory volume manager communicate requests disk tape process step tape volume manager identified volumeid component pageid receiving request tape volume manager asks cache volume manager copy desired page cache volume performance correctness reasons cache up-to-date version tape blocks cache volume manager finds entry tape block desired page steps performed fetch page buffer pool tape volume manager translates requested page address page address cache volume mapped address passed cache volume manager responsible reading page remaining steps steps tape block found disk cache manager read tertiary storage cache volume tape volume manager tape block mapping table translate logical block number physical block number step calls module schedule migration manager sends migration request physical tape block number tape transfer buffer step block-oriented tape driver processes read request placing tape block directly tape transfer buffer step point control returned tape volume manager invokes cache volume manager transfer tape block shared memory cache volume step finally normal channels steps finish bringing desired page buffer pool short cut copy page directly tape transfer buffer buffer pool step query processing extensions previous section clear tertiary storage implementation places strong emphasis minimizing number upper layers shore storage manager carefully placing bottom layer storage structure upper layers shore modified enabling preserve higher level functions concurrency control recovery transaction management indexing data resident tertiary storage minimal needed extend paradise manage data stored tertiary storage storing accessing data transparently tape sufficient insure efficient execution queries tape-resident data sets database algorithms strive minimize number random disk seeks performed factor difference cost accessing page disk randomly versus sequentially tapes story seek modern dlt tape drive taking minute literally orders magnitude difference accessing tape block randomly sequentially short seeks avoided maximum extent section describe mechanisms minimize tape seeks maximize performance queries involving spatial images stored tertiary storage system-level object abstraction database support tertiary storage question data stored tape data stored disk frequently accessed data structures indices system metadata stored disk user data context projects eosdis clear tapes hold large satellite images typically megabytes size metadata typically couple bytes stored disk separating metadata actual image reduce accesses tertiary storage types queries metadata typical satellite image information date image geo-location information instrument sensor image predicates involving date location processed accessing metadata fetching unnecessary images assuming images stored tape image represented image metadata naive approach store oid object tape-resident image part disk-resident metadata approach fine images accessed entirety processing pieces images fairly common solution paradise tiling partition image multiple tiles tile stored separate object tape tiles touched query read tape approach requires oids tiles stored part image metadata term set oids tape-resident tiles system-level object abstraction differs user-level abstraction proposed tiling process handled automatically paradise figure illustrates representation raster image body image partitioned tiles stored tape metadata tile oids stored disk collection tile oids act object abstraction image data tiled image tapemeta-data disk image abstraction tile ids figure raster image abstraction paradise abstract data type adt mechanism implementing types systemlevel object abstraction incorporated adt satellite images methods operating image pass abstracted object representation addition abstraction totally transparent upper levels system addition modifications improvements totally isolated adt code representation makes optimize tertiary storage accesses generating strings objects tertiary storage performing tape query pre-execution accurately estimating access patterns guiding runtime resource management scheduling goal projects accurate access pattern estimation important optimizing page accesses scheduling algorithms disk tape based require queue requests operate small number applications fixed access pattern benefit disk tape scheduling mechanisms part effort optimize tape accesses developed technique term query pre-execution accurately generate strings ad-hoc queries involving accesses tape-resident data sets core idea execute query phase executes query system-level object abstraction section produce string tape performing actual tape access disk-resident data proceeds normal updates query preexecution phase completed string tape block collected phase reordered fed tape scheduler section describes reordering process finally query executed time reordered string minimize number tape seeks performed idea sounds impractical demonstrate section works extremely taperesident sets satellite images general case mechanism proposed inserting schedule nodes query plan needed resolve data dependencies operators query tree order support query pre-execution phase special mechanisms added paradise query execution engine monitor processing system-level object abstractions pre-execution phase adt function invoked tuple operations object abstraction large object resides tertiary storage tape-bound requests occur method recorded data structure executed function returns indication result incomplete query processing engine proceeds work tuple end result preexecution phase sequence tape block exact order occurred query executed normal manner schema table rasters time int freq int image raster table polygons landuse int shape polygon query select rasters image clip polygons shape rasters polygons rasters time rasters freq polygons landuse figure 
opt object oriented implementation extensible database query optimization navin kabra david dewitt computer sciences department wisconsin madison fnavin dewittg wisc paper number abstract paper describe design implementation opt tool extensible database query optimization object-oriented design simplify task implementing extending modifying optimizer building optimizer opt makes easy extend query algebra add query algebra operators physical implementation algorithms system easy change search space explored easy change search strategy opt equipped number search strategies optimizer implementor opt considerably simpli task implementing optimizer database system task experimenting optimization techniques strategies decide techniques suited database system present results performance studies whichvalidate design show spite exibility opt build cient optimizers introduction constructing high-performance database engine straightforward building query optimizers remains black art writing optimizer debugging evaluating erent optimization strategies remains cult time-consuming task state commercial optimizers frequently good spite fact query optimization subject research years existing commercial optimizers brittle years patching improvement ranges cult impossible bit published extensible query optimizers research literature actual success work limited good tools needed streamline process implementing evolving query optimizers extensible query optimization frameworks proposed research literature havea number drawbacks optimizers easy addition query algebra operators algorithms researchwas supported advanced research project agency arpa order number -cs monitored oregon graduate institute science technology army research laboratory havea xedsearch strategy changed hand optimizers extensibility searchstrategyarenotvery extensible respect query algebra studies ciency resulting optimizers remainder paper describes attempt develop alternative framework constructing query optimizers easy add operators execution algorithms existing operators framework optimizer implementor experiment heuristics limit search space explored optimizer optimizer implementor erentsearch strategies tomixmultiple strategies single optimizer finally compromising ciency optimizer optimizer built extensible framework signi cantly worse space time requirements equivalent custom-made optimizer order address issues extensibility maintainability opt exploits objectoriented features nes key abstract classes virtual methods class nitions assume anyknowledge query algebra database execution engine search strategy implemented terms abstract classes search strategy invokes virtual methods abstract classes perform searchandthecost-based pruning search space optimizer speci databasesystem written deriving classesfrom abstract classes information speci query algebra execution engine whichtheoptimizer built search space execution plans explored encoded virtual methods derived classes inheritance mechanism ensures search strategy optimizer havetobechanged search strategy class virtual methods over-ridden classes derived class implement erent search strategies opt equipped number search strategies directly optimizer implementor addition optimizer implementor implement search strategies deriving classes provided search strategy classes rewriting virtual methods optimizer built opt consists components search strategy component determines strategy explore search space dynamic-programming randomized search space component determines search space space left-deep join trees space bushy join trees algebra component determines actual logical physical algebra optimizer written opt strives separation components large extent architecture componentscanbechanged minimum impact components remainder paper organized related work presented section section describes design optimizer section discusses experiences date optimizer framework illustrating ease ciency opt section presentour conclusions related work extensible query optimizers proposed literature fall categories xed search strategy easy addition algorithms operators search strategy extensible opt wehave achieve goals coming design search strategy extensible anysearch strategy implemented design addition algorithms operators system easy optimizers extensibility query algebra propose form rule-based system rewrite rules describe transformations performed optimize query expression fre gra phh systems more-or-less xed searchstrategy cult modify extend freytag fre describes architecture translation query executable plan completely based rules describes system-r style optimizer built sets rules set rules convert query algebraic tree sets rules generate access paths join orderings join methods order optimizer developed part starburst project lfl usesatwo step process optimize queries rst phase set production rules transform query heuristically equivalent query ers faster execution query suited cost-based optimization phase query processing alternatives speci grammar production rules non-terminal grammar havemultiple production rules suggesting execution alternatives conditions applicability rules construct optimal execution plan bottom fashion similar system-r optimizer cost estimates choosing alternatives approach limitations rewrite phase rst phase equivalence transformations rewrite query heuristically heuristic transformations work anumber cases heuristics make incorrect decisions based cost estimates phase cost-based optimizer built grammar likerulesthat build bigger bigger plans approachiswell suited access method join enumeration clear optimize queries non-relational operators complicated transformations optimizers generated exodus optimizer generator volcano optimizer generator algebraic equivalence rules transform operator tree query equivalent operator trees implementation rules determine algorithms implement operators algebraic transformation rules generate operator trees equivalent input query implementation rules generate access plans operator trees likethevolcano optimizer generator starburst optimizer opt incorporates extensible speci cation logical algebra operators execution algorithms logical physical properties selectivity cost estimation functions interesting physical properties input constraints execution algorithms enforcers glue operators supported opt emulate starburst exodus volcano based optimizers search strategies optimizer generators built opt constructs allowed opt implement transformation rules implementation rules volcano rewrite rules production rules starburst addition opt advantages optimizers xed search strategy opt ers choice erent strategies fact search strategy opt extensible modi optimization problem opt ers ability mix constructs optimizers speci cally volcano-like algebraic transformation rules mixed system-r style building operator trees feasible experience implementation optimizer opt shows exibilityisachieved sacri cing performance architectures proposed extensible control search strategy optimizer region-based optimizer architecture mitchell mdz modular optimizer architecture sciore sieg blackboard architecture kemper moerkotte peithner kmp based concept dividing optimizer regions carry erent parts optimization query pass regions optimized methods pass control regions control passes region xed sequence mdz hierarchy regions parent region dynamically controls sequence query passes regions optimized blackboard approach kmp knowledge sources responsible moving queries regions architectures describe general frameworks extensible query optimization support multiple optimizer control strategies addition control strategies making speci assumptions kinds manipulations allowed operator trees access plans opt put lot functionality optimizer part code depend speci query algebra makes easier write optimizer scratch opt systems discussed spite assumptions number erent search strategies implemented opt easily finally addition algorithms operators search strategy remains easy opt clear easy systems lanzelotte valduriez describe object-oriented design extensible query optimizer design search strategy code opt inspired work opt ers modeling query algebra search space opt clear separation logical algebra operator trees physical algebra access plans separation ciency optimizer clarity extensibility discusses extensibility search strategy detail clear extensible design terms adding operators algorithms modifying search space explored howsuchchanges interact search strategy opt system design 
sample query figure illustrates query involving join set polygons set raster images join implicitly clip operation image attribute tuple rasters table fields time freq integers image instance raster adt tuples polygons table fields landuse type integer shape type polygon system-level object abstraction image attribute tuple rasters relation abstractions tile ids image partition information query intended select raster images desired time freq values clip polygon shapes landuse equals clip operation function defined raster adt subsetting image desired bounding rectangle region covered polygon shape top part figure shows spatial layout query figure selected raster image tiled parts polygons interest processed middle part shows clip operation accomplished query polygons processed original order storage disk result rectangular clipped portions raster image preexecution query clip function modified record tile ids covered tiles fetching tiles tape producing clipped result end pre-execution collection tile ids exact order read tertiary storage tile ids physical oids tape-resident tiles provide accurate prediction tape blocks accessed query executed time illustrated bottom part figure notice raster image replaced abstraction result series tile ids final clipped portions image random order overlay polygons raster polygon clip raster query pre-execution clip query figure pre-execution cache-conscious tape scheduling string tape-block accesses generated query pre-execution optimize tape accesses set problem optimal tape scheduling straight forward sequential access nature tape alternatives sort requests make sequential pass tape process requests seemingly straightforward approach big drawback ignores fact tape requests returned original order order execute query tapeblocks order cached long primary secondary storage referenced executing query access wasted puts constraint optimal schedule distance original request reordered request exceed size disk cache buffer tape blocks read tape pre-fetched tape blocks prematurely ejected cache order make room recently read blocks ejecting blocks wastes work adds additional random tape seeks cope problem factor cache size terms number tape blocks process finding optimal schedule scheduling problem bounded buffer set requests find optimal scheduling requests number random tape accesses minimized added constraint bounded buffer makes problem np-hard exponential algorithms find globally optimal solution approach expensive terms time memory consumption long streams requests large cache sizes straightforward solution bounded sort break entire stream multiple cache-sized chunks sort requests chunk approach miss opportunities improvement developed simple heuristic-based one-pass algorithm find good cache-conscious tape schedule idea algorithm reorder original stream stream consists number chunks properties tape block chunk sorted location tape tape blocks chunk read order overflowing disk cache addition sliding window smooth boundary effect arise bounded sort step algorithm works moving original stream left single pass constructing optimized stream step sliding window block fit disk cache block sliding window lowest request window added optimized stream sliding window moved forward position block lowest window window sorted chunk added optimized string sliding window moved past chunk process repeated input stream processed figure illustrates sample run algorithm assume disk cache hold tape blocks initially input stream string algorithm starts step lowest window chunk reordered step chunk added optimized schedule sliding window moved past block cover step stage lowest window moved window immediately step window covers lowest stream shifted immediately sliding window covers string step note sliding window covers tape block distinct window reordered step chunk moved optimized stream step multiple chunks query chunks concurrent queries easily merged interleaving accesses multi-user environment reordering function address sorting function sophisticated functions proposed deal tapes non-linear access characteristics dlt tapes query batching final schedule produced cache-conscious scheduling algorithm direct query execution run time query issues request tape block satisfied disk cache volume tape volume manager examines query block referenced multiple times stream sliding window number blocks fit disk cache number distinct schedule identify block position schedule requested block preceded blocks reads issued blocks include requested block order schedule execution query temporarily blocked due unavailability data requested tape block finally brought cache execution resumes scheduling terms cache-sized units assured blocks read prior actual result eviction blocks referenced future sliding window unbreakable chunk cache buffer size optimized schedule original request stream step figure one-pass algorithm finding near-optimal cache-conscious schedule execution model opportunity improving performance concurrently executing queries intermixing queries environment makes problem random tape seeks worse simply running optimally scheduled individual queries concurrently work tape patterns interleaved resulting pattern general large number random seeks solution query batching batch concurrent queries combining individually optimized schedules produce globally optimized schedule drive concurrent execution queries batch merge algorithm heuristic based objective eliminating random accesses individually optimized schedules queries current batch combines chunks schedules best-fit criteria scheme query execution indirectly controlled tape scheduler multi-threaded server actual execution queries batch interleaved accesses tertiary data merged global schedule interleaved merge process takes place dynamically monitoring query arrives determine added executing batch criteria deployed check query request stream head current schedule blocked merged round queries admitted immediately current batch demonstrate section technique extremely effective reducing random tape accesses improving system throughput multi-user environment algorithm section assumes exclusive control disk cache maximum buffer size constraint size unbreakable chunk scheduling conflicts concurrent queries significant performance problems multiple user environment deal problem reduce buffer size schedule individual queries order reduce potential conflicts choice buffer size depends multiprogramming level access pattern taperesident data individual tape schedules merged run time produce optimized plan performance evaluation evaluate efficiency system realistic setting developed tertiary storage benchmark determine effectiveness techniques benchmark experimental configuration results tests presented sections tertiary storage benchmark designing effective benchmark challenge tertiary storage environment harder size database large test limits system turn makes testing process slow tedious benchmark incorporate variety access patterns order realistic order study effectiveness techniques developed scaled-down benchmark call tertiary storage mini-benchmark benchmark regional data sequoia benchmark order compare relative performance non-optimized strategies approach base benchmark consisting land polygons geo-located raster images raster images week weeks total database size approximately test set scaled ways number images constant increasing size image image sizes constant scale number images test database size slightly limit disk cache size order simulate realistic environment tape resident data sets gbs schema database figure figure suite queries defined test variety query patterns queries based raster-related queries sequoia benchmark modified produce wider variety access patterns involve small polygons clipping raster images queries repeat reduced 
basic concepts assume query logically represented operator tree operator tree tree whicheach node represents logical query algebra operator applied inputs select emp dept emp dno dept dno emp lee emp select emp lee join emp dno dept dno dept emp emp lee emp dno dept dno dept loopsjoin selectscan sql query operator tree access plan figure query representations figure shows sql query figure shows query represented tree relational operators query represented operator trees equivalent physical execution algorithms database implementing query algebra operator instance join operator implemented nested-loops sort-merge algorithms replacing operators operator tree algorithms implement rise tree algorithms access plan execution plan sac figure shows access plan operator tree figure operator tree general haveanumber access plans query optimizer search strategy abstract classes derived classes optimizer implementor writes code runtime binding opt code figure basic system design query optimization query optimizer generate operator trees represent input query parts generate access plans operator tree compute estimate properties operator trees access plans cardinality output relation estimated execution cost rest section describe implemented opt manner mentioned earlier key feature opt abstract classes virtual methods ned priori search strategy written terms classes figure overview opt architecture rst describe abstract classes opt represent operator trees access plans compute properties describe abstract classes generate manipulate erent operator trees access plans representing operator trees access plans section describe operator algorithm abstract classes classes represent operator trees access plans computing properties abstract class describe abstract class represents virtual methods describe search strategy abstract class illustrate give examples actual classes optimizer implementor mightderive abstract classes implementa simple relational query optimizer operator class relation operator select join figure operator class hierarchy relational optimizer abstract operator class represents operators query algebra operator class optimizer implementor expected derive class operator actual query algebra instance derived operator classes represents application query language operator classes optimizer implementor derivefromthe operator class implement simple sql optimizer shown figure select join classes represent relational select relational join operators dbrelation operator explained paragraph sql optimizer instance select operator represent application select operator input relation instance join operator represent application join operator input relations inputs operator database entities relations relational database exist database result application operators operator tree represented tree instances operator class accurately instance class derived abstract operator class operator instance represents query language operator applied output produced childnodes operator operator tree dummy operators serve leaf nodes operator tree dummy operators represent database entities exist database relations clause sql query represented dummy dbrelation operator examples gures classes represented byovals arrowbetween classes inheritance relation relation select join emp dno dept dno dept emp emp lee figure operator tree figure shows operator tree operator tree corresponds query shown figure instances dbrelation class representthetwo relations clause query emp dept instance select class represents selection predicate applied emp relation instance join class represents dept relation joined result selection relation rels emp dept emp dno dept dno rels emp rels emp preds rels dept preds relation select join emp dno dept dno dept emp emp lee preds emp lee preds emp lee operator instance treedescriptor instance figure operator tree tree descriptors optimization optimizer compute track properties resultant output operator tree simple relational optimizer estimate properties cardinality size relation resulting execution operator tree information depends query algebra opt rely optimizer implementor provide properties optimizer implementor expected treedescriptor class stores information operator tree information stored logical algebraic properties set relations joined predicates applied estimated properties number tuples output information interest optimizer distinguish classes class instances wehaveusedovals represent classes boxes represent instances gures class hierarchies drawn ovals operator trees access plans drawn boxes implementor operator instance pointer instance treedescriptor class stores information operator tree rooted operator instance figure reproduces operator tree figure showing treedescriptor instances operator instance treedescriptor instance stores relations joined predicates applied operator tree rooted operator instance treedescriptorclassthe optimizer implementorhas providean isequivalentmethod determines treedescriptorinstances equivalent treedescriptorinstances equivalent operator trees algebraically equivalent treedescriptor haveaniscompletequery method determines operator tree represents query sub-computation operator class virtual method called derivetreedescriptor invoked operator instance construct treedescriptor object operator tree rooted operator instance treedescriptor instances inputs operator class virtual method called canbeapplied determines operator legally applied inputs rules query algebra operator tree search strategy compute treedescriptor byinvoking operator instances tree note search strategy invokes methods abstract operator class haveany information actual class instance runtime binding proper derivetreedescriptor method invoked correct treedescriptor computed search strategy whichis implemented terms abstract operator class compute correct treedescriptors operator tree knowledge actual operators query algebra byinvoking iscompletequery method resultant treedescriptor instance determine operator tree represents complete input query similarly determine operator trees equivalent isequivalent method invoke canbeapplied method operator instances operator tree determine operator tree legal algorithm class representation access plans similar operator trees algorithm abstract class representphysical execution algorithms implement operators database system optimizer implementor expected derive class algorithm class represent actual algorithms system figure shows algorithm classes derived abstract algorithm class simple sql optimizer heapfile index algorithms dummy algorithms dbrelation operator explained earlier selectscan algorithm implement select operator represents sequential scan heapfile outputs tuples satisfying select-predicate indexselect b-tree index implement operation nestedloopsjoin mergejoin algorithms implement join operator sort algorithm operator enforce sort-order tuples relation access plan represented tree instances algorithm classes special algorithm heap file index selectscan indexselect mergejoin sort nested loopsjoin figure algorithm class hierarchy relational optimizer emp dno dept dno emp lee index emp heap file dept indexselect nested loops join figure access plan case note leaf nodes access plans represented bydummy algorithms representing access paths exist database entities relation accessed sequential heap index heapfile index dummy algorithm classes representthese cases examples note algorithm classes dummy dbrelation operator class ned previous section figure shows access plan access plan operator tree figure index emp bytheindexselect algorithm perform selection emp lee nestedloopsjoin algorithm takes result indexselect joins dept relation heapfile access method implying sequential scan similar treedescriptor class case operator trees opt requires plandescriptor class store physical properties access plan relational optimizer plandescriptor class store sort-order result figure reproduces access plan figure showing plandescriptor instances algorithm instance optimizer implementor provide isequivalent method plandescriptorclass determine physical properties access plans class provide isinteresting method speci result 
scale small polygons sets queries designed mimic scenario user interested number regions set images fixed region clip raster images finally queries designed reflect advanced queries compare images instrument period times compares fixed regions images adjacent weeks frequencies repeats process images weeks weeks raster images stored tape chronological order suite queries represents interesting combination access patterns system configuration mhz pentium pro memory running solaris run paradise server queries submitted processes running machine quantum fireball disks log regular disk volume cache disk volume tertiary storage dlttape drive drive capacity uncompressed benchmark tape volume cache disk volume regular disk volume polygons landuse clip rasters frequency weeks polygons landuse clip rasters week polygons landuse clip raster frequency week polygons landuse clip rasters frequency weeks polygons landuse clip rasters week polygons landuse clip raster frequency week fixed region clip rasters frequency weeks fixed region clip rasters week fixed region clip raster frequency week compare rasters week rasters week frequency compare rasters week rasters week frequency figure tertiary benchmark queries single-user query execution experiment tested configurations base pre-exec base configuration access tertiary data techniques section effect corresponds approach database storage engine treats tertiary storage layer storage hierarchy configuration intended simulate approach external tertiary storage manager emass migrate tertiary data per-file basis configuration raster image stored separate file tape access part image detected run-time processing engine issues request migrate entire file tape disk cache pre-exec configuration fully integrated approach base pre-exec configuration tape block size set configuration tape block size match size raster image main memory buffer cache disk cache flushed queries insure queries executed cold buffer pools table response times eleven benchmark queries configurations figure presents performance pre-exec configuration relative base base configurations performance pre-exec configuration superior queries pre-exec configuration speedup factor exact implementation architecture simulated approach making tape block size image size depending experiment part image accessed tape manager fetch entire image tape base factor queries results demonstrate query pre-execution cacheconscious tape scheduling run-time data driven query scheduling effective reducing random tape processing ad-hoc queries base pre-exec query query query query query query query query query query query table single query response times seconds query time pre-exec base pre-exec figure speedup pre-exec base significant improvement exhibited preexec configuration queries due random spatial distribution polygons selected query queries clip region fixed area eliminates randomness raster image clips leaving basically room improvement pre-exec configuration slightly slower base configuration consequence overhead query pre-execution results illustrate amount overhead worse incur tape access pattern original query reordering optimal order final queries benefit significantly query pre-execution inherent nature random tape access query preexecution tape scheduling queries result excessive amount tape head movement images weeks interesting observation set experiments configuration consistently base configuration queries reason queries exhibit high degree randomness processing image randomness reduced simply transferring entire image tape disk single strategy works queries queries access image relative performance configurations reversed case unnecessary data migration costs configuration extra work benefit reducing random image capitalized due original serial tape access pattern queries random tape access patterns queries arise moving tape head back set images base configurations similar performance configuration migrates data tests demonstrate pre-exec configuration reduces random tape manages transfer correct amount data type query query pre-execution incurs overhead phase illustrate extent overhead response times queries broken table phase represents percentage total time required preexecute query string collected phase schedule percentage total time spent finding optimal tape access schedule phase corresponds final complete execution query queries overhead pre-execution scheduling combined scaled test database ways increased size image term resolution scaleup increased number images cardinality scaleup keeping image size constant set experiments repeated queries parameter results table pre-exec configuration continues performance advantage relative base configurations phase schedule phase query query query query query query query query query query query table breakdown response time pre-exec total time query base pre-exec base pre-exec table scale images images seconds multi-user query execution turn attention execution concurrent queries concurrency reduced environment tape-resident data executing multiple queries batch excellent opportunity amortize cost scanning tape demonstrate result significant performance gains alternative configurations considered preexec batch pre-execution query batching pre-exec serial pre-execution serialized execution query time pre-exec preexecution batching multiple queries running time optimized schedule base regular concurrent execution pre-execution batching client processes started simultaneously client picked query randomly set queries submitted paradise server execution process repeated times giving total queries preferred run queries base configuration limited set tests consumed hours test time results presented figure metric total elapsed time finish queries clients pre-exec batch pre-exec serial pre-exec base algorithms ion figure multi-user query execution obvious results combination query pre-execution tape scheduling run-time query scheduling query batching strategies factor improvement reason fairly obvious concurrent execution multiple queries individually executed optimized schedules pre-exec case results large number random tape seeks poor performance hand combining individually optimized schedules batch queries produce global optimized schedule minimizes number random tape seeks maximizes performance section explore sensitivity results batch size batch size sensitivity evaluate effectiveness query batching conducted set tests measure sensitivity results size batch clients running queries randomly selected benchmark queries total elapsed time clients complete execution queries batch sizes shown figure expected performance improvement provided query batching increases batch size increased due reduction number random tape seeks performed gains obtained linear function batch size reason wide range execution times queries benchmark batch includes long-running query relative effect query batching reduced due fact time spent executing long query queries arrive subsequently admitted current batch due long query band access region dynamic admission scheme query batching extra delays queries access blocks lower addresses noticeable improvements achieved increasing batch size figure shows similar results test repeated clients running queries batch size aps figure query batching clients queries batch size tot sed tim ecs figure query batching clients queries summary paper paradise database system extended support execution queries image data sets stored magnetic tape extensions paradise storage engine shore storage manager emphasized transparent access tape-resident storage volumes main contribution paper set techniques developed optimize tape accesses query execution techniques object abstraction query pre-execution cache-conscious tape scheduling run-time data-driven query scheduling demonstrated extremely effective optimizing execution queries accessing raster 
images tertiary storage single-user environment mechanisms augmented query batching -fold performance improvement obtained multi-user environment biggest advantages query pre-execution batching simplicity implement techniques major modification higher level query optimizer operator code bottom-up reordering scheduling strategy enables preserve execution order original query plan leaves room higher level efforts optimize query execution top-down fashion acknowledgments navin kabra jignesh patel patiently answering detail questions paradise query optimizer query execution engine kristin tufte provide valuable comments initial draft paper dewitt kabra luo patel client server paradise proc vldb conference santiago chile patel building scalable geo-spatial dbms technology implementation evaluation proc sigmod conference kobler berbert nasa earth observing system data information system eosdis digest papers ieee symposium mass storage systems los alamitos quantum corporation dltproduct manual carey haas livny tapes hold data challenges tuples tertiary store proc sigmod conference gray mox gox scans measure archive june herring tefend volume serving media management networked distributed client server environment proc goddard conf mass storage systems technologies nasa con olson extending postgres database system manage tertiary storage master thesis eecs california berkeley sarawagi query processing tertiary memory databases proc vldb conference switzerland september stonebraker frew gardels meredith sequoia storage benchmark proc sigmod conference gray sequoia alternative architecture study eosdis nasa october shekita carey performance evaluation pointer-based joins proc sigmod conference keller graefe maier efficient assembly complex objects proc sigmod conference kohl staelin stonebraker highlight log-structured files system tertiary storage management proc winter usenix pages san diego january ford myllymaki log-structured organization tertiary storage proc conference data engineering rosenblum ousterhout design implementation log-structured file system acm trans computer system february grossman hanley qin caching migration multilevel persistent object stores proceedings ieee computer society mass storage system symposium sept orji optimization policies tapebased tertiary systems tech report florida international hillyer silberschatz random scheduling on-line tertiary storage systems proc sigmod conference chen rotem optimizing storage objects mass storage systems robotic devices algorithms data structures spring chen drach keating louis rotem shoshan efficient origination access multidimensional datasets tertiary systems information systems journal april sarawagi stonebraker single query optimization tertiary memory proc sigmod conference myllymaki livny joins tapes synchronizing disk tape join access proc sigmetrics conference ottawa canada myllymaki livny efficient buffering concurrent disk tape proceedings performance international conference performance theory measurement evaluation computer communication systems october stonebraker managing persistent objects multilevel store proc sigmod conference fine anderson dahlin frew olson patterson abstract latency-hiding technique high capacity mass-storage systems sequoia project report california berkeley sarawagi stonebraker reordering query execution tertiary memory databases proc vldb conference india september carey dewitt franklin hall mcauliffe naughton schuh solomon tan tsatalos white zwilling shoring persistent objects proc sigmod conference dewitt processing satellite images tertiary storage study impact tile size performance nasa goddard conference mass storage systems technologies september 
access plan interesting physical properties abstract algorithm class method method invoked algorithm instance construct plandescriptor instance access plan rooted aphysical property sort-order interesting operation carried cheaply sort-order interesting sort-merge join sac emp dno dept dno cost cost emp lee heap file sort order index emp sort order emp sort order emp cost cost sort order indexselect dept nested loops join algorithm instance plandescriptor instance figure access plan plan descriptors algorithm instance plandescriptor instances inputs algorithm class virtual method called cost computes estimated cost executing algorithm inputs cost search strategy pruning sub-optimal plans addition algorithm class inputconstraint virtual method method physical properties input usable algorithm merge-join operator requires inputs sorted join attributes section search strategy information automatically enforce physical properties database system mighthave special execution algorithms correspond operator logical algebra sorting decompression purpose algorithms perform logical data manipulation enforce physical properties outputs required subsequent query processing algorithms referred enforcers volcano optimizer generator comparable glue operators starburst lfl classes enforcers derived algorithm class relational query optimizer sort algorithm enforcer ensure inputs mergejoin algorithm sorted join attribute access plan search strategy virtual methods abstract algorithm class determine properties access plan estimate cost determine equivalence erent access plans achieved byinvoking methods abstract algorithm class knowledge actual algorithms database system generating operator trees access plans previous section wesawhow operator trees access plans represented opt search strategy operator tree access plan wesawhowitcan compute properties compare trees plans virtual methods operator algorithm abstract classes section describe operator trees access plans generated search strategy optimization treetotreegenerator class classes derived treetotreegenerator abstract class generate operator trees classes virtual method called apply takes existing operator tree creates operator trees system-r style sac search strategy illustrate concept treetotreegenerator class optimizer starts single relations builds bigger bigger operator trees rst applying selections applying joins step search strategy picks existing operator tree expands bigger operator tree applying select operation join operation top tree process expanding existing operator tree applying operator generating trees accomplished treetotreegenerator classes treetotree generator select expand initialtree generator join expand figure treetotreegenerator class hierarchy speci cally implement relational system-r style optimizer optimizer implementor abstract class selectexpand class generate applications select operator joinexpand class generate applications join operator figure selectexpand apply method expected operator instance representing operator tree create instances select operator representing application selection input operator tree similarly joinexpand apply method create join instances representing erentways applying join input figure illustrates joinexpand apply method invoked optimization query figure gure shows instance select operator represents predicate emp lee applied emp relation joinexpand apply method invoked order expand operator tree rooted select operator instance result select joined dept relation job relation instances join operator created shown gure treetotreegenerator class virtual method called canbeapplied determines treetotreegenerator applied operator instance class derived treetotreegeneratorclass designated optimizer implementor initialtreegenerator apply method class search strategy start select relation relation join job dept emp dno dept dno emp lee relation emp select emp dept job emp lee emp dno dept dno emp jno job jno join emp jno job jno operator instances existing operator instances created joinexpand figure application joinexpand apply optimization process relational optimizer initialtreegenerator creates dbrelation instance relation clause search strategy picks operator instance representing operator tree generates operator trees byinvoking apply method treetotreegenerator classes canbeapplied method determine treetotreegenerator applied operator instance process repeated generate operator trees input query note search strategy knowany details treetotreegenerator classes system list pointer instance eachofthetreetotreegenerator classes invoking virtual methods treetotreegenerator abstract class instances search strategy generate operator trees required optimization treetoplangenerator class accessplan generated operatortree operator tree instance algorithm class implement operator classes derived treetoplangenerator abstract class generate algorithm instances operator instance treetoplangenerator abstract class virtual method called apply takes operator instance input parameter creates algorithm instances representing erent ways physical execution algorithms execute operation represented operator instance treetoplan generator heap file generator index generator selectscan generator indexselect generator mergejoin generator nested loopsjoin generator figure treetoplangenerator class hierarchy relational optimizer treetoplangenerator class optimizer implementor mightderive class algorithm system classes takes operator instance creates algorithm instances indicating algorithm implement operation figure shows classes derived treetoplangenerator class emp dno dept dno emp dno dept dno loopsjoin emp dno dept dno mergejoin join operator instance algorithm instances loopsjoingenerator apply mergejoingenerator apply figure examples treetoplangenerator apply figure shows examples treetoplangenerator apply applied join operator instance nestedloopsjoingenerator apply results instance nestedloopsjoin class created mergejoingenerator apply results instance mergejoin class created operatortree searchstrategycan invoketheapply method treetoplangenerator classes operator instances tree generate access plans operator tree treetoplangenerator class canbeapplied virtual method determines treetoplangenerator applied operator instance note search strategy knowany details actual treetoplangenerator classes system list pointer instance eachofthe actual treetoplangenerator classes list invoking virtual methods instances list search strategy enumerate access plans operator tree plantoplangenerator class plantoplangenerator class modify access plan generated plantoplangenerator apply virtual method takes algorithm instance representing access plan creates algorithm instances representing access plan important class automatically insert access plan instances enforcers change physical properties output access plan required order satisfy input constraints algorithm instance relational optimizer sortenforcer class derived plantoplangenerator class enforce sort-orders results access plans figure illustrates sortenforcer apply virtual method method invoked indexselect instance input parameter creates instance sort algorithm plantoplan generator sort enforcer figure plantoplangenerator class hierarchy sort emp dno emp lee indexselect index emp algorithm instances existing algorithm instance created sortenforcer figure sortenforcer apply enforce sort-order enforcer shown gure plantoplangenerator class canbeapplied virtual method determines plantoplangenerator applied input optimization search strategy building access plans treetoplangenerator classes invokes inputconstraint method algorithm instance created turns inputs algorithm instance satisfy input constraints attempts rectify situation applying plantoplangenerator search strategy canbeappliedvirtual method determine generators enforce properties invokes apply method create access plans satisfy input constraints enforcers applied automatically optimizer implementor worry search strategies operator algorithm tree plan generator classes previous sections search strategy implemented terms abstract classes virtual methods independent query algebra sense actual operators algorithms generators system modi modifying search strategy code anumberofsearch strategies implemented opt manner implementation search strategies loosely modeled object-oriented scheme opt nes searchstrategy abstract class virtual methods search strategies opt implemented class derived searchstrategy abstract class search strategies optimization optimizer implementor declaring object correspondingclass invokingthe optimizevirtual 
method object consequence design optimizer implementor modify behavior search strategy deriving class rede ning virtual methods due space constraints describe detail refer idea works section concentrate describing search strategies implemented terms operator algorithm generator abstract classes section describe optimizer implementor easily switch search strategy describe search strategies implemented opt bottom-up search strategy similar system-r optimizer sac transformative search strategy based search engine volcano optimizer generator finally randomized search strategies iterated improvement simulated annealing phase optimization implemented bottom-up search strategy search strategy implement optimizers bottom-up dynamic-programming similar system-r optimizer sac initialtreegenerator invoked initialize collection operator trees generate bigger trees search strategy picks existing operator tree expands expand operator tree determines treetotreegenerators applied operator instance root invoking canbeapplied method treetotreegenerators thentheapply method applicable treetotreegenerators invoked operator trees operator tree correspondingaccess plans generated applying treetoplangenerators operator instances tree algorithm instances cost-basedpruning accessplans manner similar techniques system-r optimizer access plan created virtual methods algorithm class determine cost access plan determine interesting physical properties locate access plans equivalent set equivalent access plans cheapest plan plans interesting physical properties retained deleted optimization complete operator trees expanded point cheapest access plan represents complete input query returned optimal plan iscompletequery method determine access plan represents complete input query delete access plan algorithm instance root access plan deleted algorithm instances access plans deleted shared access plans transformative search strategy section examples treetotreegenerators expand tree applying operator treetotreegenerator classes transform operator tree tree words class derived treetotreegenerator class represent algebraic transformation rule volcano optimizer generator canbeapplied method determines transformation rule applicable operator tree apply method creates tree results transformation join emp dno dept dno select emp dept relation relation emp lee join emp dno dept dno emp dept relation relation emp lee select tree tree figure rule-based transformation figure shows transformative treetotreegenerator applied assume class called selectpushdownis derived treetotreegeneratorclass class represents transformation rule join immediately select select predicate attributes left input join select pushed join left input tree figure shows result selectpushdown apply invoked operator tree applied tree operator tree resulting transformation shown tree tree generated creating operator instances shown oval tree select operator instance represents selection predicate applied emp relation join operator instance represents result select joined dept relation operator instances created wehave operator tree equivalenttotheoldone searchstrategy invokesthe initialtreegeneratorto operator tree correspondingto input query repeatedly applies treetotreegenerators transformation rules existing operator trees generate equivalent operator trees canbeapplied method determine treetotreegenerator applied operator tree apply method generate tree procedure generation access plans operator tree pruning similar bottom-up search strategy note treetoplangenerator classes analogous implementation rules volcano optimizer generator optimization complete existing operator trees transformed randomized search strategies section brie ydescribe implementationof opt transformativestrategy algorithmsassumethat classesderivedfrom treetotreegenerator class represent algebraic transformation rules brie describe implementation simulated annealing algorithm implementation algorithms similar omitted brevity simulated annealing algorithm variable called temperature initialized optimization begun initialtreegenerator generate complete operator tree create access plan operator tree step random operator instance operator tree picked processing random treetotreegenerator random treetoplangenerator chosen applied operator instance rise access plan cost plan estimated search strategy accepts rejects plan probability depends erence costs plan plan temperature plan rejected plan deleted plan remains current plan plan accepted plan deleted plan current plan temperature decreased step process repeated optimization continues temperature improvement cost number steps point current plan output optimal plan extensibility opt section summarizes involved implementing optimizer extending modifying existing optimizer built opt section examples extensions applied real optimizer implementing optimizer figure shows system architecture optimizer implemented opt search strategy component represents code provided opt includes implementations search strategies part code completely independent actual query algebra database system havetobe modi implement optimizer large part code required optimizer provided opt written optimizer implementor algebra component classes derived optimizer implementor operator algorithm classes implementation treedescriptor plandescriptor classes part code depends query algebra physical implementation algorithms database system speci cally code changed optimizer modi erent search strategy switching transformative strategy simulated annealing search space explored changed switching left-deep join tree enumeration bushy join tree enumeration treetotree generator searchstrategy initialtreegen joinexpand dbrelation select join operator algorithm loopsjoin seqscan loopsjoin gen indexgen treetoplan generator plantoplan generator sort enforcer tree descriptor plan descriptor code written optimizer implementor code provided opt bottomup transformative algebra component search strategy component search spaces component figure implementing optimizer opt search space component classes derived optimizer implementor treetotreegenerator treetoplangenerator plantoplangenerator classes classes decide operator trees access plans generated play large part controlling search space explored search strategy implementing joinexpand class generates joins relation base relation restricts search space space left-deep join trees hand implementing bushyjoinexpand class considers composite inners generate bushy trees fact join enumeration algorithms implemented opt class derived treetotreegenerator class modifying optimizer changing logical physical algebra modify optimizer incorporate physical implementation algorithm class algorithm derived algorithm class class derived treetoplangenerator class algorithm implement operator adding algorithm involves adding classes optimizer existing code changed instance hash-join algorithm incorporated simple relational optimizer deriving hashjoin class algorithm class hashjoingenerator class treetoplangenerator class similarly adding operator requires deriving class operator class deriving classes treetotreegenerator class algorithms implement operator added changing search space mentioned earlier search space explored byanysearch strategy controlled generator classes changed adding generator class removing modifying existing generator class simple relational optimizer search space changed space left-deep join trees space bushy join trees adding bushyjoinexpand class search strategy code search strategy component code depends query algebra algebra component code left search space component changing generator code adding generator easy words experimenting erent search spaces optimization techniques considerably simpli opt architecture changing search strategy opt ers choice search strategies makes easy switch search strategy search strategy replaced changing code algebra search space component case search strategy changed transformative strategy randomized strategies vice versa changing search strategy require writing treetotreegenerator classes switching bottom-up system-r-like strategy transformative strategy requires replacing treetotreegenerator classes based concept expanding operator tree treetotreegenerator classes representing transformation rules code treetotreegenerator classes change easy describe speci section experiences opt section describe experiences implementing optimizers opt started simple relational optimizer system-r style join enumeration modi ways change search space extend accept complex query algebra change search strategy optimization intention illustrating ease extensibility opt report performance 
studies including performance comparison optimizer generated volcano optimizer generator show spite exibility opt cient join enumeration section simple relational optimizer system-r style join enumeration describe howitwas easily extended space bushy join trees cartesian products examples section describe simple relational optimizer repeat details brie thedbrelation select andjoin classes derived operator class represent relational operators heapfile index selectscan indexselect nestedloopsjoin mergejoinclasses derived algorithmclass represent physical implementation algorithms selectexpand joinexpand derived treetotreegeneratorclass heapfilegenerator indexgenerator selectscangenerator indexselectgenerator nestedloopsjoingenerator mergejoingenerator derived treetoplangenerator algorithms implement operators sortenforcer derived plantoplangenerator enforce sort orders note selectexpand apply method written apply selection predicates select pushdown heuristic joinexpand apply method allowed single relations right-hand input join operation left-deep join trees heuristic search space consisted operator trees selections pushed cartesian products join trees left deep algebra component includes operator algorithm classes treedescriptor plandescriptor classes consists lines code search space components includes classes derived treetotreegenerator treetoplangenerator plantoplangenerator classes consists lines code contrast search strategy component consists code provided opt optimizer implementor write code lines code fact search strategy code provided written modi optimizer implementor considerably simpli task writing optimizer clear fact search space componentisvery small lines code divided classes makes easy experiment optimization techniques decided modify search space explored include bushy join trees join trees cartesian products todothiswe derived bushyjoinenumeratorand cartesianjoinenumerator classes treetotreegenerator class generate instances join operator allowed composite inners operand allowed result join cartesian products resulted addition lines code search space component refer figure experimental evaluation optimizer studied performance optimization time estimated execution cost function number joins input query query size number joins erent queries generated randomly optimized experiments run sun sparcwith memory virtual memory limited limit command figure shows ect erentsearch spaces time optimization figure shows ect relative estimated execution costs optimal plans produced note optimization times shown logarithmic scale join enumerator classes based schemes number joins optimization time seconds logscale left-deep bushy bushy cartesian number joins estimated execution costs scaled left-deep bushy bushy cartesian figure comparison searchspaces optimization times log-scale figure comparison search spaces estimated costs scaled complex query algebra section describe optimizer extended handle complex query algebra algebra reference-valued attributes set-valued attributes path-indices extended optimizer implement optimization techniques bmg added materialize query algebra operator represents materialization reference-valued attribute words dereferencing pointer assembly algorithm class representthephysical execution algorithm implement materialize kgm unnest operator class unnestalgorithmclass represent unnesting set-valued attributes materializeexpand class derived treetotreegenerator class takes operator tree expands adding materialize operation dereferences reference-valued attribute present input materialization reference-valued attribute achieved pointer-based join specialized joinexpandclass deriving pointerjoinexpandclass class creates instances join operator correspond materialization reference-valued attributes pointer-based join unnestexpand class derived treetotreegenerator takes operator tree expands adding unnest operation unnests set-valued attribute present input optimizer extended handle path-indices select predicate involving pathexpression city mayor lee evaluated path-index materialize individual components path-expression pathindex exists city mayor predicate city mayor lee evaluated materialize city mayor objects bmg details derived algorithm class capture path-index scans pathindexscangenerator class derived treetoplangenerator class replace occurrences string materialize operators select operator operator tree bya single pathindexselect algorithm extension optimizer handle query algebra constructs resulted addition lines code algebra component cost selectivity estimation lines code search strategy component complexity extensions algebra compared size optimizer easy transformative optimizer test opt decided change optimizer bottom-up dynamic programming optimizer algebraic transformation rules words shift bottomup strategy transformative strategy change required classes derived treetotreegenerator class represent transformation rules class transformation rule instance joinassociativity class represent associativity join operator selectpushdown class capture property selects pushed joins modifying optimizer transformative paradigm required addition lines code form transformation rules wenote code algebra component changed search space component treetotreegenerators added treetoplangenerator plantoplangenerator classes unchanged transformative search strategy opt based search engine volcano optimizer generator tovalidate implementation strategy show performance implemented exible opt framework compared optimizer generated volcano volcano optimizer generator implemented optimizer equivalent transformative optimizer optimizers equivalent sense transformation rules code cost estimation selectivity estimation figures compare optimizers terms optimization times memory consumed randomlygenerated queries increasingsizes experiments wererun sun sparcwith memory gures show performance transformative search strategy opt good volcano search engine approximately degradation optimization times space utilization roughly equivalent advantage opt lies fact general framework addition features volcano exibility terms search strategy including ability mix-and-match erent search strategies interests space clarity describe implementation mechanism bywhich components path materialized memory existence path-index automatically materialized needed operation implementation similar scheme bmg section switch transformative strategy randomized strategies easier number joins optimization time seconds logscale opt volcano number joins memory requirements opt volcano figure opt volcano optimization times log-scale figure opt volcano memory requirements randomized strategies finally modi transformative optimizer randomized search strategies opt change required replace transformative search strategy object object required randomized search strategy changing transformative search strategy simulated annealing iterated improvement phase optimization vice versa trivially accomplished bychanging line code compared performance erent search strategies terms time optimize randomly generated queries increasing sizes quality plans produced stopping conditions parameters randomized search strategies figures show performance results obtained qualitatively con ndings kan smaller queries exhaustive algorithms consume time optimization randomized algorithms produce equivalent plans larger queries randomized algorithms takemuch time plans good found exhaustive algorithms con ndings phase optimization performs simulated annealing iterated improvement figure memory requirements erent strategies presented randomized strategies require negligible amount memory irrespectiveofthesize input query exhaustive strategies require exponentially increasing amounts memory queries larger shown figure randomized strategies continue give reasonable performance exhaustive strategies fail due lack memory note bottom-up transformative search strategies comparable performance terms optimization time quality plans produced exhaustive strategies explore search space bottom-up strategy signi cantadvantage space consumption perform aggressive pruning operator trees number joins optimization time seconds logscale bottom-up transformative iterated improvement simulated annealing phase optimization number joins estimated execution costs scaled bottom-up transformative iterated improvement simulated annealing phase optimization figure comparing search strategies optimization times log-scale figure comparing search strategies estimated costs scaled number joins memory requirements bottom-up transformative iterated improvement simulated annealing phase optimization figure comparing search strategies memory requirements conclusions future work paper wehave tool building extensible optimizers object-oriented design provide extensibility inheritance late binding design makes easy implement optimizer modify existing optimizers implemented opt extensibilityisprovided form ability easily extend logical physical query 
algebra easily modify search space explored search strategy andtoeven change search strategy experiences implementation optimizers opt show addition easy extend cient features opt make tool building query optimizers quickly building cient optimizer database system experimenting anumber erent optimization techniques search strategies experimentation optimizer implementor compare erent optimization strategies deciding strategy suited database system multiple search strategies option dynamically determining search strategy based input query criteria optimizer exhaustive strategy small queries randomized strategy large queries bushyjointreeenumeration small queries left-deep join tree enumeration larger queries opt build smart query optimizer dynamically customizes optimization strategy depending input plan add search strategies repertoire strategies opt heuristic pea kmp heuristics swa promising plan add debugging support opt debugging optimizer remains complex time-consuming task determining source bug optimizer produces sub-optimal plans cult hel discusses culties plan incorporate support debugging opt including visual optimizer execution tracing automated detection potential sources errors hints optimizer implementor finally plan opt study optimization complex decision-support queries included tpc-d benchmark raa cult problem opt ability easily experiment erent search strategies search spaces addition serve stress test opt acknowledgements wewould joey hellerstein number discussions mike carey naughton yannis ioannidis jignesh patel manuvir das suggesting improvements drafts paper bmg jos blakeley william mckenna goetz graefe experiences building open oodb query optimizer proceedings acm-sigmod conference washington eatrice finance georges gardarin rule based query rewriter extensible dbms proceedings international conference data engineering ieee fre johann christoph freytag rule-based view query optimization proceedings acm-sigmod conference san francisco californai graefe dewitt exodus optimizer generator proceedings acm-sigmod conference san francisco california graefe mckenna volcano optimizer generator extensibility cient search proc ieee conf data eng vienna austria gra goetz graefe rule-based query optimization extensible database systems phd thesis wisconsin madison november hel joseph hellerstein practical predicate placement proceedings acm-sigmod conference minneapolis minnesota waqar hasan hamid pirahesh query rewrite optimization starburst research report ibm yannis ioannidis younkyung cha kang randomized algorithms optimizing large join queries proceedings acm-sigmod conference june yannis ioannidis eugene wong query optimization bysimulated annealing proceedings acm-sigmod conference san francisco california june kan younkyung cha kang randomized algorithms query optimization technical report computer sciences department wisconsin madison kgm tom keller goetz graefe david maier cientassembly complex objects proceedings acm-sigmod conference denver colorado kmp alfons kemper guido moerkotte klaus peithner blackboard architecture query optimization object bases proc vldb conf lfl mavis lee johann christoph freytag guy lohman implementing interpreter functional rules query optimizer proc vldb conf los angeles california rosana lanzelotte patrickvalduriez extending search strategy query optimizer proc vldb conf barcelona september mdz gail mitchell umeshwar dayal stanley zdonik control extensible query optimizer planning based approach proc vldb conf dublin ireland ono lohmann extensible enumeration feasible joins relational query optimization proc vldb conf august pea judea pearl heuristics addison-wesley publishing company phh hamid pirahesh joseph hellerstein waqar hasan extensible rule based query rewrite optimization starburst proceedings acm-sigmod conference june raa francois raab tpc benchmark standardspeci cation revision transaction processing performance council sac selinger astrahan chamberlin lorie price access path selection relational database management system proc sigmod eugene shekita michael carey performance evaluation pointer-based joins proceedings acm-sigmod conference atlantic city jersey arun swami anoop gupta optimization large join queries proceedings acm-sigmod conference edward sciore john seig modular query optimizer generator proc ieee conf data engineering los angeles california february swa arun swami optimization large join queries combining heuristics combinatorial techniques proceedings acm-sigmod conference portland oregon june 
chapter storage management objects exodus michael carey david dewitt joel richardson eugene shekita introduction relational data model focus research database area point relational database technology well-understood number relational systems commercially support majority business applications foremost database problems support classes applications well-served relational systems computer-aided design systems scientific statistical applications image voice applications large data-intensive applications place demands database systems exceed capabilities relational systems application classes differ business applications variety ways including data modeling types operations interest storage structures access methods required operations efficient number database research efforts recently begun address problem building database systems accommodate wide range potential applications form extensibility projects include exodus wisconsin carey dewitt carey carey dewitt probe cca dayal smith manola dayal postgres berkeley stonebraker rowe rowe stonebraker starburst ibm almaden schwarz lindsay genesis ut-austin batory goals projects similar mechanisms provide extensibility approach project starburst postgres probe complete database systems well-defined data model query language system aims provide capability users add extensions abstract data types access methods framework provided data model starburst based relational model postgres extends relational model notion procedure data type triggers inferencing capabilities type hierarchy probe based extension daplex functional data model includes support spatial data class recursive queries exodus project distinguished genesis virtue database generator effort opposed attempt build single extensible dbms applications exodus genesis efforts differ significantly philosophy technical details approaches dbms software generation genesis stricter framework based building block pluggable module approach exodus powerful fixed components collection tools database implementor dbi building desired system based components exodus group addressing challenges posed emerging database applications developing facilities enable rapid implementation high-performance application-specific database systems exodus set kernel facilities applications versatile storage manager focus chapter general-purpose manager type-related dependency information addition exodus set tools dbi develop database system software implementation dbms components supported tools generate components specifications tools provided generate query optimizer rule-based description data model operators implementations graefe dewitt components abstract data types access methods database operations explicitly coded dbi due widely varying highly algorithmic nature exodus attempts simplify aspect dbi job providing programming language constructs designed specifically writing code components dbms richardson carey finally developing data model query language serve starting points subsequent exodus dbms implementation efforts chapter describe object file management facilities exodus initial design exodus storage manager outlined carey updated description reflecting design occurred developed operational version system chapter broken section describes related work generarurururururururururururururururururururururururururururururururururururu exodus provide library generally components widely-applicable access methods including trees form dynamic hashing dbi implement components library tion storage systems section overview exodus storage system presented key characteristics exodus storage manager section describes interface provided exodus storage manager higher levels exodus section makes majority chapter present detailed description data structures object storage summarize results early performance evaluation algorithms operate large storage objects section describes techniques employed versioning concurrency control recovery buffer management objects section sketches techniques implement files storage objects finally section summarizes contents chapter related work number projects construct file object management services related provided exodus kaehler krasner loom large object-oriented memory smalltalkis loom extended object storage capabilities smalltalkto manipulation objects objects problems large objects addressed system provided facilities sharing shared buffers concurrency control recovery related system file system imaxpollack file system provided support system-wide surrogates objects atomic actions objects modification reed versioning scheme reed design based premise objects small bytes special consideration clustering related objects garbage-collecting deleted objects minimize wasted file space gemstone database system maier object-oriented dbms based smalltalk-like data model interface terms storage management gemstone objects decomposed collections small elements ala smalltalk objects system object manager responsible clustering related elements disk segments gemstone architects investigated indexing issues arise object-oriented dbms environment large objects collections objects represented disk mechanisms similar employed exodus chapter darmstadt database kernel system depp paul related work motivated similar application-related considerations emphasis kernel architecture support complex records nested relations clustering components providing efficient means relocate entire complex objects host workstation components complex objects viewed records bytestring attributes objects passed kernel clients copying data page-oriented kernel buffer client-provided object buffer storage system postgres stonebraker rowe stonebraker based tuples relations tuple identified unique -bit surrogate tuples updated in-place versions modified tuples inserted database vacuuming process moves data archival disk long-term storage complex objects implemented postquel data type explicit mechanisms supporting storage manipulation large complex objects provided finally object server developed brown skarra relevant object server notion objects files similar exodus main focus work issues arising workstation server environment provide set notify lock modes support efficient object sharing environment overview exodus storage system section presents overview exodus storage system paragraphs highlight key characteristics exodus storage system expanded remainder chapter storage objects basic unit stored data exodus storage system storage object uninterpreted byte sequence virtually unlimited size providing capabilities storing manipulating storage objects regard size significant amount generality obtained access method tree written knowledge size storage objects manipulating providing generality severely limited applicability wiss chou storage system developed wisconsin wiss notion long records build tree file long records system implementation differentiates long short records concurrency control recovery simplify user task extending functionality database system concurrency control recovery mechanisms provided exodus operations shared storage objects locking concurrency control recovery accomplished combination shadowing logging versions discussed dayal smith database applications require support multiple versions objects keeping spirit minimizing amount semantics encapsulated storage system exodus generalized mechanism implement variety versioning schemes provided performance important performance issue amount copying buffer pool application programs application direct access buffer pool security problem hand database system supporting vlsi design system applications application require direct access storage objects buffer pool order obtain reasonable performance copying large multi-megabyte complex objects database system application unacceptable exodus storage system clients option directly accessing data buffer pool clients advantage option application-specific access methods operations layers applications direct access poses security problem layer copies data database system space user space easily provided minimal semantics goals minimize amount information storage system order manipulate storage objects order system extensible infeasible storage system conceptual schema conceptual schema data interpreted higher levels system hand semantics performance reasons shown chou internally speak users database implementors dbi short intend imply exodus extended naive user expect exodus extended application domain 
dbi modified occasionally applications domain dewitt buffer management performance improved allowing buffer manager capture semantics operations performed solution schema information storage system hints provided making decisions influence performance important ways buffer manager accepts hints guiding choice replacement policies storage manager supports clustering hints guide placement objects disk storage manager interface describing details large storage objects file objects collections storage objects represented exodus storage system briefly outline nature interface provided higher levels exodus cases expect level layer access methods version support exodus application layer change application expect provide library standard access methods version management code extended authors application-specific dbms intended implementation language layer richardson carey shields clients details storage manager interface expect support clients storage manager exodus exodus storage system procedural interface interface includes procedures create destroy file objects scan objects scanning purposes storage system call object storage object file object procedures creating destroying storage objects file storage objects reside file object reading storage objects exodus storage system call pointer range bytes storage object desired byte range read buffers pointer bytes returned caller call provided inform exodus bytes longer needed unpins buffer pool writing storage objects call provided exodus subrange bytes read replaced bytestring size shrinking growing storage objects calls insert bytes delete bytes offset storage object provided call append bytes end object special case insert finally transaction management exodus storage system begin commit abort transaction calls anticipate inclusion transaction-related hooks call release locks early aid efficient implementation concurrent recoverable operations access methods addition functionality outlined exodus storage system accepts number performance-related hints object creation routine accepts hints place object place object object hints achieve clustering related complex objects request object disk page size page implementing access methods regard buffer management information buffer page frames replacement policy employ accepted buffer manager supported allowing buffer group object access buffer manager accepts information per-buffer-group basis variable-partition buffer management policies dbmin chou dewitt easily supported storage objects earlier storage objects basic unit data exodus storage system storage objects grow shrink size growth shrinkage constrained occur end object exodus storage system supports insertion deletion storage object section chapter describes data structures algorithms efficiently support storage objects large dynamic storage objects storage objects small large distinction hidden clients exodus storage system small storage objects reside single disk page large storage objects occupy multiple disk pages case object identifier oid storage object form page slot pages small storage objects slotted pages ingres system wiss astrahan stonebraker chou oid small storage object pointer object disk large storage objects oid points large object header header resides slotted page large object headers small storage objects pointers pages involved representation large object pages large storage object private object shared small large storage objects pages shared versions object small storage object grows point longer accommodated single page exodus storage system automatically converts large storage object leaving object header place original small object considered alternative surrogates oid physical addresses recent proposals pollack copeland maier skarra stonebraker rowe stonebraker rejected alternative due anticipated high cost surrogates access objects surrogate index surrogate index implemented storage manager level applications surrogate support required large storage objects data structure represent large objects inspired ordered relation data structure proposed ingres stonebraker number significant differences insertion deletion algorithms stonebraker proposal figure shows large object data structure conceptually large object uninterpreted sequence bytes physically represented disk tree index byte position object collection leaf data blocks root tree large object header number count page pairs child root count child pointer maximum byte number stored subtree rooted child count rightmost child pointer size object internal nodes similar recursively defined root object contained parent node absolute byte offset child translates relative offset parent node left child root fig bytes child rest object bytes rightmost leaf node figure bytes data byte leaf node byte child root byte object note performance reasons inverse operation small object converted large object converted back small object pages header root internal blocks leaf oid figure large storage object leaf blocks large storage object pure data control information required parent leaf byte counts children size leaf block parameter data structure integral number contiguous disk pages often-updated objects leaf blocks made page length minimize amount byte-shuffling updates static objects leaf blocks consist contiguous pages lower cost scanning long sequences bytes objects leaf block size set pervolume basis trees leaf blocks allowed vary -full completely full internal node large storage object corresponds disk page count pointer pairs maximum pairs deletion algorithm works top-down manner nature top-down operation requires merge -full node entries node entries single full node shortly tree levels leaf block size object size table examples object sizes finally root node corresponds disk page possibly portion shared page count pointer pairs table shows examples approximate object size ranges supported trees height assuming leaf block sizes table assumes k-byte disk pages byte pointers -byte counts internal pages count pointer pairs obvious table levels suffice large objects large storage object data structure algorithms search range bytes insert sequence bytes point object append sequence bytes end object delete sequence bytes point object insert append delete operations proposal stonebraker stonebraker insertion deletion arbitrary number bytes large storage object poses unique problems compared inserting deleting single record ordered relation inserting deleting byte analogy case usual single-record operations single-byte operations inefficient bulk inserts deletes append operation special case insert treat differently order achieve best-case storage utilizations large objects constructed successive appends algorithms turn search search operation supports retrieval sequence bytes starting byte position large storage object retrieve sequence bytes modified rewritten referring count pointer pairs notation letting convention search algorithm start read root page call page leaf page save address stack binary search find smallest count start set start start read page page leaf desired byte page location start obtain rest bytes walk tree stack pointers maintained fig suppose find bytes set start binary search root find count set start start convention follow left child root node binary search node find count equals exceeds start set start start follow leaf page bytes bytes node bytes neighbor reachable walking stack desired bytes insert insert operation supports insertion sequence bytes 
shoring persistent applications michael carey david dewitt michael franklin nancy hall mark mcauli rey naughton daniel schuh marvin solomon tan odysseas tsatalos seth white michael zwilling computer sciences department wisconsin madison shore wisc abstract shore scalable heterogeneous object repository persistent object system development wisconsin shore represents merger objectoriented database system technologies paper give goals motivation shore describe shore features technologies describe aspects shore architecture including symmetric peer-to-peer server architecture server customization extensible value-added server facility support systems initial version shore operational expect release version midintroduction shore scalable heterogeneous object repository persistent object system developmentat wisconsin represents merger object-oriented database oodb system technologies past years signi progress oodb area applications application areas chosen leave systems favor oodbs feel applications bene oodb support impeded limitations current technology current oodbs closed restricted language persistent smalltalk unlike systems relational database systems large-scale applications require multilingual data access current oodbs application programmers face decision put data oodb case version paper appeared proceedings acm-sigmod conferenceonthe management data minneapolis research sponsored advanced research project agency arpa order number monitored army research laboratory contract daab -c-q current address department computer science maryland college park existing le-based applications rewritten leave data les current oodbs provide fairly heavy solution area transaction management dictating adoption serializability up-tothe-last-transaction data recoverability current oodbs strongly client-server architectures inappropriate execution peer-to-peer distributed systems kinds high-performance multicomputer hardware needed large scale applications goal shore project provide system addresses issues enabling holdout applications nally movetheirdata incrementally outof lesand modern persistent object repository expect current oodb clients shore attractive alternative exodus manyofuswere involved earlier object-oriented database ort called exodus cdf version exodus client-server architecture page-level locking log-based recovery based aries algorithm fzt support multiple servers distributed transactions exodus package includes programming language rcs variant supports convenient creation manipulation persistent data structures functionality performance robustness low cost free exodus made popular piece software exodus toolkit projects wisconsin erent groups countries copies ftp site storage manager open object-oriented database system serves storage engine commercial product mediadb recently announced multi-media dbms shown commercially competitive performance oodbms benchmark cdn nonetheless exodus ers limitations shared current persistent object stores exploration limitations explain motivation shore exodus storage objects untyped arrays bytes correct interpretation contents responsibility application programs instances type stored database type information stored compiletime approach data types disadvantages including easy access objects wrong type programming con guration errors version mismatch restricting type support compiler locks users single-language solutions sharing data applications cult lack stored types prevents dbms providingsuch facilities assupport heterogeneous hardware platforms data browsers garbage collectors time designed exodus felt muchvariabilityintype systems legislate common solution therehasbeen agrowingconsensus level type support oodbms system provide cat limitation exodus storage manager esm client-server architecture users constructed database servers object servers exodus client processes leading client-level server problem illustrated figure query-shipping opposed data-shipping sql serverwould cult construct ciently existing software base contrast open architecture allowed clients customize esm server process directly esm process architecture fails support clean mapping parallel processors intel paragon ibm simply run exodus server node mass storage attached support distributed transactions cient cient parallelism requires availability extensive server-to-server communication facilities limitation exodus lack support access control aspects system original thinking erent clients implement erent protection models provided built-in protection support exodus client processes manipulate objects directly cached copies database pages errant pointer destroy client data metadata rendering entire database unusable original design exodus client client sql applications exodus storage manager sql server exodus serveran exodus client figure client-level server problem envisioned client processes database systems object servers trusted software layers shore aims support environments single storage volume shared bymutually mistrusting applications finally exodus objects similar unix les untyped sequences bytes interface manipulating completely erent result existing applications built unix les easily exodus design shore strives retain good features exodus storage manager transactions performance robustness eliminating limitations shore ers exodus object shore pointer type object nes structure interface shore data language sdl single language-neutral notation describing types persistentdata shore process architecture erent exodus key ways shore symmetric peer-to-peer structure participating processor runs shore server process local disks client process interacts shore bycommunicating local shore server figure design scalable run single processor network workstations large parallel processor intel paragon ibm shore supports notion value-added server server code modularly constructed make simple users build application-speci servers facing client-level server problem paradise project dlpy shore server build geographic information system finally shore intended complete system esm addition exible process structure support typed objects shore services end users attractive including space accesssdl closely related odl data nition language recently proposed standard odmg oodb vendor consortium cat workstation app app shore app shore workstation shore shore app server server figure shore process architecture control model similar unix unix-compatible interface legacy software tools openness area language bindings traditional database services associativedata access indexing clustering remainder paper organized section overview services provided shore including system database features shore process architecture section section describes tools weare developing writing parallel object-oriented applications shore conclude section software simply paperware basic shore software operational system ciently complete binding run benchmark cdn client-server parallel environments expecting full release version shore midbasic shore system concepts hybrid system shore system augmented database features dbms le-system features section describe basic features shore explaining howit combines important ideas areas order arrive system capable addressing varietyof application requirements discussed introduction big picture shore collection cooperating data servers eachdataserver typed persistent objects organize universe persistent shore objects unix-like namespace provided unix named objects directories symbolic links individual typed objects counterpart unix plain les unlike unix shore object accessed globally unique object identi oid reused shore introduces types objects including types pools detail section type system shore objects language-neutral supporting applications programming language language binding exists objects primary data content textual untyped binary data unix system calls provided enable legacy applications existing language compilers cad tools access data content untyped manner shore structured peer-to-peer distributed system node objects stored application program wishes execute shore server process talks shore servers interfaces locally executing applications caches data pages locks order improve system performance shore object basics shore object model database object models consists objects values 
persistent datum shore object object identity denoted unique object identi oid structurally object container simple structured include typed oids objects type object behaviorally object set methods contents accessed manipulated internal structure methods object dictated object type referred interface type shore object tagged type object captures information shore object lighter-weight unix heavy support ne-grained data structures customarily represented linked lists trees graph structures nonpersistent programs support exibility dynamic structures ciency logically contiguous blocks secondary storage shore object extended variable-sized heap figure core object type heap system store variable-sized components strings variable arrays sets heap dynamic values similar top-level objects independent identity object destroyed dynamic values destroyed dynamic values linked local stored disk sets start heap swizzled memory actual memory addresses commercial oodbms deu related facility objects values distinction main erence encapsulated values form set list array shore heap arbitrary data structure demand-paging support large objects object heap closely resembles small object store database llow val dynam core ues object heapobject core figure shore object structure file system features system standpoint shore major services support object naming space management world persistent objects shore exible object namespace enable legacy unix le-based applications continue exist shore applications developed mechanisms provided permit shore object data accessed unix system calls shore object namespace shore tree-structured unix-like namespacein whichall directly indirectly distinguished root directory shore users framework register individual persistent objects roots large persistent data structures framework muchricher naming environment single-level persistent root directory found exodus current oodbs realization framework involves extending set familiar unix object types directories symbolic links regular les cross pools modules andtype objects shore directory objects provide facilities unix directories familiar unix concepts path subdirectory parent directory link hard symbolic root directory ned unix unix directory set hname oidi pairs oid refer shore object system maintains unix invariant set directories forms single rooted tree directories objects called registered objects registered object superset unix attributes ownership commercial systems tree-structured space naming databases naming organizing individual persistent objects collections access permissions timestamps support lighter-weight objects shore introduces kind registered object called pool members pool called anonymous objects clustered disk share unix attributes ownership pool anonymous objects havepathnames accessed oid likeany object operation enumerate contents pool accessed oid path registered property orthogonal type anytype object created pool anonymous object directory registered object expect atypical shore database vast majority objects anonymous registered objects serving roots entry points graphs anonymous objects preserve invariantthatall objects reachable root directory system shore imposes erent deletion semantics registered anonymous objects unix registered object explicitly deleted reclaimed system link count number directory entries referring drops anonymous object deleted time pool deleted empty oid soft dangle object refers deleted oids reused accidentally capture object oids stored contents arbitrary objects stronger integrity guarantee impractical enforce shore introduces fundamental kinds objects modules type objects cross modules type objects similar pools anonymous objects erent deletion semantics preserve existence dependency objects types cross similar symbolic links provide waytoinsert alias object directory space symbolic link path registered object cross oid arbitrary object cross symbolic links soft permitted dangle intended primarily unix compatibility feature section figure illustrates concepts directory smith entries project doc pool referring directory cross pool registered object smith project entriescontains pointers members pool sort applicationde ned directory entry points data structhe semantics timestamps slightly erent unix order make ciently maintainable retaining usefulness applications rely ture symbolic link smith project readme alias cross smith doc alias member pool attempt access path names unix compatibility interface resolvetothat anonymous object smith pool smith smith project proj root project pool smith project entries entries smith project readme smith doc smith doc doc figure shore space legacy unix tool support shore richer environment traditional systems situations tools designed les invoked database objects typical provided capitl project exodus capitl improves currentsoftwaredevelopment environments maintaining rich set attributes relationships object repository program sources object les speci cations documents represents object directed graph intraand inter-object links represented oids tools developed part capitl full advantage rich structure occasionally invoke existing tools compilers editors objects stored database approaches rewrite tools access capitl objects copy contents object operating copyback results contents permanently les storing metadata names capitl database approaches unsatisfactory reasons solutionfound forcapitl whichwehave generalized expanded shore provide special unix compatibility feature shore object optionally designate range bytes text eld compatibility library versions unix system calls open read write seek interpreting pathname arguments shore space satisfying requests fetching updating text eld objects registered objects text elds behavelike dev null read length ignore attempts change anonymous objects accessed cross applications re-linked constructed nfs server sgk entire subtree shore space mounted existing unix system applications attempt access les portion space unix kernel generates nfs protocol requests handled shore nfs valueadded server object-oriented database features mentioned section importantmotivation shore rectify shortcomings exodus shared existing object-oriented databases access control space limitations addressed previous section process structure addressed section section describe design implementation shore type system supports hardware language heterogeneity shore type system shore type system embodied shore data language sdl language shore types ned sdl similar nature object nition language odl proposal odmg consortium cat descended omg interface description language idl dialect rpc interface language osf distributed computing environment dce work sdl started roughly time odmg work omg idl starting point wehavebeen followingthe developmentof odl proceed waiting odmg complete work time odmg standards late paper design stage portions clear internally consistent goals odmg erent concentrate standardized interface existing oriented oodbs focus support inter-languageobject sharing large namespace objects objects instances interfacetypes types constructed interface type constructor interface types methods attributes relationships attributes interface type primitive types integer character real constructed types shore usual set type constructors enumerations structures arrays relationships addition shore varietyofbulk types including sets lists sequences enable shore object collection objects finally shore notion modules enable related types grouped scoping type management purposes provide taste sdl figure shows howoneof benchmark cdn types ned module const long typesize enum benchmarkop trav trav trav forward declarations interface connection interface compositepart interface atomicpart public attribute char ptype typesize attribute long relationship set connection inverse relationship set connection inverse relationship ref compositepart partof inverse parts void 
swapxy long traverse benchmarkop inout partidset visitedids const void init long ptid ref compositepart connection compositepart types figure contents sdl shore language bindings shore intended databases built application written language accessed manipulated applications written object-oriented languages clos capability important large-scale applications suchasvlsicad ciency simulating large chips clos smalltalk convenient writing design-rule checking user interface code shore methods sdl interfaces written anyofthe interest brevity details omitted languages shore language binding exists binding operational illustrate shore language binding concepts brie discussing shore binding application benchmark created rst step write description types sdl description saved called sdl step sdl type compiler create type objects types type compiler shore application creates type objects sdl nitions language-speci tool case extract derivea set class declarations special-purpose function nitions type objects generated code les header included source les supply applicationspeci implementation member functions traverse swapxy source les manipulate instances atomicpart oid type object compiled les catchversion mismatches runtime fragment generated shown figure data member types figure corresponddirectly sdl types languages ers direct support simple types shore types type sets language-appropriate presentation sdl type generated shore presents sets collection types pre-de ned template classes parameterized types ref set figure class ref compositepart encapsulates oid overloading features make behave pointer read-only instance compositepart class set connection encapsulates data structure set oids member functions enable contents accessed bindings planned work begin shore fully operational delivering good performance binding note shore application create type objects instance write graphical schema design tool create type objects install database class atomicpart public char ptype long long set connection set connection ref compositepart partof virtual void swapxy virtual long traverse benchmarkop partidset visitedids const virtual void init long ptid ref compositepart additional sdl-generated members included figure class generated sdl header generated binder application programmer implement operations interfaces binding access simple data members provided safely techniques mentioned ref-generated classes behave read-only pointers information atomic part printed function void printpart ref atomicpart cout type ptype part function directly access part type data members atomic part update attempts agged error compiler similarly member functions update contents object agged const sdl nition illustrated figure attempts call non-const member function ref caughtby compiler modify object application rst call special generated member function update returns read-write code fragment directly exchanges attributes atomic part ref atomicpart long tmp update update tmp function update coerces type ref atomicpart const atomicpart runtime ect marking referenced object dirty transmitted server transaction commits member function swapxy declared const figure legal accomplish exchange member function void atomicpart swapxy long tmp tmp nition swapxy invoked job ref atomicpart update swapxy shore binding implements collection types similarly oodbs llow obj ont ver template type set connection figure member function members returns iterator printpart function extended print atomic part outgoing connections void printpart ref atomicpart cout type ptype part outgoing connections iter connection members ref connection null print cout oodb-like services shore support concurrency control locking crash recovery logging services integrated support data caching shore provide users choice lower levels consistency recovery details reduced levels worked shore services include optimized object queries bulk types exible user-controllable notion sticky object clusters permit users cluster recluster related objects shore architecture peer-to-peer server communication figure section illustrates process structure shore shore executes group communicating processes called shore servers shore servers consist exclusively trusted code including parts system provided part standard shore release code added servers vass added sophisticated users implement specialized facilities query-shipping sql server introducing client-level server problem earlier application processes labeled app figure manipulate objects servers deal primarily xed-length pages allocatedfromdisk volumes eachofwhichismanaged single server applications trusted sense buggy malicious application modify objects authorized access corrupt metadata slot tables indexes directory structure shore server plays roles page-cache manager cache pages local volumes pages remote servers objects requested local client applications server acts agent local application processes application object sends rpc request local server fetches page returns object details provided section finally shore server responsible concurrency control recovery server obtains caches locks behalf local clients owner page server manages volume responsible arbitrating lock requests objects logging committing transaction management detail process structure great deal exibility acting owner page shore server performs role server traditional data-shipping client-server dbms acting agent application plays role client letting shore server assume roles data placement optimized workload data largely private singleuser owned shore serveron user workstation location-transparency application viewpoint provided cachingbased architecture application workstation access local remote persistent data identical manner ability cache pages local server greatly reduce observed performance penalty accessing remote data figure applications running workstation access data largely private local shore server obtaining shared data shore servers query-shipping architecture implemented higher level valueadded server sql server applications communicate directly remote servers shore software components language independent library figure depicts components shore software linked application application attempts dereference unswizzled pointer language binding generates call object-cache manager language-independent library lil present disk volumes replicated client object cachelanguage independent library application code rpc interface storage manager page cache shore vas interface server figure application server interface desired object present lil sends rpc request local server fetches page reading local disk sending request server local operating system supports shared memory server deliver page objects lil quickly experimenting cache-management strategies cache objects free page requested object toavoid paging object cache manager locks cache memory lru replacementifitgrows large oids cache swizzled point entries object table level indirection objects removed memory transaction commits track unswizzle pointers lil unix compatibility library procedures emulate common system calls open read seek finally lil responsible authenticating application server kerberos authentication system mnss shore server figure shows internal structure shore server detail divided main components server interface communicates applications storage manager manages persistent object store server interface responsible providing oid volume identi server global volume-location service server establishes network connection shore serversother data log application transaction index vas interface threads async transaction mgr recovery mgr interface page cache lock table logical cache core distributed transactions locking logging communication object operating system interface consistency page cache object access control space shore vas nfs vas figure shore server components access shore objects stored manages unix-like space structures section 
application connects server server associates unix-like process state user current directory connection user information checked registeredobjects rst accessedto protect unauthorized access unix current directory information context converting path names absolute locations space server interface value-added server vas vas nfs server section vas alternativeinterface storage manager interact storagemanagerthrougha common interface similar rpc interface application processes server debug vas client process migrate server added ciency completely debugged vas sql server query-shipping interface relational database server interface lies storage manager shown figure viewed sub-layers highest vassm interface consists primarily functions control transactions access objects indexes middle level comprises core implements records indexes transactions concurrency control recovery lowest level extensions core implement sql server vas erentuseof shore server upper layers type system shore essentially thrown facilities provided shore storage manager construction completely erent customized server distributed server capabilities section addition layers operating system interface packages multi-threading asynchronous inter-process communication implementation details detailed description storage manager scope paper subsection highlight important technical issues arise implementation cache consistency transaction management object identi implementation cache consistency shore types caches object caches applications page caches maintained shore servers types caches managed erently shore servers page caches allowed retain contents transaction boundaries called inter-transaction caching cache consistency maintained callback locking protocol hmn llow application server interface support upcalls requiring application processes respond remote procedure calls interfere synchronization mechanisms application programs threads packages graphics interviews networking interfaces object cache invalidated locks released end transaction weplan explore techniques extend object cache acrosstransaction boundaries shore project balance ciency ne-grain concurrency shore adaptive version callbacklocking dynamically adjust granularity page object whichlocking performed depending presence data con icts cfz adaptive algorithm based notion lock de-escalation jos transaction management application wishes commit transaction commit request local server transaction modi data owned multiple servers two-phase commit protocol relevant servers local server log coordinate distributed commit protocol delegate coordinator role server transactions access data owned local server commit locally peer-to-peer architecture incurs additional overhead distributed commit transaction rollback recovery facilities shore based aries recovery algorithm mhl extended client-server environmentof shore client-server distinction ects roles played server respect object server ownsan object isthe storesthe logfor object performs recovery operations object servers caching object behave clients generatelog recordsthat shipped owner object initial implementation shore relies simple extension aries call redo-at-server extension client ships dirty pages backto server log records server receives log records client redoes operations log records easy implement advantage eliminating send dirty pages backtothe server primary disadvantage server reread pages ushed cache future plan implement client-server extension aries developed implemented exodus storage manager fzt compare performance simpler redo-at-server implementation oid implementation implementation object identi ers oids considerable impact rest object manager implemented performance shore storage manager types oids physical oid records actual location object disk logical oid position independent allowing transparent reorganization reclustering higher levels shore including object cache manager logical oids representobjectreferences logical oid consists -byte volume identi -byte serial number designed long globally unique allowing independently developed databases combined large avoid reuse values conceivable operating conditions oid stored disk serial number recorded volume identi assumed volume oid crossvolume serial number identi special forwardingentry containsthe full oid object identi volume serial number relativetothatvolume map serial numbers physical oids remote logical oids volume tree index called lid index in-memory hash table cache recently translated entries server eagerly adds translations per-transaction translation cache server receives request object logical oid generally computational cost redo small compared cost receiving page data network cache requests page object object server page arrives server enters mappings objects page translation cache technique ectively reduces number lid index accesses lookup object lookup page objects parallelism shore goals shore support parallel applications single-threaded applications parallel environment challenge identify sources parallelism services interfaces applications exploit parallelism provide high-performance implementations services divide parallelism inter-transaction parallelism intra-transaction parallelism inter-transaction parallelism means running independent transactions concurrently multiple processors target architecture parallel shore shared-nothing multiprocessor suchamultiprocessor commercial shared-nothing multiprocessor network workstations shore symmetric peer-to-peer server architecture ideal basis constructing parallel persistent object store platform client-servershore process node multiprocessor obtain object stored multiprocessor presenting object oid local server intra-transaction parallelism easy identify priori waywe address large-scale parallel applications noting persistent object store applications large slow accessing large amounts data object bases grow large storing large collections homogeneous objects primarytargetof workin parallelshore provide framework operations large collections objects run parallel shore parsets basic parallel construct shore parset short parallel set parset concept proposed kilian kil adopting data parallel approach object-oriented parallel programming ways parsets expose parallelism set-oriented queries parsets parallelized relational queries parallelized relational systems coupled object-oriented programming parsets provide parallel set-apply operation whichinvokes method elementoftheparset parallel similar approach parallel apply arbitrary function member set lter operation bubba project mcc bbkv parallel shore distinguish forms parsets primary secondary terms primary secondary analogy common database indexes primary parsets physical implication primary parsets data partitioning contrast secondary parsets logical collections objects denote set objects apply executed imply objects reside object anynumber secondary parsets primary parset parsets due space constraints giving detailed description parset semantics implementation give informal description parsets parallelize benchmark code running prototype parset implementation network workstations purposes discussion ces database set composite parts subgraph atomic parts parallel implementation composite parts stored parset distributed nodes system hashing composite part atanygiven node portion parset node shore collection processors node collection composite parts node composite parts figure illustrates process communication structure parallel shore pshore application pshore application parallel designated main master process running nodes system addition master process slave processes running nodes multiprocessor slaves forked master required master lifetimes slave processes methods invoked objects parsets loop waiting messages master process suppose main program executes parset method apply composite parts composite part parset applied composite part traverses subgraph atomic parts contained composite part master send messages slaves apply composite parts partition parset slaves execute request parallel talking local servers detail appears dnsv compositepart attribute called partid separate oid composite part object fetching composite part objects object caches calling method eachone shore server node master slave shore server node slave shore server node slave parset server figure parallel shore architecture parallelism largely transparent application programmer simply writes single-threaded 
byte position arbitrarily large algorithm efficiently handles bulk insertions required mentioned standard b-tree insertion algorithm works inserting single byte inefficient large insertions insert algorithm traverse large object tree leaf byte reached search algorithm tree traversed update counts nodes reflect number bytes inserted save search path stack call leaf bytes inserted reached insert bytes overflow occurs insert internal node counts updated overflow occurs proceed left neighbor free space determined examining count information parent node number bytes leaf block sufficient amount free space accommodate modulo bytes data overflow remain filling leaves data evenly distribute data contents evenly nodes lfn brf newly allocated nodes simply allocate leaves hold overflow evenly distribute bytes bytes inserted newly allocated leaves propagate counts pointers leaves upward tree stack built internal node overflows handle leaf overflows handled neighbor check motivation neighbor checking portion step avoid allocating additional leaf node cases overflow accommodated neighboring node adds small cost expense insertion unnecessary access neighboring leaf determined based examining parent count values redistribution data succeed neighbors read disk case standard tree note modification increase cost insertion cases redistribution reading writing back node created splitting lfn brf nodes read written cost increase worth case modification leads significant improvement storage utilization carey argued additional cost reading picture redistributing data avoid system process allocating additional node free list handle overflow append append operation supports addition bytes end large object appending bytes differs inserting bytes data redistributed leaf pages overflow occurs append algorithm make rightmost traversal large object tree tree traversed update counts internal nodes reflect effect append save search path stack call rightmost leaf ifr free space hold bytes append bytes append operation complete case call left neighbor exists allocate leaves hold bytes bytes bytes appended object fill newly allocated leaves rightmost leaves tree completely full balance remaining data rightmost leaves leaving leaf -full free space ignore step propagate counts pointers leaves upward tree stack built handle internal node overflow insertion algorithm key point algorithm guarantees large object constructed successive append operations maximal leaf utilization leaves completely full large objects created steps object created extremely large algorithm improved yield higher internal node utilization treating internal nodes leaves treated decided increase cost algorithm internal node utilization critical leaf node utilization large fanout internal nodes cut-path deleted portion tree left cut-path cut-path lca figure terminology deletion algorithm delete delete operation supports deletion bytes starting byte position tree analogous problem range deletion deleting keys lower upper bounds traditional tree deletion algorithm removes record time unacceptably slow large deletions bulk delete algorithm proceeds phases phase deletes range bytes possibly leaving tree unbalanced state phase makes pass tree structure rebalance tree note phase expensive sound relevant nodes buffer-resident phase deletion arbitrary range bytes leaves large object general imply deletion number entire subtrees leaving raw edge damaged nodes nodes form cut-path deletion general left cut-paths start root include number common nodes split proceed tree leaves node left cut-paths diverge called lowest common ancestor lca delete figure illustrates relationship deleted portion tree left cut-paths lca note nodes remaining tree underflowed necessarily occur cut-path rebalancing algorithm traces cut-path top-down fashion attempting zipper split tree order minimize cost deletion algorithm small data structure memory path describes cut-path path data structure built delete phase algorithm stores disk address cut-path node number children including nodes left cut-paths information stored path sufficient determine node danger underflowing defined shortly rebalancing algorithm examines path top-down fashion path node danger underflowing tree node merged reshuffled neighboring node safe notion node danger underflowing possibly underflowed rebalancing algorithm operate downward pass tree node situation afford pair child nodes merged single child node node underflow prevent possibility potential underflows handled tree merging endangered nodes neighboring nodes borrowing entries neighboring nodes merging impossible neighbors entries node underflowed conditions holds node node leaf -full node internal node fewer entries fewer entries root node node danger underflowing conditions holds node underflowed node internal node entries entries root children cut path danger node lca entries entries root children cut path danger background definitions underflowed endangered nodes describe phase deletion algorithm deletion phase traverse object left limits deletion subtrees completely enclosed traversal deleted counts nodes cut-path updated show results deletion node cut-path tree traversed create representative node main-memory data structure path records address node number children left traverse path data structure bottom-up marking node danger defined rebalancing phase root danger step root child make child root merge reshuffle children root danger node cut-path nodes remain tree rebalanced current node danger merge reshuffle sibling node cut-path require iterations loop additional note order regard cost deletion phase algorithm phase leaf block touched deleted nodes simply handed back free space manager directly addresses parent node deletion accomplished partially deleted leaf block left cut-path simply decrementing byte count parent node partially deleted leaf block cut-path read rewritten deletion phase performance characteristics implemented large object data structure algorithms constructed main-memory prototype order investigate design alternatives performance tradeoffs study assumed k-byte page size -page -page leaf blocks experiments consisted append operation construct objects initial sizes initial storage utilization approximately running mix randomly generated read search insert delete operations objects experimented merge reshuffle step decides nodes merged bytes reshuffled neighbor updates path maintain consistent view cut-path objects ran tests -byte -byte k-byte search insert delete operations details study carey summarize major results refer interested reader original paper details basically found exodus large storage object mechanism operate large dynamic objects low cost reasonable level storage utilization insert algorithm chapter avoids allocating leaf pages neighbors unable accommodate overflow obtained average storage utilizations range percent results obtained presence random byte insertions deletions large static objects utilizations close norm utilizations range expected objects updates localized respect choice leaf block size experiments highlighted expected tradeoffs -page leaf blocks advantageous large multi-page reads leading percent performance improvement compared -page leaf blocks increased cost updates led decrease storage utilization presence random insertions deletions multi-page leaf blocks offer greatest advantages large static objects raster images storage utilization close objects built appends subjected frequent random updates versions storage objects earlier exodus storage system support versions storage objects support provided primitive updates versioned object 
leading creation version object object designated versioned non-versioned object created versioned storage object updated object header entire object case small storage object copied location disk updated version object oid version returned updater oid version remains oid originally passed update routine oid physical addresses ensure cost copying version prohibitive carey muhanna version page file object nearby page note versions recovery mechanism unreasonable reason primitive level version support exodus applications widely notions versions supported evidenced wide range version-related proposals recent literature stonebraker dadam katz lehman batory kim clifford tansel klahold snodgrass ahn katz leave maintenance data structures graphs versions alternatives objects higher level system level vary application application unlike storage system reason leave version management exodus storage system altogether efficiency prohibitively expensive terms storage space cost maintain versions large objects maintaining entire copies objects versions large storage objects maintained copying updating pages differ version version figure illustrates figure shows versions large storage object fig original version newer version created deleting bytes note shares nodes unchanged copies modified node version large storage object copy path root leaf leaves copies internal nodes figure versions large storage object change affects large fraction object length path number internal pages small relative number pages actual data due high fanout internal nodes overhead versioning large objects scheme small tree height basically proportional difference adjacent versions size objects allowing creation versions large storage objects exodus storage system supports deletion versions efficiency standpoint storage system successfully hide physical representation storage objects clients problem deleting version large object avoid discarding object pages shared needed versions object general situation pictured fig delete version direct ancestor derived descendants derived naive insure shared pages discarded traverse versions marking page visited traverse discarding unmarked page problem approach versions number pages visited large cut number pages visited observe ancestor version shares page page share page likewise descendant shares page share page suffices visit pages direct ancestor direct descendants object figure version history adjacent versions object version object directly derived versions directly derived object reduce number pages visited observing things page shared versions large object entire subtree rooted page shared versions leftmost child version root pages fig subtree shared versions root subtree height distance leaf level versions object fig observation means visit shared subtree root visit descendant pages necessarily shared observation means scan versions equal height level level detect roots shared subtrees level scanned versions unequal height check shared pages level taller versions suppose moment delete version object direct descendant suppose height based observations deletion algorithm internal level working top-down root level scan index nodes level tentatively marking page numbers encountered nodes level deletion note page numbers pages level scan level marked page number encountered unmark avoid scanning page subtree rooted page subsequent iterations discard pages level ofv marked deletion step finish discarding root algorithm easily generalized handle case heights versions unequal height greater delay scanning scanning level height root case height greater handled similarly clear algorithm generalized case versions adjacent ancestor descendant versions case step performed level adjacent version page discarded adjacent version shares page input version deletion operation takes oid version deleted set oid adjacent versions deletes version leaving pages shares adjacent versions intact earlier leave problem maintaining information adjacent versions fig higher level system implement algorithm efficiently breadth-first search scan objects main-memory hash table store page numbers marked pages note read leaf pages disk algorithm worst case sharing pages versions algorithm simply ends visiting non-leaf page version visiting leaves leaf blocks comprise vast majority version internal node fanouts hundred non-leaf pages represent storage requirements large objects typical cases algorithm visit pages adjacent versions share bulk pages apparent complexity approach cheaper terms cost approach based counts counting scheme require counts inspected deleted leaf pages requiring pages read concurrency control recovery exodus storage system concurrency control recovery services storage objects initially concurrency control provided hierarchical two-phase locking gray levels file objects storage objects eventual plans involve locking byte ranges storage objects lock entire object option provided cases object level locking sufficient expect object level locking norm small storage objects byte range locking large storage objects applications updates change contents byte range changing size range updates read rewrite bytes range concurrent searches updates disjoint regions object permitted updates insert append delete bytes lock byte range operation begins end object offsets remaining bytes indeterminate updater commits aborts ensure integrity internal pages large storage objects insert append delete operations operating changing counts pointers non-two-phase tree locking protocols bayer scholnick employed searches byte range updates descend tree structure chaining read locks read-locking node level immediately releasing level read-lock holding byte range read write locks two-phase manner inserts appends deletes affect entire root-to-leaf path root internal pages path type update write-locked duration operation insert delete append byte range write locks held two-phase manner operation completed opted locking techniques perform concurrency control techniques environments agrawal recovery small storage objects handled classical logging techniques in-place updating objects gray lindsay log entries operation-oriented recording byterange update operations arguments recovery large storage objects handled combination shadows operation logging updated internal pages leaf blocks shadowed root level updates installed atomically overwriting object header header verhofstad prior installation update root updated pages written disk parameters update operation logged log sequence number ala gray lindsay update log record root page object ensures operations large storage objects undone performing inverse operation redone re-performing operation idempotent manner recovery scheme employed versioned objects buffer management storage objects earlier objective exodus storage system design minimize amount copying takes place higher-level software system buffer related objective sizable portions large storage objects scanned directly buffer pool accommodate allocate buffer space single-page units variable-length recall inserting appending deleting bytes counts change root decide treat write operations similarly simplify recovery code chunk bbb bbb object header leaf blocks chunk descriptor figure contiguous buffering exodus chunks chunk consists integral number contiguous pages single-page units data structures occupy page disk space small objects requests singlepage units handled separately improve system performance expect majority buffer requests small objects chunks exclusively buffering data large storage objects ability allocate variable-length chunks simplifies higher-level software making read scan multi-page sequence bytes large 
storage object concern page boundaries figure sketches key aspects exodus buffering scheme large storage objects suppose exodus client requests sequence bytes read object bytes resident buffer pool non-empty portions leaf blocks desired range bytes leaf blocks fig read contiguous chunk buffer pages leaf blocks supported routines unit transfer disk buffers accomplished obtaining chunk size buffer space manager reading lastly block order begins end non-empty portion similarly constrains order leaf blocks large object read buffer pool view limitation chained potentially advantage paul chunk descriptor maintained buffer manager current region scanned including information oid pointer page frame buffer pool length portion chunk bytes requested clients pointer byte information contents chunk buffer replacement purposes rare event client read portion chunk allocated time portion read disk remaining portion appears replicated memory-to-memory copy avoid inconsistencies measures ensure replicated data updated replicated portions chunk deleted buffer pool chunk updated concurrency control ensures write lock obtained prior update chunks variable-length runs page frames exodus buffer manager employs sophisticated free space management techniques buffer managers encountered satisfy requests sizes chunks employ data structure maintains lists free chunks size chunk requested data structure examined find free chunk satisfies request notion favors chunks size requested breaking larger free chunks free chunk size chunk fewest dirty pages free chunk large satisfy request attempt made coalesce free chunks adjacent coalesc- ing fails construct large chunk request rejected sounds expensive preliminary test results shown chunk requests satisfied coalescing finally mentioned previous section buffer space allocation replacement performed notion buffer group client opens buffer group specifies number page frames group group-size replacement policy group-policy employed replacing pages buffer group descriptor returned client passed storage manager client requests subsequent operations storage objects operations performed respect group meaning client group-size pages replacement performed group pages group-policy replacement strategy client permitted multiple buffer groups open buffering schemes dbmin chou dewitt allocates buffer partition active index relation instance relational query supported simple schemes global lru easily supported buffer group mechanism file objects file objects exodus storage system collections storage objects sets storage objects restriction object resides set file objects grouping objects purposes exodus storage system mechanism sequencing objects file related objects common file sequential scanning purposes objects file disk pages allocated file file objects provide support objects co-located disk file representation representation file objects exodus similar respects representation large storage objects file object identified oid pointer root page header file object storage objects file objects distinguished bit object headers large storage objects file objects represented index structure similar tree key index case file object index disk page number key leaf page file object index collection page numbers slotted pages contained file object large object large file oid page tree figure exodus file object actual slotted pages managed separately standard techniques page allocation free space management figure shows file object index relates slotted pages objects reside file object index serves mechanism gather pages file additional properties interest facilitates scanning objects file object physical order efficiency supports fast deletion object oid file object moment considered file designs settling including possibility representing files large storage objects sequence oid supported fast object deletion scheme note objects file directly accessible oids file objects confused surrogate indices external object file object oid values point directly object creation file object allocates file object header object created file object object creation routine called optional hint form place object oid existing object file hint present object inserted slotted page recall oid identifies desired page space page object inserted neighboring page file neighboring page inspected found full slotted page page allocated newly inserted object page number inserted file object tree oid file object recorded newly allocated page co-location hint present simply appended file placing page listed file object index overflows handled manner speed location neighboring page overflow handling slotted page neighbor hint field page number recent neighboring page overflows deletion object file accomplished simply removing object page resides page empty result page number deleted file object index page returned free space manager lastly deletion entire file object lead deletion objects residing slotted pages listed file object index return pages free list removal index slotted page large object headers file object headers recursively deleted page freed immediately leaf page entry file object index bit slotted page large object headers file object headers permitting check performed file deleted reading slotted pages small objects file object issues concurrency control recovery file objects handled mechanisms similar large storage objects concurrency control page number insertions deletions provided tree locking protocols recovery accomplished shadowing highest affected level file object index logging insert delete operation finally overwriting highest affected node atomically install update note concurrency control recovery protocols exercised file index modified insertion deletion page number entries occurs slotted page added removed file object storage object concurrency control recovery mechanisms handle slotted page involve updates file object index final non-trivial issue related file objects question sort file object sequential file schema information carefully exodus storage system storage system sufficient information idea fields storage objects file object data types fields sorting accomplished client level exchanging contents storage objects client notion objects reordered note sorting necessarily moves contents objects page page oid longer valid sorting performed main oid differ surrogates storage system operations preserve integrity oid leaving forwarding address object original location object relocated summary chapter design implementation storage management component exodus extensible database management system development wisconsin basic abstraction exodus storage system storage object uninterpreted variablelength record arbitrary size file objects grouping sequencing collections storage objects data structures algorithms support large storage objects results study performance summarized support large dynamic storage objects efficiently terms storage utilization terms access update performance approach maintaining versions large objects sharing common pages versions efficient version deletion algorithm presented chapter exodus notion file objects approach buffer management concurrency control recovery mechanisms briefly covered writing design exodus storage system complete initial version system based ideas presented chapter fully operational included version system support small large objects file objects buffering variable-length portions objects shadow-based atomic updates large objects file objects exception concurrency control multi-user aspects design accounted implementation actively building version system include 
support versions full multi-user transaction management including concurrency control operation logging acknowledgements research partially supported defense advanced research projects agency contract -kby national science foundation grant dcrby ibm fellowship faculty development award dec initiatives excellence program grant microelectronics computer technology corporation mcc authors acknowledge contributions people affiliated exodus project including goetz graefe mohamed isa hashim dan frank muralikrishna david haight agrawal agrawal carey livny concurrency control performance modeling alternatives implications acm transactions database systems december astrahan astrahan system relational approach database management acm transactions data systems june batory kim batory kim support versions vlsi cad objects mcc working paper march batory batory genesis reconfigurable database management system technical report tr- department computer sciences texas austin march bayer scholnick bayer schkolnick concurrency operations b-trees acta informatica carey dewitt carey dewitt extensible database systems proceedings islamorada workshop large scale knowledge base reasoning systems febuary carey carey object file management exodus extensible database system proceedings vldb conference kyoto japan august carey carey architecture exodus extensible dbms proceedings international workshop object-oriented database systems asilomar september carey muhanna carey muhanna performance multiversion concurrency control algorithms acm transactions computer systems november carey dewitt carey dewitt overview exodus project database engineering june chou dewitt chou h-t dewitt evaluation buffer management strategies relational database systems proceedings vldb conference stockholm sweden august chou chou h-t dewitt katz klug design implementation wisconsin storage system software practice experience october clifford tansel clifford tansel algebra historical relational databases views proceedings sigmod conference austin texas copeland maier copeland maier making smalltalk database system proceedings sigmod conference boston dadam dadam lum h-d werner integration time versions relational database system proceedings vldb conference singapore august dayal smith dayal smith probe knowledge-oriented database management system proceedings islamorada workshop large scale knowledge base reasoning systems february deppish deppisch h-b paul h-j schek storage system complex objects proceedings international workshop object-oriented database systems pacific grove september graefe dewitt graefe dewitt exodus optimizer generator proceedings sigmod conference san francisco gray gray notes database operating systems operating systems advanced bayer graham seegmuller eds springer-verlag kaehler krasner kaehler krasner loom large object-oriented memory smalltalksystems smalltalkbits history words advice krasner addison-wesley katz lehman katz lehman database support versions alternatives large design files ieee transactions software engineering semarch katz katz chang bhateja version modeling concepts computer-aided design databases proceedings sigmod conference washington klahold klahold schlageter unland wilkes transaction model supporting complex applications integrated information systems proceedings sigmod conference austin lindsay lindsay notes distributed databases ibm research report ibm san jose research center july lindsay lindsay data management extension architecture proceedings acm-sigmod international conference management data san francisco maier maier development object-oriented dbms proceedings annual acm conference object-oriented programming systems languages applications portland manola dayal manola dayal pdm object-oriented data model proceedings international workshop object-oriented database systems pacific grove september paul paul architecture implementation darmstadt database kernel system proceedings acm-sigmod international conference management data san francisco pollack pollack kahn wilkinson imaxobject filing system proceedings symposium operating systems principles pacific grove december reed reed implementing atomic actions decentralized data acm transactions computer systems march richardson carey richardson carey programming constructs database system implementation exodus proceedings sigmod conference san francisco rowe stonebraker rowe stonebraker postgres data model proceedings international conference large data bases brighton england schwarz schwarz extensibility starburst database system proceedings international workshop object-oriented database systems pacific grove september skarra skarra zdonik reiss object server object-oriented database system proceedings international workshop object-oriented database systems pacific grove september snodgrass ahn snodgrass ahn taxonomy time databases proceedings sigmod conference austin stonebraker stonebraker wong kreps held design implementation ingres acm transactions database systems september stonebraker stonebraker hypothetical data bases views proceedings sigmod conference boston stonebraker stonebraker stettner lynn kalash guttman document processing relational database system acm transactions office information systems april stonebraker rowe stonebraker rowe design postgres proceedings sigmod conference washington stonebraker stonebraker postgres storage manager proceedings international conference large data bases brighton england verhofstad verhofstad recovery techniques database systems acm computing surveys june 
performance study alternative object faulting pointer swizzling strategies seth white david dewitt computer sciences department wisconsin madison white dewitt wisc abstract paper presents portable efficient method accessing memory resident persistent objects virtual memory context programming language approach objects copied buffer pool underlying object manager virtual memory demand accessed program cumulative effects updates persistent object propagated back object manager single write operation end transaction method incorporates comprehensive pointer swizzling mechanism enhance performance swizzling pointer-at-a-time software checks detect swizzled pointers paper presents results performance study comparing method presented alternative software architectures including objectstore commercially oodbms results highlight tradeoffs providing software memory-mapped support pointer swizzling quantify effects pointer swizzling performance addition significant performance impact pointer swizzling generation recovery information examined experimental results show situations software approach outperform memory-mapped approach introduction persistent programming language rich rich originally designed ease implementation data-intensive software applications database management systems require access huge amounts persistent data current implementation interpreter persistent virtual machine epvm coordinate access persistent data schuh stored exodus storage manager carey carey approach epvm memory resident persistent objects cached buffer pool exodus storage manager esm persistent objects accessed in-place addition epvm support limited form pointer swizzling paper introduces alternative implementation epvm epvm targeted cad environments common cad application design tool loads engipermission copy fee part material granted provided copies made distributed direct commercial advantage vldb copyright notice title date notice copying permission large data base endowment copy republish requires fee special permission endowment proceedings vldb conference vancouver british columbia canada neering design main memory repeatedly traverses design performing computation saves design secondary storage important property design applications perform considerable amount focused work in-memory persistent objects major fraction work involves manipulation persistent objects pointers basic approach employed epvm maintain cache virtual memory set persistent objects accessed program objects copied esm buffer pool inserted cache accessed program addition cumulative effects updates persistent object propagated back esm single write operation transaction commits finishes execution cache supports comprehensive pointer swizzling scheme swizzles inter-object pointer converts pointers object identifiers oids direct memory pointers pointers swizzled one-at-a-time program volume data accessed individual transaction exceeds size real memory objects swapped disk swizzled format virtual memory subsystem evaluate effectiveness design epvm paper presents results number performance experiments conducted benchmark catte experiments compare epvm alternative software architectures objectstore objec commercially object-oriented dbms objectstore memory-mapped approach support pointer swizzling fault objects main memory architecture represented epvm supports limited form pointer swizzling architecture support pointer swizzling corresponds conventional non-persistent programming language call esm directly experimental results illustrate tradeoffs implementations object faulting pointer swizzling including swizzling examine impact schemes generation recovery information case epvm alternative ways managing migration persistent objects esm buffer pool virtual memory examined systems included study based client server architecture feature full support transactions concurrency control recovery client server version esm frank exodu store persistent data experiments based epvm epvm research funded defense advanced research projects agency contract daab -c-q remainder paper organized section discusses related work object faulting pointer swizzling section presents detailed description implementation epvm section describes benchmark experiments section presents performance results section conclusions proposals future work related work previous approaches pointer swizzling roughly divided groups memory mapping techniques similar virtual memory software checks detect accesses nonresident objects early work software implementations pointer swizzling part implementation ps-algol atkin cock approach pointer dereferences trigger transfer objects secondary storage main memory moss presents recent study software swizzling techniques examines issue storing persistent objects buffer pool object manager versus copying virtual memory moss takes object-at-a-time approach swizzling objects memory classified swizzled unswizzled approach pointers unswizzled object swizzled immediately object objects pointers faulted memory marked unswizzled finally initial object marked swizzled advantage approach wilso generally perform unnecessary swizzling unswizzling work disadvantage objects accessed program faulted memory swizzling mechanism resulting unnecessary operations unswizzled objects memory resident definition referenced restricted form pointer swizzling supported epvm schuh maintains memory resident objects esm buffer pool swizzling inter-object pointer difficult implement efficiently local program variables pointers persistent objects swizzled advantage approach objects written back disk presence swizzled pointers general hard efficiently software approach swizzled pointers object found unswizzled memory space occupied object reused compiler stores local pointers persistent objects special pointer stack maintained parallel regular procedure activation stack space buffer pool reclaimed epvm scans pointer stack unswizzles swizzled pointers ensures dangling objects longer resident memory pointer swizzling scheme based virtual memory techniques wilso similar approach object design objectstore objec lamb basic idea presented wilso allocate virtual memory addresses pages persistent data step ahead program actual usage pages program attempts access page virtual memory page fault occurs fault intercepted underlying object manager loads page preassigned location memory advantage method swizzling programs regular virtual memory pointers allowing accesses persistent objects occur memory speeds addition compiled code access persistent nonpersistent objects objects span multiple pages virtual memory handled transparently long sufficient contiguous virtual memory address space reserved entire object disadvantage basic approach wilso programs incur unnecessary swizzling unswizzling overhead swizzling unswizzling granularity individual pages programs pointers located page objec describes extension basic technique avoid problem eliminating swizzle unswizzle pointers cases effect pointers stored swizzled format objec epvm design concepts object caching mentioned section esm provide disk storage persistent objects accessible program epvm copies objects esm client buffer pool virtual memory accessed separate schemes cache objects smaller disk page referred small objects large objects span number pages disk small objects copied esm client buffer pool entirety stored individual contiguous regions virtual memory bitmap appended beginning region record locations swizzled pointers contained small object large objects cached page-at-a-time units bytes individual large object pages cached demand pages referenced cached cached page appended bitmap track swizzled pointers page pages large object necessarily stored contiguously virtual memory fact important implications pointer swizzling essentially means pointers large objects swizzled accesses large objects pointers span page boundaries objects cached virtual memory organized hash table object identifier oid entries hash table pointers object descriptors figure case small object object descriptor single pointer copy object virtual memory paired pointer low high byte count track range modified bytes object update small object range expanded decrementing incrementing low high byte counts needed note method 
shore program parset apply calls slavecodeis generated compile time communication synchronization master slaves handled pshore runtime system state information suchasparset catalog information process ids port numbers obtained runtime system consulting parset server note executing composite part node require access atomic objects residing node transparent case slave executing slave requests objects local shore server responsible contacting shore servers remote objects needed slaves master share global oid space pshore applications shared-memory avoreven processorsdo share memory designing support programming model implementation require primitives portability goal pshore shore run wide range hardware platforms support goal parset implementation threads package turn pvm sun interprocess communication pvm public-domain message passing library writing parallel programs runs platforms ranging networks workstations multiprocessors portable parallel programming environmentinthe pshore implementation hope ensure shore pshore usable byanyone anetwork workstations conclusion shore integration system oodb concepts services system world shore draws object naming services support lower cheaper degrees transaction-related services object access mechanism legacy unix le-based tools oodb world shore draws data modeling features support associative access performance acceleration features provide scalability basis parallelizing system shore employs architecture including support symmetric peer-to-peer server communication caching addition includes support extensibility added server facility previous system exodus make shore system publicly anonymous ftp expect rst release shore occur midreferences paul adams marvin solomon overview capitl software development environment proceedings fourth international workshop software con guration management baltimore bbkv bancilhon briggs khosha valduriez fad powerful simple database language proc vldb conf brighton england cat cattell object database standard odmgmorgan kaufmann san mateo cdf michael carey david dewitt daniel frank goetz graefe muralikrishna joel richardson eugene shekita architecture exodus extensible dbms proceedings twelfth international conferenceonvery large data bases pages cdn michael carey david dewitt rey naughton benchmark proceedings acm-sigmod conference management data washington cfz carey franklin zaharioudakis fine-grained sharing pageserver oodbms submitted december deu deux system communications acm october dlpy dewitt luo patel paradise parallel geographic information system proceedings acm workshop advances geographic information systems november dnsv dewitt naughton shafer venkataraman parset design document unpublished manuscript november franklin carey client-server caching revisited proceedings international workshop distributed object management edmonton canada august published distributed object management ozsu dayal vaduriez eds morgan kaufmann san mateo edward felten dylan mcnamee newthreads user guide august fzt michael franklin michael zwilling tan michael carey david dewitt crash recovery client-server exodus proceedings acmsigmod conference management data pages june hmn howard kazarand menees nichols satyanarayanan sidebotham west scale performance distributed system acm transactions computer systems february jos joshi adaptive locking strategies multi-node data sharing environment proc vldb conf barcelona spain sept kil michael kilian parallel sets objectoriented methodology massively parallel programming phd thesis harvard center research computing technology cambridge tobin lehman michael carey concurrency control algorithm memoryresident database systems proc int conf foundations data organization algorithms paris france june llow lamb landis orenstein weinreb objectstore database system communications acm october mhl mohan haderle lindsay pirahesh schwarz aries transaction recovery method supporting negranularitylocking partial rollbacks write-ahead logging acm transactions database systems march mnss miller neuman schiller saltzer section kerberos authentication authorization system technical report project athena technical plan project athena cambridge december obj objectivity objectivity manual ont ontos ontos manual rcs joel richardson michael carey daniel schuh design programming language acm transactions programming languages systems july dennis ritchie ken thompson unix time-sharing system communications acm july sgk sandberg goldberg kleiman walsh lyon design implementation sun network lesystem usenix summer conference proceedings sun sunderam pvm framework parallel distributed computing concurrency practice experience december ver versant versant manual wang rowe cache consistency concurrency control client server dbms architecture proceedings acm sigmod conference denver june 
keeping track modified portion object works locality updates objects range modified bytes bitmap stored beginning object determines portion object written disk subset swizzled pointers object unswizzled transaction completes object descriptor large object array pointers pages large object large object page low high byte count pointer data page low dirty byte high dirty byte low dirty byte high dirty byte oid page oid pointer data page figure object descriptor large object track modified portion page manner analogous small objects figure shows small large objects cached small objects descriptors single pointer respective objects large object descriptor pointers pages large object note pointers point beginning object page bitmap figure page large object referenced object descriptor points pages object descriptors small objects organized hash table disk page objects reside small objects reside disk page overflow chain effects updates objects page propagated back esm buffer pool time transaction commits large objects separate linked list traversed end transaction write back dirty portions large object pages figure depicts small objects residing disk page objects linked page pointers object descriptors objects disk pages found overflow chain page numbers hash practice low cost strategy fact collisions rare perform pointer swizzling epvm persistent objects accessed pointers important provide efficient mapping pointers persistent objects pointer dereferenced program states unswizzled case object identifier oid swizzled meaning direct memory pointer dereferencing unswizzled pointer basically incurs cost overhead lookup oid hash table order obtain pointer referenced object dereferencing swizzled pointer avoids cost swizzled pointer direct memory pointer object difference dereferencing cost small important remember tens hundreds thousands pointer dereferences occur execution program potential savings offered pointer swizzling large key assumption pointer swizzling scheme pointers average justify costs pointer swizzling epvm supports pointer swizzling scheme converts pointers oid form direct memory pointers incrementally program execution goal quickly cheaply convert pointers swizzled format program sees swizzled pointers majority time executing software checks distinguish swizzled unswizzled pointers reasonable price checks small part program execution time fact independently confirmed moss standard kinds compiler optimizations eliminate checks program compiler software approach combines efficiency portability flexible environment conducting research swizzling scheme epvm characterized fact swizzles pointers one-at-a-time opposed approach wilso swizzles page-at-a-time moss swizzles page hash tableoid hash table large object list large object page small object large object page small object figure object cache small large objects pointers granularity objects type swizzling scheme epvm referred edge marking scheme moss implementation strategy pointers swizzled dynamically program execution key decision made execution swizzling possibility swizzle pointers dereferenced detail unswizzled pointer dereferenced execution program memory address pointer passed epvm function performs lookup oid hash table oid contained pointer pointer composed byte oid volume bytes page bytes slot number bytes unique field bytes byte offset field referenced object found obtained exodus storage manager esm possibly causing copied virtual memory inserted cache pointer swizzled virtual memory addresses pointer object type swizzling referred swizzling dereference advantage scheme pointers dereferenced swizzled amount unnecessary swizzling work minimized pointers referenced objects swizzled unnecessary operations avoided swizzling dereference present major problem pointer dereferenced copied temporary memory location local pointer variable activation stack swizzling dereference fails swizzle pointers persistent objects effect force programs pointers work unswizzled pointers execution approach epvm swizzle pointers objects discovered location pointer call type swizzling swizzling discovery pointer object discovered assigned pointer involved comparison operation number ways context epvm pointers discovered epvm passed persistent address pointer candidate swizzling contents persistent address locate object candidate pointer cache note initial step involve caching object pointer swizzled virtual memory address candidate pointer contents inspected swizzled perform lookup oid hash table find object object denoted candidate pointer found cache candidate pointer swizzled note swizzling scheme solves major problem swizzling dereference pointers persistent objects swizzled case object referenced candidate pointer found cache alternative ahead cache object eager approach result unnecessary operations object referenced candidate pointer fact needed program persistent collection object store pointers objects class routine implements deletion collection compare pointer deleted arbitrary number pointers collection comparisons discovers pointer contained collection object deletion operation fault large number objects eager swizzling discovery swizzling scheme avoid causing unnecessary operations epvm takes lazy approach swizzle candidate pointer object cached summary swizzling scheme epvm pointer dereferences fault objects cache object cache pointers object swizzled locations discovered pointers object discovered object referenced immediately swizzled lastly note swizzling discovery restricts swizzling activity pointers program programs pointers pay big price terms swizzling overhead objects needed program cached extra activity results swizzling figure designed illustrate differences swizzling dereference eager lazy variations swizzling discovery function totalcost traverses assembly persistent part objects assumed form tree simplicity depth order calculates total cost assembly part object cost field pointers subparts assume collection part objects shown figure part objects collection oids represented letters objects form tree height figure depicts format part objects stored disk connections parts represented oids note pointer dereferenced root transient local pointer variable swizzling dereference executing totalcost root swizzled subpart pointers contained part objects remain unswizzled form implies repeated traversals parts assembly encounter unswizzled pointers assembly remain format shown figure pointers located part objects discovered totalcost function expression rootsubpart evaluated dbstruct part structure part dbint pcost part subpart int totalcost part root int depth int totcost int rootsubpart depth totcost totalcost rootsubpart depthtotcost rootpcost return totcost figure function bcd bcd figure representations collection objects line note part object visited subpart pointers located object discovered suppose collection parts shown figure repeatedly traversed totalcost function beginning object depth eager implementation swizzling discovery subparts leaf node subtree visited totalcost cached figure shows basic structure part assembly memory traversal parts method total part objects read disk cached double number objects needed swizzling scheme epvm behaves traversal traversal collection part objects cached figure note objects accessed program cached pointers objects unswizzled oid form case subpart pointers swizzled discovered line traversal objects cache objects faulted cache traversal pointer root dereferenced line traversal structure collection figure note pointers objects visited program swizzled traversals collection dereference swizzled pointers performance experiments performance experiments traversal portion benchmark catte traversal portion involves repeatedly traversing collection part objects beginning randomly selected part depth-first fashion depth levels individual traversals referred iteration benchmark part visited 
iteration simple function called values part object parameters addition ability update part objects added time part object visited simple update performed fixed probability update operation defined incrementing -byte integer fields contained part object total software versions evaluated software versions classified basic architectures section experiments compare performance architectures investigate relative performance versions approach epvm usefulness pointer swizzling evaluated number experiments vary frequency updates performed objects conducted access impact swizzling approaches generation recovery information architectures examined offer equivalent transaction facilities page level locking atomicity transactions transaction rollback architectures attempt batch updates objects generate recovery information updates made object end transaction architectures traditional database approach generating log records individual update approaches important implications systems redo undo logging experiments compare software versions small database fits main memory large database represents working set size bigger main memory catte software versions architecture shown figure results conventional non-persistent programming language call esm directly approach accesses objects client buffer pool esm procedural interface routines make esm interface linked application compile time client buffer pool located application private address space experiments server process located separate machine connected client network page page page buffer pool user descriptor buffer pool lock manager recovery manager network log volume data volume esm client esm server figure architecture accesses occur transaction place visit object application read contained object calls esm interface function interface function requests page object server possibly causing server perform behalf pins object client buffer pool interface function returns data structure application user descriptor carey pointer object application read values object number times pointer contained user descriptor time application update portion object call interface function passing things user descriptor pointing object parameters update function updates portion object client buffer pool generates log record update contained object passed parameter application finished visiting object calls esm function unpin object client buffer pool objects page unpinned point page candidate replacement client buffer manager note architecture pin unpin sequence operations object generally takes place short period time relative life program single invocation function object pinned unpinned multiple times visited program addition update operation log record generated current release esm data pages cached client buffer pool transactions client communicate server reacquire locks cached pages accessed succeeding transactions transaction commit involves shipping dirty data pages log pages back server writing log pages disk releasing locks frank future esm support callbacks server client inter-transaction caching locks client eliminate ship dirty data pages back server transaction commit pointer swizzling architecture single software version based architecture referred cesm size esm client server buffer pools megabytes architecture represents approach epvm schuh figure shows client portion architecture server portion identical server shown figure epvm avoids calls storage manager maintaining cache worthy objects esm client buffer pool objects accessed time object needed application epvm calls esm interface function pins object client buffer pool returns user descriptor object referenced involve communication client server server turn perform behalf client epvm creates entry object hash table based object oid hash table maintains mapping oids user descriptors remains valid client buffer pool full program execution completes objects cached esm buffer pool accessed lookup oid hash table swizzled pointer epvm supports limited form pointer swizzling section updates objects require epvm page page page buffer pool user descriptor network connected server oid hash entry oid hash table esm client figure architecture invoke storage manager interface function interface function updates object buffer pool generates log record update transaction commit requires epvm scan oid hash table unpin objects addition usual operations performed esm commit transaction order measure effectiveness swizzling technique employed epvm experiments performed versions architecture version limited form pointer swizzling enabled swizzling turned versions referred epvm epvm megabyte client server buffer pools architecture investigated corresponds approach epvm briefly review objects accessed architecture object needed application program epvm calls esm behalf application esm pins object client buffer pool shown figure epvm user descriptor returned esm copy object virtual memory epvm inserts object cache manner depicted figure epvm calls esm unpin object client buffer pool subsequent reads updates object current transaction occur cache handled exclusively epvm transaction commit epvm scans page hash table small object updated epvm calls esm pin object client buffer pool update object note involve communication client server page object longer present client buffer pool esm updates object client buffer pool modified portion object located client buffer pool generate log record update updates large objects handled similar manner difference epvm invokes esm modified page large object performance alternative ways copying objects client buffer pool virtual memory examined copies objects one-at-a-time client buffer pool virtual memory copies objects page object page accessed schemes referred object caching page caching tradeoff approaches object caching generally requires interaction storage manager interaction object page caching requires interaction page potential perform copying versions architecture investigated object caching order study effect buffer pool size object caching size client buffer pool version set megabytes client buffer pool set megabyte megabyte server buffer pool versions referred versions pointer swizzling fourth versions designed measure benefit provided swizzling technique implemented epvm versions page caching megabyte client buffer pool make amount memory similar versions megabyte server buffer pool experiments version referred pointer swizzling version labeled m-no fourth architecture examined objectstore lamb esm objectstore client server architecture client server processes buffer recently accessed pages objects interaction client server objectstore set place granularity individual pages esm objectstore features basically transaction facilities esm recovery updates event client server failure page level locking transaction rollback objectstore supports inter-transaction caching persistent data client main memory lamb callback messages server clients order maintain coherence cached data objectstore client cache locks transactions data pages efficiently support callbacks objectstore client divided processes orens callback process application process single client connected server two-process architecture noticeable effect performance application process communicates directly server obtain data pages locks pages important difference objectstore architectures mentioned objectstore memorymapping scheme similar virtual memory implement pointer swizzling fault objects secondary storage main memory section important difference objectstore generates recovery information updates recently received objectstore manufacturer offer improved performance lacked sufficient time obtain reliable results version results presented paper objectstore persistent data logging entire dirty pages full page 
exodus extensible dbms project overview michael carey david dewitt goetz graefe david haight joel richardson daniel schuh eugene shekita scott vandenberg computer sciences department wisconsin madison abstract paper presents overview exodus extensible database system project addressing data management problems posed variety challenging applications goal project facilitate fast development high-performance application-specific database systems exodus kernel facilities including versatile storage manager addition architectural framework building application-specific database systems powerful tools automate generation systems including rule-based query optimizer generator persistent programming language libraries generic software components access methods application domains briefly describe components exodus paper describe next-generation dbms building exodus tools introduction fairly recently research development efforts database systems area focused primarily supporting traditional business applications design database systems capable supporting non-traditional application areas computer-aided design manufacturing scientific statistical applications largescale systems image voice applications emerged important research direction applications differ conventional database applications number important ways data modeling requirements vary widely kinds entities relationships relevant vlsi circuit design banking application application area specialized set operations efficiently supported database system makes sense talk joins satellite images efficient support specialized operations requires types storage structures access methods applications vlsi design involving spatial objects r-trees gutt access method data storage manipulation manage image data efficiently database system provide large arrays basic data type finally number application areas require support multiple versions entities snod daya katz number research projects addressing applications developing approaches making database system extensible dbe projects include exodus wisconsin care carey probe cca daya mano postgres berkeley ston rowe starburst ibm almaden research center schw lind genesis texas-austin bato bato goals projects similar mechanisms provide extensibility approaches postgres complete research partially supported defense advanced research projects agency contract -kby national science foundation grant iriby ibm fellowships dec incentives excellence program donations apple corporation gte laboratories microelectronics computer technology corporation mcc texas instruments exodus departure case traditional approaches database management extensible object-oriented database system database management system query language postquel predefined supporting complex objects procedures data type support active databases triggers alerters inferencing extensibility provided data types access methods simplified recovery mechanism stated goal make relational model probe system hand advanced dbms support complex objects operations dimensional data space time dimensions capability limited recursive query processing unlike postgres probe mechanism directly representing complex objects probe query language extension daplex ship starburst extensible dbms based relational data model design intended knowledgeable programmers add extensions side form abstract data types access methods external storage structures exodus starburst rule-based approach query optimization enable handle extensions lohm contrast efforts exodus genesis modular modifiable systems complete end-user dbmss handling application areas genesis project aimed identifying primitive building blocks facilities describing combine building blocks order dbms automatically composed library existing database components goal exodus project sense database software engineering project provide collection kernel dbms facilities software tools enable semi-automatic construction applicationspecific dbms application area included exodus tools intended simplify development dbms components access method query language operator paper describe exodus approach achieving extensibility section paper overview components exodus section describes lowest level system storage manager section discusses exodus approach handling difficult tasks involved extending database system implementing access methods implementing application-specific database operations exodus simplifies tasks providing programming language called extends stro facilities persistent systems programming section describes rule-based approach query optimization employed exodus section describes extra excess data model query language building aforementioned tools finally section summarizes paper discusses implementation status components exodus project overview exodus architecture principal goals exodus project provide extensibility sacrificing performance design exodus reflects careful balance exodus user user explicitly provide unlike postgres probe starburst exodus intended complete system provisions user-added extensions intended toolkit easily adapted satisfy application areas section summarize approach briefly introduce key components tools exodus exodus approach basic mechanisms employed exodus achieve extensibility performance goals feasible furnish generic solution applicable database systems application area exodus supplies lowest level layer software termed storage manager support concurrent recoverable operations storage objects size feeling level sufficient capabilities user-added extensions due generality efficiency considerations single generic solution component database system word user carefully explained paragraphs ahead cases single generic solution inappropriate exodus generator library aid user constructing software expect exodus wide variety applications potentially query language result exodus furnish single generic query language makes impossible single query optimizer suffice applications provide generator producing query optimizers algebraic query languages exodus query optimizer generator takes input collection rules operators query language transformations legally applied operators moving selections joins relational algebra query description methods execute operator including costs side effects output produces optimizer application query language form program conventional database system environment customary roles classes individuals database administrator user exodus type individual required customize exodus application-specific database system referred individual loosely user preceding paragraphs user normal sense end user bank teller cartographer user exodus facilities database engineer dbe goal engineer exodus moderate amount database expertise needed order dbe architect system tools exodus customized application-specific database system dbe initial role completed role database administrator begins dbe role provide incremental improvements efficient access methods faster operator implementations exodus system architecture present overview design exodus remainder section exodus toolkit complete dbms find clearer describe system viewpoint applicationspecific database system constructed exodus hope make clear pieces system provided modification generated automatically directly implemented dbe programming language figure presents general structure application-specific database management system implemented exodus major facilities provided aid dbe task generating system storage manager programming language compiler library type-independent access operator methods rule-based query optimizer generator tools constructing query language front-ends bottom level system storage manager basic abstraction level storage object untyped uninterpreted variable-length byte sequence arbitrary size storage manager capabilities reading updating storage objects regard size enhance functionality provided level buffer management concurrency control recovery mechanisms operations shared storage objects provided finally versioning mechanism support variety application-specific versioning schemes provided detailed description storage manager presented section shown figure depicts run-time structure exodus-based dbms major component programming language compiler implementation language components system dbe provide code extends adding generic classes iterators support persistent object types type facilities control constructs part persistent objects objects dbe index code deal compiler code catalog manager methods operator query parser query optimizer compiler compiled query methods 
access storage manager schema database tree operator code generated component coded dbi fixed component object figure general exodus database system structure index nodes arrays key-pointer pairs persistent objects referenced compiler responsible inserting calls fix unfix buffers read write portions underlying storage objects handle low-level details dbe freed worry internal structure persistent objects order regain performance enable dbe provide guidance compiler ways providing information aid buffer management confused database programming languages pascal schm rigel rowe languages intended simplify development database applications code closer integration database programming language constructs similarly object-orientedness stemming confused object-oriented database languages opal cope maie cop andr objective simplify development internal systems software dbms layered storage manager collection access methods provide associative access files storage objects support versioning desired access methods exodus provide library type-independent index structures trees grid files niev linear hashing litw access methods written generic class capability provided language section capability enables existing access methods dbe-defined abstract data types modification long capabilities provided data type satisfy requirements access methods addition dbe implement types access methods process developing application-specific database system access methods written dbe shielded map main memory data structures storage objects deal directly low-level details secondary storage capabilities provided storage manager access methods layer generalpurpose intended application-specific dbms constructed exodus layer design operator methods layer mix dbe-supplied code exodus-supplied code implied layer collection methods combined order operate typed storage objects exodus provide library methods operators prototype dbms building exodus tools section expect number application-specific data-model-specific operator methods needed general dbe implement methods operator query language target application serve implementation language task operator methods discussed section data model application-oriented dbms defined dbe exodus providing amounts internal data model type system programming language type system includes basic types int float char type constructors class struct union array additional support generic classes typed files facilities provide sufficient power implement higherlevel abstractions required end-user data models discussed section dbe responsible implementation task implementing catalog manager storing user schema information exodus provide tool dependency manager designed track schema-related dependency information tool intended maintain type-related dependencies arise types types files types stored queries types data model level information exodus dependency manager found care execution query exodus set transformations similar relational query system astr parser responsible transforming query initial form initial tree database operators parsing query optimized converted program compiled executable form output produced query optimizer consists rearranged tree operator methods instances operator query specific information selection predicates mike salary passed parameters mentioned earlier exodus generator producing optimization portion query compiler produce optimizer application-specific database system dbe supply description operators target query language list methods implement operator cost formula operator method collection transformation rules optimizer generator transform description files source code optimizer target query language query execution time optimizer behaves taking query expressed tree operators transforming optimized execution plan expressed tree methods section describes optimizer generator greater detail finally organization top level database system generated exodus depends goal support sort interactive interface query facility embedded programming language altogether kind interface future provide tools facilitate creation interactive interfaces implementing interface object-oriented data model query language section hope gain insight kind tools helpful interface level system addition learning effective current tool set storage manager section summarize key features exodus storage manager begin discussing interface storage manager higher levels system describe arbitrarily large storage objects handled efficiently discuss techniques employed versioning concurrency control recovery buffer management storage objects close discussion files storage objects detailed discussion issues found care storage manager interface storage manager procedural interface interface includes procedures create destroy files open close files file scans scanning purposes storage manager call object object file procedures creating destroying storage objects file reading storage objects storage manager call pointer range bytes storage object desired byte range read buffers pointer range returned caller call provided inform system bytes longer needed unpins buffer pool writing storage objects call provided system modify subrange bytes read shrinking growing storage objects calls insert bytes delete bytes offset storage object provided call append bytes end object finally transaction management storage manager begin commit abort transaction calls additional hooks planned aid implementing concurrent recoverable operations access methods efficiently addition functionality outlined storage manager designed accept variety performance-related hints object creation routine mentioned accepts hints place object place object object object buffer manager accepts hints size number buffers replacement policy employ hints supported allowing buffer group object access buffer manager accept hints per-buffer-group basis buffer management policies ranging simple schemes global lru complex schemes dbmin chou easily supported storage objects operations earlier storage object basic unit data storage manager storage objects small large distinction hidden higher layers exodus software small storage objects reside single disk page large storage objects occupy potentially disk pages case object identifier oid storage object form volume page slot unique unique make oid unique time usable surrogates oid small object points object disk large object oid points large object header large object header reside slotted page large object headers small storage objects pointers pages involved representation large object pages large object private shared objects pages shared versions object small object grows point longer accommodated single page storage manager automatically converts large object leaving object header place original small object considered alternative purely logical surrogates oid physical addresses recent proposals cope ston efficiency considerations led opt physical surrogate scheme logical surrogates access objects surrogate index figure shows large object data structure conceptually large object uninterpreted byte sequence physically represented tree-like index byte position object collection leaf blocks data bytes residing leaves large object header number count page pairs child root count child pointer maximum byte number stored subtree rooted child rightmost child pointer count size object internal nodes similar recursively defined root object contained parent node absolute byte offset child translates relative offset parent node left child root figure bytes child rest object bytes rightmost leaf node figure bytes data byte leaf node byte child root byte object data structure inspired ordered relation index ston update algorithms care pages header root internal blocks leaf oid figure large storage object searching accomplished computing offset information descending tree desired byte position care object 
architecture exodus extensible dbms michael carey david dewitt daniel frank goetz graefe joel richardson eugene shekita muralikrishna computer sciences department wisconsin madison abstract non-traditional application areas engineering design image voice data management scientific statistical applications artificial intelligence systems clamoring ways store efficiently process larger larger volumes data clear traditional database technology pushed limits clear single database system capable simultaneously meeting functionality performance requirements diverse set applications paper describe initial design exodus extensible database system facilitate fast development high-performance applicationspecific database systems exodus kernel facilities including versatile storage manager type manager addition architectural framework building application-specific database systems tools partially automate generation systems libraries software components access methods application domains research partially supported defense advanced research projects agency contract -kby department energy contract de-ac national science foundation grants mcs dcrand ibm faculty development award introduction recently research development efforts database management systems area focused supporting traditional business applications design database systems capable supporting non-traditional application areas including engineering applications cad cam vlsi data scientific statistical applications expert database systems image voice applications emerged important research direction applications differ conventional applications transaction processing number important ways requires set data modeling tools types entities relationships vlsi circuit design banking application application area specialized set operations efficiently supported database system makes sense talk joins satellite images efficient support specialized operations application area require types storage structures access methods r-trees gutt access method storing manipulating vlsi data managing image data database system support large multidimensional arrays basic data type storing images tuples relational database system generally impossible terribly inefficient finally number application areas require support multiple versions entities daya katz recently number database system research projects initiated address emerging class applications exodus wisconsin care care probe cca daya mano postgres ston ston berkeley gemstone servio logic corporation cope maie starburst ibm almaden research center schw genesis bato texas-austin goals projects similar mechanisms provide extensibility approach project postgres complete database management system query language postquel predefined supporting complex objects postquel procedures data type support active databases triggers alerters inferencing extensibility provided data types operators access methods simplified recovery mechanism stated goal make relational model objective probe project hand develop advanced dbms support complex objects operations dimensional data space time exodus departure case ways past extensible object-oriented database system dimensions capability intelligent query processing unlike postgres probe provide mechanism directly representing complex objects exodus probe rule-based approach query optimization query optimizer extended handle database operators methods existing operators data types extended version daplex ship query language probe gemstone query language opal complete object-oriented database system encapsulates variety ideas areas knowledge representation object-oriented non-procedural programming set-theoretic data models temporal data modeling starburst architecture extensible dbms based relational data model design intended knowledgeable programmers add extensions side form abstract data types access methods external storage structures contrast efforts genesis exodus designed modular modifiable system complete database system intended handle application areas sense exodus software engineering project goal provide collection kernel dbms facilities software tools facilitate semi-automatic generation high-performance application-specific dbmss applications paper describe architecture exodus section presents overview components exodus section describes lowest level system storage object manager summarizing material care section describes exodus type manager things general schema management facility extended application-specific abstract data types section addresses difficult task extending database system addition access methods exodus simplifies task hiding storage concurrency control recovery issues access method implementor programming language extension includes support persistent objects storage object manager exodus section discusses application-specific database operations implemented exodus section describes rule-based approach query optimization employed exodus section outlines user interface issues lie ahead section briefly summarizes paper discusses implementation plans overview exodus architecture section describe architecture exodus database system principal goals exodus project construct extensible high-performance database system design reflects careful balance exodus user user explicitly provide unlike postgres probe exodus intended complete system provisions user-added extensions intended toolbox easily adapted satisfy application areas basic mechanisms employed achieve goal feasible furnish generic solution applicable application-specific database system exodus supplies lowest level layer software termed storage object manager support concurrent recoverable operations arbitrary size storage objects feeling level sufficient capabilities user-added extensions unnecessary due generality efficiency considerations single generic solution component database system cases generic solution inappropriate exodus generator library aid user generating software expect exodus wide variety applications potentially query language result exodus furnish single generic query language impossible single query optimizer suffice applications provide generator producing query optimizers algebraic languages exodus query optimizer generator takes input collection rules operators query language transformations legally applied operators pushing selections joins description methods execute operator including costs side effects output produces optimizer application query language form source code conventional database system environment customary roles classes individuals database administrator user exodus type individual required customize exodus application-specific database system referred individual user preceding paragraphs user normal sense end user bank teller cartographer internally refer user exodus facilities database implementor dbi jim grays world make outstanding dbis goal engineer exodus moderate amount expertise required architect system tools exodus customized application-specific database system dbi role completed role database administrator begins word user carefully explained paragraphs present overview design exodus remainder section exodus toolkit complete dbms find clearer describe system viewpoint application-specific database system constructed hope make clear pieces system provided modification produced exodus generators directly implemented dbi programming language exodus system architecture figure presents structure application-specific database management system implemented exodus tools provided aid dbi task generating system storage object manager programming language compiler writing database system software generalized type manager defining maintaining schema information library type independent access methods associatively access storage objects lock manager recovery protocol stubs simplify task writing access methods database operators rule-based query optimizer compiler tools constructing user front ends bottom level system storage object manager basic abstraction level storage object untyped uninterpreted variable-length byte sequence arbitrary size storage object manager capabilities reading writing updating storage objects pieces regard size enhance functionality provided level buffer management concurrency control recovery mechanisms operations shared storage objects provided finally versioning mechanism implement variety application-specific versioning schemes supported detailed description storage object manager capabilities presented section shown figure depicts runtime structure exodus-based dbms major component 
sizes supported tree levels header leaf levels included large storage object data structure algorithms search range bytes update insert sequence bytes point object append sequence bytes end object delete sequence bytes point object insert append delete operations inserting deleting arbitrary number bytes opposed single byte large storage object poses unique problems compared inserting deleting single record tree ordered relation algorithms operations detail care results experimental evaluation storage utilization performance characteristics evaluation showed exodus storage object mechanism provide operations large dynamic objects low cost reasonable level storage utilization large dynamic objects close large static objects versions storage objects storage manager primitive support versions storage objects versions objects identified simply oids storage object working current versions frozen versions distinction recorded version object header working versions updated transactions frozen versions immutable working version object made frozen version working versions derived frozen versions desired delete version object version longer interest reason providing primitive level version support exodus applications widely notions versions supported ston dada clif klah snod katz omit version management altogether efficiency reasons prohibitively expensive terms storage space cost maintain versions large objects maintaining entire copies objects versions large objects maintained copying updating pages differ version version figure illustrates figure shows versions large storage object figure figure versions large storage object original frozen version newer working version created deriving working version subsequently deleting bytes note shares pages unchanged copies modified page page pointer bit shown figure distinguishes pointers shared pages pointers unshared pages deriving version large storage object creates copy root object subsequent updates leading creation copies nodes needed number internal pages actual large object small relative number data pages object due high fanout internal nodes overhead versioning large objects scheme small basically proportional difference adjacent versions size objects case small objects versioning accomplished simply copying entire object creating version working version updated insert append delete write operations provided storage objects storage manager supports deletion unwanted versions objects noted deleting version large object careful avoid discarding object pages shared needed versions object efficient version deletion algorithm addresses problem providing safe delete version respect set versions retained presented care concurrency control recovery storage manager concurrency control recovery services storage objects two-phase locking gray storage objects files concurrency control recovery small storage objects handled after-image logging in-place updating object level gray recovery large storage objects handled combination shadowing logging updated internal pages leaf blocks shadowed root level updates installed atomically overwriting object header notion frozen working versions present care version deletion algorithm applicable frozen working version distinction added order versions large object updated series transactions forcing derive version object header verh parameters operation caused update logged log sequence number gray maintained large object root page ensures operations large storage objects undone redone needed buffer management storage objects objective exodus storage manager design minimize amount copying buffer space required related objective sizable portions large storage objects scanned directly buffer pool higher levels exodus software requiring large objects small fit buffer pool accommodate buffer space allocated variable-length buffer blocks integral numbers contiguous pages single-page units exodus client requests sequence bytes read object non-empty portions leaf blocks desired byte range read contiguous buffer block obtaining buffer block size buffer space manager reading pages buffer block strict byte sequence order placing data byte leaf page position immediately data byte previous page recall leaf pages large storage objects full descriptor maintained current region memory including information oid pointer buffer block length actual portion buffer block bytes requested client pointer byte information contents buffer block client receives pointer descriptor buffer contents accessed free space buffer pool managed standard dynamic storage allocation techniques buffer block allocation replacement guided storage manager hint mechanism files storage objects files collections storage objects grouping objects purposes exodus storage manager mechanism sequencing objects file related objects common file sequential scanning purposes objects file disk pages allocated file files provide support objects tightly clustered disk file identified file identifier fid points root page large storage objects files represented index structure similar tree key index file index disk page number key leaf page file index collection page numbers slotted pages contained file pages managed separately standard disk allocation techniques file index serves mechanism gather pages file enables rapid scanning objects file rapid scanning consequence fact file tree keyed page number meaning scan objects file access physical order note objects file directly accessible oids file comparable surrogate index secondary indices objects file oid entries point directly objects indexed important performance standpoint discussion file representation operations concurrency control recovery found care method implementation support section application-specific database systems include access methods operator methods intended class applications undoubtedly vary application area trees hashing sufficient access methods conventional business database systems database system storing manipulating spatial data spatial access method kdb tree robi tree gutt grid file niev structures highly algorithmic nature require dbe implement simply discussed section language hides structure dbe high-level form complication index structure handle data variety types integers reals character strings adts long satisfy requirements correct operation index structure instance tree work key types provide comparison operator ston includes working data types defined dbe index code completely written debugged similar issues arise operator methods written general manner order handle unanticipated data types adding access method dbms sources complexity include coding verifying algorithms mapping data structure primitive objects provided storage system dbms iii making access method code interact properly buffer manager ensuring concurrency control recovery handled correctly access method designers interested item comprise actual code written items comprise remaining code needed add access method typical commercial dbms ston items iii issues operator methods issue dbe focus improve situation exodus programming language dbe implementing methods intended shield dbe items compiler produces code handle details based dbe index code declarative hints remainder section describe language features simplify dbe programming tasks designed dbms architecture section mind access methods operator methods utility functions dbms intended written addition components dbms includes storage manager compiler runtime database schema definitions create relation commands queries translated programs compiled result architecture system impedance mismatch cope type systems reduced system easy extend dbe add data type coding class programming language 
programming language compiler implementation language components system dbi provide code extends adding abstract data types notion persistent object pointers language type definition repertoire part persistent objects structures dbi index code deal index nodes arrays key-pointer pairs persistent objects referenced translator responsible adding calls fix unfix buffers read write piece underlying storage object operator query parser query optimizer compiler compiled query methods access methods recovery stubs storage object manager type manager schema database figure exodus system architecture lock unlock objects log images events dbi freed worry internal structure persistent objects buffering concurrency control recovery language includes statements associating locking buffering recovery protocols variables persistent objects dbi provided mechanism exercise control declaratively insuring mechanisms employed confused database programming languages rigel rowe pascal schm theseus shop plain kers languages intended simplify development database applications code closer integration database programming language constructs object-oriented query languages opal cope maie objective simplify development internal systems software dbms layered storage object manager collection access methods provide associative access files storage objects support versioning desired access methods exodus provide library type-independent index structures including trees grid files niev linear hashing litw access methods implemented type parameter capability provided language section capability enables existing access methods dbi-defined abstract data types modification long capabilities provided data type satisfy requirements access methods addition dbi implement types access methods process developing application-specific database system exodus mechanisms greatly simplify task access methods written dbi shielded map main memory data structures storage objects write code deal locking buffering recovery protocols exodus simplifies task handling concurrency control recovery access methods form layered transactions discussed section capabilities provided storage object manager access methods layer general purpose intended utilized application-specific dbms constructed exodus layer design operator methods layer mix dbi-supplied code exodus-supplied code implied layer collection methods combined order operate typed storage objects exodus provide library methods number operators operate single type storage object selection provide application data model specific methods provide methods implementing relational join operator examining object satellite image data signature crop disease general dbi implement methods operator query language target application serve implementation language task center exodus architecture type manager exodus type manager designed provide schema support wide variety application-specific database systems data modeling facilities provided exodus type system programming language type manager acting repository persistent symbol table type definitions type system includes set primitive built-in types int float char set type constructors record union variant fixed-length array insertable array variable-length sequence abstract data type adt facility dbi define data types operations addition type manager maintains associations exodus files types objects track type-related dependencies arise types types files types stored queries types designing type facilities exodus goal provide set facilities capabilities storage object manager exploited modeling wide range applications handled loss efficiency section presents detailed overview capabilities provided type manager including discussion dependency-maintenance role execution query exodus set transformations similar relational query system astr parsing query optimized compiled executable form parser responsible transforming query initial form initial tree database operators parsing optimization phases type manager invoked extract schema information executable form produced query compiler consists rearranged tree operator methods instances operator query specific information selection predicates mike salary passed parameters mentioned earlier exodus generator producing optimization portion query compiler produce optimizer application-specific database system dbi supply description operators target query language list methods implement operator cost formula operator method collection transformation rules optimizer generator transform description files source code optimizer target query language query execution time optimizer behaves taking query expressed tree operators transforming optimized execution plan expressed tree methods finally organization top level database system generated exodus depend goal support sort interactive interface embedded query interface equel allm altogether form interface plan provide generator facilitate creation initially considered providing generalized class hierarchy facility efficiently supported top type facilities provide felt applications things hierarchy interactive interfaces exploring cornell program synthesizer generator reps user interface generator exodus tool facilities needed implementing structured editors wide variety programming languages goal editors programmers formulate syntactically semantically correct programs syntax semantics typical query languages simpler modern programming languages clear apply tool remains powerful overkill supporting queries embedded programs options exist program simply calls operator methods bypassing parser optimizer linker bind program methods viewed library procedures option difficult task provide generalized tool handle programs embedded queries ala equel easy provide generic preprocessor extract queries replace calls object modules produced parser optimizer compiler unclear make underlying interface application program database system independent application-specific data model relational model tuple-at-a-time portal ston interface commonly codasyl data model database system application program exchange currency indicators record occurrences issues explored future storage object manager section summarize key features design exodus storage object manager begin discussing interface storage object manager higher levels system describe arbitrarily large storage objects handled efficiently discuss techniques employed versioning concurrency control recovery buffer management storage objects close discussion files storage objects file objects detailed discussion issues found care experimented idea generating quel-like interface tool storage object manager interface storage object manager procedural interface interface includes procedures create destroy file objects open close file objects file scans scanning purposes storage object manager call object object file object procedures creating destroying storage objects file reading storage objects storage object manager call pointer range bytes storage object desired byte range read buffers pointer bytes returned caller call provided inform exodus bytes longer needed unpins buffer pool writing storage objects call provided exodus subrange bytes read modified information needed recovery place shrinking growing storage objects calls insert bytes delete bytes offset storage object provided call append bytes end object finally transaction management storage object manager begin commit abort transaction calls additional hooks provided aid access methods layer implementing concurrent recoverable operations access methods efficiently discussed section addition functionality outlined storage object manager designed accept variety performance-related hints object creation routine mentioned accepts hints place object place object object large object expected average varies hint object disk page size page access methods level buffer manager accepts hints size number buffers replacement policy employ hints supported allowing scan group object access buffer manager accept hints per-scan-group basis allowing easy support buffer management policies dbmin chou storage objects 
upward-compatible extension stro extensions include language features number predefined classes present major features briefly refer reader rich rich rich additional details examples constructs apply dbms implementation problems persistence order provide support persistence shielding dbe interact directly lowlevel typeless view storage objects provided storage manager language mirrors existing type system constructors database attribute informally type defined fundamental type including dbshort dbint dblong dbfloat dbdouble dbchar dbvoid dbclass dbstruct dbunion classes data members fields types argument return types member functions methods similarly restricted pointer type object array type objects object persistent required type type object persistent non-persistent note type definable analogously defined type persistence orthogonal atki types program exclusively types achieve effect strict orthogonality desired types introduced compiler distinguish objects reside memory generally reside disk reside memory underlying implementation distinction made critical mainmemory-only types implemented bit efficiently normal types note macros redefine keywords class dbclass struct dbstruct union dbunion int dbint types describing type structure objects persistent supports declaration actual persistent objects storage class called persistent addition usual storage classes extern automatic static register declare persistent object named emp dbclass named employee program simply write persistent employee emp declaration emp handle persistent employee object object reside storage manager object emp instance normal class similarly member functions employee dbclass coded equivalent non-db class compiler implemented e-to-c translator translates portions persistent objects code calls storage manager needed manipulate contents persistent objects persistent objects mapped one-to-one storage objects pointers type objects oids dbe retains control format persistent objects explicitly make calls storage manager generic classes unknown types earlier types involved database programming code needing types written dbe access method code types keys types entities index code implementing join algorithm types entities called join address problem augments generic generator classes similar parameterized clusters clu lisk class parameterized terms unknown types class definition formal type names freely regular type names mechanism define class form stack specific class stack elements user class instantiate generic class providing actual type parameters class define stack class intstack handling integer data declare integer stack class intstack stack int intstack similarly dbe implement tree generic dbclass btree keytype entitytype key type type entity indexed dbclass parameters user wishes build index employees social security number system generate compile small program instantiates dbclass emp btree btree ssno type emp type persistent emp btree empssnoindex instantiations dealt efficiently linking process lines implementation clu atki figures give partial generic dbclass btreenode illustrate flavor classes dbclass represents node structure tree index defined writing generic tree dbclass discussed show shortly interface portion dbclass shown figure dbclass dbclass parameters keytype entitytype dbclass keytype required compare member function keytype entitytype addition type parameters generic classes dbclasses constant function parameters chose syntax stack int maintain compatibility existing class derivation syntax enum status found found dbclass btreenode dbclass keytype type keys tree int compare keytype compare function needed dbclass entitytype type indexed entities public type key-pointer pairs dbstruct kppair keytype keyval dbunion entitytype entityptr leaf nodes btreenode childptr interior nodes ptr internal structure tree node consisting node height leaf nodes number keys node array key pointer pairs size dbint height dbint nkeys kppair kpparray pagesize sizeof int sizeof kppair binary search function single node status searchnode keytype key int index node member functions dbclass btreenode figure generic dbclass btreenode key entity types node compare member function compares keys returns depending relative order structure tree node height count keys node array key-pointer pairs size array determined constant pagesize maximum object size bytes fit storage manager disk page size compares key function applied key passed explicit function argument illustrated figure binary search tree node status btreenode searchnode keytype key int index int min int max nkeys int mid int cmpval min max mid min max cmpval kpparray mid keyval compare key cmpval min mid cmpval index mid return found max mid return found btreenode searchnode figure code btreenode searchnode member function key-pointer pair searchnode member function figure shows code potentially persistent dbclass objects normal code fileof persistent collections addition providing support persistent objects providing generic dbclasses programming face missing type information support handling large scannable collections persistent objects similar type provision built-in generic dbclass fileof dbclass department dbclass dbclass created declaration dbclass deptfile fileof department objects type deptfile hold entire sets department objects including objects subclass department operational interface generic fileof class user bind typed pointers objects file create destroy objects file file viewed persistent heap sense statement dynamically allocating persistent objects requires specification elegant performance file create object function returns sum budgets departments file department objects file passed assume department objects public data member called budget float totalbudget deptfile depts department float sum depts null depts sum budget return sum extremely simple illustrates easy scan contents file objects typecasting needed pointer buffer calls instance fileof dbclass implemented storage manager file represented fid dbe shielded filerelated storage manager calls fileof dbclass interface finally cases restriction storing instances type subtypes file limiting untyped byte-oriented file dbclass provided iterators scans query processing typical approach structuring database system include layer scans objects database scan control abstraction state-saving interface memoryless storage systems calls interface needed record-at-a-time processing higher layers typical implementation scans allocate data structure called scan descriptor maintain needed state calls storage system user pass descriptor call control abstraction scan provided exodus notion iterator lisk iterator coroutine-like function saves data control states calls time iterator produces yields suspended resumed client matter complicated iterator client sees steady stream values produced client invoke iterator kind control statement iterate loop generalizes loop clu general idea implementing scans clear implement scan trees write iterator function btree class takes lower bound upper bound arguments scan begin searching leaf level tree lower bound keeping stack node pointers walk tree yielding object time reaching upper bound alternatively leaves linked walk sequence set iterator terminate figure shows interface definition generic btree class including constructor function initialize newly created tree index destructor function invoked clean tree destroyed member functions insert delete index entries scan iterator iterators piece executable queries access plan tree views query pipeline processing filters processing stage implemented iterator client iterators upstream pipe yields result 
operations earlier storage object basic unit data storage object manager storage objects small large distinction hidden higher layers exodus software small storage objects reside single disk page large storage objects occupy potentially disk pages case object identifier oid storage object address form page slot oid small storage object points object disk large storage object oid points large object header large object header reside slotted page large object headers small storage objects pointers pages involved representation large object pages large storage objects private shared objects pages shared versions storage object small storage object grows point longer accommodated single page storage object manager automatically convert large storage object leaving object header place original small object considered alternative logical surrogates oid physical addresses recent proposals cope ston efficiency considerations led opt physical surrogate scheme logical surrogates access objects dense surrogate index figure shows large object data structure inspired stonebraker ordered relation structure ston number significant differences care conceptually large object uninterpreted byte sequence physically represented tree index byte position object collection leaf blocks data bytes residing leaves large object header number count page pairs child root count child pointer maximum byte number stored subtree rooted child rightmost child pointer count size object internal nodes similar recursively defined root object contained parent node absolute byte offset child translates relative offset parent node left child root figure bytes child rest object bytes rightmost leaf node figure bytes data byte leaf node byte child root byte object searching accomplished computing offset information descending tree desired byte position care object sizes supported tree levels header leaf levels included large storage object data structure algorithms search range bytes update insert sequence bytes point object append sequence bytes end object delete sequence bytes point object insert append delete operations inserting deleting arbitrary number bytes opposed single byte true objects sorted surrogate case non-dense surrogate index pages header root internal blocks leaf oid figure large storage object large storage object poses unique problems compared inserting deleting single record ordered relation algorithms operations detail care results experimental evaluation storage utilization performance characteristics evaluation showed exodus storage object mechanism provide operations large dynamic objects low cost reasonable level storage utilization typically higher versions storage objects storage object manager primitive support versions storage objects version storage object retained current version preceding versions simply marked object headers versions reason providing primitive level version support exodus applications widely notions versions supported ston dada katz bato clif klah snod katz omit version management altogether efficiency reasons prohibitively expensive terms storage space cost maintain versions large objects maintaining entire copies objects versions large storage objects maintained copying updating pages differ version version figure illustrates figure shows versions large storage object figure original version newer version created deleting bytes note shares nodes unchanged copies modified figure versions large storage object node version large storage object copy path root leaf leaves copies internal nodes change affects large fraction object length path number internal pages small relative number pages actual data due high fanout internal nodes overhead versioning large objects scheme small fixed tree height basically proportional difference adjacent versions size objects allowing creation versions large storage objects supported allowing insert append delete write read modify byte range operations invoked versioning turned storage object manager supports deletion versions efficiency maintain clean abstraction problem deleting version large object avoid discarding object pages shared needed versions object care describes efficient version deletion algorithm addresses problem providing delete version respect set versions retained concurrency control recovery storage object manager concurrency control recovery services storage objects two-phase locking gray byte ranges storage objects concurrency control lock entire object option provided cases object level locking suffice ensure integrity internal pages large storage objects insert append delete operations operating changing counts pointers non-two-phase tree locking protocols baye employed recovery small storage objects handled after-image logging in-place updating object level gray recovery large storage objects handled combination shadowing logging updated internal pages leaf blocks shadowed root level updates installed atomically overwriting object header header verh parameters operation caused update logged log sequence number gray maintained large object root page ensure operations large storage objects logically undone redone needed similar scheme versioned objects before-image updated large object header entire small object retained version object buffer management storage objects objective exodus storage object manager design minimize amount copying buffer space required related objective sizable portions large storage objects scanned directly buffer pool higher levels exodus software accommodate buffer space allocated variable-length buffer blocks integral numbers contiguous pages single-page units exodus client requests sequence bytes read object non-empty portions leaf blocks desired byte range read contiguous buffer block obtaining buffer block size buffer space manager reading pages buffer block strict byte sequence order placing data byte leaf page position immediately data byte previous page recall leaf pages large storage objects full scan descriptor maintained current region scanned including information oid pointer buffer block length actual portion buffer block bytes requested client pointer byte information contents buffer block client receive pointer scan descriptor buffer contents accessed free space buffer pool managed standard dynamic storage allocation techniques buffer block allocation replacement guided storage object manager hint discussed section language hides structure dbi mechanism file objects file objects collections storage objects grouping objects purposes exodus storage object manager mechanism sequencing objects file related objects common file sequential scanning purposes objects file disk pages allocated file file objects provide support objects co-located disk large storage objects file object identified oid points root object header storage objects file objects distinguished header bit large storage objects file objects represented index structure similar tree key index case file object index disk page number key leaf page file object index collection page numbers slotted pages contained file pages managed separately standard disk allocation techniques file object index serves mechanism gather pages file nice properties facilitates scanning objects file object physical order efficiency fast deletion object oid file object oid includes page number key file object index note objects file directly accessible oids file object comparable surrogate index indices objects file entries point directly objects indexed feature important performance 
study alternative workstation-server architectures object oriented database systems david dewitt philippe futtersack david maier fernando velez authors affiliations dewitt computer sciences department wisconsin sabbatical gip altair maier department computer science engineering oregon graduate institute science technology sabbatical gip altair futtersack velez gip altair france work partially supported research grant graduate school wisconsin dewitt national science foundation grant irid maier abstract engineering scientific marketplaces workstation-server model computing emerging standard implementing object-oriented database system environment immediately presents design choice partition database functionality server workstation processors understand alternatives fundamental design decision analyze workstation-server architectures evaluating qualitatively benchmarking prototypes approaches labeled object server individual objects pass server workstation page server disk page unit transport server buffers pages file server pages transferred accessed directly workstation process remote file service nfs built prototypes architectures stripped-down version wiss storage system starting point compare performance prototypes experiment sensitivity data placement cache sizes developed object manager benchmark altair complex-object benchmark acob benchmark supports experiments vary clustering inter-object locality smearing intra-object locality test suite benchmarks includes queries scanning entire database traversing updating complex objects present results experiments run acob prototypes results single-server version wiss serves point main conclusions page-server file-server architectures benefit clustering relative performance pageand objectserver architectures sensitive degree database clustering size workstation buffer pool relative size database file-server architecture dominates page-server architecture read-intensive operations opposite true write-intensive operations introduction relational database systems technology past years apparent object-oriented database systems key database technology harnessing power technology easy systems pose difficult engineering challenges reflects commercialization relational database systems full ten years turn prototypes ingres system ston astr products conservative customers willingly relative complexity object-oriented database systems ten years technology object-oriented database systems solidified situation complicated emergence workstation-server model computing standard engineering scientific market places initial target market object-oriented database systems past tendency run database software primarily shared-server accessed high-level query language sql key premise study widespread mips workstations concentrates majority cpu cycles workstations server distribution functionality longer viable addition oodbmss differ significantly relational systems manipulate data oodbms fair amount application incorporated methods classes objects instances addition oodbmss provide support associative queries sets objects atki applications employing oodbms typically large navigational component simply run applications programs centralized server approach simply commercially viable oodbmss tend applications cad systems require computational graphical interface dedicated workstation user provide centralized solution problem acceptable distributed architecture required undertaken paper examine functionality oodbms distributed workstation server remainder paper organized section describes alternative workstation-server architectures oodbms makes qualitative comparison section presents prototype implementations architectures benchmark evaluate alternative designs section results applying benchmark prototype systems presented section related work section conclusions contained section alternative workstation server architectures introduction markedly approaches architecting oodbms workstation-server environment general approach wide number variations alternative object server approach named unit transfer server workstation object architecture server understands concept object capable applying methods objects prototype banc deux orion prototype kim pre-release versions gemstone cope employ object-server architecture alternative page server approach design server deals pages understand semantics objects apply methods objects addition providing storage retrieval database pages server concurrency control recovery services database software running workstations architecture observer horn exodus care prototypes design represents simplification page-server architecture workstations remote file service nfs sun read write database pages directly page-server design server architecture concurrency control recovery services current version gemstone architecture configured workstation-server environment term architecture file server approach subsections compare alternative architectures qualitatively viewpoint affects implementation functionality oodbms provide obvious issues left unanswered decided concentrate efforts deciding basic architectures performance equally important issues recovery strategy architecture study issues future object-server architecture object-server architecture oodbms functionality replicated workstation server shown figure addition maintain caches recently accessed objects methods applied objects workstation server workstation object searches local variations architecture serverworkstation application program communication software object manager object manager space allocation physical file index manager object cache object cache page buffer figure object cache object object found sends request object server object server cache server retrieves object disk returns requesting workstation unit transfer workstation server individual object server copy desired object local cache depending cache policy implements architecture number advantages server workstation run methods method selects small subset large collection execute server avoiding movement entire collection workstation ability valuable index collection selection operation addition balance system workload moving work workstation server vele advantage architecture simplifies design concurrency control subsystem server objects accessed application concurrency control completely centralized server implementation object-level locking straightforward design lower cost enforcing constraints relate objects manipulated application objects database constraint subpart graph mechanical assembly acyclic moving objects involved constraint workstation constraints checked server design suffers problems worse case remote procedure call rpc object hit rate workstation object cache high satisfy requests server transfer single object time capable figuring objects belong replicating work clustering mechanism objects disk page major problem architecture complicates design server server supply functionality supply sharing concurrency control recovery server capable executing arbitrary user methods case prototype meant system semaphores coordinate access shared memory read expensive slow server object cache lock table related problem arises method applied group objects distributed workstation cache server cache disk drives hold database problem complicated possibility object caches disk simultaneously addition updated version object exist workstation cache server cache method blithely execute server addressing cache inconsistencies orion adopted solutions problem case method associative query run server workstation flushes modified objects object cache back server fairly slow process orionprototype executes method workstation server kim strategy result duplicate copies object result complicated expensive postprocessing step duplicate elimination required minor problems occur object-server architecture hinder locking page level alternative object-level locking workstation server software deals pages objects tend copied multiple times object copied server page-level buffer pool object cache workstation copy place workstation object stored directly object cache networking software finally software workstation simply requests object server generally aware size object large multipage objects move entirety application needed access bytes finally design step technology trends years mip workstations increasingly common computing power end concentrated workstations server situation makes sense move work workstation server functionality server stripped bare minimum likewise years fddi replace ethernet standard technology local area networks cost sending message due software overhead transmission time overhead component dominate future 
tuples stage downstream pipe execution query pipeline demand-driven nature dbe relational dbms write operator methods select project join operations iterators fashion access plan tree results optimizing user query difficult produce code implements pipeline plugging instances iterators approach forming queries rich basis relational dbms prototype developed exodus tools demonstration sigmodthe idea illustrated excerpt relational dbms prototype code iterator member function generic class method equi-join operator iterator dsttype index join tuple dsttype rslt attrtype joinval iterate srctype outer outerquerynext tuple extract outer joinval iterate srctype innerindexscan joinval joinval concatenate outer rslt yield rslt code implements tuple iterator computing join index-based algorithm srctype srctype dsttype outer result tuple types attrtype type join attribute join method iterates stream outer relation tuples iterator tuple provided subquery outerquery feeding join tuple extracts join attribute function extract scans relation tree index join attribute dbclass btree dbclass keytype type keys tree int compare keytype compare function needed dbclass entitytype type indexed entities instantiate types tree index dbclass node btreenode keytype entitytype dbclass nodefile fileof node represent tree file nodes root pointer nodefile tree node root public btree constructor function btree destructor function entitytype insert keytype entitytype entitytype delete keytype entitytype iterator entitytype scan keytype keytype dbclass btree figure interface generic dbclass btree innerindex tree scan iterator find matching tuples time finds matching tuple calls concatenate function concatenate outer tuples forming result tuple yields result tuple operator method query stream extract concatenate functions outerquery innerindex pointers initialized based arguments passed index join class constructor shown complete rich method performance issues language dbe implement key portions code dbms performance important issue performance issue related frequently code produced compiler issues calls storage manager working optimization pass compiler perform transformations reduce frequency number fields object referenced compiler generate single call retrieve relevant portion object opposed series individual calls object large array image transform loop processes elements array nested loop processes block array elements time plan add hint facilities order dbe guide compiler making performance-related decisions buffer group sizes replacement policies critical operations performance issue relevant access method code specialized locking recovery schemes tree locking protocols baye two-phase locking log-based recovery mechanisms employed storage manager ensure correct recoverable operation programs mechanisms prove restrictive high-performance dbms long-term goal add transaction control facilities order permit clever dbes implement index-specific concurrency control recovery algorithms needed modeling end-user schemas discussed briefly section type system language sense viewed internal type system exodus support target end-user data model dbe develop mappings data model type system type system collection primitive internal exodus types includes integers floating point numbers characters enumerations type constructors include pointers arrays structures unions abstract data types rectangle complex number image operations defined dbclasses addition data model type constructors list set modeled implementing parameterized dbclasses pointers rich collection type constructors complex recursive end-user object types modeled difficulty expect internal type system exodus powerful satisfactorily model application area type system query optimization compilation unforeseeably wide variety data models hope support exodus operators methods exodus includes query optimizer generator produces application-specific query optimizer input specification generated optimizer repeatedly applies algebraic transformations query selects access paths operation transformed query transformational approach outlined ullman relational dbmss ullm microbe database project nguy rules coded pascal procedures initially considered rule-based language implement general-purpose optimizer augment data model specific rules prolog cloc ops forg interesting candidates built-in inference engine search mechanism convenience limits search algorithms fixed hard augment search heuristics important query optimization based limitation considerations call compatibility exodus components optimizer execution speed decided provide optimizer generator grae grae produces optimization procedure programming language kern generated optimization procedure takes query input producing access plan output query context tree-like expression logical operators internal nodes join relational dbms sets objects relations leaves part optimizer task produce initial algebraic query tree non-procedural expression user interface parser access plan tree operator methods internal nodes nested loops join method files indices leaves access plan obtained transformed iterator-based program procedure walks access plan tree manner loosely related frey basic optimizer generator inputs key elements optimizer generator requires description file order generate optimizer operators methods transformation rules implementation rules operators methods characterized arity transformation rules legal equivalence-preserving transformations query trees consist expressions optional condition expressions place-holders lower parts query unaffected transformation condition code fragment inserted optimizer place finally implementation rule consists method expression method implements optional condition excerpt description file prototype relational query optimizer operator join method nested-loops-join merge-join join join join nested-loops-join join declared binary operator nested-loops-join merge-join declared binary methods symbol denotes equivalence potential two-way transformation context transformation rule keyword implementation rules transformation rule states join commutative implementation rule nested loopsjoin join method merge-join method joining sorted relations implementation rule include condition test input relation sorted appropriately optimizer support functions addition declarative description data model optimizer generator requires dbe provide collection support procedures code section optimizer description procedures routines access manipulate optimizer data structures generated optimization procedure employs principal data structures mesh open mesh directed acyclic graph holds alternative operator trees access plans explored employing complex pointer structure ensure transformations identified performed quickly equal subexpressions processed open priority queue applicable transformations section cost access plan defined sum costs methods involved objective optimization minimize sum method dbe provide cost function calculating cost method based characteristics method input method cost function called generated optimizer considers method implementing operator pattern operators input arguments method cost functions pointers root node relevant portion query tree mesh nodes mesh produce input streams implementation rule addition method cost functions property function needed operator method dbe permitted define properties structures operator method node mesh operator properties logical properties intermediate results cardinalities schemas method properties physical properties method side effects sort order merge-join operator property functions called generated optimizer transformations applied method propery functions invoked methods selected node mesh arguments operator represented node method found subquery rooted node relational optimizer select join operators predicates arguments project operator field list argument method implements combined select-project operation predicate field list arguments properties dbe define data-model-dependent aspect node typically union default operator method arguments copied automatically mesh nodes fine simple transformation implementation rules join commutativity simply reorders operators query tree rules 
discussion file object representation operations concurrency control recovery found care types type manager exodus type definition facilities files exodus refer typed objects storage objects viewed programming language type system files constrained objects type restrictive sound includes union variant type constructors employee department records stored disk efficiency reasons empdept variant type defined serve type file storing records exodus type system types typed objects defined combining base types type constructors base types types accessible set operations defined correspond abstract data types adt ingres ston conventional programming languages primitive exodus base types include int float char enumerations addition exodus support addition base types rectangle complex number large base type image operations flexible adt facility section definition adts tasks dbi type constructors provided include pointers fixed length arrays insertable arrays variable length sequences records unions variants type constructors nested fashion array records permissible arrays fixed length records compiler produce code minimizes amount run time interpretation incurred accessing instance constructed type final note observe presence pointers physically realized object ids type constructors makes model complex recursive types typed objects typed objects higher level application-specific dbms expect extensible type system sufficiently powerful serve applications satisfactorily role type manager type manager facility storage persistent type information addition type definitions maintains information pieces called fragments making compiled query information relationship pieces track correspondence files types short type manager track type information related dependent information fragments query include types objects stored files close relationship type manager traditional schema facilities type manager provide complete schema facility end users store information things cardinalities protection security requirements non-type-related schema information expected vary application application maintaining sort information left application-specific dbms dbi expected maintain set catalogs storing information presumrurururururururururururururururururururururururururururururururururururu type definitions referred fragments pieces query-related information ably defined terms end-user data model target system designed support fragments exodus based late binding model database architecture database systems built exodus tools compile information database structure operations fragments stored type manager compiled query plans fragments bound compiled linked prior execution query fragments compiled earlier process requires type manager maintains dependency information fragments section maintaining ordering information important part type manager job files treated fragments slightly exist code type manager file triple form fname ftype fid fname character string naming file ftype type file fid file defined storage manager dependencies time ordering constraints hold fragments constituting complete query including files compiled linked query plan created recently program text methods adt operations employs out-of-date code creation addition observe type set operations representations source code intermediate parsed representation linkable object queries executable binary similar time ordering constraints hold representations unlike problem determining constituent parts large software system date fact functionality type manager shold unfamiliar users unix make facility feld unlike make examines dependencies timestamps started type manager maintains graph inter-fragment dependencies times graph change fragments dependencies added subtracted database type manager plays role maintaining data abstraction distinguishes make type query plan turn types constitute internal representation type strictly speaking dependent linkable object code constituent types eventually linked code object code date compiled link time call fragments sort companions make facilities companions type manager requires facility unable provide complete list objects constituting query query linked rules actions type manager maintains correct time ordering fragments mechanisms rules actions set fragments constitutes nodes acyclic directed graph rules generate arcs graph fragment found older fragments depends dependencies determined rules search made action performed bring fragment date rules actions defined syntax based regular expressions wide range default fragment dependencies specifed minimum actual rule text disambiguating heuristics exist deal action conflicts regular expressions match fragment access methods exodus application-specific database systems undoubtedly vary access methods employ trees index type based form dynamic hashing sufficient conventional business database systems relational dbms database system storing manipulating spatial data spatial index structure kdb tree robi tree gutt grid file niev structures plan provide library access methods exodus expect library grow specialized index structures undoubtedly continue developed emerging database applications seek higher higher performance complication index structure expected handle data variety types integers reals character strings newlydefined types long data type meets prerequisites correct operation index structure tree requires existence total ordering operator key type ston includes operating data types defined dbi index code completely written debugged section access methods reside top storage object manager exodus architecture application-specific database systems addition type information missing compile time provided access method code run time goals exodus project simplify task adding access methods existing application-specific database system major sources complexity adding access method programming verifying access method algorithms mapping access method data structure primitive objects provided storage system iii making access method code interact properly buffer manager ensuring concurrency control recovery handled correctly efficiently access method designer interested item comprise actual code write order add access method typical commercial dbms items comprising remaining ston improve situation dramatically hope exodus programming language dbi implementing access methods operations language effectively shields dbi items translator produces code handle details based dbi index code declarative hints remainder section outline access methods added exodus including programming constructs chosen simplify writing access method code buffering concurrency control recovery issues handled covers transparent fashion note important details design necessarily omitted discussion intended give reader general introduction ideas detail rich implementation language language derivative kern addition set programming constructs carefully chosen provide high leverage dbi number constructs inspired developments programming languages years notably clu lisk pascal jens major features include ability bind pointer variable object file declare abstract data types spirit clu clusters program structure fully modular separate compilation modules including parameterized modules amount missing type information addition type constructors control abstractions providing facilities dbi define manipulate internal structure storage objects access method tree node natural making direct calls storage object manager explicitly coding structure overlays offset computations dbi ignore fact storage objects arbitrarily large translator insert calls storage object byte ranges needed dbi output language translator source code exodus-specific constructs replaced collections lower-level constructs additional routine parameters calls storage object manager words storage object manager effectively translator target machine resulting source code linked storage object manager addition facilities language dbi declarative access storage object manager hint facilities section file-bound 
page-server architecture figure shows architecture page server architecture server basically consists large buffer pool level storage system managing pages files concurrency control recovery servers upper levels oodbms software run exclusively workstation unit transfer workstation server disk page server receives request data page sets lock page desired page server buffer pool server retrieves page disk returns workstation buffering workstation terms pages terms objects advantage object cache buffer space workstation wasted holding objects referenced application object cache cost copying object incoming data page local object cache incurred object object cache updated page object resides retrieved server turn incur operation object server design advantages disadvantages primary advantage places complexity oodbms workstation majority cpu cycles concentrated leaving server perform tasks perform concurrency control recovery entire pages transferred intact workstation server overhead server minimized glance approach wasteful single object page needed fact cost terms cpu cycles send bytes higher cost sending layer server log lock server page server buffer manager workstation application program communication software object manager page buffer page buffer file index manager figure bytes clustering mechanism worked properly significant fraction objects page eventually end referenced client finally minimizing load individual workstation places server support workstations single server delaying long complexities supporting multiple servers simplicity makes design attractive disadvantages methods evaluated workstation sequential scan collection requires pages collection transferred workstation limitation sounds disastrous mitigating factors server amount disk object server design case indexed selection pages relevant objects transferred workstation page server avoids problems flush workstation cache object-server architecture encounters executing methods server disadvantage object-level locking difficult implement object-level locking employed workstations update objects data page classical locking protocols gray transactions set locks shared page locks individual objects special precautions merge pages modified pages written back server updates lost solution object-level lock page time making locks page incompatible addition implementing nonpl b-tree locking protocols complex environment finally performance design relative architectures absolute terms dependent effectiveness clustering mechanism section examine clustering affects performance design file-server architecture final workstation-server architecture variation page-server design workstation software remote file service nfs sun read write database pages directly figure shows architecture reasons architecture attractive advantages page-server architecture minimizing overhead workstation server nfs runs operating system kernel read write database user-level context switches avoided completely improving rate data retrieved remote workstation finally widespread nfs continue evolve improved basing system nfs takes advantage server space allocation log lock server workstation application program object manager page buffer file index manager commun nfs software figure improvements addition problems inherits page-server architecture architecture problems nfs writes slow stateless protocol built top udp write operation remotely mounted nfs file flushed disk request acknowledged read operations architecture bypass server software completely combine request page request lock page send separate lock request message approach negates benefits nfs place cost lock request close cost simply requesting page setting lock side effect costly alternatives optimistic concurrency control scheme batch lock requests reduce overhead setting locks similar problem occurs coordinating allocation disk space server sending request server individual page expensive reasonable solution server allocate groups pages time workstations requesting single page time prototyping workstation-server architectures introduction section describes prototypes alternative architectures basis prototypes stripped-down single-user version wiss chou elected wiss updated block flushed disk inode unix file system data structure points updated block data page write involves disk solution problem legato menlo park recently introduced stable ram board sun servers buffer writes part oodbmss system altair objectstore system object sciences shown figure wiss consists distinct levels lowest level level deals aspects physical including allocation disk extents collections physically contiguous pages files level level buffer manager read write operations level provide buffered higher levels system pages buffer pool managed lru replacement strategy level storage-structure level level implements sequential files -trees long data items level responsible mapping records pages buffered level finally level implements access methods provide primitives scanning file sequential index long-data item scans simplify implementation prototypes produced stripped-down version wiss removing support long data items b-trees primitive scans resulting system supports records files sequential scans predicates addition serving basis prototype systems constructed version wiss lower bound performance systems compared ideal workstation-server version system performance single-processor version discussed detail object page servers required split functionality provided wiss processes termed client server processes target environment database storage structures buffer management physical management level level level level sequential file scans index file scans sequential files b-tree indices lru stack hints physical storage allocation scan mechanisms records wiss architecture figure resides disks attached machine running server process client process runs workstation provide interprocessor communication implement system sun rpc tools including rpcgen sun automatically generates procedure stubs data file describes message formats procedure names communicate remotely rpc package support communications tcp udp elected udp send streams data larger kbytes file server section simplest number workstations share data run database software workstation nfs access database shared server experiments elected ignore issues concurrency control recovery coordinating allocation disk space prototyping architecture simply meant running wiss processor disk volume remotely mounted file system belonging server shown figure level wiss makes request read write page nfs software takes care executing request server behalf workstation key motivation prototyping design lower bound fast remote data accessed nfs version sun rpc protocol implemented top udp data transfers occur kernels user-level processes illustrated results section difference significant effect execution kinds queries layer buffer manager buffer pool interface layer records files server workstation nfs application remote file server design figure page server prototyped page server architecture shown figure server process consists levels wiss rpc interface routines levels workstation process consists levels wiss level replaced thin layer executes requests level sending remote procedure call server process upper levels wiss completely unaffected current implementation design provide concurrency control recovery services server support simultaneous workstation processes complete implementation design request page lock mode desired workstation avoiding overhead message set lock addition centralized lock table server workstation maintain local cache locks holds minimize lock calls server success page-server design predicated factors extent related objects clustered page relative cost fetching individual object versus page objects illustrated table cost obtaining page server overhead rpc communications protocols transmission copying costs layer buffer 
pointer variable source program scan descriptor section variable inherits hints type definition absence hints provide reasonable default assumptions hints make knowledgeable dbi tune performance code recommending lock protocol buffer replacement strategy storage object size persistent object scan variable provide hint mechanism permit dbi influence types laid secondary storage providing dual buffering hint sense writing access methods demonstrate usefulness implementation language explain features dbi implementing trees define tree abstract data type type operations users type internal representation hidden case operations include create index destroy index lookup insert delete describe internal structure tree node dbi define c-like structure represent contents adt module typedefs adt representation type adt module btree defined figure definition variant typedef btree representation type adt note module parameters representing unknowns time dbi writing code include type key index built ordering operators keys type entity indexed module parameters freely type procedure names implementation parameterized types btree unknown quantities compiled extra hidden parameters routines form adt interface adt btree entity type key type equal type entity type type key type int equal int typedef enum internal leaf nodetype typedef struct key type btree child key ptr pair typedef struct key type entity type ptr key ptr list typedef variant nodetype nodetype internal int height key ptr pair data leaf key ptr list data btree obj pagesize lock hierarchical buffer lifo figure pointer follow private int search node node key btree node key type key simple binary search node int min max middle min max lengthof nodedata min max middle min max equal key nodedata middle return middle key nodedata middle max middle min middle return search node find entity key public entity type lookup key key type key lookup btree figure partial tree btree definition hints translator tree nodes page size hint facilities designed hint syntax preliminary intent simply convey hierarchical locking tree operations lifo buffer management policy buffer blocks scan buffers locks allocated scan basis definitions dbi proceed access manipulate storage objects standard in-memory structures figure code fragment tree search routine routine parameter node pointer btree time translator encounters statement node dereferenced translate sequence statements runtime sequence check bytes object buffer pool inspecting node scan descriptor calling storage object manager read desired bytes subsequent bytes buffer pool actual place memory key type unknown code compiled translator compile code needed information size passed covers resulting offset calculations index key-pointer-pair arrays make parameters operations pointers files call creates object file bound sets point free disposes object pointing calls provided including calls create destroy files translator recognize calls replace lower-level storage object manager calls transparent transaction management language simplifies dbi job allowing access method structures algorithms expressed natural translator adds storage object manager calls producing code section describe concurrency control recovery fit picture problem complicated fact access methods require non-two-phase locking protocols specialized recovery requirements performance reasons ston functions handled translator combination layered transactions protocol stubs flavor hint facilities provide focusing efforts difficult problem automatically buffering pieces large objects thoughts deal concurrency control recovery preliminary state layered transactions transaction management access methods exodus loosely based layered transaction model proposed weikum weik weikum model based notion architectural layers database system layer presenting set objects operations client layers operation mini-transaction nested transaction transaction client layer realized series mini-transactions servant layers concurrency control enforced two-phase locking objects layer system objects servant layer locked behalf transaction client layer locks held client transaction completes recovery layered similar manner mini-transaction executes writes level-specific recovery information log completes log information removed replaced simpler client-level representation entire operation undo effects incomplete layered transaction level effects number completed mini-transactions in-progress mini-transaction undone undo incomplete minitransaction recursively general log information run inverse completed minitransaction weikum proposes amounts per-transaction stack-based log recovery draw inspiration weikum access method transaction management facilities differ respects exodus strictly hierarchical nature collection interacting modules invalidate notion layered transaction provide general locking strict two-phase model weikum proposal allowing locks set servant explicitly released passed client important access methods two-phase locking single index operation considered unacceptable baye lock passing needed prevent phantoms key-pointer pair inserted index client retains lock index leaf page transactions run consistency problems due incorrect existence information lastly efficient log management essential performance view weikum per-transaction stack-based log unwieldy employ standard circular log management techniques ignoring entries completed minitransactions recovery processing returning discussion access methods note access methods layer presents objects indices operations insert delete search clients client transaction executes series inserts effects undone series deletes access methods layer turn client storage object manager presents storage objects operations create object insert bytes append bytes protocol stubs layered transactions simplify task writing access methods calls layers viewed primitive atomic operations transaction model task implementing model remains write code handle tree locking recovery correct difficult exodus provide collection protocol stubs managed compiler shield dbi details problem briefly protocol stub abstraction locking protocol implemented collection code fragments translator inserts points compilation program related data structures code fragments consist locking logging calls exodus transaction manager component storage object manager data structures describe information lock modes compatibility passed lock manager expect generation protocol stubs complicated task stubs considered average dbi non-extensible part basic exodus system existing stubs easy hand exodus provide collection stubs twophase locking hierarchical locking lock chaining protocol baye dbi writing access method select desired protocol compile time declarative hints mentioned earlier bracket access method operation begin end transaction keywords include stub-specific routine calls access method operation code concrete briefly sketch protocol suitable concurrent recoverable access sorts hierarchical index structures basic idea tree lock-chaining protocol baye concurrency control shadowing operation-atomicity verh tree insert operation lock chaining descend tree release locks ancestors safe node locked node realize protocol hierarchical locking protocol stub implicitly set locks nodes referenced keeping track path locked nodes dbi code determines safe node reached call lock stub routine called top-of-scope announce previously accessed nodes excluding current longer tree scope interest insert operation lock release operations transparently handled lock stub routine recovery insert operation node splitting occur top-of-scope changed nodes level automatically shadowed insert atomically installed end-of-operation overwriting top-of-scope node descendent pages safely written disk care storage object manager 
copying insufficient dbe provide argument transfer functions manipulate arguments transformation rule select product join select select xpj arg xfer join predicate operator oper argument reject one-way transformation rule replaces selection cross-product join selections function xpj arg xfer dbe provide called rule applied generated optimizer order rearrange operators predicate arguments split predicate select operator left-hand side rule join predicate select predicates operators rule right-hand side illustrates features mentioned earlier shows condition rule transformation rejected join predicate function provided dbe determines join predicate exists shows access provided operator arguments select operator left-hand side rule numbered identify uniquely rule oper argument field passed function employed condition method arguments properties operators methods accessed similar manner finally cases dbe assist optimizer estimating benefit transformation transformation performed function named transformation rule keyword estimate case function called optimizer estimate expected cost transformed query based relevant portion query tree operator arguments operator method properties glance bit code dbe write functions outlined required cost functions absolutely dbe type operator property fields operator property functions similarly method property functions needed method property type argument transfer functions estimation functions optional rules functionality required finally remember key design goal exodus optimizer generator data model independence functions built optimizer generator intend provide libraries generally functions predicate manipulation routines dbe cases operation generated optimizer generated optimization procedure starts initializing mesh open data structures mesh set tree structure original query method lowest cost estimate selected node mesh implementation rules finally transformation rules determine transformations inserted open mesh open initialized manner optimizer repeats transformation cycle open empty promising transformation selected open applied mesh nodes generated transformation optimizer find equal node mesh avoid optimizing expression nodes equal operator argument inputs equal node found replace node remaining nodes matched transformation rules analyzed methods lowest cost estimates selected algorithm parameters serve improve efficiency promise transformation calculated product top node total cost expected cost factor transformation rule insure matching transformation rule low expected cost factor applied entries open prioritized expected cost decrease expected cost factors provide easy ensure restrictive operators moved tree quickly general heuristic cost lower constructive operators join transitive closure smaller inputs apply equivalence transformations directly yield cheaper solutions needed intermediate steps expensive access plans transformations represent hill climbing limit application hill climbing factor lastly transformation results lower cost parent nodes expression reanalyzed propagate cost advantages reanalyzing factor similar hill climbing factor limits propagation cases plan cost worse equivalent subquery factor non-trivial problem select values optimization parameters guarantee optimal access plans good optimizer performance nice determined adjusted automatically automated selection hill climbing reanalyzing parameter values successfully automated choice expected cost factors current prototype initializes expected cost factors transformation rules neutral adjusts sliding geometric averages turned effective experiments prototype relational optimizers grae grae experience generated optimizers fast production access plans produce consistently close optimal found exodus optimizer generator modular framework breaking data-model-dependent code query optimizer small meaningful pieces aids rapid prototyping development query optimizers dbms supporting complex objects object orientation number components exodus ready initial trial recently turned attention process selecting target data model implement exodus toolkit goals implementation effort validate exodus approach dbms development serve forcing function developing library access methods operator methods provide system serve demonstration exodus potential users single data model query language terms goals decided design data model query language extra data model excess query language result design effort extra data model includes support complex objects shared subobjects mix objectand value-oriented semantics data support persistent objects type extra type lattice user-defined abstract data type extensions adts excess query language facilities querying updating complex object structures extended addition adt functions operators written procedures functions manipulating extra schema types written excess section paper presents overview key features extra excess details found care extra data model extra database collection named persistent objects type defined extra type system extra separates notions type instance users collect related objects semantically meaningful sets arrays queried settle queries type extents data models mylo ship bane lecl rowe extra collection type constructors includes tuple set fixed-length array variable-length array addition flavors instance values ref ref unique ref casual users query writers concerned distinction combined extra type constructors provide powerful set facilities modeling complex object types semantics finally extra support user-defined adts derived attributes automatic maintenance inverse relationships attributes figure shows simple database defined extra data model extra tuple set array constructors complex objects denoted parentheses curly braces square brackets figure fairly self-explanatory exception keywords unique ref extra subordinate entities treated values nested relational models sche objects separate identity prefaced ref ref orown unique ref type definition object creation statement declaration ref extant object ref object identity existence dependent existence object refers ref unique ref object identity existence dependent unique owning object briefly figure defines types happen tuple types person student subtype person employee subtype person department defines database consisting named persistent objects students set student objects departments set department objects form unique ref sets member objects member objects deleted owning sets subsequently destroyed department object set departments set employee objects work department owns objects employee object thought part composite bane department object employee student objects department object work major management structure employees captured manager ords attributes employee objects concepts central design extra excess extensibility support complex objects addition model incorporates basic themes common semantic data models hull peck extensibility extra excess provided abstract data type mechanism types written programming language registered system support user-defined functions procedures written excess query language operate user-defined extra types complex objects objects database possibly composed objects unique identity objects referenced identity database bato varieties complex objects identified disjoint-recursive disjoint-nonrecursive nondisjoint-recursive nondisjoint-nonrecursive extra data model capable modeling varieties extra capabilities found semantic data models primitive modeling concepts fundamental semantic data models hull peck is-a relationship generalization part-of relationship called aggregation instance-of relationship referred classification member-of relationship called association models concepts easily modeled facilities extra generalization modeled extra inherits keyword type inherits attributes functions type employee person figure note notion generalization called specialization semantic modeling literature aggregation easily modeled tuple constructor instance department aggregation employees manager ignore distinction attributes describe object components object classification simply notion type-instance dichotomy present extra distinction 
manager buffer pool interface layer records files workstation layer buffer manager buffer pool rpc stubs server rpc application page-server design figure times gathered sun processors mips cpus running sun rpc software version sunos size rpc request message bytes size reply message execution time byte bytes bytes bytes bytes bytes table object server server process page-server architecture understands pages object-server design understands objects files collections objects object-server prototype depicted figure server process consists layers wiss rpc interface level wiss workstation process consists application code special version level wiss object cache version level serves interface local object cache services provided server process rpc software operations files create destroy open close passed directly server operations objects wiss records handled case read object call interface layer checks object local object cache object returned directly application code miss local cache occurs interface layer makes space local cache writing dirty object back server requests desired object server layer buffer manager buffer pool interface layer records files serverworkstation interface layer rpc stubs object cache rpc application object server design figure object created write-through cache protocol wiss physical object-ids server needed place object page file assign object-id object remains cache marked clean updates objects residing cache handled simply marking object dirty flushing remaining dirty objects server commit time concurrency control recovery complete project reasonable time include concurrency control recovery services prototypes feel results obtained representative relative performance architectures respect concurrency control objectand page-server designs request lock request object page combined single message server grants lock reply message grant requested object page mechanism combined local cache locks obtained extra messages required add locking designs lock requests combined requests file-server design results obtained design undoubtably biased favor optimistic concurrency control suffices respect recovery services performance impact recovery mechanism write-ahead logging identical design assume log records generated objects updated log records grouped page-size chunks transmission server design compatible architectures contend omitting recovery services affect relative performance designs significantly final issue addressed complete implementations architectures maintain consistency buffer pools respect objects pages locks held end transaction normal case consistency insured semantics standard locking protocols case problems arise object-level locking pageor file-server designs write locks multiple transactions allowed objects page combining transactions server non-trivial case objects pages locked nonpl fashion typically index pages improve performance number solutions invalidating local copy object lock released consistency insured expense reduced performance solutions applicable designs felt omitting cache consistency affect results altair complex-object benchmark introduction evaluate performance alternative workstation-server architectures obvious alternatives existing benchmark design benchmark specific evaluation terms existing benchmarks sun catt hypermodel ande benchmarks appeared reasonable alternatives opted sun benchmark forms complex objects choosing random objects relate measurement wanted impact degree clustering components complex object performance alternative designs sun benchmark recently version sun benchmark designed catt suited purposes initially hypermodel benchmark appeared match objectives clustered non-clustered groupings objects problem benchmark consists large number queries afraid overwhelmed results full hypermodel benchmark understand subset select elected design benchmark tailored task evaluating alternative workstation-server designs designing benchmark borrowed number ideas hypermodel sun benchmarks attempted limit scope benchmark simpler database design smaller set queries benchmark oodbms benchmark distributed object-manager benchmark make distinction database generator number parameters controlling physical placement objects degree clustering placement records pages expressible data model data language level oodbms database design basis altair complex-object benchmark acob set complex objects object composed wiss records structure shown figure record bytes long key field integer ranges physical order objects file records form complex object organized form binary tree depth shown figure inter-record inter-object terms physical record ids object design benchmark influenced data model database system deux distinguishes values objects database object complex structure forcing sub-component object made sense distinguish inter-object intra-object treat differently justify putting records object page imagine part object created object created wiss record header key left child child dummy string bytes bytes bytes bytes bytes figure level level level level level level root complex object organization figure initially created records data page update complex object unavoidable side-effect moving component records page benchmark mechanism fraction records object smeared pages order explore effect updates performance server architectures smearing discussed detail kbyte pages complex objects consisting records fit single page set objects spans pages approximately megabytes size set criticized small realistic things wanted explore relative performance architectures entire working set application fit workstation buffer pool significantly larger set size made test impossible order minimize effect operating system buffering database pages identical sets objects experiments producing total database size megabytes acob database constructed phases phase allocates records objects forming intra-object filling record fields real object-oriented databases objects frequently form aggregation relationships part component subparts relationships suppliers parts ande simulate relationships phase attach objects leaf records complex object left fields found record shown figure triangle figure represents complex records figure attached objects termed components page page page page page complex object component objects clustered -page region figure mentioned gauge impact physical clustering complex objects performance server designs study effect phase accepts parameter called clustering factor notion clustering defined object object object clustered object located clustering region size clustering region pages considered clustered page pages physically preceding page resides section explores effect varying size clustering region relative performance architectures clustering factor varied employed phase database creation objects attach object selected objects clustered nearby selected time attached object random generated random clustering factor objects clustered selected random random object set objects selected optional phase creating database smear fraction records comprise complex object smearing simulates dispersal records object data pages caused database updates updated record long fit current page alternative version record created version fit page records object smearing selected quarter objects chosen random modified probability interior records leaf records moved page database illustrated figure move accomplished swapping record record randomly selected object figure smeared object exchanging child left child similar fashion smeared leaf node object exchanging child record left child record page page page smearing interior leaf records complex objects figure queries sequential scan scan query reads complex objects set physical order object breadth-first traversal algorithm read records comprise object query read attached components object record accessed records accessed copied address space application 
define type create statements figure finally association modeled set constructor extra set employees subordinate manager excess query language excess queries range objects created create statement excess based quel ston gem zani postquel rowe sql extensions nested relations dada sche excess designed provide uniform query interface sets arrays tuples single objects objects disjoint share subobjects object recursive objects object type define type person ssnum int char street char city char zip int birthday date define type student gpa float dept ref department inherits person define type employee jobtitle char dept ref department manager ref employee ords ref employee salary int kids person inherits person define type department char floor int employees unique ref employee create students unique ref student create departments unique ref department figure simple extra database composed nested arbitrarily addition user-defined functions written excess aggregate functions written supported clean consistent examples suffice convey basic flavor language query finds names children employees work department floor range employees retrieve kids dept floor illustrates aggregate function nested set objects query retrieves employee employee retrieves age youngest child children employees working department floor employee department range emp employees retrieve emp min kids age employees dept floor emp dept floor variable ranges employees scope min aggregate aggregate connected variable emp join employee dept floor query aggregates employee kids set-valued attribute age assumed defined function computes age person current date birthday virtual field person objects user-defined functions procedures written excess supported handled uniformly syntax illustrated age function functions invoked syntax denoting attributes functions defined types user-defined function syntax similar aggregate function invocation syntax shown previous excess procedures invoked manner consistent excess syntax performing updates procedures differ functions functions return side-effects procedures side-effects return details examples presented care extra excess system architecture extra excess environment consist frontend process backend process illustrated figure essentially extra excess-specific version figure frontend process parses query converts optimizable form optimizes converts optimized query sends program backend execution optimizer generated exodus optimizer generator frontend interfaces extra excess data dictionary processing data definition language requests performing authorization data dictionary designed extra database stored exodus storage manager data drawn separately figure simply clarify function backend process consists components compiler compiles code executables calls exodus storage manager loader dynamically load compiled queries run-time system erts erts operator methods access methods written dbe methods generic method libraries provided exodus exodus storage manager part backend serves repository persistent objects component system directly manipulates persistent data finally backend send query results frontend formatting output summary current status paper exodus extensible database system project aimed simplifying development high-performance application-specific database systems explained exodus model world includes classes database experts designers implementors exodus database engineers dbes responsible exodus produce application-specific dbmss database administrators dbas managers systems produced dbes addition users application-specific dbmss engineers scientists office workers computer-aided designers groups resulting systems support focus paper architecture exodus tools aid dbe work plan support precompiled queries execution path shown figure query tree file screen formatter output results statistical requests results checks consistency authorization dictionary data excess executable query operator methods access methods code compiler optimized generation code optimizertree conversion parse treequery parser storage manager backend process query tree figure extra excess system architecture exodus includes component requires change application area application area storage manager flexible low-level storage manager concurrent recoverable access storage objects arbitrary size addition exodus libraries database system components widely applicable including access methods operator methods system layers constructed dbe combination borrowing components libraries writing components make writing components painless exodus database implementation language largely shield dbe low-level details persistent programming vehicle provided defining adts makes easy dbe write operations adts large image voice adt upper level system exodus generator produces query optimizer description operations methods finally extra excess next-generation data model query language object-oriented flavor drive exodus developments initial implementation exodus tools basically complete including components single-user version storage manager running providing excellent performance small large storage objects work versions concurrency control recovery underway implementation rule-based query optimizer generator completed year ago generate full relational query optimizer compiler coming nicely virtually language features hints working time effort focused optimization issues coalescing storage manager calls improving implementation generic classes sigmodwe demonstrated relational dbms prototype implemented exodus tools working initial extra excess implementation andr andrews harris combining language database advances object-oriented development environment proc oopsla conf orlando oct astr astrahan system relational approach database management acm trans database sys june atki atkinson buneman types persistence database programming languages acm comp surveys june atki atkinson liskov scheifler aspects implementing clu acm national conf proc bane banerjee data model issues object-oriented applications acm trans office info sys jan bato batory buchmann molecular objects abstract data types data models framework proc vldb conf singapore aug bato batory concepts database system compiler proc acm principles database sys conf austin march bato batory genesis extensible database management system ieee trans software eng nov baye bayer schkolnick concurrency operations b-trees acta informatica care carey dewitt extensible database systems knowledge base management integrating artificial intelligence database technologies brodie mylopoulos eds springer-verlag care carey object file management exodus extensible database system proc vldb conf kyoto japan aug care carey architecture exodus extensible dbms proc int workshop object-oriented database sys pacific grove sept care carey dewitt overview exodus dbe care carey dewitt vandenberg data model query language exodus proc sigmod conf chicago june chou chou dewitt evaluation buffer management strategies relational database systems proc vldb conf stockholm sweden aug clif clifford tansel algebra historical relational databases views proc sigmod conf austin texas cloc clocksin mellish programming prolog springer-verlag york cope copeland maier making smalltalk database system proc sigmod conf boston dbe database engineering special issue extensible database systems carey june dada dadam lum h-d werner integration time versions relational database system proc vldb conf singapore aug dada dadam dbms prototype support extended relations integrated view flat tables proc sigmod conf washington daya dayal smith probe knowledge-oriented database management system knowledge base management integrating artificial intelligence database technologies brodie mylopoulos eds springer-verlag feld feldman make program maintaining computer programs software practice experience forg forgy ops manual computer science technical report carnegie-mellon 
acm sigmod international conference management data san diego june crash recovery client-server exodus michael franklin michael zwilling tan michael carey david dewitt computer sciences technical report march computer sciences department wisconsin-madison work partially supported defense advanced research projects agency contracts -kand nag- national science foundation grant iriand grant ibm corporation crash recovery client-server exodus michael franklin michael zwilling tan michael carey david dewitt computer sciences department wisconsin madison abstract paper address correctness performance issues arise implementing logging crash recovery page-server environment issues result characteristics page-server systems fact data modified cached client database buffers accessible server performance cost tradeoffs inherent client-server environment describe recovery system implemented page-server system client-server version exodus storage manager implementation supports efficient buffer management policies flexibility interaction clients server reduces load server performing work involved generating log records clients present preliminary performance analysis implementation examining relative costs logging recovery operations identifying areas future improvement introduction networks powerful workstations servers computing environment choice application domains result recent commercial experimental dbmss constructed run environments systems referred client-server dbmss recovery long studied centralized distributed database systems gray lind gray moha bhg recently architectures shared-disk systems lome rahm distributed transaction facilities dst hmsc published recovery issues client-server database systems paper describes implementation challenges performance tradeoffs involved implementing recovery system based experience building client-server implementation exodus storage manager cdrs exod exod client-server dbms architectures categorized send requests server queries requests specific data items refer systems type queryshipping systems type data-shipping systems data-shipping systems categorized page-servers interact physical units data individual pages groups pages segments object-servers interact logical units data tuples objects dfmv debate relative advantages architectures respect current technology trends ston comm dfmv commercial relational database systems adopted query-shipping architectures query-shipping architectures advantage similar process structure single-site database system work partially supported defense advanced research projects agency contracts -kand nag- national science foundation grant iriand grant ibm corporation provide easy migration path existing single-site system client-server environment advantage minimizing communication data satisfies query server requesting clients contrast relational dbms systems virtually commercial object-oriented database systems oodbms recent research prototypes adopted variant data-shipping approach deux objectstore llow orion kgbw data-shipping architectures potential advantage avoiding bottlenecks server exploiting processing power memory client machines important performance majority processing power memory client-server environment client workstations network bandwidth improves cost additional communication compared query-shipping architectures significant data-shipping approach good match objectoriented database systems systems accessed persistent programming language separate query language performance database objects swizzled main memory representation cached client memory accessed directly application programs workload demonstrates performance advantages data-shipping architectures catt implementing recovery query-shipping architectures raises issues traditional recovery approaches architecture database engine remains largely unchanged contrast datashipping architectures present set problems issues design recovery logging subsystems dbms arise main architectural features data-shipping architectures differentiate traditional centralized distributed systems related architectures shared-disk systems features database modifications made primarily clients stable copy database log server client manages local buffer pool communication clients server expensive compared local interprocess communication shared memory access client machines tend performance reliability characteristics hardware capabilities server machines client-server exodus storage manager esm-cs data-shipping system employs page-server architecture implementation recovery esm-cs involves main components logging subsystem manages access append-only log stable storage recovery subsystem information log provide transaction rollback abort system restart crash recovery implementation recovery involves close cooperation buffer manager lock manager recovery algorithm based aries moha aries chosen simplicity flexibility ability support efficient steal force buffer management policy support savepoints nested-top-level actions ability support fine-grained concurrency control logical undo algorithm moha directly implemented page-server architecture architecture violates explicit implicit assumptions original algorithm based paper describe recovery manager paying attention modifications aries method required due correctness efficiency concerns recovery page-server system discuss engineering decisions made design esm-cs logging recovery subsystems noted aries algorithm recently extended ways similar extensions describe paper describes extension algorithm reduce work performed system restart algorithm esm-cs required similar extension efficiency order operate correctly page-server environment mnp describe extensions aries shared-disk environment expected solutions environment applicable page-server environment correctness efficiency reasons discuss extensions related work section remainder paper structured section describes esm-cs architecture attention issues affect logging recovery section overview aries section motivates describes modifications made aries page-server environment section presents study performance esm-cs logging recovery implementation section describes related work section presents conclusions client-server environment section present overview esm-cs architecture general concentrate design esm-cs logging subsystem intent description twofold intended provide background understand recovery algorithm implementation highlights engineering decisions made design logging recovery subsystems detailed description architecture found exod architecture overview esm-cs multi-user system full support indexing concurrency control recovery designed client-server environment addition supporting features esm-cs support features provided previously exodus storage manager large versioned objects cdrs system runs unix decstation sparcstation sunworkstations storage manager accessed procedure call interface programming language rcs persistent programming language based figure shows architecture esm-cs design driven anticipated capabilities performance reliability characteristics clients server network server expected cpu power disk capacity memory single client sum processing power memory clients expected greater server clients expected reliable server resources database system main cost communication expected cpu overhead sending receiving messages system consists main parts client library linked user application server runs separate process architecture clear division labor server clients server main repository database log support lock management page allocation deallocation recovery rollback clients perform data index manipulation normal non-recovery rollback operation client process application linked database volume log volume server process recovery lock buffer mgr mgr mgr client process application buffer pool lock cache application buffer pool lock cache client process workstation workstation server figure architecture client-server exodus client library buffer pool lock cache runs single transaction time server multi-threaded handle requests multiple clients separate disk processes perform asynchronous current system supuniv frey freytag goodman translating relational queries iterative programs program transformation approach proc acm sigmod conf grae graefe dewitt exodus optimizer generator proc sigmod conf san francisco grae graefe rule-based query optimization extensible database systems thesis comp sci dept univ wisconsin madison gray gray notes database operating systems operating systems advanced bayer graham seegmuller eds springer-verlag gutt guttman r-trees dynamic index structure spatial searching proc sigmod conf boston hull hull king semantic database modeling survey applications research issues acm comp surveys sept katz katz chang bhateja version modeling concepts computer-aided design databases proc sigmod conf washington kern kernighan ritchie programming language prentice-hall englewood cliffs klah klahold transaction model supporting complex applications integrated information systems proc sigmod conf austin lecl lecluse object-oriented data model proc sigmod conf chicago june lind lindsay mcpherson pirahesh data management extension architecture proc sigmod conf san francisco lisk liskov abstraction mechanisms clu comm acm aug litw litwin linear hashing tool file table addressing proc vldb conf montreal canada oct lohm lohman grammar-like functional rules representing query optimization alternatives proc sigmod conf chicago june maie maier stein development implementation object-oriented dbms research directions object-oriented programming shriver wegner eds mit press mano manola dayal pdm object-oriented data model proc int workshop object-oriented database sys pacific grove sept grove sept mylo mylopoulos language facility designing database-intensive applications acm trans database sys june nguy nguyen ferrat galy high-level user interface local network database system proc ieee infocom conf niev nievergelt hintenberger sevcik grid file adaptable symmetric multikey file structure acm trans database sys march peck peckham maryanski semantic data models acm comp surveys sept rich richardson carey programming constructs database system implementation exodus proc sigmod conf san francisco rich richardson carey implementing persistence proc newcastle workshop persistent object sys newcastle australia jan rich richardson carey design programming language tech rep computer sciences dept univ wisconsin madison jan robi robinson k-d-b-tree search structure large multidimentional dynamic indexes proc sigmod conf june rowe rowe schoens data abstraction views updates rigel proc sigmod conf boston rowe rowe stonebraker postgres data model proc vldb conf brighton england aug sche schek scholl relational model relation-valued attributes information sys schm schmidt high level language constructs data type relation acm trans database sys sept schw schwarz extensibility starburst database system proc int workshop object-oriented database sys pacific grove sept ship shipman functional data model data language daplex acm trans database sys march snod snodgrass ahn taxonomy time databases proc sigmod conf austin ston stonebraker wong kreps design implementation ingres acm trans database sys sept ston stonebraker hypothetical data bases views proc sigmod conf boston ston stonebraker document processing relational database system acm trans office info sys april ston stonebraker personal communication july ston stonebraker inclusion types relational data base systems proc data engineering conf los angeles feb ston stonebraker rowe design postgres proc sigmod conf washington stro stroustrup programming language addison-wesley reading ullm ullman principles database systems computer science press rockville verh verhofstad recovery techniques database systems acm comp surveys june zani zaniolo database language gem proc sigmod conf san jose 
port access multiple servers single client process note figure shows clients server executing separate machines run server number clients separate processes machine communication clients server implemented reliable tcp connections unix sockets communication initiated client responded server server responds requests client specific pages locks transaction services mechanism server initiate contact client added significant complexity clients requiring multi-threaded order respond unexpected messages server stated esm-cs employs page-server architecture client sends requests specific data index pages server 
logging implement recovery largely due fact objectstore applications allowed update objects dereferencing normal virtual memory pointers objectstore track modified portions pages objects epvm amount real memory client caching pages objects single transaction fixed megabyte client server buffer pools experiments architecture referred benchmark database esm small benchmark database catte consumed total k-byte disk pages consisted collection part objects object average bytes size additionally sun benchmark requires objects indexed parts indexed array object pointers oids array pointers b-tree index order performance differences due differing b-tree implementations influencing results total size index esm bytes small database including part index required pages objectstore part object connections part objects database connections implemented pointers systems database required disk space esm largely differences pointers persistent data stored systems large benchmark database identical small database part objects large database occupied disk pages index size megabytes esm objectstore large database required pages objects large database catte due limitations amount swap space objects eliminated problem providing database fit real memory workstations hardware experiments performed identically configured sun sparcstation elcs approximately mips client machine server machines connected private ethernet machines megabytes main memory data stored server megabyte raw disk partitions located separate sun disk drives partition transaction log store normal data virtual memory swap area client machine located sun megabytes size benchmark results small database results section results running variations traversal portion benchmark small benchmark database objects experiments repeated times averaged obtain results shown times listed seconds tables present individual cold warm hot iteration times updates performed entire benchmark run executed single transaction cold time execution time iteration benchmark persistent data cached memory client server machines warm time execution time tenth iteration benchmark hot times obtained repeating traversal warm iteration objects memory swizzling prior beginning hot iteration number operations performed client iteration times tables include overhead transaction begin commit table compares version software architectures discussed section versions selected generally comparable sense similar amount memory slightly memory cesm time cold iteration epvm small difference cesm epvm due overhead inserting objects oid hash table epvm slower epvm due overhead caching full pages objects worst cold iteration fact performs fewest operations understanding works partially due overhead mapping data client address space ordering times warm iteration table reverse cold iteration faster versions warm iteration incurs essentially overhead accessing in-memory objects case terms performance faster epvm epvm incurs overhead inserting large number objects oid hash table caches pages objects aggressive caching epvm cached additional objects previous iterations cesm worst performance warm iteration due overhead calling esm object visited iteration table presents results versions based epvm worst performance cold iteration small client buffer pool size forces reread pages server surprising slower performs operations due fact server buffer pool large hold pages read client case shipping pages server faster reading disk faster due overhead incurs copying full pages virtual memory similarity m-no shows essentially advantage disadvantage swizzling cold iteration warm iteration table shows performance m-no object caching versions warm iteration objects cached pages precisely pages cached warm iteration page caching versions objects cached object caching versions caches fewer objects warm iteration cached additional objects previous iterations accounts strange fact m-no page caching swizzling faster full swizzling continues reread pages server warm iteration worst performance turning swizzling warm case table shows swizzling reduction execution time page caching times epvm -no shown tables essentially difference epvm epvm -no cold iteration experiment warm iteration swizzling made epvm faster epvm -no hot times table represent asymptotic behavior versions conversion copying inmemory objects taking place additional version labeled added table represents implementation benchmark coded non-persistent transient inmemory objects represents performance persistent system hope achieve hot case examine architectural differences hot iteration fact performance identical shows memory-mapped architecture imposes additional overhead hot case faster overhead swizzle checks epvm function calls incurs addition fact pointers persistent objects bytes long opposed bytes slows performance epvm terms performance slower epvm swizzle pointers traversal updates version cold warm cesm epvm table single transaction updates times seconds traversal updates version cold warm m-no table single transaction updates times seconds traversal updates version hot hot random m-no epvm epvm -no cesm table single transaction updates times seconds persistent objects extra level indirection imposed user descriptors cesm worst performance hot iteration hot time approximately times epvm times due fact cesm calls esm pin unpin object visited iteration identical hot iteration shown comparing m-no swizzling improved performance hot case page caching swizzling makes difference epvm surprising hot column table faster closer inspection benchmark implementation noticed unix function random called visit part object part overhead determining perform update column table shows results hot traversal overhead calling random removed note approximately times performance closer expect differences architectures similarly difference epvm increases sets hot results included illustrate quickly difference performance architectures diminishes small amount computation performed object access table cold warm iteration times traversal updates small database iteration executed separate transaction table relative performance architectures identical table cold iteration comparing cold iteration times table table shows overhead transaction commit minor versions updates warm iteration results table highlight effects inter-transaction caching performance large part caches data pages locks transactions client communicate server process read page accessed previous iterations versions esm hand communicate server read uncached data pages reacquire locks cached pages caches fewest pages transactions megabyte client buffer pool worst performance ran experiment inter-transaction caching esm inter-transaction caching improved performance cesm epvm warm iteration cold warm times versions based epvm shown multiple transactions experiment cold iteration times shown table traversal updates version cold warm cesm epvm table multiple transactions updates times seconds warm iteration times slower warm times table locks pages reacquired performance warm iteration faster faster pointer swizzling made essentially difference epvm experiment addition hot times warm times hot time seconds faster warm time table hot times cesm epvm approximately faster warm times effect adding updates traversal figure presents total execution time single transaction consisting cold warm hot iterations update probability ranges non-swizzling versions epvm -no m-no epvm shown addition performance cesm roughly faster epvm fastest time updates relative performance degrades updates added due high cost transaction commit transaction commit expensive full page logging performance 
program records object smeared reading object require access disk page query included simulates reading instances class smearing query good test instruction path length design accesses database strictly sequential maximizing chance performance cpu limiting factor query sequential activity designed understand relative costs accessing data disk directly attached processor wiss running local disk accessing remotely server designs degree database clustering effect execution time query probability moved computed individually node smearing involves swapping internal record object internal record object approximately ths objects affected smearing process implementation benchmark record ids root records stored separate set case sequential scan query execution times presented section include time read elements set random read random update queries set root record ids read in-memory array separate processing step processing time step included execution times presented queries random read query processes randomly selected complex objects components sequence operations applied object selected root record object read partial depth-first traversal performed tree depth root record considered depth average records object attached components root records attached components read partial traversal performed electing perform stage depth-first traversal probability expected number records read level root children depth records depth records depth expected records reads level selectivity factor query related structural density parameter chang katz chan selectivity appears middle range structural densities observed traces access patterns suite vlsi tools query designed simulate applications user checks collection complex objects selected subcomponents beginning transaction session section extent database clustered significant effect execution time query pageand file-server designs random update query basically update version random read query random objects selected processing query records depth selected reading updated average complex object processed records updated records read updates performed place overwriting record copy structure database changed query designed understand benefits transferring individual objects workstation server pageand file-server designs complete pages single updated record transferred back server workstation case object server updated objects transferred back server hand updated object back proper data page page longer server page cache case page reread disk updated object added query affected degree database clustered extent records object smeared benchmark organization load program queries previous section composed actual benchmark evaluate server designs benchmark consisted steps executed order random number seed set start step section wide number versions benchmark constructed varying parameters degree clustering smearing selected size workstation server buffer pools build identical sets complex objects degree database clustering choice smearing sets assigned names order constructed set built set built step benchmark apply scan query sets order reason ordering attempt minimize extent buffering pages operating system affects results obtained elected sets objects based relative sizes set objects operating system buffer pool sun server experiments megabytes memory server memory increased number objects set expanded number sets employed step run random read query sets order fourth step run random update query sets order final component benchmark run sequential scan random read random update queries set resetting random number generator queries set sets order motivation final phase benchmark explore effectively server designs utilized local buffer caches performance evaluation section present results performance evaluation prototypes single-site version wiss point section describe hardware environment conduct experiments results obtained building acob database contained section section describes clustering smearing experiments finally section explore size buffer pools workstation affects architectures individually comparatively test environment experiments sun workstations running version sun operating system machine megabytes memory megabyte disk drives quantum prodrive machines run normal multiuser mode tests activity database constructed disk drive server machine insure differences drives affect results obtained configuring systems encountered number problems relating buffer space allocation problem deciding buffer space allocate wiss file-server prototype default configuration pageand object-server designs -page kbyte pages buffer pool workstation server option -page buffer pools wiss file-server prototype choice fair real environment buffer space server pageand object-server designs shared multiple workstations addition page buffer pools workstation server effective single -page buffer pool obvious solution decided same-size buffer pool workstation process pageand object-server prototypes problem encountered limiting amount buffering performed operating system virtual memory manager sunos treats program data pages uniformly feature affect buffering workstation pageand object-server prototypes impact file-server server prototype provide effective buffer pool size approximately pages clean turning feature running file-server prototype modified kernel workstation processor artificially limited size physical memory pages chosen physical memory hold unix kernel benchmark program page wiss buffer pool page nfs buffer pool standard unix utility programs elected reduce size physical memory processor disk holding database attached design equal opportunity memory buffering importantly restricting amount memory server made benchmark intensive change masked interesting differences architectures reader howrurururururururururururururururururururururururururururururururururururu sun cpu rated mips versions unix typically allocate physical memory buffering data pages reserve rest memory program pages adb set physmem vmunix fact mind interpreting results presented paper database build time table time prototypes build unsmeared database clustering factors presented observations order system affected slightly clustering factor fileand page-server designs slower wiss results line building database disk attached remote processor startling result object-server prototype factor slower fileand page-server prototypes evident tests presented object server cache ineffective build test performance worse designs high cost transferring objects individually omitted times build smeared database higher relative performance systems remained system clustering clustering factor factor wiss secs secs file server secs secs page server secs secs object server secs secs table clustering smearing tests collection tests fixed workstation server buffer pools pages varied clustering factor wiss file-server buffer pools set pages clustering region fixed pages figures present results obtained benchmark queries section unsmeared smeared databases scan query results obtained scan query figures expected design unaffected clustering factor query reads object entirety object component objects startling result object server extremely poor performance relative designs unsmeared database page server approximately times faster object server source difference high cost fetching records composing object separate rpc operation page-server design pages fetched server workstation rpc response time seconds clustering factor figure scan query smeared file server object server page server wiss figure scan query unsmeared clustering factor response time seconds file server object server page server wiss response time seconds clustering factor figure random read query smeared file server object server page server wiss response time seconds clustering factor figure random read query unsmeared 
esm-cs strict two-phase locking data non-twophase locking indexes data locked page coarser granularity index page splits logged nested top level actions moha committed enclosing transaction commits transaction clients cache data index pages local buffer pool committing transaction client sends pages modified transaction server current implementation client cache purged completion commit abort transaction future enhancements inter-transaction caching pages cfls clients initiate transactions sending start transaction message server request commit abort transaction sending message server server decide abort transaction due system error deadlock aborting transaction server notifies client transaction aborted response message receives client mechanism server initiate contact client execution transaction client generates log records updates data index pages server manages log circular buffer abort executing transactions danger running log space logging subsystem main challenges designing recovery system minimize negative performance impact logging normal operation stated previous section log esm-cs server decision made reasons lose access data result client failure economical require clients log disks log server operations data indexes behalf application programs performed clients efficient interface shipping log records clients server required logging subsystem extension centralized logging subsystem intended work efficiently client-server environment log records data pages aries-based recovery algorithm depends write-ahead-logging wal protocol gray server wal protocol insures log records pertaining updated page written stable storage page allowed over-written stable storage transaction commit log records written stable storage order implement wal protocol server enforce similar protocol clients server client send log records server prior sending pages updates performed policy enforced reasons simplifies transaction rollback insuring server log records rollback updates pages server uncommitted updates policy enforced transaction rollback caused client crash require performing restart recovery affected pages server log records lost due client crash policy enforced client server server buffer manager complicated manage dependencies arrival log records clients flushing dirty pages stable storage efficiency clients group log records pages send server page time log pages buffered client server time transaction provided order wal protocol satisfied logging update place log dependency updated page log page log record written update dependency buffer manager insure log pages including log page updated page dependent server updated page returned server similar mechanism server enforce wal protocol respect buffers stable storage log record structure client generates log records operation updates data index page log records redo undo information specific operation performed log entire images pages clients log bytes affected operation decision motivated desire reduce overheads expense sending data clients server pages large pages make large objects bytes longer expense writing log decision made regard log records generated client span log page boundaries log records generated clients smaller log page wholly contained single log page server restriction simplifies sending log records client handling log record pages server clients simply send pages log records server fill server receive log pages needing manage partial log records receive pages log records multiple clients needing merge multiple pages client restriction easily implemented client requires operations logged slightly differently performed creation data object larger size log page logged create portion object append remaining data server handling log records result log dependency mechanism boundary spanning restriction client times forced partially fill log pages result inefficient log space unnecessary writes log server subject restrictions imposed clients combine log records received clients log page write log records received client multiple pages order conserve log writes server preserve ordering log records received client maintain wal protocol updated pages buffer log pages addition log records received clients server generates log records log records include records commit abort transactions allocation deallocation pages files server writes log records system restart transaction rollback section server log records subject size constraint imposed client log records span multiple log pages overview aries section present overview aries recovery method basis esm-cs recovery system discussion concentrates features algorithm pertinent esm-cs environment complete discussion algorithm reader referred moha aries fairly recent refinement write-ahead-logging wal protocol section wal protocol enables steal force buffer management policy means pages stable storage overwritten time data pages forced disk order commit transaction wal implementations page database log sequence number lsn uniquely identifies log record latest update applied page lsn referred pagelsn recovery determine update page redone lsn information determine point log redo pass commence restart system crash lsns implemented physical address log record log enable efficient location log record lsn power aries algorithm due redo paradigm repeating history redoes updates transactions including eventually undone repeating history greatly simplifies implementation fine grained locking logical undo operations moha sections resulting simplicity aries adapted computing environments aries pass algorithm restart recovery pass analysis pass processes log forward recent checkpoint pass determines information dirty pages active transactions subsequent passes pass redo pass history repeated processing log forward earliest log record require redo insuring logged operations applied pass undo pass pass proceeds backwards end log removing database effects transactions committed time crash passes shown figure note relative ordering starting point redo pass endpoint undo pass checkpoint shown figure passes detail normal operation aries maintains important data structures normal operation transaction table status information transaction running information includes field called lastlsn lsn recent log record written transaction data structure called dirty page table entry dirty page page considered dirty updates reflected stable storage entry dirty page table includes field called recoverylsn lsn log record caused page dirty recoverylsn lsn earliest log record redone page restart log records belonging transaction linked backwards time field log record called prevlsn field log record written transaction lastlsn field transaction table entry prevlsn field record record lsn entered lastlsn transaction table entry normal operation checkpoints periodically aries form fuzzy checkpoints bhg extremely inexpensive checkpoint checkpoint record possibly constraints log record size constructed includes contents transaction table dirty page table checkpoints efficient operations quiesced database pages flushed perform checkpoint effectiveness log time end logcheckpoint start oldest progress transaction analysis redo undo update potentially lost crash figure passes aries restart checkpoints reducing amount log maintained limited part earliest recoverylsn dirty pages checkpoint time helpful background process periodically writes dirty pages stable storage analysis job analysis pass restart recovery threefold determines point log start redo pass determines pages dirty time crash order avoid unnecessary 
file server object server page server wiss call page object-server design total rpc calls made order make object server competitive queries rpc call fetch single record solution server return records object single rpc call change require server understand structure object significantly complicating design database smeared performance object-server design unaffected page file-server prototypes slow significantly part increase five-fold increase number disk operations required approximately factor accounts seconds approximately increases observed fileand page-server architectures remainder represents cost fetching additional pages server page-server architecture cost retrieving pages rpc mechanism estimated table approximately seconds difference illustrates efficient nfs user-level rpc mechanism object server unaffected fetches number records database smeared increased activity part server masked cost object-at-atime fetches random read query performance random read query smeared unsmeared databases figures clustering factor increased number disk performed design execute query decreases buffer pool hit rate improves approximately reduction improves performance wiss behavior objectand page-server designs absolute terms relative complicated systems -page buffer pools workstation server increasing probability object found buffer pools turns buffer size dominant factor behavior dominated costs rpc access server execution query involves wiss records independent clustering factor clustering factor object server observes cache hit rate clustering factor increased cache hit rate increases result fewer objects requested server producing estimated rpc savings seconds total improvement increase observed wiss response time seconds remaining seconds due primarily reduction number disk performed server page-server design clustering factor increased buffer cache hit rate increases resulting savings rpcs savings translates estimated rpc savings approximately seconds rpc times table section remaining seconds improvement response time server fewer differences performance pageand file-server designs primarily due difference cost fetching page nfs rpc call clustering factor low database smeared figure page-server design forced large number rpc accesses expensive accessing page nfs general performance pageand file-server designs sensitive database clustering factor page-server design worse performance object-server design smeared database low clustering factor simply page retrieved server ends fetching objects referenced page removed buffer pool hand object server fetches objects performance immune clustering factor smearing multiuser environment immunity change bottleneck switches rpc mechanism disk arm object fetched results random disk access random update query random read query query randomly selects objects processing case records depth selected reading traversal updated average complex object processed records updated results contained figures unsmeared smeared databases query illustrates extremely poor performance writes nfs file server factor slower wiss clustering factor clustering factor increased response time file-server design improves factor worse wiss unsmeared database factor worse smeared database improvement occurs higher clustering factor chance page ends written decreases important mind results reflect performance file-server design implemented nfs remote file service difference result extra copies modified output rpcgen eliminate copy introduced rpcgen software response time seconds clustering factor figure random update query smeared response time seconds clustering factor figure random update query unsmeared file server object server page server wiss file server object server page server wiss response time seconds clustering factor figure queries smeared response time seconds clustering factor figure queries unsmeared file server object server page server wiss file server object server page server wiss behave differently clustering factor smearing significantly affect performance page-server design pages flow directions workstation server impact magnified page end written back server query object-server design exhibits significantly performance designs fetching objects referenced application writing back objects modified performance object-server design insensitive clustering smearing query illustrates page writes nfs expensive page writes rpc clustering factor response time file server higher page server difference due nfs stateless protocol performs write operation acknowledging message unsmeared database difference response times decreases slightly clustering level increased fewer pages written recall clustering factor level number pages written architectures queries tests final test involves running scan random read random update queries sequentially flushing workstation server cache queries purpose query simulate case user runs associative query collection order select set objects manipulated set objects updated results obtained architectures presented figures graphs reveal interesting results database smeared page-server design outperforms object server full range clustering factors primarily object server performs poorly scan component experiment object server performance unaffected clustering smearing expected results random read update queries performance page server improves significantly clustering factor increased similarly performance file-server design improves clustering factoring increased fewer nfs writes performed database smeared performance page file servers degrades expected object-server design slightly superior performance clustering factor reached smearing significant performance impact object-server sensitivity clustering region size observing results presented curious sensitivity results size clustering region test sensitivity repeated queries unsmeared database clustering regions pages recall definition clustered states object clustered object lies clustering region surrounding unsmeared database results figures primary effect smearing shift file page server curves constant amount change fundamental shapes interesting results obtained presented figures figure presents execution time random read query pageand object-server designs sizes clustering regions results demonstrate relative performance systems sensitive size clustering region clustering region size pages performance page server object server clustering factor clustering region shrunk page crossover point drops clustering factor increased pages crossover point climbs results reveal page server perforresponse time seconds clustering factor figure random read query clustering region pages clustering region pages clustering region page object server page server response time seconds clustering factor figure random update query clustering region pages clustering region pages clustering region page file server page server mance remains sensitive clustering factor size clustering region reveal performance page server superior degree database clustering region clustering restricted consist pages figure presents execution time random update query pageand file-server architectures object server execution time fairly constant seconds changing size clustering region simply shifts positions pageand file-server architectures change fundamental shape spacing interesting result clustering region page page server outperforms object server clustering factor impact workstation buffer space final set experiments selected clustering factors varied size buffer pool workstation pages pages size set objects pageand object-server designs server buffer pool fixed pages results displayed figures expected size workstation buffer pool effect performance sequential scan query object-server design response time increases explanation offer increase artifact hash table object cache organized random read random update queries offer interesting results performance pageand file-server architectures improve size buffer pool increases performance object 
levels frequency updates high pages updated faster updates performed performance epvm continually degrades update probability increased generates log record update surprising epvm cases due large part fact log records generated epvm processed asynchronously server transaction running faster epvm update probability greater commit time constant objects visited transaction updated worst performance figure reread pages server transaction running commit phase performance shows object caching perform client buffer pool large avoid reread data pages difference reread pages transaction commit order generate recovery information bigger client buffer pool performance identical performance figure presents execution time traversal varying write probability iteration benchmark constitutes separate transaction curves m-no epvm -no cesm omitted due similarity curves epvm performance update probability low update probability increased relative performance degrades due high cost transaction commit slower figure reread pages server transaction executing overhead greater cost extra copying curve shows memory object caching performs cases epvm avoids extra copying overhead object caching versions reread data pages server context single transaction finally note inter-transaction caching improved write probability seconds cold warm hot epvm figure benchmark run single transaction hot iterations seconds cold warm hot cesm mno epvm figure single read-only transaction performance epvm read-only write prob improvement smaller updates fixed overhead sending dirty data pages back server end transaction posted gain performance caching added figures fix number cold warm iterations vary number hot iterations figures benchmark run single transaction figure update probability figure write probability seconds cold warm hot epvm figure benchmark run multiple transactions hot iterations seconds cold warm hot cesm epvm mno figure single transaction update prob figures illustrate large difference cpu requirements cesm versions large number hot traversals performed easy figure epvm performance number hot iterations number hot iterations greater epvm approximately hot iterations performed hot iterations faster faster epvm posts improvement cesm m-no shows improvement iterations results epvm -no shown epvm faster epvm -no iterations times figure times omitted figure number hot traversals epvm performance number hot traversals hot iterations fastest surprising hot traversals performed order perform due high cost transaction commit turning swizzling iterations m-no slower epvm -no shown slower epvm shown figure cases performance initially faster faster iterations figure demonstrates varies fraction part object updated update probability remains fixed experiment part objects defined array integers bytes usual nonpointer data benchmark x-axis shows percentage array updated surprisingly flat performance updates full page logging versions based epvm show change performance updates added number log pages generated varied update fraction increased esm required roughly seconds process extra log pages performance epvm degrades quickly larger portion updated generates log record update number log pages generated epvm bytes updated seconds cold warm hot epvm figure single transaction update prob varied update integer update array large database results large database parts experiments number page faults occurred important versions page faults listed parentheses number normal operations client versions experienced page faults number page faults obtained unix getrusage system call tables present cold warm times observed benchmark executed single transaction time transaction begin commit included cesm performance cold iteration table fewer operations slower cesm due copying costs epvm slower cesm primarily effective job buffer management worst performance cold iteration due cost mapping data client address space performs warm iteration comparing architectures strictly fair case allowed memory shown number page faults experiences cesm epvm close terms performance epvm slower due fact performs insert objects oid hash table surprisingly slower epvm warm iteration cold iteration due data mapping costs orens table worst performance cold iteration performs operations slower due overhead copying full pages swizzling makes difference cold iteration relative times warm iteration similar cold iteration performance m-no swizzling dirties pages virtual memory causing written disk fact doesn show number page faults shown table numbers give number pages read swap area process times epvm -no essentially identical epvm cold warm iterations shown traversal updates version cold warm cesm epvm table single transaction updates times seconds traversal updates version cold warm m-no table single transaction updates times seconds iteration executed single transaction cold times times shown versions tables warm iteration times versions included table performance slower decrease performance due fact cache data virtual memory performed lot unnecessary copying slower warm iteration faster m-no epvm -no epvm multiple transactions experiment repeating experiment inter-transaction caching showed caching impact performance large database caching improved performance epvm warm iteration figure presents total execution time traversal cold warm hot iterations run single transaction worst performance cases surprising results presented table read case slower case scans page hash table transaction commit determine objects updated significant amount virtual memory swapping activity poor performance commit phase makes slower versions noted large database case strictly fair compare epvm cesm page caching object caching versions caching versions allowed memory comparison epvm cesm fair versions equal amounts memory times epvm -no shown epvm m-no shown figure faster read case swizzling dirtied pages virtual memory caused write probability seconds cold warm hot epvm cesm figure benchmark run single transaction increase paging activity difference m-no gradually diminished updates performed m-no update probability figure presents total execution time traversal cold warm hot iterations executed separate transactions worst performance cases figure cesm performance slightly faster epvm turning object page caching performance page caching intermediate illustrates tradeoff made object caching reread pages server page caching caches objects copies data virtual memory epvm -no shown m-no shown epvm figure conclusions paper presented detailed discussion implementation pointer swizzling object caching epvm paper analyzed relative performance versions epvm benchmark epvm compared alternative methods supporting persistent data access including memory-mapped approach objectstore cold iteration times objectstore slower cold times architectures based esm small large database objectstore fastest warm iteration time small database large database objectstore worst warm performance results suggest performance objectstore worse esm mapping data process address space expensive operation hot iteration results small database showed memory-mapped scheme objectstore times write probability seconds cold warm hot epvm cesm figure benchmark run multiple transactions faster software approach epvm operating in-memory data observed difference performance small amount additional computation added paper compared total elapsed time architectures transaction workloads small database figures objectstore performance read-only case shown generally performed objectstore 
directly support shadow-based recovery translator generate code versioning mechanism storage object manager accomplish task briefly language dbi facility writing access method operations worrying issues size objects making calls storage object manager access method specific concerns concurrency control recovery implementation language access methods compiler heart exodus system application specialized fundamental type type operations written dbi operations deal arbitrarily large portions objects dbi add adt called matrix provide matrix multiplication operator dbi job significantly simpler write desired code regard size underlying storage objects finally operators implement application data model written operator methods operator methods layer procedures implement operators provided user database system operator procedures methods exist relational dbms layer nested-loops sort-merge implementations relational join operation general operators data model schema independent operators implementations defined independently conceptual schema information join operator join relations long join attributes compatible result semantically meaningless strategies implementing generic operators procedures implementing operators request schema information run-time type manager strategy query optimizer compiler compile schema information code fragments compiled query pass operator method run-time case join optimizer produce code fragments extract source relation join attributes procedure source relation compare join attributes compose result tuple source tuples solution layer parameterized modules types tuples joined projected unknown case providing generic semantics-free operators database users number researchers webe rowe derr lyng proposed provide schema dependent operations users database employees departments type operations supported form hire-employee change-job hire-employee operation invoked base entities updated fashion insure database remains consistent capabilities exodus implementing style operators feasible dbi implement operators directly functionality provided access methods storage object manager alternatively implemented generic operators appears database administrator iris database derr lyng expected implement schema-specific operators underlying database system basically relational nature case access methods anticipate providing level operator support library operator methods data models methods performing associative accesses selection scanning objects contained file object rule based query optimization compilation unforeseeably wide variety data models hope support exodus operators methods exodus includes optimizer generator produces applicationspecific query optimizer input specification generated optimizer repeatedly applies algebraic transformations query selects access paths operation transformed query transformational approach outlined ullman relational dbmss ullm microbe database project nyug rules coded pascal procedures initially considered rule-based language implement general-purpose optimizer augment data model specific rules prolog warr cloc ops forg loops bobr interesting candidates built-in inference engine search mechanism convenience limits search algorithms fixed hard augment search heuristics important query optimization based limitation considerations call compatibility exodus components optimizer execution speed decided provide optimizer generator grae produces optimization procedure programming language kern generated optimization procedure takes query input producing access plan output query context tree-like expression logical operators internal nodes join relational dbms sets objects relations leaves regard part optimizer task produce initial algebraic query tree non-procedural expression user interface parser access plan tree operator methods internal nodes hash join method files indices leaves access plan obtained transformed iterative program techniques due freytag frey frey key elements optimizer generator description file order generate optimizer operators methods transformation rules implementation rules operators methods characterized arity transformation rules legal equivalence-preserving transformations query trees consist expressions optional condition expressions place holders lower parts query affected transformation condition code fragment inserted optimizer place finally implementation rule consists method expression method implements optional condition excerpt description file relational dbms operator join method hash-join merge-join join join join hash-join operator method declarations number inputs symbol denotes equivalence keyword implementation rules merge-join joining sorted relations rule merge-join include condition test input relation sorted addition declarative description data model optimizer requires dbi supply collection procedures method cost function supplied calculates method cost characteristics method input cost access plan defined sum costs methods involved property function needed operator method operator property functions determine logical properties intermediate results cardinalities record widths method property functions determine physical properties side effects sort order generated optimization procedure operates maintaining principal data structures mesh open mesh directed acyclic graph alternative operator trees access plans explored complex pointer structure employed ensure equal subexpressions stored optimized accesses transformations performed quickly open priority queue set applicable transformations ordered cost decrease expected applying transformations mesh initialized tree structure original query method lowest cost estimate selected node implementation rules transformations determined inserted open transformation rules optimizer repeats transformation cycle open empty promising transformation selected open applied mesh nodes generated transformation optimizer find equal node mesh avoid optimizing expression nodes equal operator argument inputs equal node found replace node remaining nodes matched transformation rules analyzed methods lowest cost estimates selected algorithm parameters serve improve efficiency promise transformation calculated product top node total cost expected cost factor transformation rule matching transformation low expected cost factor applied expected cost factors provide easy ensure restrictive operators moved tree quickly general heuristic cost lower constructive operators join transitive closure input data wasted effort perform equivalence transformation yield cheaper solution transformation intermediate step expensive access plan transformations represent hill climbing limit application hill climbing factor transformation results lower cost parent nodes expression reanalyzed propagate cost advantages appears difficult problem select values parameters guarantee optimal access plans good optimizer performance nice determined adjusted automatically current prototype initializes expected cost factors neutral adjusts sliding geometric averages turned effective preliminary experiments experimenting hill climbing reanalyzing factors determine method adjustment exodus user interfaces discussed section database system provide facilities hoc embedded queries tuple-at-a-time portal ston interfaces record-oriented database systems begun thinking provide general technique handling embedded queries programs goals exodus project develop data model independent techniques interface programs application specific database systems prove difficult hard envision generic interface tool satisfactorily interface vlsi layout tool vlsi database system environment approach treat application program procedures operators database system enabling program directly access typed objects buffer pool alternatively provide library interface tools portals browsing sets objects graphical interfaces applications intend explore alternative solutions problem future hoc query interfaces tools based attribute grammars promising unlike grammars generators yacc parsing syntax input query grammars complex sets attributes attribution functions capture semantics query incorporating knowledge schema information guide query construction detect errors generate structures transmission optimizer test ideas constructing quel interface cornell program synthesizer generator reps generator takes formal input specification producing output interactive syntaxand semantics-driven editor similar flavor 
server levels buffer pool increased pages point cache size longer limiting factor objects referenced query fit cache performance object server limited cost transferring objects rpc designs cache full pages buffer pools performance continues improve expect improvement buffer pool size pages random read query relative difference page server file server diminishes size buffer pool increased fewer fewer remote accesses performance advantage provided nfs decreases case random update query observe file server sensitive page server size workstation buffer pool small buffer sizes page-write costs dominating speculate absolute size clustering region matter key size clustering region relative size workstation buffer pool case file server prototype addition increasing size buffer pool page increments increased size physical memory workstation page increments response time seconds workstation buffer size figure scan query clustering factor response time seconds workstation buffer size figure scan query clustering factor file server object server page server wiss file server object server page server wiss response time seconds workstation buffer size figure random read query clustering factor response time seconds workstation buffer size file server object server page server wiss figure random read query clustering factor file server object server page server wiss response time seconds workstation buffer size figure random update clustering factor response time seconds workstation buffer size figure random update clustering factor file server object server page server wiss file server object server page server wiss response time seconds workstation buffer size figure queries clustering factor response time seconds workstation buffer size file server object server page server wiss figure queries clustering factor file server object server page server wiss factor file server database fits memory benefits nfs reads compensate expensive write operations pages written object server performs page server buffer size small clustering factor buffer size size database pageand file-server designs outperform object server conclude memory reasonable substitute effective clustering entire database fit main memory clustering factor performance designs close queries observe page server sensitive size workstation buffer pool clustering clustering region sizes -page buffer pool case pages referenced query fit buffer pool high clustering factor large buffer sizes job compensating lack effective clustering opposite effective clustering compensating small buffer sizes random read query -page buffer clustering factor performs page buffer clustering factor behavior noticeable random update queries tests related work previous work similar study hagmann ferrari hagm split functionality version ingres system ways machines measured cpu disk network usage investigation departs respects work aimed determining partitioning database function shared central processor dedicated back-end machine briefly mention workstation-server environments results interpreted relative environment pair central machines combined cpu time good measure comparing software configurations environment questionable comparison target environment workstation cycles plentiful server cycles scarce benchmark chosen indicative relational data-processing loads structures operations chosen representative processing design databases finally important experiment sensitivity software configurations physical aspects data system parameters experiments effect data placement buffer pool sizes architectures direct comparisons performance prototypes tempered uncertainty effect multi-user environment results relative sensitivity prototypes data system parameters robust aim-p database project investigated workstation-server linkage depp high-level view independent database systems taking advantage common physical format speed transfers check-out model long transactions differs view partitioning functionality single database system machines aim-p scheme communication takes place logical query language physical page levels work detail architectural alternatives provide performance analysis spite differences model aim-p techniques concurrency control update auxiliary access structures work context results similar obtained stamos stam simulated behavior memory architectures non-distributed single-user object manager strategies clustering conclusions similar page buffering sensitive clustering object buffering object buffering shows performance page buffering buffer space limited relative size working set application similar architectural issues arise design distributed object-oriented operating systems comandos marq system default storage system respond single objects virtual object memory object fault logical clusters objects declared cluster delivered object requested conclusions analyzed workstation-server architectures object server page server file server object server transfers individual objects machines page server transfers disk pages file server transfers pages remote file service mechanism nfs analyzed architecture qualitatively main advantage page-server file-server architectures simple design server complexity oodbms workstation approach coincides current trend powerful workstations main drawbacks fine-grained concurrency difficult implement non-two phase locking protocols indices involve workstation objects manipulated server object-server architecture implies complicated server design suffers issue rpc time object read server main advantages correspond page server limitations fine-grained concurrency control centralized server method selects small subset large collection execute server avoiding movement entire collection workstation behavior easy implement compare performance architectures built prototypes stripped-down version wiss starting point experiment sensitivity data placement cache sizes developed object manager benchmark altair complex-object benchmark main conclusions experiments object-server architecture insensitive clustering sensitive workstation buffer sizes point point performance determined cost fetching objects rpc mechanism object-server viable incorporate mechanism passing multiple objects values message workstation server portals relational systems pass groups tuples easy find instances bundling feasible response selection set request display complete state complex object general method predicting object result invoking method means provide capability provide automatic bundling queries hypermodel ande sun catt catt benchmarks short processing queries server note prefetching scheme based transitivity unit clustering object-server prefetched objects passed workstation groups individually prefetching physical pages unit clustering odd situation reading page server extracting objects rebundling objects transmission workstation page-server architecture sensitive size workstation buffer pool clustering traversing updating complex objects page-server architecture superior sequential scan queries object server architecture demonstrates superior performance database poorly clustered workstation buffer pool small relative size database file server performance good reading pages database nfs writes slow update query combination queries file server sensitive size workstation buffer pool page server observations lead postulate clear winner page-server approach beneficial clustering algorithm effective workstations large buffer pools object-server approach perform poorly applications tend scan large data sets perform page server applications performing updates running workstations small buffer pools file server approach based solely nfs ruled expensive buffered writes separate messages locking problem hybrid architecture maximize performance naive ideal read pages nfs write individual objects back server point drawback aforementioned concurrency control problem fact object cache maintained workstation preliminary studies page sizes showed impact performance designs intend study issue addition examine multiuser issues carefully acknowledgements jacob stein 
implementing crash recovery quickstore performance study seth white david dewitt sun microsystems computer sciences department garcia ave wisconsin mountain view madison seth white eng sun dewitt wisc abstract implementing crash recovery object-oriented database system oodbms raises challenging issues performance present traditional dbmss performance concerns result significant architectural differences oodbmss traditional database systems differences oodbms target applications paper compares performance alternative approaches implementing crash recovery oodbms based client-server architecture basic recovery techniques examined paper termed page differencing sub-page differencing whole-page logging redo-at-server recovery techniques implemented context quickstore memory-mapped store built exodus storage manager performance compared database benchmark results performance study show techniques based differencing generally provide superior performance whole-page logging introduction paper examines performance alternative approaches implementing crash recovery quickstore white memory-mapped store persistent built exodus storage manager esm carey providing recovery services system quickstore raises challenging implementation issues memory-mapped storage system kinds applications object-oriented database management systems oodbmss strive support cax gis ois quickstore implemented top exodus storage manager esm client-server page-shipping system dewitt raises additional performance concerns recovery present database systems based traditional designs centralized dbmss systems based query-shipping architecture paper examines basic recovery techniques termed page differencing sub-page differencing whole-page logging redo-at-server recovery techniques implemented context quickstore esm accurate comparison performance made performance study carried object-oriented database benchmark carey performance results illustrate impact database sizes update patterns client memory relative performance techniques addition number clients accessing database varied order compare scalability recovery algorithms remainder paper organized section presents detailed discussion factors briefly mentioned make recovery quickstore challenging problem section describes alternative techniques implementing recovery quickstore section describes performance study carried compare performance recovery schemes section presents performance results section discusses related work finally section presents conclusions proposals future work challenges recovery challenge faced quickstore recovery results persistent objects accessed memory-mapped architecture white quickstore supports comprehensive pointer swizzling strategy application programs manipulate persistent objects directly esm client buffer pool dereferencing normal virtual memory pointers strategy applications update persistent objects memory speeds essentially overhead makes detecting portions objects updated difficult systems traditional implementation techniques oodbmss perform pointer swizzling implement pointer swizzling traditional software-based techniques function part database runtime system typically called perform update hook system record fact update occurred note approach requires special compiler support insert function calls updates application code order make updates transparent factor affecting design recovery scheme quickstore quickstore oodbmss designed handle non-traditional database applications cad geographic information systems gis office information systems ois applications type typically read objects memory work intensively repeatedly traversing relationships objects updating objects behavior differs dramatically exhibited relational database systems update individual tuple update operation giving employees company annual raise requires single update employee tuple relational database systems typically update tuple generate log record recovery purposes individual update strategy practical oodbms object updated times single method invocation batch effects updates order achieve good performance attempting generate single log research contained paper conducted author graduate student wisconsin-madison research sponsored advanced research project agency arpa order number monitored army research laboratory contract daab -c-q record records effects updates object final consideration design recovery scheme quickstore arises fact quickstore based clientserver architecture updates performed client workstations raises issue cache consistency clients server frank client server buffer pools cached copies page updated addition increase availability stable copy transaction log maintained server clients required ship log records describing updates network server transaction commit differs traditional approach centralized database systems updates performed server log records generated locally server recovery strategies section describes basic recovery schemes implemented evaluated quickstore page differencing sub-page differencing whole-page logging redo-at-server begin describing implementation recovery esm techniques built top involve modifications underlying esm recovery scheme noted recovery algorithms discussed context quickstore quickstore specific general applicable similar client-server oodbms recovery esm exodus storage manager client-server page-shipping system dewitt clients servers manage local buffer pools client access object page cached local buffer pool sends request network server page server reads page secondary storage main memory sends copy page client retains copy page buffer pool objects updated clients clients generate log records describe updates recovery purposes log records updates redo undo information update operation range bytes object updated log record values portion object log records collected client server page-at-a-time simplicity esm enforces rule log records generated page back server page server page cached buffer pool log records describing updates present page esm server manages circular append-only log secondary storage steal no-force buffer management policy haerd clients cache pages local buffer pools transaction boundaries inter-transaction caching locks clients supported dirty pages back server commit time order maintain cache consistency clients server simplify recovery log records generated behalf transaction written log server transaction commits dirty pages forced disk frank detailed description esm recovery scheme page differencing approach esm recovery mechanism handles generation log records updates recovery straightforward basic services provided esm time update performed log record generated situation avoid obvious quickstore application detect fact update occurred application programs allowed update objects simply dereferencing standard virtual memory pointers enabling recovery page differencing problems mentioned addressed employing page differencing scheme generate log records approach works quickstore application programs access persistent data mapping range virtual memory unix mmap system call address space application process location client buffer pool database page cached main memory white refer range virtual memory mapped page frame virtual memory virtual memory frames contiguous uniform size read permission enabled virtual frame mapped page buffer pool persistent objects located page accessed application process objects page accessed dereferencing standard virtual memory pointers virtual frame write access automatically enabled virtual frame mapped write access enabled actions enable recovery page attempt application program update object page recovery enabled result page-fault causing quickstore fault-handling routine invoked quickstore runtime system maintains in-memory table entry called page descriptor virtual frame page database inmemory table implemented height balanced binary tree fault-handling routine invoked begins searching in-memory table page descriptor virtual memory address caused fault inspecting status information contained page descriptor entry faulthandler detect access violation due write attempt recovery enabled page paging buffer pool taking place fault-handler copies page area memory termed recovery buffer sets page descriptor entry point copy faulthandler obtains exclusive lock page esm needed 
providing information current architecture gemstone gilbert harrus jon kepecs rusty sandberg srinivasan understanding nfs sunos operates mike carey robert hagmann mike stonebraker constructive comments earlier draft paper ande anderson berre mallison porter schneider hypermodel benchmark proc intl conf extending data base technology venice march astr astrahan system relational database management system acm tods june atki atkinson bancilhon dewitt dittrich maier zdonik object-oriented database system manifesto proc conf deductive object-oriented databases kyoto japan december banc bancilhon barbedette benzaken delobel gamerman lecluse pfeffer richard velez design implementation object-oriented database system advances objectoriented databases proc intl workshop object-oriented database systems dittrich lecture notes computer science springer-verlag bret bretl gemstone data management system object-oriented concepts databases applications kim lochovsky eds acm press care carey exodus extensible dbms project overview zdon catt cattell object-oriented dbms performance measurement advances object-oriented databases proc intl workshop object-oriented database systems dittrich lecture notes computer science springer-verlag catt cattell skeen engineering database benchmark submitted acm tods chan chang katz exploiting inheritance structure semantics effective clustering buffering object-oriented dbms proc acm sigmod intl conf management data portland june chou chou dewitt katz klug design implementation wisconsin storage system software practice experience october cope copeland maier making smalltalk database system proc acm sigmod intl conf management data june depp deppisch obermeit tight database cooperation server-workstation environment proc international conference distributed computing systems june deux deux story ieee transactions data knowledge engineering march gray gray granularity locks degrees consistency shared data base modeling data base management systems nijssen north-holland hagm hagmann ferrari performance analysis back-end database architectures acm tods mar horn hornick zdonik shared segmented memory object-oriented database acm toois jan kim kim architecture orion generation database system ieee transactions data knowledge engineering march kung kung robinson optimistic methods concurrency control acm tods june lind lindsay notes distributed database systems technical report ibm research laboratory san jose california july marq marques guedes extending operating system support object-oriented environment proc oopsla orleans oct sun network programming guide sun microsystems part number stam stamos static grouping small objects enhance performance paged virtual memory acm tocs ston stonebraker design implementation ingres acm tods september vele velez bernard darnis object manager overview proc vldb amsterdam august zdon zdonik maier readings object-oriented database systems introduction fundamentals object-oriented databases morgan-kaufmann san mateo 
quickstore high performance mapped object store seth white david dewitt computer sciences department computer sciences department wisconsin wisconsin madison madison white wisc dewitt wisc abstract paper presents quickstore memory-mapped storage system persistent built top exodus storage manager quickstore fast access in-memory objects allowing application programs access objects normal virtual memory pointers paper presents results detailed performance study benchmark study compares performance quickstore latest implementation programming language systems quickstore exemplify basic approaches hardware software implement persistence object-oriented database systems addition systems underlying storage manager compiler allowing make applesto-apples comparison hardware software techniques introduction paper presents quickstore memory-mapped storage system persistent built top exodus storage manager esm carey quickstore standard virtual memory hardware trigger transfer persistent data secondary storage main memory wilso advantage approach access in-memory persistent objects efficient access transient objects application programs access objects dereferencing normal virtual memory pointers overhead software residency checks moss schuh white quickstore implemented class library linked application requiring special compiler support quickstore modified version gnu debugger gdb obtain information describing physical layout persistent objects quickstore information provided gdb automatically maintain database schemas memory-mapped architecture quickstore supports persistence orthogonal type transient persistent objects manipulated compiled code quickstore esm store persistent data disk features client-server architecture full support transactions concurrency control recovery indices large objects quickstore places additional limits size database amount data accessed context single transaction limited size virtual memory paper presents results detailed performance study benchmark carey compare performance quickstore latest implementation rich persistent programming language developed wisconsin based comparison quickstore interesting systems takes radically approach implementing persistence quickstore employs hardware faulting scheme relies virtual memory support mentioned interpretive approach implemented software systems quickstore exemplify basic approaches hardware software implement persistence object-oriented database systems quickstore underlying storage manager esm compiler make apples-to-apples comparison hardware software swizzling schemes previously remainder paper organized section discusses related work hardware software based pointer swizzling schemes points performance results presented paper differ previous studies section describes design quickstore section presents experimental methodology section presents results performance study section conclusions proposals future work version paper appeared proceedings acm-sigmod conference management data minneapolis research sponsored advanced research project agency arpa order number monitored army research laboratory contract daab -c-q related work detailed proposal advocating virtual memory techniques trigger transfer persistent objects disk main memory appeared wilso basic approach wilso termed pointer swizzling page fault time scheme pointers page converted disk format normal virtual memory pointers swizzled page-fault handling routine application access newly resident page addition pages virtual memory allocated non-resident pages step ahead actual access protected pages page-fault signaled technique wilso programs access persistent objects dereferencing standard virtual memory pointers eliminating software residency checks basic ideas presented wilso time independently designers objectstore objec lamb commercial oodbms product object design implementation objectstore outlined briefly objec differs interesting ways scheme wilso notably pointer swizzling implemented pointers represented disk approach outlined objec pointers persistent objects stored disk virtual memory pointers stored disk format wilso words pointer fields objects simply assigned page resident main memory objectstore page persistent objects referenced application program objectstore attempts assign page virtual address page memory resident pages accessed application assigned previous locations memory pointers contained pages retain previous values swizzled changed reflect assignment pages memory locations part faulting process page assigned previous address conflict page pointers objects page altered swizzled reflect location page scheme requires system maintain additional information describing previous assignment disk pages virtual memory addresses hope processing information expensive average swizzling pointers pages faulted memory application program note quickstore similar objectstore quickstore stores pointers disk virtual memory pointers section detailed discussion implementation quickstore texas singh cricket shek storage systems virtual memory techniques implement persistence texas stores pointers disk -byte file offsets swizzles pointers virtual addresses wilso fault time data stored single file implemented raw unix disk partition texas singh quickstore texas implementation details similarities systems systems implemented libraries add persistence programs compiler support systems support notion persistence orthogonal type compiled code manipulate transient persistent objects systems database size bigger size virtual memory texas single user single processor system quickstore built top clientserver exodus features client-server architecture full transaction support including concurrency control recovery support distributed transactions quickstore manipulates objects directly esm client buffer pool texas copies objects separate heap area allocated virtual memory limits amount data accessed single transaction texas size disk swap area backing application process quickstore manages paging esm client buffer pool explicitly texas simply pages swapped disk virtual memory subsystem process size exceeds size physical memory cricket hand mach external pager facility map persistent data application address space shek details recent related system dali jagad designed main memory storage manager dali memory mapping techniques specifically designed handle main memory databases differs substantially quickstore dali performs pointer swizzling dali database partitioned units called database files mapped contiguously process address space database pointers dali database file identifier offset dereferencing database pointer involves indexing fixed size array open database files adding starting address database file contained array offset contained pointer large number database files expected happen search inmemory tree structure required determine starting address database file discuss previous performance studies pointer swizzling object faulting techniques point study presented differs moss study software swizzling techniques examines issues relevant pointer swizzling swizzling performance simply object identifiers locate objects objects manipulated buffer pool underlying storage manager copied separate area memory swizzling takes place moss lazy eager swizzling eager swizzling involves prefetching entire collection objects memory pointers swizzled lazy swizzling swizzles pointers incrementally objects accessed faulted memory application program copy swizzling approaches white showed perform database size larger physical memory study presented differs moss pages objects replaced buffer pool moss considers small data sets paging occurs systems examine include concurrency control recovery examined moss hoski examines performance object faulting schemes context persistent smalltalk implementation hoski includes scheme virtual memory techniques detect accesses non-resident objects approach hoski allocates fault-blocks special objects stand non-resident objects protected pages application access object fault block access violation signaled results presented hoski show scheme poor performance clear due overhead virtual memory result extra work performed object fault locate eliminate outstanding pointers fault block caused fault work involves examining pointer 
emacs query language editor guide user step-by-step creating properly formed queries transform calculus representation query syntax tree operator language recognized optimizer process producing syntax tree editor responsible translating calculus representation initial algebraic representation query editor call type manager provide access schema information schema information determines large part underlying semantics query concrete syntax query language abstract syntax translation abstract syntax database operator language generated automatically formal specification straightforward process change enhance language recognized user interface summary current status paper design exodus extensible database system intended simplify development high-performance application-specific database systems explained exodus model world includes classes database experts designers implementors exodus database implementors dbis responsible exodus produce application-specific dbmss database administrators dbas managers systems produced dbis addition users application-specific dbmss engineers scientists office workers computer-aided designers groups resulting systems support focus paper architecture exodus tools aid dbi task exodus includes components require change application application storage object manager flexible storage manager concurrent recoverable access storage objects arbitrary size type manager repository type information related information file types dependencies types code types addition exodus libraries database system components widely applicable including components access methods version management simple operations system layers constructed dbi combination borrowing components libraries writing components make writing components painless exodus database implementation language largely shield dbi details internal object formats buffer management concurrency control recovery protocols vehicle provided defining adts makes easy dbi write operations adts large image adt upper level system exodus generator produces query optimizer compiler description operations methods tools generating application-specific front-end software planned initial design exodus basically complete including components implementation components begun preliminary prototyping work order validate storage object manager algorithms operating large storage objects care half storage object manager implemented time implementation rule-based query optimizer generator basically complete generate full relational query optimizer type manager programming language translator implementation efforts underway hope initial implementations key components exodus middle expect bring relational dbms top exodus test tools begin challenging applications test flexibility approach ait ait-kaci nasr logic inheritance proceedings popl conference petersburg january allm allman held stonebraker embedding data manipulation language general purpose programming language proceedings sigplan-sigmod conference data abstraction salt lake city utah march astr astrahan system relational approach database management acm transactions data systems june bato batory kim support versions vlsi cad objects working paper march bato batory barnett garza smith tsukuda twichell wise genesis reconfigurable database management system technical report tr- department computer sciences texas austin march baye bayer schkolnick concurrency operations b-trees acta informatica bobr bobrow stefik loops manual loops release notes xerox palo alto care carey dewitt extensible database systems proceedings islamorada workshop large scale knowledge base reasoning systems february care carey dewitt stonebraker personal communication july care carey dewitt richardson shekita object file management exodus extensible database system proceedings vldb conference kyoto japan august chou chou h-t dewitt evaluation buffer management strategies relational database systems proceedings vldb conference stockholm sweden august clif clifford tansel algebra historical relational databases views proceedings sigmod conference austin texas cloc clocksin mellish programming prolog springer-verlag york cope copeland maier making smalltalk database system proceedings sigmod conference boston dada dadam lum h-d werner integration time versions relational database system proceedings vldb conference singapore august daya dayal smith probe knowledge-oriented database management system proceedings islamorada workshop large scale knowledge base reasoning systems february derr derrett fishman kent lyngaek ryan object-oriented approach data management proceedings compcon conference san francisco february feld feldman make program maintaining computer programs software practice experience vol forg forgy ops manual computer science technical report carnegie-mellon frey freytag translating relational queries iterative programs thesis harvard september frey freytag goodman translating relational queries iterative programs program transformation approach proceedings acm sigmod conference grae graefe dewitt exodus optimizer generator submitted december gray gray notes database operating systems operating systems advanced bayer graham seegmuller eds springer-verlag gutt guttman r-trees dynamic index structure spatial searching proceedings sigmod conference boston jens jensen wirth pascal user manual report springer-verlag york katz katz lehman database support versions alternatives large design files ieee transactions software engineering semarch katz katz chang bhateja version modeling concepts computer-aided design databases proceedings sigmod conference washington kern kernighan ritchie programming language prentice-hall englewood cliffs kers kersten wasserman architecture plain data base handler software practice experience klah klahold schlageter unland wilkes transaction model supporting complex applications integrated information systems proceedings sigmod conference austin lisk liskov snyder atkinson schaffert abstraction mechanisms clu comm acm august litw litwin linear hashing tool file table addressing proceedings vldb conference montreal canada october lyng lyngbaek kent data modeling methodology design implementation information systems proceedings international workshop object-oriented database systems pacific grove september nguy nguyen ferrat galy high-level user interface local network database system proceedings ieee infocom maie maier stein otis purdy development object oriented dbms proceedings oopsla portland september mano manola dayal pdm object-oriented data model proceedings international workshop object-oriented database systems pacific grove september niev nievergelt hintenberger sevcik grid file adaptable symmetric multikey file structure acm transactions database systems vol march reps reps teitelbaum synthesizer generator proceedings acm sigsoft sigplan software engineering symposium practical software development environments pittsburgh penn apr appeared joint issue sigplan notices acm soft eng notes acm rich richardson carey programming constructs database system implementation exodus submitted robi robinson k-d-b-tree search structure large multidimentional dynamic indexes proceedings sigmod conference june rowe rowe schoens data abstraction views updates rigel proceedings sigmod conference boston schm schmidt high level constructs data type relations acm transactions database systems september schw schwarz extensibility starburst database system proceedings international workshop object-oriented database systems pacific grove september ship shipman functional data model data language daplex acm transactions database systems march shop shopiro theseus programming language relational databases acm transactions database systems december snod snodgrass ahn taxonomy time databases proceedings sigmod conference austin ston stonebraker hypothetical data bases views proceedings sigmod conference boston ston stonebraker stettner lynn kalash guttman document processing relational database system acm transactions office information systems april ston stonebraker rowe database portals application program interface proceedings vldb conference singapore august ston stonebraker personal communication july ston stonebraker inclusion types relational data base systems proceedings data engineering conference los angeles february ston 
stonebraker rowe design postgres proceedings sigmod conference washington ston stonebraker object management postgres procedures proceedings international workshop object-oriented database systems pacific grove september ullm ullman principles database systems computer science press rockville verh verhofstad recovery techniques database systems acm computing surveys june warr warren pereira pereira prolog language implementation compared lisp proceedings acm sigart-sigplan symp programming languages webe weber software engineering view database systems proceedings vldb conference weik weikum h-j schek architectural issues transaction management multi-layered systems proceedings vldb conference singapore august 
redo pass determines transactions committed time crash undone analysis pass begins recent checkpoint scans forward end log reconstructs transaction table dirty page table determine state system time crash begins copies structures logged checkpoint record contents tables modified log records encountered forward scan log record transaction transaction table encountered transaction added table log record commit abort transaction encountered transaction removed transaction table log record update page dirty page table encountered page added dirty page table lsn record caused page entered table recorded recoverylsn page end analysis pass dirty page table conservative pages flushed stable storage list database pages dirty time crash transaction table entries transactions require undo processing undo phase earliest recoverylsn entries dirty page table called firstlsn spot log begin redo phase redo stated earlier aries employs redo paradigm called repeating history redoes updates transactions committed effect repeating history end redo pass database state respect logged updates time crash occurred redo pass begins log record lsn firstlsn determined analysis scans forward redo update logged action re-applied pagelsn page set lsn redone log record logging performed result redo log record algorithm determine logged update redone affected page dirty page table update require redo affected page dirty page table recoverylsn page table entry greater lsn record checked update require redo lsn stored page pagelsn checked require page read disk pagelsn greater equal lsn record checked update require redo update redone undo undo pass scans backwards end log undo pass transactions committed time crash undone aries undo unconditional operation pagelsn affected page checked case undo performed due fact repeating history redo pass insures logged updates applied page update undone undo operation applied page logged special type log record called compensation log record clr addition undo information clr field called undonxtlsn undonxtlsn lsn log record undone transaction set prevlsn field log record undone logging clrs fashion enables aries avoid undo effects undo result system crash abort limiting amount work undone bounding amount logging event multiple crashes clr encountered backwards scan operation performed page backwards scan continues log record referenced undonxtlsn field clr jumping undone update updates transaction undone case multiple transactions discussed shortly execution shown figure figure transaction logged updates lsns system crashed time redo database brought date respect log redone weren stable storage transaction progress time crash undone undo pass update undone resulting writing clr lsn undonxtlsn points undone resulting writing clr lsn undonxtlsn points system crashed time undone history repeated redo brings database back state application lsn clr undo begins restart examine log record record clr modification performed page undo skip record lsn stored undonxtlsn field clr lsn continue undoing update log record lsn undo pass interrupted time crash note extra logging performed result crash order undo multiple transactions restart undo list lsn undone transaction undone log record processed undo prevlsn log time write page lsn write page write page restart clr lsn undo clr undo lsn restart clr undo lsn figure clrs undo undonxtlsn case clr entered lsn undone transaction undo pass moves log record lsn recent lsns redone undo continues backward log transactions list undone including log record undo transaction rollback transaction aborts savepoints works similarly undo pass restart algorithm difference transaction rollback single transaction part transaction undone keeping list lsns undone multiple transactions rollback simply follow backward chain log records transaction rolled back transaction abort rollback continues log record transaction undone savepoints rollback continues lsn savepoint reached recovery esm-cs aries page-server environment section describe problems addressed adapting aries pageserver environment outline solutions implemented issues arise main architectural features page-server environment modification data client database buffers log recovery manager server expense communicating clients server issue violates important assumptions aries algorithm addressed correctness implementation issue results performance tradeoffs page-server environment tradeoffs significant impact algorithm design presence separate buffers clients fundamental departure environment original aries algorithm difference creates problems transaction rollback system restart aries rollback undo unconditional operation rollback effects logged updates copies pages stable storage server buffer pool page-server environment server log records updates affected database pages rollback unconditional undo result corruption database system crashes due attempts undo operations reflected server copy page difference buffering related problem system restart correctness restart algorithm depends ability determine pages possibly dirty copy stable storage time crash section information gathered starting dirty page table logged recent checkpoint augmenting based log records encountered analysis pass page-server system process sufficient pages dirty client server checkpoint dirty page table problem addressed result incorrect recovery due violation repeating history property redo problem arises due expense communication clients server inability clients efficiently assign lsns aries expects lsns unique log log records added log monotonically increasing lsn order centralized shared memory system easily achieved single source generating lsns cheaply accessed time log record generated page-server environment clients generate log records parallel making difficult efficiently assign unique lsns arrive server monotonically increasing order lsns physical based log record addresses server required involved generation lsns summarize issues addressed page-server environment assignment state identifiers lsns place pages make undo conditional operation analysis pass system restart ensure correctness issues effects algorithm subsections algorithm summarized section log record counters lrcs log sequence numbers lsns section aries requires log record identified log sequence number lsn page pagelsn field lsn recent log record applied page lsns unique monotonically increasing required log record lsn physical address record log discussed efficiently generate lsns page-server system solution problem clients generate lsns locally client unique monotonically increasing temporarily place lsns pagelsn field affected page sending page server server responsible converting local lsns global lsns affected pages arrive client server inform clients mapping local lsns global making client responsible installing correct lsns data pages allowing migrate back server solutions rejected complication inefficiency resulting tight coupling processing opposed receipt log records server shipping pages clients general problem lsns page-server system overloaded ways identify state page respect log record identify state page respect position log lsn determine point begin redo page identify log find relevant record clients inexpensive access log responsible point solution separate functionality point introducing notion log record count lrc lrc counter page lrc page monotonically increasing uniquely identifies operation applied page storing 
enables write access virtual frame caused fault point work needed enable recovery faulted-on page complete control returned application program proceed update objects page directly client buffer pool figure shows effect actions inmemory data structures maintained quickstore figure page cached client buffer pool shaded show recovery buffer page descriptor page buffer pool figure page diffing approach updated copy page recovery enabled recovery buffer page descriptor page set point copy figure shows recovery buffer room pages fixed number pages esm client buffer pool fixed recovery buffer full free space periodically additional page updated generating log records page copied recovery buffer space recovery buffer managed simple fifo replacement policy generating log records pages transaction commit time paging buffer pool occurs recovery buffer full values objects contained recovery buffer updated values buffer pool compared diffed determine log records generated actual algorithm generating log records slightly sophisticated simple approach generating single log record modified region object simple approach rejected potential generate great deal unnecessary log traffic object words word bytes updated simple approach generate log records object esm log record header approximately bytes total space log bytes bytes log header bytes image hand log record generated bytes bytes bytes image providing savings amount log space algorithm generating log records diffing identify consecutive modified regions object page region exists single log record generated object log records principle span objects current implementation recovery esm figure shows object modified regions labeled diffing algorithm starts beginning object initially identify modified regions easy show after-image format log records esm distance satisfies equation size size log record header generating separate log records region generate amount log traffic case algorithm generate log record proceeding additional regions log record immediately generated advantageous combine region discovered figure combining modified regions object hand size distance small algorithm combines regions single region figure illustrates case combined single region log record generated step algorithm decide combine additional regions case mentioned algorithm continues identifying modified region object repeats previous check newly discovered region combined region previous iteration region previous iteration log record generated shown figure algorithm examine regions logged separately combined distance large algorithm generate separate log records finally note decision combine consecutive modified regions depends distance size order regions examined matter algorithm guaranteed generate minimum amount log traffic sub-page differencing approach page differencing recovery scheme previous section potential disadvantages obvious disadvantage cpu overhead copying diffing page fairly high updates performed page addition page diffing potential waste space recovery buffer copying page objects page updated increase number log records generated transaction recovery buffer full page-wise granularity page diffing scheme applications allowed update objects normal virtual memory pointers virtual memory page-based alternative approach interpret update operations software accomplished general compiling persistent applications special compiler inserts additional code handle update operations code simply function call replaces usual pointer dereference points application program updates occur case function invoked part quickstore runtime system approach yields system objects read memory speed standard virtual memory pointers update operations heavy-weight requiring function call software overhead hope approach extra cost incurred update repaid reduced recovery costs figure illustrates in-memory data structures quickstore implement sub-page differencing approach approach page divided contiguous sequence regions called blocks blocks uniform size experimented block sizes ranging bytes figure shows page descriptor page updated holds pointer array pointers copies blocks modified entry array block page array entries unmodified blocks null blocks sub-page unit copying diffing objects reasons cheaper terms cpu cost identify block page updated object update occurs objects page big k-bytes size case advantages sub-page diffing approach lost updates sparse page descriptor page buffer pool recovery buffer figure sub-page diffing approach enabling recovery sub-page differencing time quickstore update function called page descriptor page address memory location updated passed parameter page descriptor found check made block updated copied check inexpensive address location memory updated index array block pointers contained page descriptor applying simple logical operations copy block made copy recovery buffer addition status flags page descriptor examined exclusive lock acquired page write access enabled virtual frame mapped page finally update performed note write access enabled automatically virtual frames sub-page approach chose enabling write access runtime system catch erroneous writes virtual frames updated extra cost approach low generating log records sub-pages page diffing approach approach generates log records transaction commit time modified page paged buffer manager recovery buffer full log records generated diffing original values blocks contained recovery buffer modified versions blocks located buffer pool diffing scheme section addition avoid expense diffing altogether simply logging entire blocks experimented techniques refer sub-page approach diffing sub-page logging upcoming discussion performance whole-page logging approach section describes recovery algorithm included study algorithm termed whole-page logging wpl entire modified pages written log log records updated regions objects note wpl basic approach objectstore lamb commercial oodbms product advantages wpl avoids client cpu cost incurred diffing schemes copying diffing wpl avoids memory overhead clients storing original values pages blocks potentially improve performance allowing wpl allocate memory client buffer pool generate fewer log records finally wpl applications update objects memory speeds dereferencing normal virtual memory pointers cost performing updates low disadvantage whole-page logging logs entire afterimages dirty pages server means pages dirtied transaction forced log server transaction commits note cost shipping dirty pages back server add additional costs esm recovery algorithm sends updated pages back server transaction commits section wpl scheme rely support provided esm recovery diffing schemes wpl differs previous schemes actions clients server support recovery actions performed clients whole-page logging algorithm works clients application attempts update page client page-fault signaled usual quickstore page-fault handling routine marks copy page cached buffer pool dirty addition requesting exclusive lock enables write access virtual memory frame mapped page control returned application program dirty pages shipped back server transaction commits possibly sooner paging client buffer pool occurs note log records generated updates clients approach dirty pages shipped back server actions performed server server receives dirty page appends page log caches copy page buffer pool server original copy page disk overwritten copy page transaction updated page commits paging server buffer pool dirty page replaced transaction page read log reaccessed transaction transaction reaches commit point original 
updates performed main reason appears objectstore full page logging order support crash recovery epvm cesm performed objectstore frequency updates low multiple transactions large database memory-mapped approach objectstore slower performance epvm cesm versions based epvm performance small database cost copying full pages small compared cost copying individual objects case avoided reread pages server normal transaction execution large database generally performed performed lot unnecessary copying work experienced paging virtual memory lowered performance case swizzling scheme epvm noticeably hurt performance small database improved performance cases table column large database swizzling improve performance resulted decrease cases due fact caused increase amount virtual memory paging activity lastly note swizzling scheme epvm improved performance cases small database effect large database feel important conclusion drawn results presented paper important performance comparing architectures simply comparing speed architectures manipulate in-memory data comparing recovery issues capture true differences performance systems future explore variations object caching page caching schemes studied context epvm approach combining relative strengths found interested finding efficient ways generating recovery information context epvm memorymapped approach efficient method generating recovery information memory-mapped approach found feel performance improved substantially atkin atkinson chisholm cockshott algorithms persistent heap software practice experience vol march catte cattell engineering database benchmark benchmark handbook database transaction processing systems jim gray morgan-kaufman carey carey exodus extensible dbms project overview readings object-oriented databases zdonik maier eds morgan-kaufman carey carey storage management objects exodus object-oriented concepts databases applications kim lochovsky eds addison-wesley cock cockshott persistent object management system software practice experience vol exodu exodus storage manager technical documentation department computer sciences wisconsin-madison january frank franklin crash recovery client-server exodus proc acm sigmod int conf management data san diego california lamb lamb landis orenstein weinreb objectstore database system cacm vol october moss eliot moss working persistent objects swizzle swizzle coins object-oriented systems laboratory technical report massachusetts amherst objec object design objectstore user guide release october orens orenstein personal communication rich richardson carey schuh design programming language technical report computer sciences dept wisconsin feb rich richardson compiled item faulting proc int workshop persistent object systems martha vineyard september schuh schuh carey dewitt persistence experiences implementing persistent object bases principles practice fourth international workshop persistent object systems wilso paul wilson pointer swizzling page fault time efficiently supporting huge address spaces standard hardware technical report uic-eecs- illinois chicago december acknowledgements jack orenstein dan weinreb benson margulies object design helpful comments feedback results presented paper special dan schuh implemented epvm compiler mike zwilling mike franklin implemented aries based recovery algorithm exodus storage manager nancy hall implemented intertransaction caching 
fields transient persistent objects pointers fault block finally note effects page replacement buffer pool updates considered hoski white performance implementations language rich schuh objectstore objec lamb commercial oodbms compared results presented white inconclusive providing true comparison software hardware-based schemes underlying storage managers systems systems compilers study presented paper systems underlying storage manager compiler differences performance due swizzling faulting technique additional difference systems compared white examined systems included current study restrictive terms amount data accessed transaction systems manage paging persistent data explicitly differs approach epvm white limited amount data accessed transaction size disk swap area backing process allowed objects swapped disk virtual memory subsystem size process exceeded size physical memory finally note hoski examines performance alternative methods detecting recording occurrence updates persistent programming language smalltalk supports recovery system failures techniques studied hoski differencing generate log records quickstore study presented differs hoski goal hoski compare techniques detecting recording updates context single underlying language implementation goal study compare performance software hardware-based pointer swizzling hoski examine scheme virtual memory page faults detect occurrence updates briefly compare quickstore approach examined hoski hoski copy swizzling approach objects copied buffer pool underlying object manager separate object cache located memory accessed application program hardwarebased detection scheme hoski requires virtual memory page object cache hold object unprotected reprotected time object copied page producing substantial amount overhead read-only transactions approach quickstore in-place access page-at-a-time swizzling page protection manipulated object page updated technique quickstore doesn impact performance read-only transactions expect detecting updates cheaper quickstore scheme studied hoski quickstore design concepts mentioned section quickstore esm store persistent objects disk esm features page-shipping dewitt architecture objects transferred server client page-at-a-time page objects read buffer pool esm client applications quickstore access objects page directly esm client buffer pool dereferencing normal virtual memory pointers note objects accessed context transaction quickstore overview memory-mapped architecture section describes memory-mapping scheme quickstore give application programs access persistent objects understand approach view virtual address space application process divided contiguous sequence frames equal length case frames k-bytes size size pages disk esm client buffer pool viewed smaller sequence k-byte frames coordinate access persistent objects quickstore maintains physical mapping virtual memory frames frames buffer pool physical mapping dynamic paging buffer pool requires frame virtual memory mapped frames buffer pool points time mapping viewed logical mapping virtual memory frames disk pages viewed mapping static virtual frame disk page transaction figure illustrates mapping scheme detail buffer pool shown figure frames labeled virtual memory frames denoted upper-case letters disk pages lower-case discussion refer virtual memory frame beginning address frame page read disk quickstore virtual memory frame page selected access protected application attempts access object page dereferencing pointer frame page-fault signaled fault handling routine part quickstore runtime system invoked buffer pool buffer pool buffer pool buffer pool figure mapping virtual frames buffer pool fault handling routine responsible reading page disk updating data structures enabling access permission virtual frame caused fault execution program resume figure page read disk frame buffer pool page mapped virtual address read access enabled frame application read objects contained page note mapping virtual address page established application access objects page dereferencing pointers frame time mapping remain valid end current transaction longer requested order preserve semantics pointers application objects page case mapping virtual frame buffer frame moment objects page pointers objects non-resident pages virtual frames assigned pages page faulted memory haven mechanism assigning virtual frames disk pages covered detail section discusses pointer swizzling frame non-resident page remains access protected program attempts deference pointer frame page fault results page read buffer pool figure doesn explicitly show frames referenced pointers page important current discussion buffer pool full paging occur page selected replacement buffer manager section discusses buffer pool management details happened figure page read disk frame buffer pool replacing page page mapped virtual address read access enabled note assume buffer pool full figure additional virtual frames shown mapped remaining frames buffer pool frame application continues access additional pages objects database situation shown figure result figure page read memory replaced page frame buffer pool page mapped virtual frame read access enabled illustrates general number virtual frames frame buffer pool transaction point reader wondering happen figure application attempted dereference pointers virtual frame page replaced buffer pool page won pointers refer data page problem avoided disabling read access frame page memory application dereferences pointers frame page-fault signaled fault handling routine invoked fault handling routine call esm reread page map virtual frame frame buffer pool enable read permission frame illustrate figure shows result page immediately referenced replaced figure case reread esm frame buffer pool frame mapped virtual memory address illustrates dynamic nature mapping virtual memory frames frames buffer pool virtual frame mapped buffer frame figure remapped buffer frame figure note mapping virtual frames disk pages static virtual frame mapped disk page implementation details quickstore unix mmap system call implement physical mapping virtual memory frames frames esm client buffer pool control virtual frames access protections modify esm client software slightly order accommodate mmap mmap associates virtual memory addresses offsets file esm calls unix function malloc allocate space memory client buffer pool make esm mmap work buffer pool allocation code changed open file resize equal size size client buffer pool buffer allocation code calls mmap associate range virtual memory entire file rest esm client software range memory access buffer pool memory allocated malloc important thing note file serves backing store buffer pool swap space actual physical memory allocated virtual frames mapped file mmap mapping huge amount virtual memory buffer pool doesn affect size process increase size page tables maintained operating system note contiguous range addresses esm client access buffer pool k-byte ranges addresses application program access pages buffer pool simply integrate existing storage manager esm memory mapped approach general required memory mapped implementation point mmap caused minor performance problems implementation workstation client machine benchmark experiments sun elc virtually mapped cpu cache accessing page physical memory buffer pool virtual address ranges caused cpu cache flushed process switched address ranges increased number min faults virtual memory page faults require unix terminology experienced application note effects phenomena discussing performance results section in-memory data structures quickstore 
lsn page store lrc field page referred pagelrc order map lrcs entries log log record structure augmented include lrc field lrc page result logged operation note reasons explained sections lrcs size structure lsns current system eight-byte integer lrcs page modified lrc page pagelrc updated copied log record server examines page update applied page current pagelrc compared lrc contained log record modification pagelrc greater equal lrc log record update reflected page lrcs advantage private page manipulated client intervention server removes efficiency flexibility problems lsns main disadvantages lrcs physical log pointers directly serve access point log care insure combination page lrc refers unique log record approaches handling problems addressed sections conditional undo esm-cs log records operations performed clients arrive server dirty pages effects operations aborting transaction encounter log records operations effects reflected pages server attempting undo operation performed result corrupted data implement undo conditional operation scanning log backwards rollback restart undo page log record examined undo performed logged operations applied section undo aries unconditional operation operations undone checking applied page aries reasons aries dirty pages located system buffer pool time rollback logged operations reflected pages server history repeated restart redo assured operations time crash reflected pages stable storage buffer pool undo pass restart begins note version aries aries rrh conditional undo algorithm conditional undo restart undo esm-cs conditional undo required correctness rollback undo aries rrh discussed section conditional undo clrs written undo operations including performed pagelrcs affected pages updated undo operation performed reasons requirements shown figure figure transaction logged updates lrcs page page server update applied applied transaction rolls back conditional undo results lrc undone clr pertaining update written problem arise server crashes logging clr page reflecting undo written stable storage shown figure restart redo repeats history redoing lrcs clr undo pass encounters clr undonxtlsn nil considers transaction completely undone incorrectly leaves effects lrcs page rollback log clrs updates updates applied page pagelrc updated fake undo performed lrc rollback work properly encounters log record lrc erroneously infer update applied page pagelrc greater attempt undo update resulting corrupted page log time checkpoint write page lrc write page rollback restart lsn client buffer server buffer lrc lrc lrc page state lrc lrc stable storage redo lrc clr undo lrc lrc redo lrc effects error lrc write page lrc lrc lrc redo lrc redo lrc lrcs left page figure error due missing clrs conditional undo point solution log undo operations performed update lrc page undo performed page additional complication due lrcs lsns problem case logged updates page undone pagelrc lrcs log records rolled-back transaction pagelrc simply incremented updates subsequent transactions values pagelrc map multiple log records violation important invariant result problems redo undo problem occur lsns guaranteed unique monotonically increasing making impossible generate duplicate lsn problem solved taking advantage fact lrcs unique monotonically increasing page consecutive solution requires server send lsn current end-of-log lsn log record written time sends page client piggybacking end-of-log lsn message header client receives data index page server initializes pagelrc field received page end-of-log lsn page note page marked dirty client pagelrc initialized page written server actual update applied client updates page increments pagelrc page server updates page page formatting compensation undo places lsn log record page pagelrc field resulting pagelrcs guaranteed unique monotonically increasing necessarily consecutive respect page reasons page locking insures page modified client time normal operation server modifies pages restart rollback exclusive access affected pages time pagelrc updated multiple places simultaneously updates page change pagelrc generate log records flushed server page flushed log record including clrs written increases server end-of-log lsn server sends page client includes lsn current end-of-log message lsn client initialize pagelrc page client increments pagelrc log record writes performing correct analysis system restart solutions explained previous sections remaining issue addressed insure analysis pass system restart algorithm produces correct information state pages time crash related problems solved regard maintaining recoverylsns dirty pages determining pages require redo determining point log start redo pass maintaining recoverylsn page analysis pass restart algorithm aries computes lsn earliest log record require redo explained section lsn called firstlsn computed taking minimum recoverylsns pages considered dirty end analysis pass centralized system recoverylsn page storing lsn update page dirty buffer pool control information page page-server environment clients access lsn update log record update performed reasons previously problem solved clients attach approximate recoverylsn page initially dirty page implement extend mechanism section server piggybacks lsn current end-of-log reply sends client client initially dirties page attaches recent end-of-log lsn received server recoverylsn page lsn guaranteed equal lsn log record eventually generated operation dirties page client communicate server order initiate transaction clients send dirty pages server commit approximate recoverylsn earlier end-of-log lsn time transaction dirties page initiated typically recent client returns dirty page server sends approximate recoverylsn page message page page considered dirty server marked dirty approximate recoverylsn entered buffer pool control information page server determining pages require redo fundamental problem implementing aries algorithm pageserver environment presence buffer pools clients manifestation difference problem determining pages dirty time crash pages updates log copy page stable storage system crashed page considered dirty basic aries analysis algorithm satisfies criteria dirty page table logged recent complete checkpoint prior crash log records updates page log checkpoint reasons page updated client checkpoint dirty page table simply page back server written stable storage checkpoint problems page longer dirty point reason page updated client back server prior taking checkpoint note page server checkpoint lost crash case log records updates page appeared checkpoint updates skipped redo pass page dirty figure shows problem figure transaction updated page page log record lrc server sending page server checkpoint occurred client dirtied page lrc server commit request server wrote commit record forced disk committing transaction server crashed page flushed disk case restart redo lrc aries analysis algorithm page considered dirty appears recent checkpoint dirty page table referenced log records checkpoint require redo violate durability committed updates update lrc lost fortunately problem missed dirty pages correctness implications updates transactions commit system crashes reason updates transactions committed prior crash undone undo pass restart conditional undo algorithm section tolerate absence effects logged updates page 
values updated pages located disk permanent locations updated values pages flushed log commit log record transaction makes abort transaction time commit point reached simply ignoring updated values pages located log cached memory undo processing updates required page updated committed transaction maintained log things page read log overwrite permanent location disk log space page reused copy page contained log longer needed recovery reason fairly obvious suppose transaction updates page commits forced log crash resulting loss server volatile memory occurs time commits overwrites permanent location disk stored log order system correctly restart safely overwritten permanent location disk copy restart space page log reused subsequent transaction updates page commits forcing copy page log initial copy page log overwrites permanent location page effect needed point crash note maintained log transaction wrote commits server maintains in-memory table called wpl table track pages contained log needed recovery purposes table entry page pid page identifies permanent location disk entries log sequence number lsn log record generated page lsn identifies physical location page log additional fields stored entry include transaction tid transaction dirtied page additional status information page initially written log status information records fact transaction dirtied page committed finally table entries pointer refers entry previously logged copy page copy needed recovery server maintains list active transaction pages logged transaction transaction commits wpl table entry page list updated show transaction modified page committed order reclaim log space background thread asynchronously reads pages modified committed transactions log optimization pages modified transaction cached server buffer pool commit time simply marked read page read log server free flush page disk time entry page wpl table removed recovering crash order recover unexpected crash server periodically takes checkpoints checkpoint time wpl table written log order recover unexpected failure server reconstruct wpl table entries pages updated committed transactions written permanent disk locations server resume normal operation restart crash requires single pass log begins end log proceeds backward recent checkpoint record start pass list records committed transactions termed committed transactions list ctl initialized empty pass transaction added ctl commit record transaction encountered backward scan log record modified page encountered entry page inserted wpl table transaction updated page committed transaction list modify record transaction commit crash checkpoint record reached committed transaction list entry transaction committed checkpoint contents checkpoint record examined entries checkpoint record pertain members ctl marked pertaining transactions committed checkpoint added newly constructed wpl table point wpl table fully reconstructed normal processing resume redo-at-server approach final recovery algorithm examined termed redo-atserver redo algorithm modification ariesbased recovery algorithm esm clients send log records dirty pages back server recall usual exodus recovery algorithm sends log records dirty pages back server log records forced disk commit redo log record received server redo information log record update server copy page disadvantage redo server read page secondary storage order apply log record addition obvious advantage ship dirty pages clients server redo appealing implementation standpoint simplifies implementation storage manager providing cache consistency clients server frank redo initial version shore carey persistent object system developed wisconsin redo involves storage manager level combination recovery schemes mentioned previously make recovery services provided exodus study conjunction scheme implementation discussion recovery schemes section implemented context quickstore esm diffing schemes require base recovery services provided esm modifying gnu compiler gnu compiler compile quickstore application code insert function calls updates support sub-page diffing approach function calls inserted hand application level save time implementing whole-page logging made existing esm recovery code esm supported whole-page logging newly created pages made esm client support wpl fairly minor made server substantial involved tasks maintenance wpl table section rereading pages log implementing redo-at-server easy esm server supported redo part aries-based recovery scheme hard server apply log record page log records received inserting function call spot server code performance experiments section describes performance study conducted compare performance recovery algorithms previous section object-oriented database benchmark basis carrying study carey benchmark database structure database benchmark discussed detail carey describe briefly completeness database intended suggestive cad cam case applications key component database set composite parts composite part intended suggest design primitive register cell vlsi cad application composite part document object models small amount documentation composite part composite part graph atomic parts intuitively atomic parts composite part units composite part constructed atomic part composite part graph designated root part atomic part connected bidirectional association atomic parts varied connections atomic parts implemented interposing connection object pair connected atomic parts additional structure imposed set composite parts structure called assembly hierarchy assembly made composite parts case base assembly made assembly objects case complex assembly level assembly hierarchy consists base assembly objects base assembly bi-directional association composite parts chosen random set composite parts higher levels assembly hierarchy made complex assemblies complex assembly bi-directional association subassemblies base assemblies complex assembly level assembly hierarchy complex assemblies complex assembly higher hierarchy assembly hierarchy called module modules intended model largest subunits database application module manual object larger version document included database sizes study termed small big table shows parameters construct databases note parameters correspond standard database specification carey table module small database size module small database carey modules big database differ small database composite parts levels assembly hierarchy big database versus small database small big database modules number clients access database varied experiment module accessed single client module represents private data client decided clients share data order avoid locking conflicts deadlocks major effect performance removing effects simplified experiments allowed concentrate differences performance due recovery mechanisms studied parameter small big numatomicpercomp numconnperatomic documentsize bytes manual size bytes numcomppermodule numassmperassm numassmlevels numcompperassm nummodules table benchmark database parameters table lists total size databases size module database size module small database small entire module cached main memory client addition total size small database small fits main memory server experiments performed small database test performance recovery algorithms entire database cached main memory size module big database larger main memory single client addition single client amount data accessed bigger memory server experiments performed big database test relative performance algorithms significant amount paging taking place system small big module total table database sizes megabytes benchmark operations section describes benchmark operations study goal study 
maintains in-memory table track current mapping virtual memory frames disk pages point time table entry page faulted memory entries additional pages referenced pointers pages refer page table entry current mapping essence page persistent data application program deference pointer current mapping entries table called page descriptors bytes long figure shows format page descriptor note disk pages types pages sets objects smaller disk page called small object pages pages individual pages multi-page objects called large object pages table entries small object pages large object pages differ respects discussed separately page descriptor small object page range virtual addresses page physical address page disk pointer page pinned buffer pool physical address page implementation oid special meta-object bytes located small object page page descriptors fields flags types access allowed frame page read write exclusive page lock obtained page previously read memory current transaction flag swizzling work page reread transaction pointers pages guaranteed valid page descriptor heap pointer recovery purposes scheme large object pages complicated scheme small object pages virtual memory frames multi-page object contiguous reserved avoid maintaining individual table entries page multi-page object multi-page objects accessed mapping represented single entry mapping table range virtual addresses entry entire range contiguous addresses object physical address field oid object page multi-page object accessed application program table entry split entry table page accessed entry contiguous sub-sequence unaccessed pages table entries sub-sequences unaccessed pages multi-page objects split turn pages contained sub-sequence accessed figure illustrates splitting process large object descriptor figure shows descriptor large object accessed object pages long mapped virtual memory frames physical disk address virtual address range flags pointer page buffer pool memory pointers recovery heap pointer figure format page descriptor object identifier virtual address flags object identifier virtual address flags object identifier virtual address flags object identifier virtual address flags read figure splitting large object descriptor oid object denoted letter figure shows eighth page object accessed figure page descriptor allocated recently accessed page virtual address range descriptor records fact descriptor virtual memory frame read access frame enabled descriptor pointer shown copy page cached buffer pool figure shows additional page descriptors represent remaining pages object descriptor represents pages object precede page represents pages follow page note offset shown page object represented descriptor stored page descriptor descriptor correct pages object table organizes page descriptors range virtual memory addresses height balanced binary tree reason binary tree makes splitting operation large objects efficient helpful ranges addresses allocated persistent data ordered current scheme allocating virtual frames disk pages global counter stored disk incremented frame size time frame allocated disk page counter persistent successive runs program don reuse virtual memory addresses unnecessarily allocating objects database bigger size virtual memory counter wrap scan in-memory binary tree order find virtual frame page descriptors hashed based physical address oid inserted hash table large objects entry page object inserted hash table hash table implements reverse mapping physical disk address virtual memory address hash table fault handling routine part pointer swizzling process section details pointer swizzling quickstore quickstore stores pointers disk virtual memory addresses format memory figure shows format pointer quickstore high order bits contained pointer viewed identifying virtual memory frame low order bits identify offset frame actual object referenced pointer located objects allowed move pages offset identifies unique object portion object virtual memory pointers meaningful context individual process system maintains additional meta-data associates pointers disk objects describe meta-data stored quickstore briefly touch alternative implementation strategies quickstore associates meta-data individual disk pages case small object pages page direct pointer oid mapping object meta-data page pointer contained meta-object located page term mapping object object records mapping virtual frames referenced pointers page disk pages effect page memory resident mapping objects essentially arrays virtual address range disk address pairs mapping information stored separately disk pages objects space required store mapping information page vary time pointers page updated number frames referenced pointers page change changing number entries mapping object multi-page objects implemented similarly small object pages array meta-objects appended end large offsetframe figure format pointer quickstore object meta-object page large object meta-object pointer oid bitmap object records locations pointers page swizzled quickstore modified version gdb type information objects maintain bitmaps pages modified version gdb outputs description layout type stored schema application disk application creates object database information application schema update bitmap page object schema database figure illustrates structures ensure pointers application program valid swizzled pointers figure disk page mapped virtual frame page accessed application program read access frame enabled actions quickstore fault-handling routine page accessed illustrated figure figure fault-handler read page page mapping object mapping objects page main memory fault-handler examines entry mapping object disk address contained entry lookup page descriptor disk address inmemory table entry found table created information contained mapping object entry figure mapping object page pointers objects distinct disk pages include page pages page page fault handler pages discovers page descriptor entry page mapping table entries created table entry created disk page pages case large object assigned previous virtual frame obtained mapping object entry virtual frame unused frame selected entry disk page found table system checks page mapped virtual frame contained mapping object entry disk page mapped virtual frame contained entry swizzling process terminates figure page mapped frame addition pages assigned frames frames pages referenced pointers contained page assigned memory locations occupied time page memory isn update swizzle pointers page swizzling process terminates disk pages mapped locations figure additional swizzling work required suppose page couldn assigned frame page assigned frame case pointers page objects page updated referenced frame page pointers swizzled bitmap object entry pointer buffer pool mapping table entry pointer mapping object page buffer pool mapping table figure pointer swizzling collisions page read disk find update pointers page changed subset pointers contained page changed pointers page examined advance pointers updated note bitmap objects fixed size stored separately data page cases comment alternative ways storing mapping information support pointer swizzling storing information mapping virtual memory frames disk pages page basis store groups pages object-oriented systems group pages units called segments clusters store information level entire database possibly file chose follow approach makes keeping mapping information date considerably complex suppose database 
examine recovery performance include tests perform updates addition update tests stress index updates tests included study shed additional light performance recovery algorithms experiments performed traversal operations traversals perform depth-first traversal assembly hierarchy base assembly visited composite parts visited depth search graph atomic parts performed traversal increments attributes contained atomic parts returns count number updates performed update root atomic part composite part update atomic parts composite part update atomic parts times experiment traversals run repeatedly client steady state performance system observed traversal run separate transaction client server buffer pools flushed transactions data cached memory transaction boundaries software versions experimented quickstore recovery software versions table shows names identify versions performance section generally consists parts part identifies scheme generating log records specifies underlying recovery strategy esm redo addition size recovery buffer diffing schemes appended systems pd-redodenotes system page diffing recovery buffer combination redo-at-server recovery case whole-page logging part wpl note sub-page diffing versions shown performance section block size bytes experimented block sizes performance similar description pd-esm page diffing esm recovery sd-esm sub-page diffing esm recovery sl-esm sub-page logging diffing esm recovery pd-redo page diffing redo recovery wpl page logging table software versions hardware test vehicle sun workstations isolated ethernet sun ipx workstation configured megabytes memory megabyte disk drives model sun gigabyte disk drive model sun server sun hold system software swap space sun drive esm hold database sun drive hold esm transaction log data recovery disks configured raw carey specifies attributes swapped increment multiple updates object change object guarantees diffing schemes generate log record modified object clients response time seconds wpl pd-esm sd-esm pd-redo figure small database clients throughput trans min wpl pd-esm sd-esm pd-redo figure small database clients response time seconds wpl sd-esm sl-esm pd-esm pd-redo figure small database clients throughput trans min wpl sd-esm sl-esm pd-esm pd-redo figure small database clients response time seconds wpl sd-esm sl-esm pd-esm pd-redo figure small database client page writes total writes log writes wpl esm redo wpl esm redo figure client writes small database disks clients sun sparc elc workstations mips configured megabytes memory megabyte disk drive model sun disk drives hold system software swap devices performance results section presents performance results present analyze results obtained small database turn results obtained big database unconstrained cache results section presents results experiments small database systems megabytes memory client caching persistent data systems diffing allocated client buffer pool recovery buffer allocation memory allowed persistent data modified unmodified accessed client cached completely client main memory small database data accessed clients cached server buffer pool figures show response time throughput versus number active clients traversal software versions pd-redo page diffing redo recovery performance wpl whole-page logging update root atomic part composite part worst wpl slower pd-redo client performance relative systems steadily worsens number clients increases clients wpl times slower pd-redo wpl slow performance experiment sparse updates causing wpl write significantly pages log systems figure shows total number pages data log number log record pages shipped client server average transaction results figure labeled underlying recovery scheme determined number pages system pd-esm sd-esm write performance paging occurs clients generate number log records dirty pages main difference pd-esm sd-esm case amount data copied recovery buffer diffed transaction number pages written log server close total number pages shipped wpl close number log pages shipped systems figure shows wpl writes pages back server average pd-redo writes diffing scheme pdredo effective reducing amount work required server recovery case performance pd-esm sd-esm lies systems figure surprisingly response time sd-esm slightly faster pd-esm client clients savings cpu cost provided sd-esm small part response time experiment absolute difference response time clients response time seconds wpl pd-esm sd-esm pd-redo figure small constrained cache clients throughput trans min wpl pd-esm sd-esm pd-redo figure small constrained cache clients response time seconds wpl pd-esm sd-esm pd-redo figure small constrained cache sd-esm pd-esm change significantly number clients varied roughly seconds amounted savings milliseconds sd-esm page updated difference cpu usage pd-esm sdesm figure approximately low small difference cpu usage caused partly cpu overhead clients shipping dirty pages back server response time sl-esm shown figure basically sd-esm number additional log pages generated sl-esm relative sd-esm small experiment throughput results shown figure mirror response time results figure figure shows throughput increases number clients systems diffing wpl saturated clients increase throughput pd-esm pd-redo number clients increases turn figures show results traversal comparing figure figure shows difference performance systems smaller performs significantly updates page slowing performance diffing schemes pd-redo multi-user performance difference performance pd-redo wpl ranges number clients increases pdredo write significant number log records disk transaction figure wpl faster remaining systems single client performance degrades swiftly systems writing log records server bottleneck wpl interestingly performance pd-esm sd-esm identical due fact client cpu usage systems performance sd-esm bit worse relative pd-esm updates objects page updated causing sd-esm copy diffing work addition updates performed cost updates factor sd-esm update incurs cost function call cpu overhead section performance difference sl-esm sd-esm approximately cases figure showing worthwhile diff byte blocks copied sub-page diffing scheme lastly figure shows transaction update atomic parts composite part throughput begins level clients systems wpl showing increase throughput clients figure shows response time results traversal response time pd-esm pd-redo wpl change significantly relative systems applications update objects dereferencing normal virtual memory pointers performance sd-esm sl-esm seconds slower independent number clients due higher cost performing updates systems overhead performing updates significant total additional updates performed transaction relative performance pd-esm client clients faster performance sd-esm figure throughput results shown similar deduced response time results figure addition number pages total pages log record pages client server figure constrained cache results section presents results obtained running systems restricted amount memory client previous section small database client megabytes memory caching persistent data systems diffing allocated client buffer pool recovery buffer allocation memory results client buffer pool large avoid paging performance wpl previous section insufficient space recovery buffer hold data required diffing schemes commit time figures show response time throughput traversal constrained case sd-esm performance figure sd-esm faster pd-esm faster wpl clients pd-esm slower sdesm case experiences contention recovery buffer pd-esm generate times pages 
providing missing updates occur log updates applied log time checkpoint write page lrc restart commit transaction lsn lrc dirty lrc dirty lrc dirty lrc dirty lrc client buffer server buffer page state stable storage error update lrc lost figure lost update due missed dirty pages page condition holds case problem arises recent image dirty page lost crash problem missing dirty pages arises committed transactions solve problem logging dirty page information transaction commit time client sends dirty page server page recoverylsn added list dirty pages transaction page flushed stable storage removed list refer list commit dirty page list logging commit record transaction server logs contents list committing transaction restart analysis commit dirty page list encountered page appears list added recoverylsns dirty page table entry table alternative solution considered log receipt dirty pages server similar logging buffer operations lind restart analysis add pages encountered log records dirty page table solution correct felt additional log overhead normal operation prove unacceptable investigated solutions involved clients checkpointing process solutions rejected violate system design constraint prohibits server depending clients crucial functions determining begin redo pass final problem addressed section determining proper point log begin redo recall aries lsn begin redo called firstlsn determined minimum recoverylsns pages dirty page table end analysis phase page dirty time checkpoint updates logged prior checkpoint reflected copy page stable storage safe begin redo page log record page encountered analysis earlier note safe begin earlier redo conditional earlier operations redone page-server environment case scenario shown figure transaction logged updates page page log record arrived server checkpoint arrived checkpoint dirty page effects updates shipped client server checkpoint page dirty page table recorded checkpoint server crashes point shown figure restart analysis log record lrc encountered page added dirty page table lsn record recoverylsn lsn starting redo page point result lrc redone lrc applied leave page inconsistent state pages dirtied transaction eventually commits commit dirty page list section conservative recoverylsns insure redo begin proper point log pages pages dirtied transaction commit dirty page table recorded recent checkpoint recoverylsn dirty page table entry valid problem addressed pages pages dirtied transaction commit added dirty page table analysis pass shown figure solve problem conservative approximation solution requires transaction table structure section recorded checkpoint log time checkpoint write page lrc restart lsn client buffer server buffer lrc dirty lrc dirty lrc dirty dirty dirty page state lrc dirty lrc write page lrc lrc dirty lrc stable storage attempt redo lrc error figure inconsistent redo due missed log record augmented include field lsn generated transaction called startlsn analysis page added dirty page table marked newly added page tagged transaction transaction caused considered dirty end analysis entries pages added dirty page table due update uncommitted transaction recoverylsn replaced transaction startlsn conservative approximation results correct behavior extra redo pages read stable storage determine logged update redone number pages conservative approximation required small taking checkpoints recall aries checkpoints fairly inexpensive require data pages forced quiescing operations summary algorithm preceding discussion fairly detailed resulting algorithm requires aries algorithm normal operation transaction added transaction table lsn log record generated transaction entered transaction startlsn client estimate current end-of-log lsn estimate updated receipt message server data index page arrives client pagelrc page initialized estimated end-of-log lsn page marked dirty result initialization client performs update page increments pagelrc page places pagelrc log record update page marked dirty current estimated end-of-log lsn entered recoverylsn page buffer control information client server performs update page places lsn log record generates pagelrc page log record update page marked dirty lsn entered recoverylsn page buffer control information server client sends dirty page server includes page recoverylsn message server receives dirty page client page added list dirty pages transaction dirtied transaction commits list logged commit dirty page list transaction restart analysis transaction added transaction table result encountering log record lsn log record entered transaction startlsn commit log record encountered pages commit dirty page list added dirty page table recoverylsn dirty page table entry page set minimum recoverylsn page dirty page table commit dirty page list end analysis pages added dirty page table analysis pass due log records generated non-committing transactions conservative recoverylsn recoverylsn startlsn transaction caused page considered dirty restart redo pass restart algorithm unchanged lrcs comparisons log records pages lsns undo restart rollback undo log record lrc stored record compared pagelrc affected page log record lrc greater equal pagelrc actual undo performed fake undo performed actual undo performed logging clr undone operation performing undo page placing lsn clr pagelrc affected page fake undo performed simply logging clr undone operation page modified marked dirty pagelrc page unaffected fake undo performance section describe initial study performance logging recovery subsystems esm-cs investigate overhead logging transaction types examine relative costs components logging discuss costs reduced finally present performance measurements transaction rollback restart recovery performance experiments section run sparcstation elcs memory running version sunos operating system client server processes run separate machines machines located isolated ethernet network client server software compiled optimization log database stored separate disks raw disk partitions remove operating system buffering log page size database page size times obtained gettimeofday getrusage system calls reported seconds page fault swapping operating system events recorded getrusage checked ensure activity minimal distort performance results logging experiments set experiments investigated overhead imposed transactions logging subsystem normal operation databases experiments table databases initially data pages approximately full database consists physical space describe results types transactions applied databases transaction type write sequentially scans database writes updates half bytes object updating total data transaction type insert sequentially scans database inserts data beginning object increase size resulting insertion data insert increase number pages database page free space accommodate inserted data write transactions log data insert transactions log inserted data table shows results running experiments logging experiments server buffer pool mbytes entire database cached server buffer pool experiment run client buffer pool mbytes entire database fits client buffer pool transaction section inter-transaction caching supported client buffer pool empty beginning transaction large buffer pools order isolate effects logging removing sources variability disk making logging significant part total work performed tests write-intensiveness transactions accentuates impact logging normal 
composed large number clusters pages mapping tables maintained individual clusters database bigger virtual memory distributed virtual frame pages database case pages relocated brought memory page relocations problem pages cluster accessed application mapping information cluster date read rest pages cluster update consistent mapping multiple versions mapping information version pages mapping changed pages mapping versions mapping information stored scheme worse storing mapping information individual pages buffer pool management buffer managers traditional database systems typically lru algorithm clock style algorithm approximates lru page replacement policy felt clock algorithm choice quickstore implementing type scheme turned difficult context memory-mapped system objects buffer pool accessed dereferencing virtual memory pointers reason information buffer manager indicating pages accessed recently recall traditional implementation clock bit frame buffer pool frame accessed clock hand swept bit set database system time page accessed reset clock algorithm set flag dereferencing pointer quickstore solution problem clock algorithm access-protect virtual frame buffer pool frame clock hand reaches frame subsequently reaccessed page-fault occur fault handling routine re-enable access page scheme replaces usual setting unsetting bits traditional clock algorithm enabling disabling access permissions virtual memory frames experimented solution experience extra overhead manipulating page protections handling additional page-faults made approach prohibitively expensive terms performance avoid problem quickstore simplified clock algorithm scheme clock hand begins sweep stopped previous invocation algorithm clock hand reaches page access enabled algorithm selects page replacement clock hand reaches end buffer pool finding candidate replacement entire virtual address space process persistent data reprotected single call mmap algorithm restarted clock hand begins scanning starting frame buffer pool scheme performed original scheme outlined experiments compared favorably traditional clock replacement algorithm section recovery implementing recovery updates poses special problems context memory-mapped scheme application programs update objects dereferencing virtual memory pointers difficult portions objects modified require logging desirable batch effects updates log applications update object times transaction due considerations mentioned decided page diffing scheme generate log records objects updated quickstore virtual memory frames mapped pages database updated write access enabled attempt application program update object page page-fault fault-handler detects access violation due write attempt copies original values contained objects page in-memory area called recovery buffer fault-handler obtains exclusive lock page esm needed enables write access virtual frame caused fault returning control application application program update objects page directly buffer pool transaction commit time paging buffer pool occurs recovery buffer full values objects contained heap updated values objects buffer pool compared diffed determine log records generated log records created managed normal recovery services provided esm frank processes diffing generating log records interleaved quickstore understand case byte k-byte object updated case minimizes amount data written log generating log records modified byte big log record entire object hand bytes modified generate single log record bytes object cheaper generating multiple log records log record large byte header area storing information needed esm recovery scheme algorithm minimizes amount data written log deciding generate log records individual modified regions object combine regions log single unit fairly straight forward discussed detail takes account things number bytes separating modified regions object size log records generated make decision care processing updates update mapping tables modified page recall mapping table page track set pages referred pointers page updates objects page change pages members set making update mapping tables updating mapping table page requires pointer contained page examined in-memory table consulted determine page database bitmap page locate pointers pointers set referenced pages constructed set compared element element set set changed mapping object page updated reflect set referenced pages performance experiments section describes structure benchmark database benchmark operations included performance study hardware software systems included study discussed include description current implementation programming language aid understanding performance results presented section benchmark database database intended suggestive cad cam case applications sizes database small medium table summarizes parameters database key component database set composite parts composite part intended suggest design primitive register cell vlsi cad application number composite parts module controlled parameter numcomppermodule set composite part number attributes including integer attributes builddate composite part document object models small amount documentation composite part document integer attribute small character attribute title character string attribute text length string attribute controlled parameter documentsize parameter small medium numatomicpercomp numconnperatomic documentsize bytes manual size bytes numcomppermodule numassmperassm numassmlevels numcompperassm nummodules table benchmark database parameters composite part graph atomic parts intuitively atomic parts composite part units composite part constructed atomic part composite part graph designated root part small database composite part graph atomic parts medium database composite part graph atomic parts atomic part integer attributes builddate docid builddate values atomic parts randomly chosen range minatomicdate maxatomicdate atomic part connected bi-directional association atomic parts parameter numconnperatomic connections atomic parts implemented interposing information-bearing connection object pair connected atomic parts connection object integer field length short character array type figure depicts composite part document object graph atomic parts type typenumber builddate title widget docs text widget doesn put spec docid documentation figure composite part document object design library composite parts base assemblies complex assemblies manual text type builddate manual design root module figure structure module additional structure imposed set composite parts structure called assembly hierarchy assembly made composite parts case base assembly made assembly objects case complex assembly level assembly hierarchy consists base assembly objects base assembly objects integer attributes builddate base assembly bi-directional association composite parts chosen random set composite parts higher levels assembly hierarchy made complex assemblies complex assembly bi-directional association subassemblies base assemblies complex assembly level assembly hierarchy complex assemblies complex assembly higher hierarchy levels assembly hierarchy assembly hierarchy called module modules intended model largest subunits database application modules scalar attributes module manual object larger version document manuals included testing handling large simple objects figure roughly depicts full structure single user benchmark database picture misleading terms shape scale actual assembly fanout assemblies small medium databases compared atomic parts small database atomic parts medium database benchmark operations section describes benchmark operations study operations omitted didn highlight additional differences systems compared operations referred type number consist set tests termed traversals set query tests queries hand coded quickstore provide declarative query language comment implementation execute queries part specification carey traversals traversal performs depth-first traversal 
log records average transaction sd-esm figure wpl competitive performance number clients low worst performance clients performance wpl degrades faster performance systems update atomic parts composite part times clients throughput trans min wpl pd-esm sd-esm pd-redo figure small constrained cache client page writes total writes log writes wpl pd-esm sd-esm pdredo wpl pd-esm sd-esm pd-redo figure client writes small constrained cache server performance limiting factor wpl hand diffing schemes benefit ability perform work clients scale performance pd-redo appears approaching sd-esm number clients increases pd-redo scales systems suffer overhead shipping dirty pages back server pd-redo performance clients slower sd-esm clients throughput results shown figure show transaction throughput increases systems wpl saturated number clients increases sd-esm pd-redo show biggest increases throughput throughput sd-esm increases times number clients increased throughput pd-redo increases factor turn figures show response time throughput traversal wpl performance client faster sd-esm performer clients sd-esm performance clients sd-esm faster wpl sd-esm scales wpl performs recovery work clients wpl relies heavily server page diffing systems pd-esm pd-redo worst performance figure reason figure shows number page writes transaction systems figure pd-esm produces times log pages transaction sdesm addition number log pages produced pd-esm approaching number pages written log transaction wpl due high level contention recovery buffer pd-esm pd-redo slightly faster pd-esm number clients low clients pd-esm performance pd-redo scale pd-esm figure cpu overhead applying log records server pd-redo results shown experiment similar results difference times sd-esm consistently slower seconds relative times big database results section results experiments run big database experiments systems memory client caching persistent data systems diffing alternative strategies partitioning memory client buffer pool recovery buffer explored systems memory client buffer pool remaining recovery buffer allocated buffer pool recovery buffer figure shows average response time system performing traversal surprisingly wpl fastest response time number clients clients pd-esmhas performance pd-esmis faster wpl clients wpl fast performance experiment devote memory clients buffer pool decreasing amount paging system lessening burden server server log disk bottleneck wpl number clients increases eventually pd-esmperforms previous experiments diffing scheme pd-esmappears scale makes clients aggregate processing power lessen burden server log disk cpu comparing performance pd-esmand pd-esmin figure shows importance choosing good division memory client buffer pool recovery buffer pd-esmhas performance pd-esmwhen client multiple clients paging client server expensive pdesm- faster figure shows systems smaller client buffers pool begin thrash significantly clients throughput pd-esmcontinues increase number clients increases increase small clients interestingly difference performance pdesm- sd-esmin figure significant amount paging client buffer pool figure paging buffer pool systems time clients responsetime seconds pd-esmpd-esm- sd-esmwpl pd-redofigure big database clients throughput trans min pd-esmpd-esm- sd-esmwpl pd-redo figure big database clients responsetime seconds big database pd-esmpd-esm- sd-esmwpl pd-redofigure big database clients throughput trans min pd-esmpd-esm- sd-esmwpl pd-redofigure big database modified page replaced client buffer pool number log records generated pd-esmand sd-esmthus sub-page diffing save terms number log records generated figure small constrained experiment figure fact sd-esmonly generates fewer log records pd-esmin figure opposed generating fewer log records figure finally note pd-redois competitive pd-esmwhen fewer clients performance grades quickly systems number clients increases larger number pages reread disk server pd-redoas number clients increases log records describing updates pages applied comparing results shown figure figure relative performance systems dense updates sparse updates similar big database wpl relative pd-esmdur- ing updates larger number objects page causing pd-esmto generate log records pd-esmscales systems including wpl performance pd-esmappears surpass wpl clients performance sd-esmand pd-esmis identical figure figure sdesm- generates log records pd-esmand savings client cpu cost provided sd-esmfor performing diffing copying work provide noticeable benefit terms performance scalability redo algorithm worst figure sparse update case figure clients pd-redois slower pd-esmfigure shows throughput dense traversal run big database surprisingly throughput results dense traversal similar sparse traversal figure figure highlights fact systems larger client buffer pool wpl pd-esmscale systems smaller buffer pools sd-esmpd- esmpd-redo- avoiding paging client server big database important achieving good performance avoiding generation additional log records pd-esmand wpl wpl large client buffer pool begins thrash clients server performance bottleneck related work section discusses related work design implementation recovery algorithms client-server database systems compare study presented studies dealt issue recovery performance frank describes design implementation crash recovery exodus storage manager esm addition frank discusses issues addressed implementing recovery client-server environment recovery algorithm frank based aries mohan supports write-ahead-logging steal force buffer management policy server esm requires dirty pages shipped client server transaction commits termed policy note esm addresses recovery issues raised client server architecture address issues discussed section issues specific object-oriented systems memory-mapped stores recently mohan presented algorithm termed aries csa extends basic aries recovery algorithm client-server environment aries csa differs esm supports fine-granularity locking esm aries csa supports unconditional undo difference approaches clients aries csa checkpoints addition checkpoints server esm checkpoints performed server principle recovery techniques section esm conjunction aries csa clear features finegranularity locking supported aries csa memory-mapped storage system quickstore memory-mapped approach inherently page-based related study recovery performance appears hoski study presented hoski differs study presented concerned alternative methods detecting recording occurrence updates issues examine strategies processing log records client-server environment ariesbased schemes whole-page logging redo-at-server interesting note study presented results differ substantially results presented hoski variation results undoubtedly due architectural differences systems examined studies hoski transaction log located client machine server esm advantage locating log server esm increases system availability client crashes server continue processing requests clients placing log server impacts performance log records clients server network written disk differences alternative techniques generating log records smaller system log located server system log records written disk client reasons differences results implementation details hoski study examine tradeoffs involved detecting occurrence updates software versus virtual memory hardware support hoski copy architecture objects copied one-at-a-time accessed client buffer pool separate area memory called object cache hardware-based recovery scheme hoski requires virtual memory page object cache hold object unprotected reprotected time object copied page producing substantial amount overhead read-only transactions approach quickstore in-place access page-at-a-time swizzling page protection manipulated object page updated results show hardware-based detection scheme results presented hoski scheme quickstore impact performance read-only transactions hoski examines schemes termed card marking similar sub-page approach examined results presented 
operation reasons overhead logging reflected table higher database objects object objects pages database size bytes page fewlarge somemedium manysmall table description experimental databases experiment number operation execution time sec logging operations size bytes logging logging write fewlarge write somemedium write manysmall insert fewlarge insert somemedium table results logging experiments data cached server show results running insert manysmall database overhead object headers inserts applied objects page forward objects pages database expected actual application numbers presented table obtained running transaction times taking average runs experiment report total execution time transaction logging turned logging turned total comprises time initiate execute terminate commit transaction including time send dirty pages server approximately seconds cases final column shows execution time overhead incurred due logging shown table overhead logging varied substantially transactions transaction types overhead logging increased number operations log records generated amount actual data updated remained constant increase due size overhead added log record esm-cs overhead bytes bytes record header bytes operation information result overhead number log pages generated written increased considerably larger number smaller operations performed transaction operations write fewlarge experiment generated log records log pages operations write manysmall experiment generated log records log pages comparing transaction types logging time overhead insert tests write tests time overhead insert fewlarge compared write fewlarge difference insert logs inserted data write logs images resulting larger volume logged data write order understand cost logging esm-cs analyzed cost components logging shown table logging time broken parts generating log records client shipping pages log records client server writing log pages server buffer log disk obtain breakdown altered esm-cs logging components selectively turned log record generation time calculated computing difference running transactions log generation turned running logging turned shipping writing log pages occur parallel client server activity costs measured ways separately measure actual time ship write number pages columns labeled actual results measurements selectively turn shipping writing log pages compute differences time observed client times shown columns labeled observed reflect previously mentioned experiment generate ship write total records log pages log pages overhead observed actual observed actual observed write fewlarge write somemedium write manysmall insert fewlarge insert somemedium table logging cost breakdown seconds parallelism results table shown graphically figure figure area white represents time perform transaction logging expected actual costs significant overhead factor writing log records disk shipping log pages server time write pages disk cost generating log records small fewlarge cases significant transactions generated log records occurred number log records generated increased faster rate number log pages client point view observed cost shipping significant writing cost writing performed parallel client server activity principle shipping log pages performed parallel activity compute time transactions small tests network busy client data page lock requests shipping log pages server compete network shipping data pages client exception write manysmall case case significant compute time due generation log records log page shipping performed parallel generation log records comparable published performance results logging systems difficult find results write-intensive experiments lead conclude performance initial logging implementation reasonable numbers areas improvement clear results reducing amount logged information result significant performance improvements small updates current log record overhead size bytes slightly larger typical log record header size approximately bytes gray sufficient coding effort esm-cs log record overhead reduced bytes smaller approach reduce number log records generated special cases write manysmall objects page updated logging entire pages clear performing shipping writing log pages parallel activity observed cost logging reduced considerably write-intensive transactions algorithms exploit parallelism investigated logging cost components log writing log shipping log generation transaction time measurement act actual obsv observed act act act act act obsv obsv obsv obsv obsv w-fewlg w-somemed w-manysm i-fewlg i-somemed time sec figure actual observed logging costs transaction rollback recovery performance addition logging experiments previously ran simple experiments gain insight performance rollback recovery experiments databases write transactions previous section table shows results experiments comparison purposes shows execution times transactions logging turned table measure cost transaction rollback aborted transaction dirty pages log records shipped back server experiment rollback perform data pages database cached server buffer restart recovery show time required analysis redo phases server forced crash immediately transaction committed server buffer large store entire database data pages written stable storage prior crash data pages reread disk recovery transaction rollback results primarily determined time read log generate compensation log records write log records disk cost performing undo operations seconds longest case compensation log records write operations require redo information logged clrs undone clrs writes half operation information normal write log records fine granularity updates write manysmall case results log space log record headers undoing write fewlarge case generated half log pages original transaction undoing write manysmall case required log space original transaction generation compensation log records results significant log disk arm movement records appended log rollback scan log backwards disk arm movement expensive write manysmall case amount compensation log space generated greater excessive disk arm movement problem long-running write-intensive transactions esm-cs designed support object-oriented database systems type transaction encountered plan reduce disk arm movement batching newly written log pages writing groups restart tests showed significant increase cost analysis redo phases volume log data increased note checkpoints tests analysis phase scanned entire log access data pages analysis times improved taking frequent checkpoints redo phase scanned log read data pages stable storage cost performing redo operations small reduce experiment execution rollback analysis redo time time time write fewlarge write somemedium write manysmall table rollback recovery times seconds cost restart recently mru buffering lru log pages analysis pass redo scans log direction analysis phases restart improved prefetching log pages pages dirty page table restart improvements made transaction rollback system restart performance current implementation acceptable related work section describe related work including extensions aries algorithm recovery algorithms proposed shared-disk architectures recovery distributed transaction facilities recovery page-server object-server systems aries rrh extensions recent aries rrh restricted repeating history algorithm relaxes aries requirement history repeated transactions restart redo conditions explained updates transactions progress time crash redone restart restricted repeating history requires notion conditional undo aries rrh writes clr undo operation includes lsn record undone called undonelsn clr subsequent redo pass event crash clrs 
assembly hierarchy base assembly visited composite parts visited depth-first search graph atomic parts performed traversal returns count number atomic parts visited additional work traversal traversal similar visiting entire graph atomic parts composite part visits root atomic part returns similar include updates traversal increments attributes contained atomic parts update root atomic part composite part update atomic parts composite part update atomic parts composite part times traversals similar builddate field atomic parts incremented field indexed highlights cost updates indexed fields traversals based picks random atomic part traverses root design hierarchy scans manual object module counts occurrences character compares characters manual carey specifies attributes swapped increment multiple updates object change object guarantees diffing scheme recovery quickstore generate log record queries query randomly retrieves atomic parts index based part selects recent atomic parts based builddate recent queries index scan find parts query document objects random index title field visits base assemblies composite part document traversing pointers documents composite parts processing collection pointers base assemblies maintained part composite part object referred single level make operation finds base assemblies composite part build date build date base assembly implemented nested loops pointer join base assemblies composite parts iterates collection base assemblies maintained module base assembly object visited composite parts traversed hardware test vehicle pair sun workstations isolated ethernet sun ipx workstation configured megabytes memory megabyte disk drives model sun gigabyte disk drive model sun server sun hold system software swap space sun drive esm hold database sun drive hold esm transaction log data recovery disks configured raw disks client sun sparc elc workstation mips configured megabytes memory megabyte disk drive model sun disk drive hold system software swap device software systems examined study esm provide disk storage persistent objects esm files untyped objects arbitrary size b-tree indices esm page-server architecture client processes request pages server tcp server satisfy request buffer pool disk initiated invoking disk process perform actual operation disk process read page server process returns requesting client process copy buffer pool esm concurrency control recovery services locking provided page file levels special nonpl protocol index pages recovery based logging changed portions objects esm disk page size k-bytes unit transfer client server client server buffer pools set pages mbytes pages mbytes release sunos run workstations experiments quickstore compiled gnu com- piler compiler modified version gnu compiler database systems tested section briefly describes current implementation language quickstore offer basically functionality implements persistence software interpreter epvm epvm functional interface operations dereferencing unswizzled pointer handled calling epvm function perform dereference part handling persistent object epvm turn call esm page object memory update internal data structures returning control application addition calls epvm functions code generated compiler modified version gnu compiler in-line code sequences handle basic operations residency checks dereferences swizzled pointers in-line require function call improves performance quickstore epvm accesses memory-resident persistent objects directly esm client buffer pool interpreter maintains hash table entry page objects memory pointer swizzling scheme epvm similar scheme epvm schuh swizzled pointers point directly objects buffer pool swizzling scheme swizzles pointers local variables functions pointers persistent objects swizzled makes page replacement buffer pool difficult white update operations persistent objects handled interpreter function epvm update scheme copies original values objects side buffer updates objects place buffer pool original values objects updated values generate log records transaction commit sooner side buffer buffer pool full diffing performed quickstore epvm employs scheme breaks large objects chunks logging purposes objects smaller logged entirety quickstore detailed description quickstore section quickstore offer functionality important point fundamental systems differ degree systems support notion object identity khosh section scheme quickstore implement mapping virtual memory frames disk pages mapping maintained pages memory reside disk mapping pointers persistent objects viewed virtual frame offset pair high order bits pointer identify virtual memory frame referenced pointer low order bits offset frame virtual memory frames mapped disk pages pointers offsets locations pages scheme doesn support object identity object outstanding deleted page contained object faulted memory subsequent program runs mapped virtual memory frame program dereferences dangling pointers deleted object error explicitly flagged object occupies overlaps space page previously deleted object dangling pointers object quickstore doesn fully support object identity checked objects overhead prohibitive meta-data required associate unique pointer page oid order magnitude greater current scheme quickstore aware commercial research system including objectstore supports types normal pointers context memory-mapped scheme hand supports object identity fully including checked implements storing pointers full byte oids objects reasonable approach incur costs objects larger quickstore database larger generally performs result dereferencing big pointers expensive terms cpu requirements dereferencing regular virtual memory pointers differences included system performance study system identical quickstore size object padded object comparing performance system performance experiments faults place insight overhead faulting memory-mapped approach comparing quickstore advantage gained quickstore due smaller object size addition system approximating performance hybrid memory-mapped scheme large pointers embedded objects supporting checked unchecked performance results database sizes size database important understanding performance results table shows database sizes quickstore quickstore big objects qs-b database roughly big database objects qs-b padded size objects implementation small medium cases schemes systems store pointers qs-b database slightly bigger database due overhead storing bitmaps locations pointers pages mapping objects mapping objects accounted approximately database size qs-b bitmaps generally accounted additional small medium qs-b table database sizes megabytes small cold results section presents cold results small database experiments cold results obtained running benchmark operations data cached memory client server machines times presented represent average runs benchmark operations noted times computed calling unix function getimeofday granularity microseconds client machine read-only results figure table list cold response times number client requests read-only traversals figure shows faster difference performance largely due smaller database size read fewer pages disk table activity resulted reading clusters composite parts composite part cluster occupied page pages required accounts roughly ratio number disk reads systems comparing qs-b qs-b slower qs-b issues slightly requests qs-b read mapping objects support memory-mapped scheme performance difference largely due number disk reads system performs table shows amount number disk reads decreases due size difference composite part dfs assembly hierarchy visiting atomic parts atomic part objects connection objects composite part clustered disk composite 
hoski show size sub-page region recovery great impact performance difference performance reported hoski due fact small sub-page unit recovery reduce diffing costs updates sparse results presented study hand show size sub-page blocks important savings cpu costs block size small smaller block sizes result generation fewer log records space recovery buffer tight hoski case differences results due fact in-place scheme hoski copy approach cost supporting concurrency control system examined hoski single user system support concurrency study presented differs hoski examine scalability recovery schemes number clients accessing database increases examine performance recovery techniques large database significant amount paging object replacement taking place system hoski issues note performance study contained white results recovery performance systems compared white objectstore exodus built underlying storage manager accurately measure performance differences due recovery white oodbmss commercially published recovery algorithms system deux aries-based approach support recovery differs esm aries csa shadowing avoid undo popular commercial oodbms objectstore lamb quickstore memory-mapping scheme give application programs access persistent data objectstore whole-page logging support recovery basic idea approach dirty pages shipped client server written log transaction allowed commit differs aries-based schemes mentioned require log records generated updates written disk commit time wilso describes texas storage manager memory-mapping scheme wilso propose differencing detect updates persistent data finally note whole-page logging approach recovery elhar presents design database cache conclusions paper presented in-depth comparison performance approaches implementing recovery quickstore memory-mapped storage manager based client-server page-shipping architecture recovery algorithms designed meet unique performance requirements faced system quickstore results performance study show diffing generate log records updates clients generally superior terms performance page logging diffing approach takes advantage aggregate cpu power clients lessen burden server support recovery scalability prevents server performance bottleneck quickly number clients accessing database increases study compared performance underlying recovery schemes diffing algorithms based included recovery algorithm exodus storage manager simplified scheme termed redoat-server redo redo approach provided significant performance benefits cases small database producing moderate number log records transaction failed perform database bigger server buffer pool volume log records server transaction high results presented study show redo suffer disk cpu bottlenecks server system builders decide simplifications system design coding worth poor scalability redo situations finally study compared performance page-based sub-page diffing techniques surprisingly sub-page diffing techniques provided advantage terms performance page-based approach apparently due fact diffing inexpensive operation compared costs involved system network disk access costs sub-page diffing approach pay situation amount memory devoted recovery low system designers decide situation arise practice justify sub-page diffing addition shown sub-page diffing worse performance page-diffing updates performed repeatedly fact weighed mild advantages technique deciding implementation strategy finally results showed diffing worthwhile sub-page granularity recovery systems sub-page granularity diffing comparable worse performance systems diffing future explore improvements recovery schemes based differencing diffing approach enhanced adapt dynamic workload class techniques explore involves dynamically varying amount memory allocated buffer pool recovery buffer client transactions carey carey storage management objects exodus object-oriented concepts databases applications kim lochovsky eds addison-wesley carey carey dewitt naughton benchmark proc acm sigmod conf washington carey carey dewitt franklin hall mcauliffe naughton schuh solomon tan tsatalos white zwilling shoring persistent applications proc acm sigmod conf minneapolis dewitt dewitt futtersack maier velez study alternative workstation-server architectures object-oriented database systems proc vldb conf brisbane australia august deux deux system comm acm vol october elhar elhardt bayer database cache high performance fast restart database systems acm trans database sys december frank franklin crash recovery client-server exodus proc acm sigmod conf san diego california frank franklin caching memory management client-server database systems thesis wisconsin-madison tech report july haerd haerder reuter principles transaction oriented database recovery taxonomy computing surveys vol february hoski hosking brown moss update logging persistent programming languages comparative performance evaluation proc vldb conf dublin ireland lamb lamb landis orenstein weinreb objectstore database system comm acm vol october mohan mohan haderle lindsay pirahesh schwartz aries transaction recovery method supporting fine-granularity locking partial rollbacks writeahead logging acm trans database sys vol march mohan mohan narang aries csa method database recovery client-server architectures proc acm sigmod conf minneapolis moss eliot moss working persistent objects swizzle swizzle ieee trans software eng august rich richardson carey schuh design programming language acm trans prog lang sys vol july schuh schuh carey dewitt persistence experiences implementing persistent object bases principles practice proc int workshop pers obj sys martha vineyard sept white white dewitt performance study alternative object faulting pointer swizzling strategies proc vldb conf vancouver british columbia august white white dewitt quickstore high performance mapped object store proc acm sigmod conf minneapolis wilso wilson kakkad pointer swizzling page fault time efficiently compatibly supporting huge address spaces standard hardware proc int workshop obj orientation operating sys paris france sept acknowledgements people wisconsin helped build exodus storage manager special mike zwilling patiently answered questions exodus working paper tan provided valuable advice implement redo-atserver algorithm 
redone undonelsn stored clr equal pagelsn affected page aries rrh esm-cs clrs written undo operations applied unlike esm-cs fake clrs needed correctness fake clrs aries rrh simplify media recovery differences aries rrh esm-cs conditional undo result fact aries rrh designed enhance performance aries restart esm-cs conditional undo developed order correctly implement transaction rollback page-server system conditional undo option aries requirement esm-cs aries rrh avoid redoing work redo esm-cs benefit including full rrh support extension require slight modifications existing system recovery shared-disk systems shared-disk system bhid multiple processing nodes memory share common pool disks communicate messages environment similarities page-server environment include multiple processing nodes shared memory data operations transaction performed single processing node database partitioned respect processing nodes important differences environments include page-server asymmetric environment capabilities clients capabilities server clients diskless workstations clients inherently unreliable tend individual offices homes machine room concurrently activities database access synchronized clock cheaply processors system clients servers connected slower links nodes shared disk system server potential bottleneck responsible providing database access locking logging services clients aries shared disk extensions aries extended shared disk environment recent papers mnp addresses problems migrating single-site database system shared disk environment problem relevant work lack monotonically increasing lsns due separate log node system solution store update sequence numbers usns pages lsns usns initialized based clock time page formatted requiring clocks synchronized acceptable implementation-dependent limit aspects solution depend fact system log maintain information physical lsns buffer pool recovery lrcs solve similar problem esm-cs due lack synchronized clocks local logs solution estimated end-of-log lsn approximate recoverylsns section protocols discussed transferring pages nodes shared-disk system node log protocols transfer page nodes writing page disk protocols subject recovery issues similar arise esm-cs node log records page dirty node protocols page dirtied lock exists global lock manager glm implement recovery glm entries extended lsn information recoverylsn page fact recoverylsn approximation based end-of-log lsn node requesting lock disadvantages implementing similar solution page-server system glm store dirty page information negate performance benefits coarse-grained file-level locking coarse-grained locking provided option esm-cs performance enhancement systems vaxcluster version rdb vms josh solution preclude non-centralized locking algorithms page-server environment cfls shown papers overhead centralized locking page-server environment major performance impact workloads locking protocols finegrained record-level locking data-sharing system similar ideas finegrained locking esm-cs shared disk algorithms lome describes algorithm recovery systems multiple logs algorithm stores previous state identifier updated page similar pagelsn pagelrc log record update allowing logs easily merged redo algorithm require synchronized clocks prove client-server environment clients perform logging section chose implement client logging reasons including unreliability clients compared server expense extra client disks lome acknowledges reliability problem suggests approaches addressing algorithm recovery shared-disk systems multiple logs presented rahm algorithm defined steal buffer management policy logging redo algorithm differs previously assigns responsibility recovery partitions database systems algorithm depends individual logs systems require substantial communication expensive client-server system perform redo failed node recovery distributed transaction facilities recovery concern systems provide general transaction support network computing environment systems include distributed logging facility cmu camelot dst ibm almaden quicksilver system hmsc intended run hardware environment similar esm-cs designed systems fundamentally software architectures esm-cs systems attempt shield clients details recovery making servers primarily responsible logging recovery esm-cs hand takes approach distributing logging work clients perform data operations approach consistent page-server architecture esm-cs attempts exploit resources clients order offload work server steal force buffer management policy esm-cs efficient client server memory resources server disk resources support steal force enabled techniques section recovery page-server object-server architectures stated earlier written systems implement page-server objectserver architectures details recovery systems provided due part fact systems commercial systems proprietary implementations system deux employs aries-based approach shadowing order avoid undo orionsx system object-server version orion kgbw force policy undo log unaware systems implemented steal force policy page-server object-server system conclusions paper problems arise implementing recovery page-server environment presented recovery method addresses problems recovery method designed goal minimizing impact recovery-related overhead normal processing providing reasonable rollback system restart times method supports efficient buffer management policies flexibility interaction clients server clients off-load server performing work involved generating log records implementation method esm-cs presented measurements impact recovery normal operation performance rollback system restart compared work related systems algorithm proposals measurements obtained promising overhead cases reasonable study raised issues addressed order improve performance system issues include reducing log record size batching writes log disk prefetching log recovery exploiting additional parallelism logging operations server operations client normal processing additional studies realistic workloads required order obtain understanding performance impact logging recovery subsystems addition plan extend recovery system include media recovery restricted repeating history redo support inter-transaction caching finally work raised number interesting possibilities alternative recovery system designs plan investigate performance tradeoffs alternatives acknowledgements mohan number informative discussions aries algorithm suggesting improvements made implementation simpler dave haight initial work converting original exodus storage manager single-site client-server system nancy hall zack helped build version system praveen seshadri provided helpful comments earlier draft paper bhg bernstein hadzilacos goodman concurrency control recovery database systems addison-wesley bhid bhide analysis transaction processing architectures proc vldb conf los angeles aug catt cattell engineering database benchmark benchmark handbook database transaction processing systems gray morgan kaufmann cdrs carey dewitt richardson shekita storage management objects exodus object-oriented concepts databases applications kim lochovsky eds addisonwesley cfls carey franklin livny shekita data caching tradeoffs client-server dbms architectures proc acm sigmod int conf management data denver june comm committee advanced dbms function generation data base system manifesto sigmod record vol sept dfmv dewitt futtersack maier velez study alternative workstation-server architectures object-oriented database systems proc vldb conf brisbane australia aug dst daniels spector thompson distributed logging transaction processing proc acm sigmod int conf management data san francisco deux deux system cacm vol oct exod exodus project group exodus storage manager architectural overview exodus project document wisconsin madison nov exod exodus project group exodus storage manager exodus project document wisconsin madison nov gray gray notes data base operating systems operating systems advanced bayer graham seegmuller eds springer-verlag gray gray recovery manager system database manager acm computing surveys vol june gray gray personal communication december gray reuter transaction processing concepts techniques morgan kaufmann 
san mateo hmsc haskin malachi sawdon chan recovery management quicksilver acm transactions computer systems vol february haerder reuter principles transaction oriented database recovery taxonomy computing surveys vol december josh joshi adaptive locking strategies multi-node data sharing environment proc int conference large data bases barcelona september kgbw kim garza ballou woelk architecture orion next-generation database system ieee transactions knowledge data engineering vol march lind lindsay notes distributed databases ibm research report san jose july llow lamb landis orenstein weinreb objectstore database system cacm vol oct lome lomet recovery shared disk systems multiple redo logs technical report crl dec cambridge research lab cambridge oct moha mohan haderle lindsay pirahesh schwarz aries transaction method supporting fine-granularity locking partial rollbacks write-ahead logging ibm research report ibm almaden research center november acm transactions database systems mohan narang recovery coherency-control protocols fast intersystem page transfer fine-granularity locking shared disks transaction environment proc int conference large data bases barcelona september mnp mohan narang palmer case study problems migrating distributed computing page recovery multiple logs shared disks environment ibm research report ibm almaden research center march mohan pirahesh aries-rrh restricted repeating history aries recovery method proc int conference data engineering kobe april rahm rahm recovery concepts data sharing systems proc int symposium faulttolerant computing montreal june richardson carey persistence language issues implementation software practice experience vol dec rcs richardson carey schuh design programming language submitted ston stonebraker architecture future data base systems data engineering vol dec wang rowe cache consistency concurrency control client server dbms architecture proc acm sigmod int conf management data denver june 
part object implementation dfs assembly hierarchy visiting root atomic part response time seconds qs-b figure traversal cold times small database qs-b table client requests traversals small database clusters systems noticeably fewer operations unlike generally doesn read entire clusters performance qs-b slower detailed faulting times shown illustrate difference performance close actual percentage difference individual page fault costs systems cpu cost performing traversal impact performance performance slower increased faulting costs relative reason faults expensive large fraction faults due reading pages base assembly objects pages larger mapping tables pointers base assembly objects composite part objects uniformly distributed composite part objects database increases average cost reading mapping tables number table entries average average traverse assembly hierarchy starting randomly selected atomic part examined fault relative performance slows objects accessed unclustered fashion increases amount operations required read mapping objects mapping objects clustered disk order pages correspond table shows performs finally note qs-b slower relative turning figure shows roughly times slower interpreter invoked character manual examined simply dereference virtual memory pointer access manual contrast figure shows fast difference due faulting costs work objects faulted surprising faulting costs high case touches pages database pages accessed clustered qs-b similar performance character data size systems cold response time client requests queries shown figure table faster faster qs-b memory mapped scheme slower case small number atomic part objects accessed accessed randomly fault performed systems atomic part object accessed addition table shows performs additional operations read mapping objects number additional required read mapping objects high mentioned mapping objects clustered disk pages correspond accesses pages database unclustered pages mapping objects tend read performance table shows qs-b contributes worse performance reasons similar small fraction atomic part objects accessed accesses unclustered point roughly fault required object accessed faults require additional read mapping objects larger percentage objects accessed performance figure shows faster faults fewer pages case object accesses highly clustered faster qs-b illustrating effect performance differences faulting costs scan manual object counting occurrences character compare characters manual equal randomly retrieve atomic parts retrieve recent atomic parts retrieve recent atomic parts response time seconds qs-b figure query cold times small database qs-b table client requests queries small database slower partly due unclustered accesses document composite part objects require roughly fault object accessed systems factor large fraction objects accessed base assembly objects producing higher faulting costs due large amount mapping information basically performance figure performs fewer operations higher fault cost prevents performing faster finally note faster qs-b results presented figures show memory-mapped scheme offers performance objects accessed clustered fashion objects accessed unclustered fashion performance case smaller object size doesn provide noticeable savings performs slightly total operations read mapping objects results presented lookup document objects find base assemblies composite part pointer join base assemblies composite parts figures demonstrated page faulting cost memory mapped approach noticeably higher software approach differences cpu cost determined relative performance qs-b slower performance figures detailed faulting results examine differences faulting costs systems detail table shows average cost fault milliseconds systems times calculated subtracting time required execute hot traversal time required cold traversal dividing result number page faults average fault cost make results obtained accurate numbers perform calculation represented average runs traversal experiment table faulting cost qs-b slightly higher speculated due larger number pages referenced average outbound pointers qs-b pages qs-b database outbound pointer pointer refers object page page pointer increase size mapping tables qs-b turned case average number outbound pointers page small database qs-b comparison table interesting shows individual page faults roughly expensive figure qs-b averages correlates closely difference response time qs-b time system qs-b table average faulting cost time description min faults page fault misc cpu overhead data map swizzling mmap total table detailed faulting times understand additional faulting overhead memory mapped scheme table shows detailed breakdown average faulting time check present detailed numbers costs similar fault pages min fault entry table present due implementation interacts virtually mapped cpu cache client machine section effect increased average fault time entry labeled page fault table time required detect illegal page access invoke fault handler page faults comprised average faulting time note measure times min fault page fault entries directly running benchmark times obtained measuring test application performed operations thousand times tight loop remaining table entries break time spent fault handling routine entry misc cpu overhead includes time address caused fault in-memory table residency status checks determine action handling fault miscellaneous work data time needed read page objects disk update buffer manager data structures accounted largest fraction faulting time portion time spent reading mapping tables map swizzling entry time needed process mapping table entries swizzling costs low accounting faulting cost average pages read mapped locations memory occupied previously swizzling time doesn include overhead updating pointers pages inconsistent current mapping final entry labeled mmap average time mmap system call change access protections accounted modest faulting time finally note sums detailed times table correlate closely total fault times table update results traversals include updates figure shows total response time traversals run single transaction read requests identical table traversals performed additional read index pages updates root atomic part composite part faster figure surprising faster traversal updates difference performance diminishes page-at-a-time scheme handling updates expensive object-at-a-time approach sparse updates part increase response time due fact number page access violations increases doubling additional access violations occur attempt made update object page transaction fault-handling routine invoked handle access violation mentioned section routine performs functions copies objects contained page recovery buffer original values contained objects generate logging records updates diffing time calls esm obtain update exclusive lock response time seconds qs-b figure response times page finally virtual memory protections page instruction caused exception restarted measurements showed total seconds needed carry work amounted roughly pages updated spent copying objects page upgrade lock page average spent calling mmap change page protection write access response time increases relative transaction commit expensive figure commit time broken time required perform basic activities small amount additional time perform minor functions reinitializing data structures basic operations involves diffing objects pages updated calling esm generate log records determined updates occur diffing phase required total seconds seconds spent calling esm generate log records 
needed time needed average diff modified pages counting time generate log records milliseconds major task performed transaction commit update mapping object modified page measurements showed seconds page required phase commit processing final step committing transaction performed esm involves writing log records disk server flushing dirty pages back server client phase commit processing required commit time seconds qs-b figure commit times seconds turning faster expect relative updates dense copies diffs fewer objects unnecessarily fact absolute performance degrades slightly relative due increased time commit diffing objects generating log records precisely seconds required diffing seconds generating log records average diffing cost page counting logging note performance basically performance slower repeatedly updating object inexpensive objects accessed normal virtual memory pointers updating object approach requires function call update performance difference narrows relative performance cases similar overheads index maintenance make difference noticeable contrast stable performance systems response times systems steadily increase update indexed attribute results update logging update index schemes employed esm b-tree indices differ slightly performance basically systems supports automatic index maintenance index updates coded method invocations class variable type index qs-b slower systems traversals area hold recovery data wasn big hold objects modified pages traversals qs-b small hot results hot results obtained re-running benchmark operations data needed operation cached client main memory cold traversal figure shows hot times traversals figure shows hot times queries run small database times qs-b omitted identical shown expect performance generally surprising slower determine reasons small difference qpt ball profile benchmark application table presents profiling results hot traversal time broken table based percentage cpu time spent groups functions table shows spent time executing epvm interpreter functions time spent dereferencing unswizzled pointers spent considerable amount time allocating deallocating space transient heap entry malloc iterator object allocated heap node assembly object composite part atomic part object graph visited traversal iterator object establishes cursor collection response time seconds figure traversal hot times pointers sub-objects sub-objects traversed entry labeled part set table time spent executing functions maintain set atomic part ids visited composite part subgraph atomic parts set needed atomic part visited amount time spent functions implement traversal functions iterate collections pointers sub-objects implement recursive traversal higher percentage reflects additional cost dereferencing large pointers node object graph visited simple function called examines field object make object faulted memory time spent functions systems detailed numbers table surprising small amount additional work involving transient data structures needed implement accounts large percentage cost results show quickly small amount additional computation mask differences cost accessing persistent data systems times slower performs relative sparse traversal dense traversal overhead maintaining transient data structures sets part ids maintained root part visited performance systems close visits objects database precise simply pointers single atomic part root module differences traversal cost easily diminished costs overhead atomic part index figure shows factor slower scans manual object large object spanning pages disk case epvm function call performed character manual scanned accesses character manual virtual memory pointer spent time executing epvm functions systems identical performance work persistent data involves pointers time shown figure largely reflects similarity time description epvm malloc part set traverse misc total table hot traversal detail index lookup costs systems discuss query hot times shown figure performance queries times slower faster lot pointer dereferences part pointer join base assemblies composite parts times reflect cost index lookups systems slower index scan code slightly efficient due coding differences fundamental difference systems performs index lookups make performance similar response time seconds figure query hot times medium cold results section presents cold times benchmark operations run medium database results presented represent average runs benchmark experiments figure presents cold response times traversal operations table number client requests figure case small database performance faster performs fewer hand faster qs-b comparing relative performance qs-b small database figure gap performance qs-b widens medium database additional cost qs-b managing paging client buffer pool performance slower page fault required read composite part systems higher fault costs times shown similar small database case slower due higher fault costs slower due overhead calling epvm scan character manual results shown identical small case figure table show cold response times client requests queries run medium database performance queries benefits accesses atomic parts unclustered difference performance narrows accesses clustered case interesting slower performs significantly fewer operations slower overhead managing paging client buffer pool object accesses unclustered resulting high number page-faults object access slower performance response time seconds qs-b figure medium database traversal cold times qs-b table traversal cold response time seconds qs-b figure medium database query cold times qs-b table query cold turning traversals figure perform updates outperforms traversals update root atomic part composite part understandable considers basically amount work process updates small database case makes cost difference traversal main factor effecting relative performance relative performance worsens causing similar performance recovery expensive buffer recovery smaller fraction database updated qs-b worse performance figure caused fact addition higher traversal costs qs-b higher costs recovery response time seconds qs-b figure medium database traversal cold times effect collisions quickstore assign disk page virtual memory location occupied memory section considers effect performance relocating pages memory addresses faulted memory increases faulting costs pointers persistent objects updated reflect assignment disk pages virtual memory addresses approaches dealing page relocations approach updates swizzles pointers modified pages faulted memory written back database implies made data accessed subsequent transactions refer system qs-cr quickstore continual relocation approach commits changed mapping database approach costly initially avoid relocations future approach disadvantage turn read-only transaction update transaction refer approach qs-or quickstore one-time relocation figure presents results run small database percentage pages relocated memory varied pages relocated experiment picked random figure shows number relocations small performance systems significantly affected relocation percentage qs-or slower relocations occur difference performance qs-or qs-cr point performance qs-cr slows percentage relocated pages decrease performance qs- qs-or slower qs-cr pages relocated commit updates pages database page relocation response time seconds qs-cr qs-or figure vary relocations conclusions paper compared performance quickstore memory-mapping techniques implement persistence performance persistent version software interpreter benchmark basis comparing performance systems results study give clear accurate picture tradeoffs approaches summarize results cold traversal experiments showed object accesses clustered quickstore 
performance object sizes quickstore smaller due schemes systems represent pointers disk quickstore smaller object size perform significantly fewer disk operations read number objects accesses clustered object accesses unclustered performance quickstore comparable worse performance reason change relative clustered case difference systems number pages faulted memory object access unclustered experiments exposed fact quickstore higher faults costs addition cases quickstore lower performance due higher faulting costs lower performance quickstore influenced cost reading large amount mapping information support memory-mapping scheme higher faulting costs memory-mapping scheme highlighted performance qs-b quickstore big objects experiments scanned large objects qs-b performance lower read-only cold experiments memory-mapped schemes performance large objects accessed large object accesses require significantly cpu work software approach additional cost caused slower cold case traversals faulting costs examined detail shown average cost fault quickstore roughly higher largest component additional faulting cost memory mapping scheme time required read mapping information disk comprised average cost fault detailed cost analysis showed overhead handling page protection faults manipulating page access protections smallest component faulting cost quickstore cpu cost swizzling pointers average cost fault performance quickstore generally updates performed results update experiments showed page-based diffing scheme quickstore generate log records expensive updates sparse update activity heavy log records generated transaction commit quickstore performed relative higher percentage objects updated page quickstore copied diffed fewer objects unnecessarily case detailed times update experiments showed cost diffing ranged milliseconds page update operations hot results helped quantify performance advantage memory-mapped scheme working inmemory objects cases difference performance quickstore quickstore times faster showed quickly performance systems converged small amount additional work performed results showed significantly slower quickstore in-memory work large objects required accesses handled interpreter finally examined performance quickstore pages objects relocated memory increases amount swizzling work performed quickstore percentage pages relocated small performance systems noticeably worsen high percentage relocations noticeable effect performance mapping tables written back database approach appeared avoid writing changed mapping tables disk continually relocate pages memory negative impact performance approach small ball ball larus optimally profiling tracing programs popl january carey carey storage management objects exodus object-oriented concepts databases applications kim lochovsky eds addison-wesley carey carey dewitt naughton benchmark proceedings acm sigmod international conference management data washington dewitt dewitt futtersack maier velez study alternative workstation-server architectures object-oriented database systems proceedings international conferece large data bases brisbane australia august frank franklin zwilling tan carey dewitt crash recovery client-server exodus proceedings acm sigmod international conference management data california hoski hosking moss object fault handling persistent programming languages performance evaluation proceedings acm conference object-oriented programming systems languages oopsla hoski hosking brown moss update logging persistent programming languages comparative performance evaluation proceedings international conferece large data bases dublin ireland jagad jagadish lieuwen rastogi silberschatz dali high performance main memory storage manager proceedings international conferece large data bases santiago chile september khosh khoshafian copeland object identity proceedings acm conference object-oriented programming systems languages oopsla pages november lamb lamb landis orenstein weinreb objectstore database system communications acm vol october moss eliot moss working persistent objects swizzle swizzle ieee transactions software engineering august objec object design objectstore user guide release october rich richardson carey schuh design programming language acm transactions programming languages systems vol july schuh schuh carey dewitt persistence experiences proceedings fourth international workshop persistent object systems martha vineyard sept shek shekita zwilling cricket mapped persistent object store proceedings fourth international wor kshop persistent object systems martha vineyard sept wilso paul wilson pointer swizzling page fault time efficiently supporting huge address spaces standard hardware technical report uic-eecs- illinois chicago december 
